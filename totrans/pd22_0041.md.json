["```py\nSELECT  Column1,  Column2,  mean(Column3),  sum(Column4)\nFROM  SomeTable\nGROUP  BY  Column1,  Column2 \n```", "```py\nIn [1]: speeds = pd.DataFrame(\n ...:    [\n ...:        (\"bird\", \"Falconiformes\", 389.0),\n ...:        (\"bird\", \"Psittaciformes\", 24.0),\n ...:        (\"mammal\", \"Carnivora\", 80.2),\n ...:        (\"mammal\", \"Primates\", np.nan),\n ...:        (\"mammal\", \"Carnivora\", 58),\n ...:    ],\n ...:    index=[\"falcon\", \"parrot\", \"lion\", \"monkey\", \"leopard\"],\n ...:    columns=(\"class\", \"order\", \"max_speed\"),\n ...: )\n ...: \n\nIn [2]: speeds\nOut[2]: \n class           order  max_speed\nfalcon     bird   Falconiformes      389.0\nparrot     bird  Psittaciformes       24.0\nlion     mammal       Carnivora       80.2\nmonkey   mammal        Primates        NaN\nleopard  mammal       Carnivora       58.0\n\nIn [3]: grouped = speeds.groupby(\"class\")\n\nIn [4]: grouped = speeds.groupby([\"class\", \"order\"]) \n```", "```py\nIn [5]: df = pd.DataFrame(\n ...:    {\n ...:        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n ...:        \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n ...:        \"C\": np.random.randn(8),\n ...:        \"D\": np.random.randn(8),\n ...:    }\n ...: )\n ...: \n\nIn [6]: df\nOut[6]: \n A      B         C         D\n0  foo    one  0.469112 -0.861849\n1  bar    one -0.282863 -2.104569\n2  foo    two -1.509059 -0.494929\n3  bar  three -1.135632  1.071804\n4  foo    two  1.212112  0.721555\n5  bar    two -0.173215 -0.706771\n6  foo    one  0.119209 -1.039575\n7  foo  three -1.044236  0.271860 \n```", "```py\nIn [7]: grouped = df.groupby(\"A\")\n\nIn [8]: grouped = df.groupby(\"B\")\n\nIn [9]: grouped = df.groupby([\"A\", \"B\"]) \n```", "```py\nIn [10]: df2 = df.set_index([\"A\", \"B\"])\n\nIn [11]: grouped = df2.groupby(level=df2.index.names.difference([\"B\"]))\n\nIn [12]: grouped.sum()\nOut[12]: \n C         D\nA \nbar -1.591710 -1.739537\nfoo -0.752861 -1.402938 \n```", "```py\nIn [13]: def get_letter_type(letter):\n ....:    if letter.lower() in 'aeiou':\n ....:        return 'vowel'\n ....:    else:\n ....:        return 'consonant'\n ....: \n\nIn [14]: grouped = df.T.groupby(get_letter_type) \n```", "```py\nIn [15]: index = [1, 2, 3, 1, 2, 3]\n\nIn [16]: s = pd.Series([1, 2, 3, 10, 20, 30], index=index)\n\nIn [17]: s\nOut[17]: \n1     1\n2     2\n3     3\n1    10\n2    20\n3    30\ndtype: int64\n\nIn [18]: grouped = s.groupby(level=0)\n\nIn [19]: grouped.first()\nOut[19]: \n1    1\n2    2\n3    3\ndtype: int64\n\nIn [20]: grouped.last()\nOut[20]: \n1    10\n2    20\n3    30\ndtype: int64\n\nIn [21]: grouped.sum()\nOut[21]: \n1    11\n2    22\n3    33\ndtype: int64 \n```", "```py\nIn [22]: df2 = pd.DataFrame({\"X\": [\"B\", \"B\", \"A\", \"A\"], \"Y\": [1, 2, 3, 4]})\n\nIn [23]: df2.groupby([\"X\"]).sum()\nOut[23]: \n Y\nX \nA  7\nB  3\n\nIn [24]: df2.groupby([\"X\"], sort=False).sum()\nOut[24]: \n Y\nX \nB  3\nA  7 \n```", "```py\nIn [25]: df3 = pd.DataFrame({\"X\": [\"A\", \"B\", \"A\", \"B\"], \"Y\": [1, 4, 3, 2]})\n\nIn [26]: df3.groupby(\"X\").get_group(\"A\")\nOut[26]: \n X  Y\n0  A  1\n2  A  3\n\nIn [27]: df3.groupby([\"X\"]).get_group((\"B\",))\nOut[27]: \n X  Y\n1  B  4\n3  B  2 \n```", "```py\nIn [28]: df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n\nIn [29]: df_dropna = pd.DataFrame(df_list, columns=[\"a\", \"b\", \"c\"])\n\nIn [30]: df_dropna\nOut[30]: \n a    b  c\n0  1  2.0  3\n1  1  NaN  4\n2  2  1.0  3\n3  1  2.0  2 \n```", "```py\n# Default ``dropna`` is set to True, which will exclude NaNs in keys\nIn [31]: df_dropna.groupby(by=[\"b\"], dropna=True).sum()\nOut[31]: \n a  c\nb \n1.0  2  3\n2.0  2  5\n\n# In order to allow NaN in keys, set ``dropna`` to False\nIn [32]: df_dropna.groupby(by=[\"b\"], dropna=False).sum()\nOut[32]: \n a  c\nb \n1.0  2  3\n2.0  2  5\nNaN  1  4 \n```", "```py\nIn [33]: df.groupby(\"A\").groups\nOut[33]: {'bar': [1, 3, 5], 'foo': [0, 2, 4, 6, 7]}\n\nIn [34]: df.T.groupby(get_letter_type).groups\nOut[34]: {'consonant': ['B', 'C', 'D'], 'vowel': ['A']} \n```", "```py\nIn [35]: grouped = df.groupby([\"A\", \"B\"])\n\nIn [36]: grouped.groups\nOut[36]: {('bar', 'one'): [1], ('bar', 'three'): [3], ('bar', 'two'): [5], ('foo', 'one'): [0, 6], ('foo', 'three'): [7], ('foo', 'two'): [2, 4]}\n\nIn [37]: len(grouped)\nOut[37]: 6 \n```", "```py\nIn [38]: n = 10\n\nIn [39]: weight = np.random.normal(166, 20, size=n)\n\nIn [40]: height = np.random.normal(60, 10, size=n)\n\nIn [41]: time = pd.date_range(\"1/1/2000\", periods=n)\n\nIn [42]: gender = np.random.choice([\"male\", \"female\"], size=n)\n\nIn [43]: df = pd.DataFrame(\n ....:    {\"height\": height, \"weight\": weight, \"gender\": gender}, index=time\n ....: )\n ....: \n\nIn [44]: df\nOut[44]: \n height      weight  gender\n2000-01-01  42.849980  157.500553    male\n2000-01-02  49.607315  177.340407    male\n2000-01-03  56.293531  171.524640    male\n2000-01-04  48.421077  144.251986  female\n2000-01-05  46.556882  152.526206    male\n2000-01-06  68.448851  168.272968  female\n2000-01-07  70.757698  136.431469    male\n2000-01-08  58.909500  176.499753  female\n2000-01-09  76.435631  174.094104  female\n2000-01-10  45.306120  177.540920    male\n\nIn [45]: gb = df.groupby(\"gender\") \n```", "```py\nIn [46]: gb.<TAB>  # noqa: E225, E999\ngb.agg        gb.boxplot    gb.cummin     gb.describe   gb.filter     gb.get_group  gb.height     gb.last       gb.median     gb.ngroups    gb.plot       gb.rank       gb.std        gb.transform\ngb.aggregate  gb.count      gb.cumprod    gb.dtype      gb.first      gb.groups     gb.hist       gb.max        gb.min        gb.nth        gb.prod       gb.resample   gb.sum        gb.var\ngb.apply      gb.cummax     gb.cumsum     gb.fillna     gb.gender     gb.head       gb.indices    gb.mean       gb.name       gb.ohlc       gb.quantile   gb.size       gb.tail       gb.weight \n```", "```py\nIn [47]: arrays = [\n ....:    [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n ....:    [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n ....: ]\n ....: \n\nIn [48]: index = pd.MultiIndex.from_arrays(arrays, names=[\"first\", \"second\"])\n\nIn [49]: s = pd.Series(np.random.randn(8), index=index)\n\nIn [50]: s\nOut[50]: \nfirst  second\nbar    one      -0.919854\n two      -0.042379\nbaz    one       1.247642\n two      -0.009920\nfoo    one       0.290213\n two       0.495767\nqux    one       0.362949\n two       1.548106\ndtype: float64 \n```", "```py\nIn [51]: grouped = s.groupby(level=0)\n\nIn [52]: grouped.sum()\nOut[52]: \nfirst\nbar   -0.962232\nbaz    1.237723\nfoo    0.785980\nqux    1.911055\ndtype: float64 \n```", "```py\nIn [53]: s.groupby(level=\"second\").sum()\nOut[53]: \nsecond\none    0.980950\ntwo    1.991575\ndtype: float64 \n```", "```py\nIn [54]: arrays = [\n ....:    [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n ....:    [\"doo\", \"doo\", \"bee\", \"bee\", \"bop\", \"bop\", \"bop\", \"bop\"],\n ....:    [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n ....: ]\n ....: \n\nIn [55]: index = pd.MultiIndex.from_arrays(arrays, names=[\"first\", \"second\", \"third\"])\n\nIn [56]: s = pd.Series(np.random.randn(8), index=index)\n\nIn [57]: s\nOut[57]: \nfirst  second  third\nbar    doo     one     -1.131345\n two     -0.089329\nbaz    bee     one      0.337863\n two     -0.945867\nfoo    bop     one     -0.932132\n two      1.956030\nqux    bop     one      0.017587\n two     -0.016692\ndtype: float64\n\nIn [58]: s.groupby(level=[\"first\", \"second\"]).sum()\nOut[58]: \nfirst  second\nbar    doo      -1.220674\nbaz    bee      -0.608004\nfoo    bop       1.023898\nqux    bop       0.000895\ndtype: float64 \n```", "```py\nIn [59]: s.groupby([\"first\", \"second\"]).sum()\nOut[59]: \nfirst  second\nbar    doo      -1.220674\nbaz    bee      -0.608004\nfoo    bop       1.023898\nqux    bop       0.000895\ndtype: float64 \n```", "```py\nIn [60]: arrays = [\n ....:    [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n ....:    [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n ....: ]\n ....: \n\nIn [61]: index = pd.MultiIndex.from_arrays(arrays, names=[\"first\", \"second\"])\n\nIn [62]: df = pd.DataFrame({\"A\": [1, 1, 1, 1, 2, 2, 3, 3], \"B\": np.arange(8)}, index=index)\n\nIn [63]: df\nOut[63]: \n A  B\nfirst second \nbar   one     1  0\n two     1  1\nbaz   one     1  2\n two     1  3\nfoo   one     2  4\n two     2  5\nqux   one     3  6\n two     3  7 \n```", "```py\nIn [64]: df.groupby([pd.Grouper(level=1), \"A\"]).sum()\nOut[64]: \n B\nsecond A \none    1  2\n 2  4\n 3  6\ntwo    1  4\n 2  5\n 3  7 \n```", "```py\nIn [65]: df.groupby([pd.Grouper(level=\"second\"), \"A\"]).sum()\nOut[65]: \n B\nsecond A \none    1  2\n 2  4\n 3  6\ntwo    1  4\n 2  5\n 3  7 \n```", "```py\nIn [66]: df.groupby([\"second\", \"A\"]).sum()\nOut[66]: \n B\nsecond A \none    1  2\n 2  4\n 3  6\ntwo    1  4\n 2  5\n 3  7 \n```", "```py\nIn [67]: df = pd.DataFrame(\n ....:    {\n ....:        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n ....:        \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n ....:        \"C\": np.random.randn(8),\n ....:        \"D\": np.random.randn(8),\n ....:    }\n ....: )\n ....: \n\nIn [68]: df\nOut[68]: \n A      B         C         D\n0  foo    one -0.575247  1.346061\n1  bar    one  0.254161  1.511763\n2  foo    two -1.143704  1.627081\n3  bar  three  0.215897 -0.990582\n4  foo    two  1.193555 -0.441652\n5  bar    two -0.077118  1.211526\n6  foo    one -0.408530  0.268520\n7  foo  three -0.862495  0.024580\n\nIn [69]: grouped = df.groupby([\"A\"])\n\nIn [70]: grouped_C = grouped[\"C\"]\n\nIn [71]: grouped_D = grouped[\"D\"] \n```", "```py\nIn [72]: df[\"C\"].groupby(df[\"A\"])\nOut[72]: <pandas.core.groupby.generic.SeriesGroupBy object at 0x7ff2cef1c730> \n```", "```py\nIn [73]: grouped[[\"A\", \"B\"]].sum()\nOut[73]: \n A                  B\nA \nbar        barbarbar        onethreetwo\nfoo  foofoofoofoofoo  onetwotwoonethree \n```", "```py\nIn [74]: grouped = df.groupby('A')\n\nIn [75]: for name, group in grouped:\n ....:    print(name)\n ....:    print(group)\n ....: \nbar\n A      B         C         D\n1  bar    one  0.254161  1.511763\n3  bar  three  0.215897 -0.990582\n5  bar    two -0.077118  1.211526\nfoo\n A      B         C         D\n0  foo    one -0.575247  1.346061\n2  foo    two -1.143704  1.627081\n4  foo    two  1.193555 -0.441652\n6  foo    one -0.408530  0.268520\n7  foo  three -0.862495  0.024580 \n```", "```py\nIn [76]: for name, group in df.groupby(['A', 'B']):\n ....:    print(name)\n ....:    print(group)\n ....: \n('bar', 'one')\n A    B         C         D\n1  bar  one  0.254161  1.511763\n('bar', 'three')\n A      B         C         D\n3  bar  three  0.215897 -0.990582\n('bar', 'two')\n A    B         C         D\n5  bar  two -0.077118  1.211526\n('foo', 'one')\n A    B         C         D\n0  foo  one -0.575247  1.346061\n6  foo  one -0.408530  0.268520\n('foo', 'three')\n A      B         C        D\n7  foo  three -0.862495  0.02458\n('foo', 'two')\n A    B         C         D\n2  foo  two -1.143704  1.627081\n4  foo  two  1.193555 -0.441652 \n```", "```py\nIn [77]: grouped.get_group(\"bar\")\nOut[77]: \n A      B         C         D\n1  bar    one  0.254161  1.511763\n3  bar  three  0.215897 -0.990582\n5  bar    two -0.077118  1.211526 \n```", "```py\nIn [78]: df.groupby([\"A\", \"B\"]).get_group((\"bar\", \"one\"))\nOut[78]: \n A    B         C         D\n1  bar  one  0.254161  1.511763 \n```", "```py\nIn [79]: animals = pd.DataFrame(\n ....:    {\n ....:        \"kind\": [\"cat\", \"dog\", \"cat\", \"dog\"],\n ....:        \"height\": [9.1, 6.0, 9.5, 34.0],\n ....:        \"weight\": [7.9, 7.5, 9.9, 198.0],\n ....:    }\n ....: )\n ....: \n\nIn [80]: animals\nOut[80]: \n kind  height  weight\n0  cat     9.1     7.9\n1  dog     6.0     7.5\n2  cat     9.5     9.9\n3  dog    34.0   198.0\n\nIn [81]: animals.groupby(\"kind\").sum()\nOut[81]: \n height  weight\nkind \ncat     18.6    17.8\ndog     40.0   205.5 \n```", "```py\nIn [82]: animals.groupby(\"kind\", as_index=False).sum()\nOut[82]: \n kind  height  weight\n0  cat    18.6    17.8\n1  dog    40.0   205.5 \n```", "```py\nIn [83]: df.groupby(\"A\")[[\"C\", \"D\"]].max()\nOut[83]: \n C         D\nA \nbar  0.254161  1.511763\nfoo  1.193555  1.627081\n\nIn [84]: df.groupby([\"A\", \"B\"]).mean()\nOut[84]: \n C         D\nA   B \nbar one    0.254161  1.511763\n three  0.215897 -0.990582\n two   -0.077118  1.211526\nfoo one   -0.491888  0.807291\n three -0.862495  0.024580\n two    0.024925  0.592714 \n```", "```py\nIn [85]: grouped = df.groupby([\"A\", \"B\"])\n\nIn [86]: grouped.size()\nOut[86]: \nA    B \nbar  one      1\n three    1\n two      1\nfoo  one      2\n three    1\n two      2\ndtype: int64 \n```", "```py\nIn [87]: grouped.describe()\nOut[87]: \n C                      ...         D \n count      mean       std  ...       50%       75%       max\nA   B                                ... \nbar one     1.0  0.254161       NaN  ...  1.511763  1.511763  1.511763\n three   1.0  0.215897       NaN  ... -0.990582 -0.990582 -0.990582\n two     1.0 -0.077118       NaN  ...  1.211526  1.211526  1.211526\nfoo one     2.0 -0.491888  0.117887  ...  0.807291  1.076676  1.346061\n three   1.0 -0.862495       NaN  ...  0.024580  0.024580  0.024580\n two     2.0  0.024925  1.652692  ...  0.592714  1.109898  1.627081\n\n[6 rows x 16 columns] \n```", "```py\nIn [88]: ll = [['foo', 1], ['foo', 2], ['foo', 2], ['bar', 1], ['bar', 1]]\n\nIn [89]: df4 = pd.DataFrame(ll, columns=[\"A\", \"B\"])\n\nIn [90]: df4\nOut[90]: \n A  B\n0  foo  1\n1  foo  2\n2  foo  2\n3  bar  1\n4  bar  1\n\nIn [91]: df4.groupby(\"A\")[\"B\"].nunique()\nOut[91]: \nA\nbar    1\nfoo    2\nName: B, dtype: int64 \n```", "```py\nIn [92]: grouped = df.groupby(\"A\")\n\nIn [93]: grouped[[\"C\", \"D\"]].aggregate(\"sum\")\nOut[93]: \n C         D\nA \nbar  0.392940  1.732707\nfoo -1.796421  2.824590\n\nIn [94]: grouped = df.groupby([\"A\", \"B\"])\n\nIn [95]: grouped.agg(\"sum\")\nOut[95]: \n C         D\nA   B \nbar one    0.254161  1.511763\n three  0.215897 -0.990582\n two   -0.077118  1.211526\nfoo one   -0.983776  1.614581\n three -0.862495  0.024580\n two    0.049851  1.185429 \n```", "```py\nIn [96]: grouped = df.groupby([\"A\", \"B\"], as_index=False)\n\nIn [97]: grouped.agg(\"sum\")\nOut[97]: \n A      B         C         D\n0  bar    one  0.254161  1.511763\n1  bar  three  0.215897 -0.990582\n2  bar    two -0.077118  1.211526\n3  foo    one -0.983776  1.614581\n4  foo  three -0.862495  0.024580\n5  foo    two  0.049851  1.185429\n\nIn [98]: df.groupby(\"A\", as_index=False)[[\"C\", \"D\"]].agg(\"sum\")\nOut[98]: \n A         C         D\n0  bar  0.392940  1.732707\n1  foo -1.796421  2.824590 \n```", "```py\nIn [99]: df.groupby([\"A\", \"B\"]).agg(\"sum\").reset_index()\nOut[99]: \n A      B         C         D\n0  bar    one  0.254161  1.511763\n1  bar  three  0.215897 -0.990582\n2  bar    two -0.077118  1.211526\n3  foo    one -0.983776  1.614581\n4  foo  three -0.862495  0.024580\n5  foo    two  0.049851  1.185429 \n```", "```py\nIn [100]: animals\nOut[100]: \n kind  height  weight\n0  cat     9.1     7.9\n1  dog     6.0     7.5\n2  cat     9.5     9.9\n3  dog    34.0   198.0\n\nIn [101]: animals.groupby(\"kind\")[[\"height\"]].agg(lambda x: set(x))\nOut[101]: \n height\nkind \ncat    {9.1, 9.5}\ndog   {34.0, 6.0} \n```", "```py\nIn [102]: animals.groupby(\"kind\")[[\"height\"]].agg(lambda x: x.astype(int).sum())\nOut[102]: \n height\nkind \ncat       18\ndog       40 \n```", "```py\nIn [103]: grouped = df.groupby(\"A\")\n\nIn [104]: grouped[\"C\"].agg([\"sum\", \"mean\", \"std\"])\nOut[104]: \n sum      mean       std\nA \nbar  0.392940  0.130980  0.181231\nfoo -1.796421 -0.359284  0.912265 \n```", "```py\nIn [105]: grouped[[\"C\", \"D\"]].agg([\"sum\", \"mean\", \"std\"])\nOut[105]: \n C                             D \n sum      mean       std       sum      mean       std\nA \nbar  0.392940  0.130980  0.181231  1.732707  0.577569  1.366330\nfoo -1.796421 -0.359284  0.912265  2.824590  0.564918  0.884785 \n```", "```py\nIn [106]: (\n .....:    grouped[\"C\"]\n .....:    .agg([\"sum\", \"mean\", \"std\"])\n .....:    .rename(columns={\"sum\": \"foo\", \"mean\": \"bar\", \"std\": \"baz\"})\n .....: )\n .....: \nOut[106]: \n foo       bar       baz\nA \nbar  0.392940  0.130980  0.181231\nfoo -1.796421 -0.359284  0.912265 \n```", "```py\nIn [107]: (\n .....:    grouped[[\"C\", \"D\"]].agg([\"sum\", \"mean\", \"std\"]).rename(\n .....:        columns={\"sum\": \"foo\", \"mean\": \"bar\", \"std\": \"baz\"}\n .....:    )\n .....: )\n .....: \nOut[107]: \n C                             D \n foo       bar       baz       foo       bar       baz\nA \nbar  0.392940  0.130980  0.181231  1.732707  0.577569  1.366330\nfoo -1.796421 -0.359284  0.912265  2.824590  0.564918  0.884785 \n```", "```py\nIn [108]: grouped[\"C\"].agg([\"sum\", \"sum\"])\nOut[108]: \n sum       sum\nA \nbar  0.392940  0.392940\nfoo -1.796421 -1.796421 \n```", "```py\nIn [109]: grouped[\"C\"].agg([lambda x: x.max() - x.min(), lambda x: x.median() - x.mean()])\nOut[109]: \n <lambda_0>  <lambda_1>\nA \nbar    0.331279    0.084917\nfoo    2.337259   -0.215962 \n```", "```py\nIn [110]: animals\nOut[110]: \n kind  height  weight\n0  cat     9.1     7.9\n1  dog     6.0     7.5\n2  cat     9.5     9.9\n3  dog    34.0   198.0\n\nIn [111]: animals.groupby(\"kind\").agg(\n .....:    min_height=pd.NamedAgg(column=\"height\", aggfunc=\"min\"),\n .....:    max_height=pd.NamedAgg(column=\"height\", aggfunc=\"max\"),\n .....:    average_weight=pd.NamedAgg(column=\"weight\", aggfunc=\"mean\"),\n .....: )\n .....: \nOut[111]: \n min_height  max_height  average_weight\nkind \ncat          9.1         9.5            8.90\ndog          6.0        34.0          102.75 \n```", "```py\nIn [112]: animals.groupby(\"kind\").agg(\n .....:    min_height=(\"height\", \"min\"),\n .....:    max_height=(\"height\", \"max\"),\n .....:    average_weight=(\"weight\", \"mean\"),\n .....: )\n .....: \nOut[112]: \n min_height  max_height  average_weight\nkind \ncat          9.1         9.5            8.90\ndog          6.0        34.0          102.75 \n```", "```py\nIn [113]: animals.groupby(\"kind\").agg(\n .....:    **{\n .....:        \"total weight\": pd.NamedAgg(column=\"weight\", aggfunc=\"sum\")\n .....:    }\n .....: )\n .....: \nOut[113]: \n total weight\nkind \ncat           17.8\ndog          205.5 \n```", "```py\nIn [114]: animals.groupby(\"kind\").height.agg(\n .....:    min_height=\"min\",\n .....:    max_height=\"max\",\n .....: )\n .....: \nOut[114]: \n min_height  max_height\nkind \ncat          9.1         9.5\ndog          6.0        34.0 \n```", "```py\nIn [115]: grouped.agg({\"C\": \"sum\", \"D\": lambda x: np.std(x, ddof=1)})\nOut[115]: \n C         D\nA \nbar  0.392940  1.366330\nfoo -1.796421  0.884785 \n```", "```py\nIn [116]: grouped.agg({\"C\": \"sum\", \"D\": \"std\"})\nOut[116]: \n C         D\nA \nbar  0.392940  1.366330\nfoo -1.796421  0.884785 \n```", "```py\nIn [117]: speeds\nOut[117]: \n class           order  max_speed\nfalcon     bird   Falconiformes      389.0\nparrot     bird  Psittaciformes       24.0\nlion     mammal       Carnivora       80.2\nmonkey   mammal        Primates        NaN\nleopard  mammal       Carnivora       58.0\n\nIn [118]: grouped = speeds.groupby(\"class\")[\"max_speed\"]\n\nIn [119]: grouped.cumsum()\nOut[119]: \nfalcon     389.0\nparrot     413.0\nlion        80.2\nmonkey       NaN\nleopard    138.2\nName: max_speed, dtype: float64\n\nIn [120]: grouped.diff()\nOut[120]: \nfalcon       NaN\nparrot    -365.0\nlion         NaN\nmonkey       NaN\nleopard      NaN\nName: max_speed, dtype: float64 \n```", "```py\nIn [121]: result = speeds.copy()\n\nIn [122]: result[\"cumsum\"] = grouped.cumsum()\n\nIn [123]: result[\"diff\"] = grouped.diff()\n\nIn [124]: result\nOut[124]: \n class           order  max_speed  cumsum   diff\nfalcon     bird   Falconiformes      389.0   389.0    NaN\nparrot     bird  Psittaciformes       24.0   413.0 -365.0\nlion     mammal       Carnivora       80.2    80.2    NaN\nmonkey   mammal        Primates        NaN     NaN    NaN\nleopard  mammal       Carnivora       58.0   138.2    NaN \n```", "```py\nIn [125]: speeds\nOut[125]: \n class           order  max_speed\nfalcon     bird   Falconiformes      389.0\nparrot     bird  Psittaciformes       24.0\nlion     mammal       Carnivora       80.2\nmonkey   mammal        Primates        NaN\nleopard  mammal       Carnivora       58.0\n\nIn [126]: grouped = speeds.groupby(\"class\")[[\"max_speed\"]]\n\nIn [127]: grouped.transform(\"cumsum\")\nOut[127]: \n max_speed\nfalcon       389.0\nparrot       413.0\nlion          80.2\nmonkey         NaN\nleopard      138.2\n\nIn [128]: grouped.transform(\"sum\")\nOut[128]: \n max_speed\nfalcon       413.0\nparrot       413.0\nlion         138.2\nmonkey       138.2\nleopard      138.2 \n```", "```py\nIn [129]: index = pd.date_range(\"10/1/1999\", periods=1100)\n\nIn [130]: ts = pd.Series(np.random.normal(0.5, 2, 1100), index)\n\nIn [131]: ts = ts.rolling(window=100, min_periods=100).mean().dropna()\n\nIn [132]: ts.head()\nOut[132]: \n2000-01-08    0.779333\n2000-01-09    0.778852\n2000-01-10    0.786476\n2000-01-11    0.782797\n2000-01-12    0.798110\nFreq: D, dtype: float64\n\nIn [133]: ts.tail()\nOut[133]: \n2002-09-30    0.660294\n2002-10-01    0.631095\n2002-10-02    0.673601\n2002-10-03    0.709213\n2002-10-04    0.719369\nFreq: D, dtype: float64\n\nIn [134]: transformed = ts.groupby(lambda x: x.year).transform(\n .....:    lambda x: (x - x.mean()) / x.std()\n .....: )\n .....: \n```", "```py\n# Original Data\nIn [135]: grouped = ts.groupby(lambda x: x.year)\n\nIn [136]: grouped.mean()\nOut[136]: \n2000    0.442441\n2001    0.526246\n2002    0.459365\ndtype: float64\n\nIn [137]: grouped.std()\nOut[137]: \n2000    0.131752\n2001    0.210945\n2002    0.128753\ndtype: float64\n\n# Transformed Data\nIn [138]: grouped_trans = transformed.groupby(lambda x: x.year)\n\nIn [139]: grouped_trans.mean()\nOut[139]: \n2000   -4.870756e-16\n2001   -1.545187e-16\n2002    4.136282e-16\ndtype: float64\n\nIn [140]: grouped_trans.std()\nOut[140]: \n2000    1.0\n2001    1.0\n2002    1.0\ndtype: float64 \n```", "```py\nIn [141]: compare = pd.DataFrame({\"Original\": ts, \"Transformed\": transformed})\n\nIn [142]: compare.plot()\nOut[142]: <Axes: > \n```", "```py\nIn [143]: ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())\nOut[143]: \n2000-01-08    0.623893\n2000-01-09    0.623893\n2000-01-10    0.623893\n2000-01-11    0.623893\n2000-01-12    0.623893\n ... \n2002-09-30    0.558275\n2002-10-01    0.558275\n2002-10-02    0.558275\n2002-10-03    0.558275\n2002-10-04    0.558275\nFreq: D, Length: 1001, dtype: float64 \n```", "```py\nIn [144]: cols = [\"A\", \"B\", \"C\"]\n\nIn [145]: values = np.random.randn(1000, 3)\n\nIn [146]: values[np.random.randint(0, 1000, 100), 0] = np.nan\n\nIn [147]: values[np.random.randint(0, 1000, 50), 1] = np.nan\n\nIn [148]: values[np.random.randint(0, 1000, 200), 2] = np.nan\n\nIn [149]: data_df = pd.DataFrame(values, columns=cols)\n\nIn [150]: data_df\nOut[150]: \n A         B         C\n0    1.539708 -1.166480  0.533026\n1    1.302092 -0.505754       NaN\n2   -0.371983  1.104803 -0.651520\n3   -1.309622  1.118697 -1.161657\n4   -1.924296  0.396437  0.812436\n..        ...       ...       ...\n995 -0.093110  0.683847 -0.774753\n996 -0.185043  1.438572       NaN\n997 -0.394469 -0.642343  0.011374\n998 -1.174126  1.857148       NaN\n999  0.234564  0.517098  0.393534\n\n[1000 rows x 3 columns]\n\nIn [151]: countries = np.array([\"US\", \"UK\", \"GR\", \"JP\"])\n\nIn [152]: key = countries[np.random.randint(0, 4, 1000)]\n\nIn [153]: grouped = data_df.groupby(key)\n\n# Non-NA count in each group\nIn [154]: grouped.count()\nOut[154]: \n A    B    C\nGR  209  217  189\nJP  240  255  217\nUK  216  231  193\nUS  239  250  217\n\nIn [155]: transformed = grouped.transform(lambda x: x.fillna(x.mean())) \n```", "```py\nIn [156]: grouped_trans = transformed.groupby(key)\n\nIn [157]: grouped.mean()  # original group means\nOut[157]: \n A         B         C\nGR -0.098371 -0.015420  0.068053\nJP  0.069025  0.023100 -0.077324\nUK  0.034069 -0.052580 -0.116525\nUS  0.058664 -0.020399  0.028603\n\nIn [158]: grouped_trans.mean()  # transformation did not change group means\nOut[158]: \n A         B         C\nGR -0.098371 -0.015420  0.068053\nJP  0.069025  0.023100 -0.077324\nUK  0.034069 -0.052580 -0.116525\nUS  0.058664 -0.020399  0.028603\n\nIn [159]: grouped.count()  # original has some missing data points\nOut[159]: \n A    B    C\nGR  209  217  189\nJP  240  255  217\nUK  216  231  193\nUS  239  250  217\n\nIn [160]: grouped_trans.count()  # counts after transformation\nOut[160]: \n A    B    C\nGR  228  228  228\nJP  267  267  267\nUK  247  247  247\nUS  258  258  258\n\nIn [161]: grouped_trans.size()  # Verify non-NA count equals group size\nOut[161]: \nGR    228\nJP    267\nUK    247\nUS    258\ndtype: int64 \n```", "```py\n# result = ts.groupby(lambda x: x.year).transform(\n#     lambda x: (x - x.mean()) / x.std()\n# )\nIn [162]: grouped = ts.groupby(lambda x: x.year)\n\nIn [163]: result = (ts - grouped.transform(\"mean\")) / grouped.transform(\"std\")\n\n# result = ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())\nIn [164]: grouped = ts.groupby(lambda x: x.year)\n\nIn [165]: result = grouped.transform(\"max\") - grouped.transform(\"min\")\n\n# grouped = data_df.groupby(key)\n# result = grouped.transform(lambda x: x.fillna(x.mean()))\nIn [166]: grouped = data_df.groupby(key)\n\nIn [167]: result = data_df.fillna(grouped.transform(\"mean\")) \n```", "```py\nIn [168]: df_re = pd.DataFrame({\"A\": [1] * 10 + [5] * 10, \"B\": np.arange(20)})\n\nIn [169]: df_re\nOut[169]: \n A   B\n0   1   0\n1   1   1\n2   1   2\n3   1   3\n4   1   4\n.. ..  ..\n15  5  15\n16  5  16\n17  5  17\n18  5  18\n19  5  19\n\n[20 rows x 2 columns]\n\nIn [170]: df_re.groupby(\"A\").rolling(4).B.mean()\nOut[170]: \nA \n1  0      NaN\n 1      NaN\n 2      NaN\n 3      1.5\n 4      2.5\n ... \n5  15    13.5\n 16    14.5\n 17    15.5\n 18    16.5\n 19    17.5\nName: B, Length: 20, dtype: float64 \n```", "```py\nIn [171]: df_re.groupby(\"A\").expanding().sum()\nOut[171]: \n B\nA \n1 0     0.0\n 1     1.0\n 2     3.0\n 3     6.0\n 4    10.0\n...     ...\n5 15   75.0\n 16   91.0\n 17  108.0\n 18  126.0\n 19  145.0\n\n[20 rows x 1 columns] \n```", "```py\nIn [172]: df_re = pd.DataFrame(\n .....:    {\n .....:        \"date\": pd.date_range(start=\"2016-01-01\", periods=4, freq=\"W\"),\n .....:        \"group\": [1, 1, 2, 2],\n .....:        \"val\": [5, 6, 7, 8],\n .....:    }\n .....: ).set_index(\"date\")\n .....: \n\nIn [173]: df_re\nOut[173]: \n group  val\ndate \n2016-01-03      1    5\n2016-01-10      1    6\n2016-01-17      2    7\n2016-01-24      2    8\n\nIn [174]: df_re.groupby(\"group\").resample(\"1D\", include_groups=False).ffill()\nOut[174]: \n val\ngroup date \n1     2016-01-03    5\n 2016-01-04    5\n 2016-01-05    5\n 2016-01-06    5\n 2016-01-07    5\n...               ...\n2     2016-01-20    7\n 2016-01-21    7\n 2016-01-22    7\n 2016-01-23    7\n 2016-01-24    8\n\n[16 rows x 1 columns] \n```", "```py\nIn [175]: speeds\nOut[175]: \n class           order  max_speed\nfalcon     bird   Falconiformes      389.0\nparrot     bird  Psittaciformes       24.0\nlion     mammal       Carnivora       80.2\nmonkey   mammal        Primates        NaN\nleopard  mammal       Carnivora       58.0\n\nIn [176]: speeds.groupby(\"class\").nth(1)\nOut[176]: \n class           order  max_speed\nparrot    bird  Psittaciformes       24.0\nmonkey  mammal        Primates        NaN \n```", "```py\nIn [177]: speeds.groupby(\"class\")[[\"order\", \"max_speed\"]].nth(1)\nOut[177]: \n order  max_speed\nparrot  Psittaciformes       24.0\nmonkey        Primates        NaN \n```", "```py\nIn [178]: product_volumes = pd.DataFrame(\n .....:    {\n .....:        \"group\": list(\"xxxxyyy\"),\n .....:        \"product\": list(\"abcdefg\"),\n .....:        \"volume\": [10, 30, 20, 15, 40, 10, 20],\n .....:    }\n .....: )\n .....: \n\nIn [179]: product_volumes\nOut[179]: \n group product  volume\n0     x       a      10\n1     x       b      30\n2     x       c      20\n3     x       d      15\n4     y       e      40\n5     y       f      10\n6     y       g      20\n\n# Sort by volume to select the largest products first\nIn [180]: product_volumes = product_volumes.sort_values(\"volume\", ascending=False)\n\nIn [181]: grouped = product_volumes.groupby(\"group\")[\"volume\"]\n\nIn [182]: cumpct = grouped.cumsum() / grouped.transform(\"sum\")\n\nIn [183]: cumpct\nOut[183]: \n4    0.571429\n1    0.400000\n2    0.666667\n6    0.857143\n3    0.866667\n0    1.000000\n5    1.000000\nName: volume, dtype: float64\n\nIn [184]: significant_products = product_volumes[cumpct <= 0.9]\n\nIn [185]: significant_products.sort_values([\"group\", \"product\"])\nOut[185]: \n group product  volume\n1     x       b      30\n2     x       c      20\n3     x       d      15\n4     y       e      40\n6     y       g      20 \n```", "```py\nIn [186]: sf = pd.Series([1, 1, 2, 3, 3, 3])\n\nIn [187]: sf.groupby(sf).filter(lambda x: x.sum() > 2)\nOut[187]: \n3    3\n4    3\n5    3\ndtype: int64 \n```", "```py\nIn [188]: dff = pd.DataFrame({\"A\": np.arange(8), \"B\": list(\"aabbbbcc\")})\n\nIn [189]: dff.groupby(\"B\").filter(lambda x: len(x) > 2)\nOut[189]: \n A  B\n2  2  b\n3  3  b\n4  4  b\n5  5  b \n```", "```py\nIn [190]: dff.groupby(\"B\").filter(lambda x: len(x) > 2, dropna=False)\nOut[190]: \n A    B\n0  NaN  NaN\n1  NaN  NaN\n2  2.0    b\n3  3.0    b\n4  4.0    b\n5  5.0    b\n6  NaN  NaN\n7  NaN  NaN \n```", "```py\nIn [191]: dff[\"C\"] = np.arange(8)\n\nIn [192]: dff.groupby(\"B\").filter(lambda x: len(x[\"C\"]) > 2)\nOut[192]: \n A  B  C\n2  2  b  2\n3  3  b  3\n4  4  b  4\n5  5  b  5 \n```", "```py\nIn [193]: df\nOut[193]: \n A      B         C         D\n0  foo    one -0.575247  1.346061\n1  bar    one  0.254161  1.511763\n2  foo    two -1.143704  1.627081\n3  bar  three  0.215897 -0.990582\n4  foo    two  1.193555 -0.441652\n5  bar    two -0.077118  1.211526\n6  foo    one -0.408530  0.268520\n7  foo  three -0.862495  0.024580\n\nIn [194]: grouped = df.groupby(\"A\")\n\n# could also just call .describe()\nIn [195]: grouped[\"C\"].apply(lambda x: x.describe())\nOut[195]: \nA \nbar  count    3.000000\n mean     0.130980\n std      0.181231\n min     -0.077118\n 25%      0.069390\n ... \nfoo  min     -1.143704\n 25%     -0.862495\n 50%     -0.575247\n 75%     -0.408530\n max      1.193555\nName: C, Length: 16, dtype: float64 \n```", "```py\nIn [196]: grouped = df.groupby('A')['C']\n\nIn [197]: def f(group):\n .....:    return pd.DataFrame({'original': group,\n .....:                         'demeaned': group - group.mean()})\n .....: \n\nIn [198]: grouped.apply(f)\nOut[198]: \n original  demeaned\nA \nbar 1  0.254161  0.123181\n 3  0.215897  0.084917\n 5 -0.077118 -0.208098\nfoo 0 -0.575247 -0.215962\n 2 -1.143704 -0.784420\n 4  1.193555  1.552839\n 6 -0.408530 -0.049245\n 7 -0.862495 -0.503211 \n```", "```py\nIn [199]: def f(x):\n .....:    return pd.Series([x, x ** 2], index=[\"x\", \"x^2\"])\n .....: \n\nIn [200]: s = pd.Series(np.random.rand(5))\n\nIn [201]: s\nOut[201]: \n0    0.582898\n1    0.098352\n2    0.001438\n3    0.009420\n4    0.815826\ndtype: float64\n\nIn [202]: s.apply(f)\nOut[202]: \n x       x^2\n0  0.582898  0.339770\n1  0.098352  0.009673\n2  0.001438  0.000002\n3  0.009420  0.000089\n4  0.815826  0.665572 \n```", "```py\nIn [203]: df.groupby(\"A\", group_keys=True).apply(lambda x: x, include_groups=False)\nOut[203]: \n B         C         D\nA \nbar 1    one  0.254161  1.511763\n 3  three  0.215897 -0.990582\n 5    two -0.077118  1.211526\nfoo 0    one -0.575247  1.346061\n 2    two -1.143704  1.627081\n 4    two  1.193555 -0.441652\n 6    one -0.408530  0.268520\n 7  three -0.862495  0.024580 \n```", "```py\nIn [204]: df.groupby(\"A\", group_keys=False).apply(lambda x: x, include_groups=False)\nOut[204]: \n B         C         D\n0    one -0.575247  1.346061\n1    one  0.254161  1.511763\n2    two -1.143704  1.627081\n3  three  0.215897 -0.990582\n4    two  1.193555 -0.441652\n5    two -0.077118  1.211526\n6    one -0.408530  0.268520\n7  three -0.862495  0.024580 \n```", "```py\nIn [205]: df\nOut[205]: \n A      B         C         D\n0  foo    one -0.575247  1.346061\n1  bar    one  0.254161  1.511763\n2  foo    two -1.143704  1.627081\n3  bar  three  0.215897 -0.990582\n4  foo    two  1.193555 -0.441652\n5  bar    two -0.077118  1.211526\n6  foo    one -0.408530  0.268520\n7  foo  three -0.862495  0.024580 \n```", "```py\nIn [206]: df.groupby(\"A\").std(numeric_only=True)\nOut[206]: \n C         D\nA \nbar  0.181231  1.366330\nfoo  0.912265  0.884785 \n```", "```py\nIn [207]: from decimal import Decimal\n\nIn [208]: df_dec = pd.DataFrame(\n .....:    {\n .....:        \"id\": [1, 2, 1, 2],\n .....:        \"int_column\": [1, 2, 3, 4],\n .....:        \"dec_column\": [\n .....:            Decimal(\"0.50\"),\n .....:            Decimal(\"0.15\"),\n .....:            Decimal(\"0.25\"),\n .....:            Decimal(\"0.40\"),\n .....:        ],\n .....:    }\n .....: )\n .....: \n\nIn [209]: df_dec.groupby([\"id\"])[[\"dec_column\"]].sum()\nOut[209]: \n dec_column\nid \n1        0.75\n2        0.55 \n```", "```py\nIn [210]: pd.Series([1, 1, 1]).groupby(\n .....:    pd.Categorical([\"a\", \"a\", \"a\"], categories=[\"a\", \"b\"]), observed=False\n .....: ).count()\n .....: \nOut[210]: \na    3\nb    0\ndtype: int64 \n```", "```py\nIn [211]: pd.Series([1, 1, 1]).groupby(\n .....:    pd.Categorical([\"a\", \"a\", \"a\"], categories=[\"a\", \"b\"]), observed=True\n .....: ).count()\n .....: \nOut[211]: \na    3\ndtype: int64 \n```", "```py\nIn [212]: s = (\n .....:    pd.Series([1, 1, 1])\n .....:    .groupby(pd.Categorical([\"a\", \"a\", \"a\"], categories=[\"a\", \"b\"]), observed=True)\n .....:    .count()\n .....: )\n .....: \n\nIn [213]: s.index.dtype\nOut[213]: CategoricalDtype(categories=['a', 'b'], ordered=False, categories_dtype=object) \n```", "```py\nIn [214]: df = pd.DataFrame({\"key\": [1.0, 1.0, np.nan, 2.0, np.nan], \"A\": [1, 2, 3, 4, 5]})\n\nIn [215]: df\nOut[215]: \n key  A\n0  1.0  1\n1  1.0  2\n2  NaN  3\n3  2.0  4\n4  NaN  5\n\nIn [216]: df.groupby(\"key\", dropna=True).sum()\nOut[216]: \n A\nkey \n1.0  3\n2.0  4\n\nIn [217]: df.groupby(\"key\", dropna=False).sum()\nOut[217]: \n A\nkey \n1.0  3\n2.0  4\nNaN  8 \n```", "```py\nIn [218]: days = pd.Categorical(\n .....:    values=[\"Wed\", \"Mon\", \"Thu\", \"Mon\", \"Wed\", \"Sat\"],\n .....:    categories=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"],\n .....: )\n .....: \n\nIn [219]: data = pd.DataFrame(\n .....:   {\n .....:       \"day\": days,\n .....:       \"workers\": [3, 4, 1, 4, 2, 2],\n .....:   }\n .....: )\n .....: \n\nIn [220]: data\nOut[220]: \n day  workers\n0  Wed        3\n1  Mon        4\n2  Thu        1\n3  Mon        4\n4  Wed        2\n5  Sat        2\n\nIn [221]: data.groupby(\"day\", observed=False, sort=True).sum()\nOut[221]: \n workers\nday \nMon        8\nTue        0\nWed        5\nThu        1\nFri        0\nSat        2\nSun        0\n\nIn [222]: data.groupby(\"day\", observed=False, sort=False).sum()\nOut[222]: \n workers\nday \nWed        5\nMon        8\nThu        1\nSat        2\nTue        0\nFri        0\nSun        0 \n```", "```py\nIn [223]: import datetime\n\nIn [224]: df = pd.DataFrame(\n .....:    {\n .....:        \"Branch\": \"A A A A A A A B\".split(),\n .....:        \"Buyer\": \"Carl Mark Carl Carl Joe Joe Joe Carl\".split(),\n .....:        \"Quantity\": [1, 3, 5, 1, 8, 1, 9, 3],\n .....:        \"Date\": [\n .....:            datetime.datetime(2013, 1, 1, 13, 0),\n .....:            datetime.datetime(2013, 1, 1, 13, 5),\n .....:            datetime.datetime(2013, 10, 1, 20, 0),\n .....:            datetime.datetime(2013, 10, 2, 10, 0),\n .....:            datetime.datetime(2013, 10, 1, 20, 0),\n .....:            datetime.datetime(2013, 10, 2, 10, 0),\n .....:            datetime.datetime(2013, 12, 2, 12, 0),\n .....:            datetime.datetime(2013, 12, 2, 14, 0),\n .....:        ],\n .....:    }\n .....: )\n .....: \n\nIn [225]: df\nOut[225]: \n Branch Buyer  Quantity                Date\n0      A  Carl         1 2013-01-01 13:00:00\n1      A  Mark         3 2013-01-01 13:05:00\n2      A  Carl         5 2013-10-01 20:00:00\n3      A  Carl         1 2013-10-02 10:00:00\n4      A   Joe         8 2013-10-01 20:00:00\n5      A   Joe         1 2013-10-02 10:00:00\n6      A   Joe         9 2013-12-02 12:00:00\n7      B  Carl         3 2013-12-02 14:00:00 \n```", "```py\nIn [226]: df.groupby([pd.Grouper(freq=\"1ME\", key=\"Date\"), \"Buyer\"])[[\"Quantity\"]].sum()\nOut[226]: \n Quantity\nDate       Buyer \n2013-01-31 Carl          1\n Mark          3\n2013-10-31 Carl          6\n Joe           9\n2013-12-31 Carl          3\n Joe           9 \n```", "```py\nIn [227]: df = df.set_index(\"Date\")\n\nIn [228]: df[\"Date\"] = df.index + pd.offsets.MonthEnd(2)\n\nIn [229]: df.groupby([pd.Grouper(freq=\"6ME\", key=\"Date\"), \"Buyer\"])[[\"Quantity\"]].sum()\nOut[229]: \n Quantity\nDate       Buyer \n2013-02-28 Carl          1\n Mark          3\n2014-02-28 Carl          9\n Joe          18\n\nIn [230]: df.groupby([pd.Grouper(freq=\"6ME\", level=\"Date\"), \"Buyer\"])[[\"Quantity\"]].sum()\nOut[230]: \n Quantity\nDate       Buyer \n2013-01-31 Carl          1\n Mark          3\n2014-01-31 Carl          9\n Joe          18 \n```", "```py\nIn [231]: df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=[\"A\", \"B\"])\n\nIn [232]: df\nOut[232]: \n A  B\n0  1  2\n1  1  4\n2  5  6\n\nIn [233]: g = df.groupby(\"A\")\n\nIn [234]: g.head(1)\nOut[234]: \n A  B\n0  1  2\n2  5  6\n\nIn [235]: g.tail(1)\nOut[235]: \n A  B\n1  1  4\n2  5  6 \n```", "```py\nIn [236]: df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=[\"A\", \"B\"])\n\nIn [237]: g = df.groupby(\"A\")\n\nIn [238]: g.nth(0)\nOut[238]: \n A    B\n0  1  NaN\n2  5  6.0\n\nIn [239]: g.nth(-1)\nOut[239]: \n A    B\n1  1  4.0\n2  5  6.0\n\nIn [240]: g.nth(1)\nOut[240]: \n A    B\n1  1  4.0 \n```", "```py\nIn [241]: g.nth(5)\nOut[241]: \nEmpty DataFrame\nColumns: [A, B]\nIndex: [] \n```", "```py\n# nth(0) is the same as g.first()\nIn [242]: g.nth(0, dropna=\"any\")\nOut[242]: \n A    B\n1  1  4.0\n2  5  6.0\n\nIn [243]: g.first()\nOut[243]: \n B\nA \n1  4.0\n5  6.0\n\n# nth(-1) is the same as g.last()\nIn [244]: g.nth(-1, dropna=\"any\")\nOut[244]: \n A    B\n1  1  4.0\n2  5  6.0\n\nIn [245]: g.last()\nOut[245]: \n B\nA \n1  4.0\n5  6.0\n\nIn [246]: g.B.nth(0, dropna=\"all\")\nOut[246]: \n1    4.0\n2    6.0\nName: B, dtype: float64 \n```", "```py\nIn [247]: business_dates = pd.date_range(start=\"4/1/2014\", end=\"6/30/2014\", freq=\"B\")\n\nIn [248]: df = pd.DataFrame(1, index=business_dates, columns=[\"a\", \"b\"])\n\n# get the first, 4th, and last date index for each month\nIn [249]: df.groupby([df.index.year, df.index.month]).nth([0, 3, -1])\nOut[249]: \n a  b\n2014-04-01  1  1\n2014-04-04  1  1\n2014-04-30  1  1\n2014-05-01  1  1\n2014-05-06  1  1\n2014-05-30  1  1\n2014-06-02  1  1\n2014-06-05  1  1\n2014-06-30  1  1 \n```", "```py\nIn [250]: df.groupby([df.index.year, df.index.month]).nth[1:]\nOut[250]: \n a  b\n2014-04-02  1  1\n2014-04-03  1  1\n2014-04-04  1  1\n2014-04-07  1  1\n2014-04-08  1  1\n...        .. ..\n2014-06-24  1  1\n2014-06-25  1  1\n2014-06-26  1  1\n2014-06-27  1  1\n2014-06-30  1  1\n\n[62 rows x 2 columns]\n\nIn [251]: df.groupby([df.index.year, df.index.month]).nth[1:, :-1]\nOut[251]: \n a  b\n2014-04-01  1  1\n2014-04-02  1  1\n2014-04-03  1  1\n2014-04-04  1  1\n2014-04-07  1  1\n...        .. ..\n2014-06-24  1  1\n2014-06-25  1  1\n2014-06-26  1  1\n2014-06-27  1  1\n2014-06-30  1  1\n\n[65 rows x 2 columns] \n```", "```py\nIn [252]: dfg = pd.DataFrame(list(\"aaabba\"), columns=[\"A\"])\n\nIn [253]: dfg\nOut[253]: \n A\n0  a\n1  a\n2  a\n3  b\n4  b\n5  a\n\nIn [254]: dfg.groupby(\"A\").cumcount()\nOut[254]: \n0    0\n1    1\n2    2\n3    0\n4    1\n5    3\ndtype: int64\n\nIn [255]: dfg.groupby(\"A\").cumcount(ascending=False)\nOut[255]: \n0    3\n1    2\n2    1\n3    1\n4    0\n5    0\ndtype: int64 \n```", "```py\nIn [256]: dfg = pd.DataFrame(list(\"aaabba\"), columns=[\"A\"])\n\nIn [257]: dfg\nOut[257]: \n A\n0  a\n1  a\n2  a\n3  b\n4  b\n5  a\n\nIn [258]: dfg.groupby(\"A\").ngroup()\nOut[258]: \n0    0\n1    0\n2    0\n3    1\n4    1\n5    0\ndtype: int64\n\nIn [259]: dfg.groupby(\"A\").ngroup(ascending=False)\nOut[259]: \n0    1\n1    1\n2    1\n3    0\n4    0\n5    1\ndtype: int64 \n```", "```py\nIn [260]: np.random.seed(1234)\n\nIn [261]: df = pd.DataFrame(np.random.randn(50, 2))\n\nIn [262]: df[\"g\"] = np.random.choice([\"A\", \"B\"], size=50)\n\nIn [263]: df.loc[df[\"g\"] == \"B\", 1] += 3 \n```", "```py\nIn [264]: df.groupby(\"g\").boxplot()\nOut[264]: \nA         Axes(0.1,0.15;0.363636x0.75)\nB    Axes(0.536364,0.15;0.363636x0.75)\ndtype: object \n```", "```py\nIn [265]: n = 1000\n\nIn [266]: df = pd.DataFrame(\n .....:    {\n .....:        \"Store\": np.random.choice([\"Store_1\", \"Store_2\"], n),\n .....:        \"Product\": np.random.choice([\"Product_1\", \"Product_2\"], n),\n .....:        \"Revenue\": (np.random.random(n) * 50 + 10).round(2),\n .....:        \"Quantity\": np.random.randint(1, 10, size=n),\n .....:    }\n .....: )\n .....: \n\nIn [267]: df.head(2)\nOut[267]: \n Store    Product  Revenue  Quantity\n0  Store_2  Product_1    26.12         1\n1  Store_2  Product_1    28.86         1 \n```", "```py\nIn [268]: (\n .....:    df.groupby([\"Store\", \"Product\"])\n .....:    .pipe(lambda grp: grp.Revenue.sum() / grp.Quantity.sum())\n .....:    .unstack()\n .....:    .round(2)\n .....: )\n .....: \nOut[268]: \nProduct  Product_1  Product_2\nStore \nStore_1       6.82       7.05\nStore_2       6.30       6.64 \n```", "```py\nIn [269]: def mean(groupby):\n .....:    return groupby.mean()\n .....: \n\nIn [270]: df.groupby([\"Store\", \"Product\"]).pipe(mean)\nOut[270]: \n Revenue  Quantity\nStore   Product \nStore_1 Product_1  34.622727  5.075758\n Product_2  35.482815  5.029630\nStore_2 Product_1  32.972837  5.237589\n Product_2  34.684360  5.224000 \n```", "```py\nIn [271]: dfg = pd.DataFrame({\"A\": [1, 1, 2, 3, 2], \"B\": list(\"aaaba\")})\n\nIn [272]: dfg\nOut[272]: \n A  B\n0  1  a\n1  1  a\n2  2  a\n3  3  b\n4  2  a\n\nIn [273]: dfg.groupby([\"A\", \"B\"]).ngroup()\nOut[273]: \n0    0\n1    0\n2    1\n3    2\n4    1\ndtype: int64\n\nIn [274]: dfg.groupby([\"A\", [0, 0, 0, 1, 1]]).ngroup()\nOut[274]: \n0    0\n1    0\n2    1\n3    3\n4    2\ndtype: int64 \n```", "```py\nIn [275]: df = pd.DataFrame(np.random.randn(10, 2))\n\nIn [276]: df\nOut[276]: \n 0         1\n0 -0.793893  0.321153\n1  0.342250  1.618906\n2 -0.975807  1.918201\n3 -0.810847 -1.405919\n4 -1.977759  0.461659\n5  0.730057 -1.316938\n6 -0.751328  0.528290\n7 -0.257759 -1.081009\n8  0.505895 -1.701948\n9 -1.006349  0.020208\n\nIn [277]: df.index // 5\nOut[277]: Index([0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype='int64')\n\nIn [278]: df.groupby(df.index // 5).std()\nOut[278]: \n 0         1\n0  0.823647  1.312912\n1  0.760109  0.942941 \n```", "```py\nIn [279]: df = pd.DataFrame(\n .....:    {\n .....:        \"a\": [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],\n .....:        \"b\": [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n .....:        \"c\": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n .....:        \"d\": [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n .....:    }\n .....: )\n .....: \n\nIn [280]: def compute_metrics(x):\n .....:    result = {\"b_sum\": x[\"b\"].sum(), \"c_mean\": x[\"c\"].mean()}\n .....:    return pd.Series(result, name=\"metrics\")\n .....: \n\nIn [281]: result = df.groupby(\"a\").apply(compute_metrics, include_groups=False)\n\nIn [282]: result\nOut[282]: \nmetrics  b_sum  c_mean\na \n0          2.0     0.5\n1          2.0     0.5\n2          2.0     0.5\n\nIn [283]: result.stack(future_stack=True)\nOut[283]: \na  metrics\n0  b_sum      2.0\n c_mean     0.5\n1  b_sum      2.0\n c_mean     0.5\n2  b_sum      2.0\n c_mean     0.5\ndtype: float64 \n```", "```py\nIn [1]: speeds = pd.DataFrame(\n ...:    [\n ...:        (\"bird\", \"Falconiformes\", 389.0),\n ...:        (\"bird\", \"Psittaciformes\", 24.0),\n ...:        (\"mammal\", \"Carnivora\", 80.2),\n ...:        (\"mammal\", \"Primates\", np.nan),\n ...:        (\"mammal\", \"Carnivora\", 58),\n ...:    ],\n ...:    index=[\"falcon\", \"parrot\", \"lion\", \"monkey\", \"leopard\"],\n ...:    columns=(\"class\", \"order\", \"max_speed\"),\n ...: )\n ...: \n\nIn [2]: speeds\nOut[2]: \n class           order  max_speed\nfalcon     bird   Falconiformes      389.0\nparrot     bird  Psittaciformes       24.0\nlion     mammal       Carnivora       80.2\nmonkey   mammal        Primates        NaN\nleopard  mammal       Carnivora       58.0\n\nIn [3]: grouped = speeds.groupby(\"class\")\n\nIn [4]: grouped = speeds.groupby([\"class\", \"order\"]) \n```", "```py\nIn [5]: df = pd.DataFrame(\n ...:    {\n ...:        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n ...:        \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n ...:        \"C\": np.random.randn(8),\n ...:        \"D\": np.random.randn(8),\n ...:    }\n ...: )\n ...: \n\nIn [6]: df\nOut[6]: \n A      B         C         D\n0  foo    one  0.469112 -0.861849\n1  bar    one -0.282863 -2.104569\n2  foo    two -1.509059 -0.494929\n3  bar  three -1.135632  1.071804\n4  foo    two  1.212112  0.721555\n5  bar    two -0.173215 -0.706771\n6  foo    one  0.119209 -1.039575\n7  foo  three -1.044236  0.271860 \n```", "```py\nIn [7]: grouped = df.groupby(\"A\")\n\nIn [8]: grouped = df.groupby(\"B\")\n\nIn [9]: grouped = df.groupby([\"A\", \"B\"]) \n```", "```py\nIn [10]: df2 = df.set_index([\"A\", \"B\"])\n\nIn [11]: grouped = df2.groupby(level=df2.index.names.difference([\"B\"]))\n\nIn [12]: grouped.sum()\nOut[12]: \n C         D\nA \nbar -1.591710 -1.739537\nfoo -0.752861 -1.402938 \n```", "```py\nIn [13]: def get_letter_type(letter):\n ....:    if letter.lower() in 'aeiou':\n ....:        return 'vowel'\n ....:    else:\n ....:        return 'consonant'\n ....: \n\nIn [14]: grouped = df.T.groupby(get_letter_type) \n```", "```py\nIn [15]: index = [1, 2, 3, 1, 2, 3]\n\nIn [16]: s = pd.Series([1, 2, 3, 10, 20, 30], index=index)\n\nIn [17]: s\nOut[17]: \n1     1\n2     2\n3     3\n1    10\n2    20\n3    30\ndtype: int64\n\nIn [18]: grouped = s.groupby(level=0)\n\nIn [19]: grouped.first()\nOut[19]: \n1    1\n2    2\n3    3\ndtype: int64\n\nIn [20]: grouped.last()\nOut[20]: \n1    10\n2    20\n3    30\ndtype: int64\n\nIn [21]: grouped.sum()\nOut[21]: \n1    11\n2    22\n3    33\ndtype: int64 \n```", "```py\nIn [22]: df2 = pd.DataFrame({\"X\": [\"B\", \"B\", \"A\", \"A\"], \"Y\": [1, 2, 3, 4]})\n\nIn [23]: df2.groupby([\"X\"]).sum()\nOut[23]: \n Y\nX \nA  7\nB  3\n\nIn [24]: df2.groupby([\"X\"], sort=False).sum()\nOut[24]: \n Y\nX \nB  3\nA  7 \n```", "```py\nIn [25]: df3 = pd.DataFrame({\"X\": [\"A\", \"B\", \"A\", \"B\"], \"Y\": [1, 4, 3, 2]})\n\nIn [26]: df3.groupby(\"X\").get_group(\"A\")\nOut[26]: \n X  Y\n0  A  1\n2  A  3\n\nIn [27]: df3.groupby([\"X\"]).get_group((\"B\",))\nOut[27]: \n X  Y\n1  B  4\n3  B  2 \n```", "```py\nIn [28]: df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n\nIn [29]: df_dropna = pd.DataFrame(df_list, columns=[\"a\", \"b\", \"c\"])\n\nIn [30]: df_dropna\nOut[30]: \n a    b  c\n0  1  2.0  3\n1  1  NaN  4\n2  2  1.0  3\n3  1  2.0  2 \n```", "```py\n# Default ``dropna`` is set to True, which will exclude NaNs in keys\nIn [31]: df_dropna.groupby(by=[\"b\"], dropna=True).sum()\nOut[31]: \n a  c\nb \n1.0  2  3\n2.0  2  5\n\n# In order to allow NaN in keys, set ``dropna`` to False\nIn [32]: df_dropna.groupby(by=[\"b\"], dropna=False).sum()\nOut[32]: \n a  c\nb \n1.0  2  3\n2.0  2  5\nNaN  1  4 \n```", "```py\nIn [33]: df.groupby(\"A\").groups\nOut[33]: {'bar': [1, 3, 5], 'foo': [0, 2, 4, 6, 7]}\n\nIn [34]: df.T.groupby(get_letter_type).groups\nOut[34]: {'consonant': ['B', 'C', 'D'], 'vowel': ['A']} \n```", "```py\nIn [35]: grouped = df.groupby([\"A\", \"B\"])\n\nIn [36]: grouped.groups\nOut[36]: {('bar', 'one'): [1], ('bar', 'three'): [3], ('bar', 'two'): [5], ('foo', 'one'): [0, 6], ('foo', 'three'): [7], ('foo', 'two'): [2, 4]}\n\nIn [37]: len(grouped)\nOut[37]: 6 \n```", "```py\nIn [38]: n = 10\n\nIn [39]: weight = np.random.normal(166, 20, size=n)\n\nIn [40]: height = np.random.normal(60, 10, size=n)\n\nIn [41]: time = pd.date_range(\"1/1/2000\", periods=n)\n\nIn [42]: gender = np.random.choice([\"male\", \"female\"], size=n)\n\nIn [43]: df = pd.DataFrame(\n ....:    {\"height\": height, \"weight\": weight, \"gender\": gender}, index=time\n ....: )\n ....: \n\nIn [44]: df\nOut[44]: \n height      weight  gender\n2000-01-01  42.849980  157.500553    male\n2000-01-02  49.607315  177.340407    male\n2000-01-03  56.293531  171.524640    male\n2000-01-04  48.421077  144.251986  female\n2000-01-05  46.556882  152.526206    male\n2000-01-06  68.448851  168.272968  female\n2000-01-07  70.757698  136.431469    male\n2000-01-08  58.909500  176.499753  female\n2000-01-09  76.435631  174.094104  female\n2000-01-10  45.306120  177.540920    male\n\nIn [45]: gb = df.groupby(\"gender\") \n```", "```py\nIn [46]: gb.<TAB>  # noqa: E225, E999\ngb.agg        gb.boxplot    gb.cummin     gb.describe   gb.filter     gb.get_group  gb.height     gb.last       gb.median     gb.ngroups    gb.plot       gb.rank       gb.std        gb.transform\ngb.aggregate  gb.count      gb.cumprod    gb.dtype      gb.first      gb.groups     gb.hist       gb.max        gb.min        gb.nth        gb.prod       gb.resample   gb.sum        gb.var\ngb.apply      gb.cummax     gb.cumsum     gb.fillna     gb.gender     gb.head       gb.indices    gb.mean       gb.name       gb.ohlc       gb.quantile   gb.size       gb.tail       gb.weight \n```", "```py\nIn [47]: arrays = [\n ....:    [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n ....:    [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n ....: ]\n ....: \n\nIn [48]: index = pd.MultiIndex.from_arrays(arrays, names=[\"first\", \"second\"])\n\nIn [49]: s = pd.Series(np.random.randn(8), index=index)\n\nIn [50]: s\nOut[50]: \nfirst  second\nbar    one      -0.919854\n two      -0.042379\nbaz    one       1.247642\n two      -0.009920\nfoo    one       0.290213\n two       0.495767\nqux    one       0.362949\n two       1.548106\ndtype: float64 \n```", "```py\nIn [51]: grouped = s.groupby(level=0)\n\nIn [52]: grouped.sum()\nOut[52]: \nfirst\nbar   -0.962232\nbaz    1.237723\nfoo    0.785980\nqux    1.911055\ndtype: float64 \n```", "```py\nIn [53]: s.groupby(level=\"second\").sum()\nOut[53]: \nsecond\none    0.980950\ntwo    1.991575\ndtype: float64 \n```", "```py\nIn [54]: arrays = [\n ....:    [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n ....:    [\"doo\", \"doo\", \"bee\", \"bee\", \"bop\", \"bop\", \"bop\", \"bop\"],\n ....:    [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n ....: ]\n ....: \n\nIn [55]: index = pd.MultiIndex.from_arrays(arrays, names=[\"first\", \"second\", \"third\"])\n\nIn [56]: s = pd.Series(np.random.randn(8), index=index)\n\nIn [57]: s\nOut[57]: \nfirst  second  third\nbar    doo     one     -1.131345\n two     -0.089329\nbaz    bee     one      0.337863\n two     -0.945867\nfoo    bop     one     -0.932132\n two      1.956030\nqux    bop     one      0.017587\n two     -0.016692\ndtype: float64\n\nIn [58]: s.groupby(level=[\"first\", \"second\"]).sum()\nOut[58]: \nfirst  second\nbar    doo      -1.220674\nbaz    bee      -0.608004\nfoo    bop       1.023898\nqux    bop       0.000895\ndtype: float64 \n```", "```py\nIn [59]: s.groupby([\"first\", \"second\"]).sum()\nOut[59]: \nfirst  second\nbar    doo      -1.220674\nbaz    bee      -0.608004\nfoo    bop       1.023898\nqux    bop       0.000895\ndtype: float64 \n```", "```py\nIn [60]: arrays = [\n ....:    [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n ....:    [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n ....: ]\n ....: \n\nIn [61]: index = pd.MultiIndex.from_arrays(arrays, names=[\"first\", \"second\"])\n\nIn [62]: df = pd.DataFrame({\"A\": [1, 1, 1, 1, 2, 2, 3, 3], \"B\": np.arange(8)}, index=index)\n\nIn [63]: df\nOut[63]: \n A  B\nfirst second \nbar   one     1  0\n two     1  1\nbaz   one     1  2\n two     1  3\nfoo   one     2  4\n two     2  5\nqux   one     3  6\n two     3  7 \n```", "```py\nIn [64]: df.groupby([pd.Grouper(level=1), \"A\"]).sum()\nOut[64]: \n B\nsecond A \none    1  2\n 2  4\n 3  6\ntwo    1  4\n 2  5\n 3  7 \n```", "```py\nIn [65]: df.groupby([pd.Grouper(level=\"second\"), \"A\"]).sum()\nOut[65]: \n B\nsecond A \none    1  2\n 2  4\n 3  6\ntwo    1  4\n 2  5\n 3  7 \n```", "```py\nIn [66]: df.groupby([\"second\", \"A\"]).sum()\nOut[66]: \n B\nsecond A \none    1  2\n 2  4\n 3  6\ntwo    1  4\n 2  5\n 3  7 \n```", "```py\nIn [67]: df = pd.DataFrame(\n ....:    {\n ....:        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n ....:        \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n ....:        \"C\": np.random.randn(8),\n ....:        \"D\": np.random.randn(8),\n ....:    }\n ....: )\n ....: \n\nIn [68]: df\nOut[68]: \n A      B         C         D\n0  foo    one -0.575247  1.346061\n1  bar    one  0.254161  1.511763\n2  foo    two -1.143704  1.627081\n3  bar  three  0.215897 -0.990582\n4  foo    two  1.193555 -0.441652\n5  bar    two -0.077118  1.211526\n6  foo    one -0.408530  0.268520\n7  foo  three -0.862495  0.024580\n\nIn [69]: grouped = df.groupby([\"A\"])\n\nIn [70]: grouped_C = grouped[\"C\"]\n\nIn [71]: grouped_D = grouped[\"D\"] \n```", "```py\nIn [72]: df[\"C\"].groupby(df[\"A\"])\nOut[72]: <pandas.core.groupby.generic.SeriesGroupBy object at 0x7ff2cef1c730> \n```", "```py\nIn [73]: grouped[[\"A\", \"B\"]].sum()\nOut[73]: \n A                  B\nA \nbar        barbarbar        onethreetwo\nfoo  foofoofoofoofoo  onetwotwoonethree \n```", "```py\nIn [22]: df2 = pd.DataFrame({\"X\": [\"B\", \"B\", \"A\", \"A\"], \"Y\": [1, 2, 3, 4]})\n\nIn [23]: df2.groupby([\"X\"]).sum()\nOut[23]: \n Y\nX \nA  7\nB  3\n\nIn [24]: df2.groupby([\"X\"], sort=False).sum()\nOut[24]: \n Y\nX \nB  3\nA  7 \n```", "```py\nIn [25]: df3 = pd.DataFrame({\"X\": [\"A\", \"B\", \"A\", \"B\"], \"Y\": [1, 4, 3, 2]})\n\nIn [26]: df3.groupby(\"X\").get_group(\"A\")\nOut[26]: \n X  Y\n0  A  1\n2  A  3\n\nIn [27]: df3.groupby([\"X\"]).get_group((\"B\",))\nOut[27]: \n X  Y\n1  B  4\n3  B  2 \n```", "```py\nIn [28]: df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n\nIn [29]: df_dropna = pd.DataFrame(df_list, columns=[\"a\", \"b\", \"c\"])\n\nIn [30]: df_dropna\nOut[30]: \n a    b  c\n0  1  2.0  3\n1  1  NaN  4\n2  2  1.0  3\n3  1  2.0  2 \n```", "```py\n# Default ``dropna`` is set to True, which will exclude NaNs in keys\nIn [31]: df_dropna.groupby(by=[\"b\"], dropna=True).sum()\nOut[31]: \n a  c\nb \n1.0  2  3\n2.0  2  5\n\n# In order to allow NaN in keys, set ``dropna`` to False\nIn [32]: df_dropna.groupby(by=[\"b\"], dropna=False).sum()\nOut[32]: \n a  c\nb \n1.0  2  3\n2.0  2  5\nNaN  1  4 \n```", "```py\nIn [28]: df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n\nIn [29]: df_dropna = pd.DataFrame(df_list, columns=[\"a\", \"b\", \"c\"])\n\nIn [30]: df_dropna\nOut[30]: \n a    b  c\n0  1  2.0  3\n1  1  NaN  4\n2  2  1.0  3\n3  1  2.0  2 \n```", "```py\n# Default ``dropna`` is set to True, which will exclude NaNs in keys\nIn [31]: df_dropna.groupby(by=[\"b\"], dropna=True).sum()\nOut[31]: \n a  c\nb \n1.0  2  3\n2.0  2  5\n\n# In order to allow NaN in keys, set ``dropna`` to False\nIn [32]: df_dropna.groupby(by=[\"b\"], dropna=False).sum()\nOut[32]: \n a  c\nb \n1.0  2  3\n2.0  2  5\nNaN  1  4 \n```", "```py\nIn [33]: df.groupby(\"A\").groups\nOut[33]: {'bar': [1, 3, 5], 'foo': [0, 2, 4, 6, 7]}\n\nIn [34]: df.T.groupby(get_letter_type).groups\nOut[34]: {'consonant': ['B', 'C', 'D'], 'vowel': ['A']} \n```", "```py\nIn [35]: grouped = df.groupby([\"A\", \"B\"])\n\nIn [36]: grouped.groups\nOut[36]: {('bar', 'one'): [1], ('bar', 'three'): [3], ('bar', 'two'): [5], ('foo', 'one'): [0, 6], ('foo', 'three'): [7], ('foo', 'two'): [2, 4]}\n\nIn [37]: len(grouped)\nOut[37]: 6 \n```", "```py\nIn [38]: n = 10\n\nIn [39]: weight = np.random.normal(166, 20, size=n)\n\nIn [40]: height = np.random.normal(60, 10, size=n)\n\nIn [41]: time = pd.date_range(\"1/1/2000\", periods=n)\n\nIn [42]: gender = np.random.choice([\"male\", \"female\"], size=n)\n\nIn [43]: df = pd.DataFrame(\n ....:    {\"height\": height, \"weight\": weight, \"gender\": gender}, index=time\n ....: )\n ....: \n\nIn [44]: df\nOut[44]: \n height      weight  gender\n2000-01-01  42.849980  157.500553    male\n2000-01-02  49.607315  177.340407    male\n2000-01-03  56.293531  171.524640    male\n2000-01-04  48.421077  144.251986  female\n2000-01-05  46.556882  152.526206    male\n2000-01-06  68.448851  168.272968  female\n2000-01-07  70.757698  136.431469    male\n2000-01-08  58.909500  176.499753  female\n2000-01-09  76.435631  174.094104  female\n2000-01-10  45.306120  177.540920    male\n\nIn [45]: gb = df.groupby(\"gender\") \n```", "```py\nIn [46]: gb.<TAB>  # noqa: E225, E999\ngb.agg        gb.boxplot    gb.cummin     gb.describe   gb.filter     gb.get_group  gb.height     gb.last       gb.median     gb.ngroups    gb.plot       gb.rank       gb.std        gb.transform\ngb.aggregate  gb.count      gb.cumprod    gb.dtype      gb.first      gb.groups     gb.hist       gb.max        gb.min        gb.nth        gb.prod       gb.resample   gb.sum        gb.var\ngb.apply      gb.cummax     gb.cumsum     gb.fillna     gb.gender     gb.head       gb.indices    gb.mean       gb.name       gb.ohlc       gb.quantile   gb.size       gb.tail       gb.weight \n```", "```py\nIn [47]: arrays = [\n ....:    [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n ....:    [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n ....: ]\n ....: \n\nIn [48]: index = pd.MultiIndex.from_arrays(arrays, names=[\"first\", \"second\"])\n\nIn [49]: s = pd.Series(np.random.randn(8), index=index)\n\nIn [50]: s\nOut[50]: \nfirst  second\nbar    one      -0.919854\n two      -0.042379\nbaz    one       1.247642\n two      -0.009920\nfoo    one       0.290213\n two       0.495767\nqux    one       0.362949\n two       1.548106\ndtype: float64 \n```", "```py\nIn [51]: grouped = s.groupby(level=0)\n\nIn [52]: grouped.sum()\nOut[52]: \nfirst\nbar   -0.962232\nbaz    1.237723\nfoo    0.785980\nqux    1.911055\ndtype: float64 \n```", "```py\nIn [53]: s.groupby(level=\"second\").sum()\nOut[53]: \nsecond\none    0.980950\ntwo    1.991575\ndtype: float64 \n```", "```py\nIn [54]: arrays = [\n ....:    [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n ....:    [\"doo\", \"doo\", \"bee\", \"bee\", \"bop\", \"bop\", \"bop\", \"bop\"],\n ....:    [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n ....: ]\n ....: \n\nIn [55]: index = pd.MultiIndex.from_arrays(arrays, names=[\"first\", \"second\", \"third\"])\n\nIn [56]: s = pd.Series(np.random.randn(8), index=index)\n\nIn [57]: s\nOut[57]: \nfirst  second  third\nbar    doo     one     -1.131345\n two     -0.089329\nbaz    bee     one      0.337863\n two     -0.945867\nfoo    bop     one     -0.932132\n two      1.956030\nqux    bop     one      0.017587\n two     -0.016692\ndtype: float64\n\nIn [58]: s.groupby(level=[\"first\", \"second\"]).sum()\nOut[58]: \nfirst  second\nbar    doo      -1.220674\nbaz    bee      -0.608004\nfoo    bop       1.023898\nqux    bop       0.000895\ndtype: float64 \n```", "```py\nIn [59]: s.groupby([\"first\", \"second\"]).sum()\nOut[59]: \nfirst  second\nbar    doo      -1.220674\nbaz    bee      -0.608004\nfoo    bop       1.023898\nqux    bop       0.000895\ndtype: float64 \n```", "```py\nIn [60]: arrays = [\n ....:    [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n ....:    [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n ....: ]\n ....: \n\nIn [61]: index = pd.MultiIndex.from_arrays(arrays, names=[\"first\", \"second\"])\n\nIn [62]: df = pd.DataFrame({\"A\": [1, 1, 1, 1, 2, 2, 3, 3], \"B\": np.arange(8)}, index=index)\n\nIn [63]: df\nOut[63]: \n A  B\nfirst second \nbar   one     1  0\n two     1  1\nbaz   one     1  2\n two     1  3\nfoo   one     2  4\n two     2  5\nqux   one     3  6\n two     3  7 \n```", "```py\nIn [64]: df.groupby([pd.Grouper(level=1), \"A\"]).sum()\nOut[64]: \n B\nsecond A \none    1  2\n 2  4\n 3  6\ntwo    1  4\n 2  5\n 3  7 \n```", "```py\nIn [65]: df.groupby([pd.Grouper(level=\"second\"), \"A\"]).sum()\nOut[65]: \n B\nsecond A \none    1  2\n 2  4\n 3  6\ntwo    1  4\n 2  5\n 3  7 \n```", "```py\nIn [66]: df.groupby([\"second\", \"A\"]).sum()\nOut[66]: \n B\nsecond A \none    1  2\n 2  4\n 3  6\ntwo    1  4\n 2  5\n 3  7 \n```", "```py\nIn [67]: df = pd.DataFrame(\n ....:    {\n ....:        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n ....:        \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n ....:        \"C\": np.random.randn(8),\n ....:        \"D\": np.random.randn(8),\n ....:    }\n ....: )\n ....: \n\nIn [68]: df\nOut[68]: \n A      B         C         D\n0  foo    one -0.575247  1.346061\n1  bar    one  0.254161  1.511763\n2  foo    two -1.143704  1.627081\n3  bar  three  0.215897 -0.990582\n4  foo    two  1.193555 -0.441652\n5  bar    two -0.077118  1.211526\n6  foo    one -0.408530  0.268520\n7  foo  three -0.862495  0.024580\n\nIn [69]: grouped = df.groupby([\"A\"])\n\nIn [70]: grouped_C = grouped[\"C\"]\n\nIn [71]: grouped_D = grouped[\"D\"] \n```", "```py\nIn [72]: df[\"C\"].groupby(df[\"A\"])\nOut[72]: <pandas.core.groupby.generic.SeriesGroupBy object at 0x7ff2cef1c730> \n```", "```py\nIn [73]: grouped[[\"A\", \"B\"]].sum()\nOut[73]: \n A                  B\nA \nbar        barbarbar        onethreetwo\nfoo  foofoofoofoofoo  onetwotwoonethree \n```", "```py\nIn [74]: grouped = df.groupby('A')\n\nIn [75]: for name, group in grouped:\n ....:    print(name)\n ....:    print(group)\n ....: \nbar\n A      B         C         D\n1  bar    one  0.254161  1.511763\n3  bar  three  0.215897 -0.990582\n5  bar    two -0.077118  1.211526\nfoo\n A      B         C         D\n0  foo    one -0.575247  1.346061\n2  foo    two -1.143704  1.627081\n4  foo    two  1.193555 -0.441652\n6  foo    one -0.408530  0.268520\n7  foo  three -0.862495  0.024580 \n```", "```py\nIn [76]: for name, group in df.groupby(['A', 'B']):\n ....:    print(name)\n ....:    print(group)\n ....: \n('bar', 'one')\n A    B         C         D\n1  bar  one  0.254161  1.511763\n('bar', 'three')\n A      B         C         D\n3  bar  three  0.215897 -0.990582\n('bar', 'two')\n A    B         C         D\n5  bar  two -0.077118  1.211526\n('foo', 'one')\n A    B         C         D\n0  foo  one -0.575247  1.346061\n6  foo  one -0.408530  0.268520\n('foo', 'three')\n A      B         C        D\n7  foo  three -0.862495  0.02458\n('foo', 'two')\n A    B         C         D\n2  foo  two -1.143704  1.627081\n4  foo  two  1.193555 -0.441652 \n```", "```py\nIn [77]: grouped.get_group(\"bar\")\nOut[77]: \n A      B         C         D\n1  bar    one  0.254161  1.511763\n3  bar  three  0.215897 -0.990582\n5  bar    two -0.077118  1.211526 \n```", "```py\nIn [78]: df.groupby([\"A\", \"B\"]).get_group((\"bar\", \"one\"))\nOut[78]: \n A    B         C         D\n1  bar  one  0.254161  1.511763 \n```", "```py\nIn [79]: animals = pd.DataFrame(\n ....:    {\n ....:        \"kind\": [\"cat\", \"dog\", \"cat\", \"dog\"],\n ....:        \"height\": [9.1, 6.0, 9.5, 34.0],\n ....:        \"weight\": [7.9, 7.5, 9.9, 198.0],\n ....:    }\n ....: )\n ....: \n\nIn [80]: animals\nOut[80]: \n kind  height  weight\n0  cat     9.1     7.9\n1  dog     6.0     7.5\n2  cat     9.5     9.9\n3  dog    34.0   198.0\n\nIn [81]: animals.groupby(\"kind\").sum()\nOut[81]: \n height  weight\nkind \ncat     18.6    17.8\ndog     40.0   205.5 \n```", "```py\nIn [82]: animals.groupby(\"kind\", as_index=False).sum()\nOut[82]: \n kind  height  weight\n0  cat    18.6    17.8\n1  dog    40.0   205.5 \n```", "```py\nIn [83]: df.groupby(\"A\")[[\"C\", \"D\"]].max()\nOut[83]: \n C         D\nA \nbar  0.254161  1.511763\nfoo  1.193555  1.627081\n\nIn [84]: df.groupby([\"A\", \"B\"]).mean()\nOut[84]: \n C         D\nA   B \nbar one    0.254161  1.511763\n three  0.215897 -0.990582\n two   -0.077118  1.211526\nfoo one   -0.491888  0.807291\n three -0.862495  0.024580\n two    0.024925  0.592714 \n```", "```py\nIn [85]: grouped = df.groupby([\"A\", \"B\"])\n\nIn [86]: grouped.size()\nOut[86]: \nA    B \nbar  one      1\n three    1\n two      1\nfoo  one      2\n three    1\n two      2\ndtype: int64 \n```", "```py\nIn [87]: grouped.describe()\nOut[87]: \n C                      ...         D \n count      mean       std  ...       50%       75%       max\nA   B                                ... \nbar one     1.0  0.254161       NaN  ...  1.511763  1.511763  1.511763\n three   1.0  0.215897       NaN  ... -0.990582 -0.990582 -0.990582\n two     1.0 -0.077118       NaN  ...  1.211526  1.211526  1.211526\nfoo one     2.0 -0.491888  0.117887  ...  0.807291  1.076676  1.346061\n three   1.0 -0.862495       NaN  ...  0.024580  0.024580  0.024580\n two     2.0  0.024925  1.652692  ...  0.592714  1.109898  1.627081\n\n[6 rows x 16 columns] \n```", "```py\nIn [88]: ll = [['foo', 1], ['foo', 2], ['foo', 2], ['bar', 1], ['bar', 1]]\n\nIn [89]: df4 = pd.DataFrame(ll, columns=[\"A\", \"B\"])\n\nIn [90]: df4\nOut[90]: \n A  B\n0  foo  1\n1  foo  2\n2  foo  2\n3  bar  1\n4  bar  1\n\nIn [91]: df4.groupby(\"A\")[\"B\"].nunique()\nOut[91]: \nA\nbar    1\nfoo    2\nName: B, dtype: int64 \n```", "```py\nIn [92]: grouped = df.groupby(\"A\")\n\nIn [93]: grouped[[\"C\", \"D\"]].aggregate(\"sum\")\nOut[93]: \n C         D\nA \nbar  0.392940  1.732707\nfoo -1.796421  2.824590\n\nIn [94]: grouped = df.groupby([\"A\", \"B\"])\n\nIn [95]: grouped.agg(\"sum\")\nOut[95]: \n C         D\nA   B \nbar one    0.254161  1.511763\n three  0.215897 -0.990582\n two   -0.077118  1.211526\nfoo one   -0.983776  1.614581\n three -0.862495  0.024580\n two    0.049851  1.185429 \n```", "```py\nIn [96]: grouped = df.groupby([\"A\", \"B\"], as_index=False)\n\nIn [97]: grouped.agg(\"sum\")\nOut[97]: \n A      B         C         D\n0  bar    one  0.254161  1.511763\n1  bar  three  0.215897 -0.990582\n2  bar    two -0.077118  1.211526\n3  foo    one -0.983776  1.614581\n4  foo  three -0.862495  0.024580\n5  foo    two  0.049851  1.185429\n\nIn [98]: df.groupby(\"A\", as_index=False)[[\"C\", \"D\"]].agg(\"sum\")\nOut[98]: \n A         C         D\n0  bar  0.392940  1.732707\n1  foo -1.796421  2.824590 \n```", "```py\nIn [99]: df.groupby([\"A\", \"B\"]).agg(\"sum\").reset_index()\nOut[99]: \n A      B         C         D\n0  bar    one  0.254161  1.511763\n1  bar  three  0.215897 -0.990582\n2  bar    two -0.077118  1.211526\n3  foo    one -0.983776  1.614581\n4  foo  three -0.862495  0.024580\n5  foo    two  0.049851  1.185429 \n```", "```py\nIn [100]: animals\nOut[100]: \n kind  height  weight\n0  cat     9.1     7.9\n1  dog     6.0     7.5\n2  cat     9.5     9.9\n3  dog    34.0   198.0\n\nIn [101]: animals.groupby(\"kind\")[[\"height\"]].agg(lambda x: set(x))\nOut[101]: \n height\nkind \ncat    {9.1, 9.5}\ndog   {34.0, 6.0} \n```", "```py\nIn [102]: animals.groupby(\"kind\")[[\"height\"]].agg(lambda x: x.astype(int).sum())\nOut[102]: \n height\nkind \ncat       18\ndog       40 \n```", "```py\nIn [103]: grouped = df.groupby(\"A\")\n\nIn [104]: grouped[\"C\"].agg([\"sum\", \"mean\", \"std\"])\nOut[104]: \n sum      mean       std\nA \nbar  0.392940  0.130980  0.181231\nfoo -1.796421 -0.359284  0.912265 \n```", "```py\nIn [105]: grouped[[\"C\", \"D\"]].agg([\"sum\", \"mean\", \"std\"])\nOut[105]: \n C                             D \n sum      mean       std       sum      mean       std\nA \nbar  0.392940  0.130980  0.181231  1.732707  0.577569  1.366330\nfoo -1.796421 -0.359284  0.912265  2.824590  0.564918  0.884785 \n```", "```py\nIn [106]: (\n .....:    grouped[\"C\"]\n .....:    .agg([\"sum\", \"mean\", \"std\"])\n .....:    .rename(columns={\"sum\": \"foo\", \"mean\": \"bar\", \"std\": \"baz\"})\n .....: )\n .....: \nOut[106]: \n foo       bar       baz\nA \nbar  0.392940  0.130980  0.181231\nfoo -1.796421 -0.359284  0.912265 \n```", "```py\nIn [107]: (\n .....:    grouped[[\"C\", \"D\"]].agg([\"sum\", \"mean\", \"std\"]).rename(\n .....:        columns={\"sum\": \"foo\", \"mean\": \"bar\", \"std\": \"baz\"}\n .....:    )\n .....: )\n .....: \nOut[107]: \n C                             D \n foo       bar       baz       foo       bar       baz\nA \nbar  0.392940  0.130980  0.181231  1.732707  0.577569  1.366330\nfoo -1.796421 -0.359284  0.912265  2.824590  0.564918  0.884785 \n```", "```py\nIn [108]: grouped[\"C\"].agg([\"sum\", \"sum\"])\nOut[108]: \n sum       sum\nA \nbar  0.392940  0.392940\nfoo -1.796421 -1.796421 \n```", "```py\nIn [109]: grouped[\"C\"].agg([lambda x: x.max() - x.min(), lambda x: x.median() - x.mean()])\nOut[109]: \n <lambda_0>  <lambda_1>\nA \nbar    0.331279    0.084917\nfoo    2.337259   -0.215962 \n```", "```py\nIn [110]: animals\nOut[110]: \n kind  height  weight\n0  cat     9.1     7.9\n1  dog     6.0     7.5\n2  cat     9.5     9.9\n3  dog    34.0   198.0\n\nIn [111]: animals.groupby(\"kind\").agg(\n .....:    min_height=pd.NamedAgg(column=\"height\", aggfunc=\"min\"),\n .....:    max_height=pd.NamedAgg(column=\"height\", aggfunc=\"max\"),\n .....:    average_weight=pd.NamedAgg(column=\"weight\", aggfunc=\"mean\"),\n .....: )\n .....: \nOut[111]: \n min_height  max_height  average_weight\nkind \ncat          9.1         9.5            8.90\ndog          6.0        34.0          102.75 \n```", "```py\nIn [112]: animals.groupby(\"kind\").agg(\n .....:    min_height=(\"height\", \"min\"),\n .....:    max_height=(\"height\", \"max\"),\n .....:    average_weight=(\"weight\", \"mean\"),\n .....: )\n .....: \nOut[112]: \n min_height  max_height  average_weight\nkind \ncat          9.1         9.5            8.90\ndog          6.0        34.0          102.75 \n```", "```py\nIn [113]: animals.groupby(\"kind\").agg(\n .....:    **{\n .....:        \"total weight\": pd.NamedAgg(column=\"weight\", aggfunc=\"sum\")\n .....:    }\n .....: )\n .....: \nOut[113]: \n total weight\nkind \ncat           17.8\ndog          205.5 \n```", "```py\nIn [114]: animals.groupby(\"kind\").height.agg(\n .....:    min_height=\"min\",\n .....:    max_height=\"max\",\n .....: )\n .....: \nOut[114]: \n min_height  max_height\nkind \ncat          9.1         9.5\ndog          6.0        34.0 \n```", "```py\nIn [115]: grouped.agg({\"C\": \"sum\", \"D\": lambda x: np.std(x, ddof=1)})\nOut[115]: \n C         D\nA \nbar  0.392940  1.366330\nfoo -1.796421  0.884785 \n```", "```py\nIn [116]: grouped.agg({\"C\": \"sum\", \"D\": \"std\"})\nOut[116]: \n C         D\nA \nbar  0.392940  1.366330\nfoo -1.796421  0.884785 \n```", "```py\nIn [83]: df.groupby(\"A\")[[\"C\", \"D\"]].max()\nOut[83]: \n C         D\nA \nbar  0.254161  1.511763\nfoo  1.193555  1.627081\n\nIn [84]: df.groupby([\"A\", \"B\"]).mean()\nOut[84]: \n C         D\nA   B \nbar one    0.254161  1.511763\n three  0.215897 -0.990582\n two   -0.077118  1.211526\nfoo one   -0.491888  0.807291\n three -0.862495  0.024580\n two    0.024925  0.592714 \n```", "```py\nIn [85]: grouped = df.groupby([\"A\", \"B\"])\n\nIn [86]: grouped.size()\nOut[86]: \nA    B \nbar  one      1\n three    1\n two      1\nfoo  one      2\n three    1\n two      2\ndtype: int64 \n```", "```py\nIn [87]: grouped.describe()\nOut[87]: \n C                      ...         D \n count      mean       std  ...       50%       75%       max\nA   B                                ... \nbar one     1.0  0.254161       NaN  ...  1.511763  1.511763  1.511763\n three   1.0  0.215897       NaN  ... -0.990582 -0.990582 -0.990582\n two     1.0 -0.077118       NaN  ...  1.211526  1.211526  1.211526\nfoo one     2.0 -0.491888  0.117887  ...  0.807291  1.076676  1.346061\n three   1.0 -0.862495       NaN  ...  0.024580  0.024580  0.024580\n two     2.0  0.024925  1.652692  ...  0.592714  1.109898  1.627081\n\n[6 rows x 16 columns] \n```", "```py\nIn [88]: ll = [['foo', 1], ['foo', 2], ['foo', 2], ['bar', 1], ['bar', 1]]\n\nIn [89]: df4 = pd.DataFrame(ll, columns=[\"A\", \"B\"])\n\nIn [90]: df4\nOut[90]: \n A  B\n0  foo  1\n1  foo  2\n2  foo  2\n3  bar  1\n4  bar  1\n\nIn [91]: df4.groupby(\"A\")[\"B\"].nunique()\nOut[91]: \nA\nbar    1\nfoo    2\nName: B, dtype: int64 \n```", "```py\nIn [92]: grouped = df.groupby(\"A\")\n\nIn [93]: grouped[[\"C\", \"D\"]].aggregate(\"sum\")\nOut[93]: \n C         D\nA \nbar  0.392940  1.732707\nfoo -1.796421  2.824590\n\nIn [94]: grouped = df.groupby([\"A\", \"B\"])\n\nIn [95]: grouped.agg(\"sum\")\nOut[95]: \n C         D\nA   B \nbar one    0.254161  1.511763\n three  0.215897 -0.990582\n two   -0.077118  1.211526\nfoo one   -0.983776  1.614581\n three -0.862495  0.024580\n two    0.049851  1.185429 \n```", "```py\nIn [96]: grouped = df.groupby([\"A\", \"B\"], as_index=False)\n\nIn [97]: grouped.agg(\"sum\")\nOut[97]: \n A      B         C         D\n0  bar    one  0.254161  1.511763\n1  bar  three  0.215897 -0.990582\n2  bar    two -0.077118  1.211526\n3  foo    one -0.983776  1.614581\n4  foo  three -0.862495  0.024580\n5  foo    two  0.049851  1.185429\n\nIn [98]: df.groupby(\"A\", as_index=False)[[\"C\", \"D\"]].agg(\"sum\")\nOut[98]: \n A         C         D\n0  bar  0.392940  1.732707\n1  foo -1.796421  2.824590 \n```", "```py\nIn [99]: df.groupby([\"A\", \"B\"]).agg(\"sum\").reset_index()\nOut[99]: \n A      B         C         D\n0  bar    one  0.254161  1.511763\n1  bar  three  0.215897 -0.990582\n2  bar    two -0.077118  1.211526\n3  foo    one -0.983776  1.614581\n4  foo  three -0.862495  0.024580\n5  foo    two  0.049851  1.185429 \n```", "```py\nIn [100]: animals\nOut[100]: \n kind  height  weight\n0  cat     9.1     7.9\n1  dog     6.0     7.5\n2  cat     9.5     9.9\n3  dog    34.0   198.0\n\nIn [101]: animals.groupby(\"kind\")[[\"height\"]].agg(lambda x: set(x))\nOut[101]: \n height\nkind \ncat    {9.1, 9.5}\ndog   {34.0, 6.0} \n```", "```py\nIn [102]: animals.groupby(\"kind\")[[\"height\"]].agg(lambda x: x.astype(int).sum())\nOut[102]: \n height\nkind \ncat       18\ndog       40 \n```", "```py\nIn [103]: grouped = df.groupby(\"A\")\n\nIn [104]: grouped[\"C\"].agg([\"sum\", \"mean\", \"std\"])\nOut[104]: \n sum      mean       std\nA \nbar  0.392940  0.130980  0.181231\nfoo -1.796421 -0.359284  0.912265 \n```", "```py\nIn [105]: grouped[[\"C\", \"D\"]].agg([\"sum\", \"mean\", \"std\"])\nOut[105]: \n C                             D \n sum      mean       std       sum      mean       std\nA \nbar  0.392940  0.130980  0.181231  1.732707  0.577569  1.366330\nfoo -1.796421 -0.359284  0.912265  2.824590  0.564918  0.884785 \n```", "```py\nIn [106]: (\n .....:    grouped[\"C\"]\n .....:    .agg([\"sum\", \"mean\", \"std\"])\n .....:    .rename(columns={\"sum\": \"foo\", \"mean\": \"bar\", \"std\": \"baz\"})\n .....: )\n .....: \nOut[106]: \n foo       bar       baz\nA \nbar  0.392940  0.130980  0.181231\nfoo -1.796421 -0.359284  0.912265 \n```", "```py\nIn [107]: (\n .....:    grouped[[\"C\", \"D\"]].agg([\"sum\", \"mean\", \"std\"]).rename(\n .....:        columns={\"sum\": \"foo\", \"mean\": \"bar\", \"std\": \"baz\"}\n .....:    )\n .....: )\n .....: \nOut[107]: \n C                             D \n foo       bar       baz       foo       bar       baz\nA \nbar  0.392940  0.130980  0.181231  1.732707  0.577569  1.366330\nfoo -1.796421 -0.359284  0.912265  2.824590  0.564918  0.884785 \n```", "```py\nIn [108]: grouped[\"C\"].agg([\"sum\", \"sum\"])\nOut[108]: \n sum       sum\nA \nbar  0.392940  0.392940\nfoo -1.796421 -1.796421 \n```", "```py\nIn [109]: grouped[\"C\"].agg([lambda x: x.max() - x.min(), lambda x: x.median() - x.mean()])\nOut[109]: \n <lambda_0>  <lambda_1>\nA \nbar    0.331279    0.084917\nfoo    2.337259   -0.215962 \n```", "```py\nIn [110]: animals\nOut[110]: \n kind  height  weight\n0  cat     9.1     7.9\n1  dog     6.0     7.5\n2  cat     9.5     9.9\n3  dog    34.0   198.0\n\nIn [111]: animals.groupby(\"kind\").agg(\n .....:    min_height=pd.NamedAgg(column=\"height\", aggfunc=\"min\"),\n .....:    max_height=pd.NamedAgg(column=\"height\", aggfunc=\"max\"),\n .....:    average_weight=pd.NamedAgg(column=\"weight\", aggfunc=\"mean\"),\n .....: )\n .....: \nOut[111]: \n min_height  max_height  average_weight\nkind \ncat          9.1         9.5            8.90\ndog          6.0        34.0          102.75 \n```", "```py\nIn [112]: animals.groupby(\"kind\").agg(\n .....:    min_height=(\"height\", \"min\"),\n .....:    max_height=(\"height\", \"max\"),\n .....:    average_weight=(\"weight\", \"mean\"),\n .....: )\n .....: \nOut[112]: \n min_height  max_height  average_weight\nkind \ncat          9.1         9.5            8.90\ndog          6.0        34.0          102.75 \n```", "```py\nIn [113]: animals.groupby(\"kind\").agg(\n .....:    **{\n .....:        \"total weight\": pd.NamedAgg(column=\"weight\", aggfunc=\"sum\")\n .....:    }\n .....: )\n .....: \nOut[113]: \n total weight\nkind \ncat           17.8\ndog          205.5 \n```", "```py\nIn [114]: animals.groupby(\"kind\").height.agg(\n .....:    min_height=\"min\",\n .....:    max_height=\"max\",\n .....: )\n .....: \nOut[114]: \n min_height  max_height\nkind \ncat          9.1         9.5\ndog          6.0        34.0 \n```", "```py\nIn [115]: grouped.agg({\"C\": \"sum\", \"D\": lambda x: np.std(x, ddof=1)})\nOut[115]: \n C         D\nA \nbar  0.392940  1.366330\nfoo -1.796421  0.884785 \n```", "```py\nIn [116]: grouped.agg({\"C\": \"sum\", \"D\": \"std\"})\nOut[116]: \n C         D\nA \nbar  0.392940  1.366330\nfoo -1.796421  0.884785 \n```", "```py\nIn [117]: speeds\nOut[117]: \n class           order  max_speed\nfalcon     bird   Falconiformes      389.0\nparrot     bird  Psittaciformes       24.0\nlion     mammal       Carnivora       80.2\nmonkey   mammal        Primates        NaN\nleopard  mammal       Carnivora       58.0\n\nIn [118]: grouped = speeds.groupby(\"class\")[\"max_speed\"]\n\nIn [119]: grouped.cumsum()\nOut[119]: \nfalcon     389.0\nparrot     413.0\nlion        80.2\nmonkey       NaN\nleopard    138.2\nName: max_speed, dtype: float64\n\nIn [120]: grouped.diff()\nOut[120]: \nfalcon       NaN\nparrot    -365.0\nlion         NaN\nmonkey       NaN\nleopard      NaN\nName: max_speed, dtype: float64 \n```", "```py\nIn [121]: result = speeds.copy()\n\nIn [122]: result[\"cumsum\"] = grouped.cumsum()\n\nIn [123]: result[\"diff\"] = grouped.diff()\n\nIn [124]: result\nOut[124]: \n class           order  max_speed  cumsum   diff\nfalcon     bird   Falconiformes      389.0   389.0    NaN\nparrot     bird  Psittaciformes       24.0   413.0 -365.0\nlion     mammal       Carnivora       80.2    80.2    NaN\nmonkey   mammal        Primates        NaN     NaN    NaN\nleopard  mammal       Carnivora       58.0   138.2    NaN \n```", "```py\nIn [125]: speeds\nOut[125]: \n class           order  max_speed\nfalcon     bird   Falconiformes      389.0\nparrot     bird  Psittaciformes       24.0\nlion     mammal       Carnivora       80.2\nmonkey   mammal        Primates        NaN\nleopard  mammal       Carnivora       58.0\n\nIn [126]: grouped = speeds.groupby(\"class\")[[\"max_speed\"]]\n\nIn [127]: grouped.transform(\"cumsum\")\nOut[127]: \n max_speed\nfalcon       389.0\nparrot       413.0\nlion          80.2\nmonkey         NaN\nleopard      138.2\n\nIn [128]: grouped.transform(\"sum\")\nOut[128]: \n max_speed\nfalcon       413.0\nparrot       413.0\nlion         138.2\nmonkey       138.2\nleopard      138.2 \n```", "```py\nIn [129]: index = pd.date_range(\"10/1/1999\", periods=1100)\n\nIn [130]: ts = pd.Series(np.random.normal(0.5, 2, 1100), index)\n\nIn [131]: ts = ts.rolling(window=100, min_periods=100).mean().dropna()\n\nIn [132]: ts.head()\nOut[132]: \n2000-01-08    0.779333\n2000-01-09    0.778852\n2000-01-10    0.786476\n2000-01-11    0.782797\n2000-01-12    0.798110\nFreq: D, dtype: float64\n\nIn [133]: ts.tail()\nOut[133]: \n2002-09-30    0.660294\n2002-10-01    0.631095\n2002-10-02    0.673601\n2002-10-03    0.709213\n2002-10-04    0.719369\nFreq: D, dtype: float64\n\nIn [134]: transformed = ts.groupby(lambda x: x.year).transform(\n .....:    lambda x: (x - x.mean()) / x.std()\n .....: )\n .....: \n```", "```py\n# Original Data\nIn [135]: grouped = ts.groupby(lambda x: x.year)\n\nIn [136]: grouped.mean()\nOut[136]: \n2000    0.442441\n2001    0.526246\n2002    0.459365\ndtype: float64\n\nIn [137]: grouped.std()\nOut[137]: \n2000    0.131752\n2001    0.210945\n2002    0.128753\ndtype: float64\n\n# Transformed Data\nIn [138]: grouped_trans = transformed.groupby(lambda x: x.year)\n\nIn [139]: grouped_trans.mean()\nOut[139]: \n2000   -4.870756e-16\n2001   -1.545187e-16\n2002    4.136282e-16\ndtype: float64\n\nIn [140]: grouped_trans.std()\nOut[140]: \n2000    1.0\n2001    1.0\n2002    1.0\ndtype: float64 \n```", "```py\nIn [141]: compare = pd.DataFrame({\"Original\": ts, \"Transformed\": transformed})\n\nIn [142]: compare.plot()\nOut[142]: <Axes: > \n```", "```py\nIn [143]: ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())\nOut[143]: \n2000-01-08    0.623893\n2000-01-09    0.623893\n2000-01-10    0.623893\n2000-01-11    0.623893\n2000-01-12    0.623893\n ... \n2002-09-30    0.558275\n2002-10-01    0.558275\n2002-10-02    0.558275\n2002-10-03    0.558275\n2002-10-04    0.558275\nFreq: D, Length: 1001, dtype: float64 \n```", "```py\nIn [144]: cols = [\"A\", \"B\", \"C\"]\n\nIn [145]: values = np.random.randn(1000, 3)\n\nIn [146]: values[np.random.randint(0, 1000, 100), 0] = np.nan\n\nIn [147]: values[np.random.randint(0, 1000, 50), 1] = np.nan\n\nIn [148]: values[np.random.randint(0, 1000, 200), 2] = np.nan\n\nIn [149]: data_df = pd.DataFrame(values, columns=cols)\n\nIn [150]: data_df\nOut[150]: \n A         B         C\n0    1.539708 -1.166480  0.533026\n1    1.302092 -0.505754       NaN\n2   -0.371983  1.104803 -0.651520\n3   -1.309622  1.118697 -1.161657\n4   -1.924296  0.396437  0.812436\n..        ...       ...       ...\n995 -0.093110  0.683847 -0.774753\n996 -0.185043  1.438572       NaN\n997 -0.394469 -0.642343  0.011374\n998 -1.174126  1.857148       NaN\n999  0.234564  0.517098  0.393534\n\n[1000 rows x 3 columns]\n\nIn [151]: countries = np.array([\"US\", \"UK\", \"GR\", \"JP\"])\n\nIn [152]: key = countries[np.random.randint(0, 4, 1000)]\n\nIn [153]: grouped = data_df.groupby(key)\n\n# Non-NA count in each group\nIn [154]: grouped.count()\nOut[154]: \n A    B    C\nGR  209  217  189\nJP  240  255  217\nUK  216  231  193\nUS  239  250  217\n\nIn [155]: transformed = grouped.transform(lambda x: x.fillna(x.mean())) \n```", "```py\nIn [156]: grouped_trans = transformed.groupby(key)\n\nIn [157]: grouped.mean()  # original group means\nOut[157]: \n A         B         C\nGR -0.098371 -0.015420  0.068053\nJP  0.069025  0.023100 -0.077324\nUK  0.034069 -0.052580 -0.116525\nUS  0.058664 -0.020399  0.028603\n\nIn [158]: grouped_trans.mean()  # transformation did not change group means\nOut[158]: \n A         B         C\nGR -0.098371 -0.015420  0.068053\nJP  0.069025  0.023100 -0.077324\nUK  0.034069 -0.052580 -0.116525\nUS  0.058664 -0.020399  0.028603\n\nIn [159]: grouped.count()  # original has some missing data points\nOut[159]: \n A    B    C\nGR  209  217  189\nJP  240  255  217\nUK  216  231  193\nUS  239  250  217\n\nIn [160]: grouped_trans.count()  # counts after transformation\nOut[160]: \n A    B    C\nGR  228  228  228\nJP  267  267  267\nUK  247  247  247\nUS  258  258  258\n\nIn [161]: grouped_trans.size()  # Verify non-NA count equals group size\nOut[161]: \nGR    228\nJP    267\nUK    247\nUS    258\ndtype: int64 \n```", "```py\n# result = ts.groupby(lambda x: x.year).transform(\n#     lambda x: (x - x.mean()) / x.std()\n# )\nIn [162]: grouped = ts.groupby(lambda x: x.year)\n\nIn [163]: result = (ts - grouped.transform(\"mean\")) / grouped.transform(\"std\")\n\n# result = ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())\nIn [164]: grouped = ts.groupby(lambda x: x.year)\n\nIn [165]: result = grouped.transform(\"max\") - grouped.transform(\"min\")\n\n# grouped = data_df.groupby(key)\n# result = grouped.transform(lambda x: x.fillna(x.mean()))\nIn [166]: grouped = data_df.groupby(key)\n\nIn [167]: result = data_df.fillna(grouped.transform(\"mean\")) \n```", "```py\nIn [168]: df_re = pd.DataFrame({\"A\": [1] * 10 + [5] * 10, \"B\": np.arange(20)})\n\nIn [169]: df_re\nOut[169]: \n A   B\n0   1   0\n1   1   1\n2   1   2\n3   1   3\n4   1   4\n.. ..  ..\n15  5  15\n16  5  16\n17  5  17\n18  5  18\n19  5  19\n\n[20 rows x 2 columns]\n\nIn [170]: df_re.groupby(\"A\").rolling(4).B.mean()\nOut[170]: \nA \n1  0      NaN\n 1      NaN\n 2      NaN\n 3      1.5\n 4      2.5\n ... \n5  15    13.5\n 16    14.5\n 17    15.5\n 18    16.5\n 19    17.5\nName: B, Length: 20, dtype: float64 \n```", "```py\nIn [171]: df_re.groupby(\"A\").expanding().sum()\nOut[171]: \n B\nA \n1 0     0.0\n 1     1.0\n 2     3.0\n 3     6.0\n 4    10.0\n...     ...\n5 15   75.0\n 16   91.0\n 17  108.0\n 18  126.0\n 19  145.0\n\n[20 rows x 1 columns] \n```", "```py\nIn [172]: df_re = pd.DataFrame(\n .....:    {\n .....:        \"date\": pd.date_range(start=\"2016-01-01\", periods=4, freq=\"W\"),\n .....:        \"group\": [1, 1, 2, 2],\n .....:        \"val\": [5, 6, 7, 8],\n .....:    }\n .....: ).set_index(\"date\")\n .....: \n\nIn [173]: df_re\nOut[173]: \n group  val\ndate \n2016-01-03      1    5\n2016-01-10      1    6\n2016-01-17      2    7\n2016-01-24      2    8\n\nIn [174]: df_re.groupby(\"group\").resample(\"1D\", include_groups=False).ffill()\nOut[174]: \n val\ngroup date \n1     2016-01-03    5\n 2016-01-04    5\n 2016-01-05    5\n 2016-01-06    5\n 2016-01-07    5\n...               ...\n2     2016-01-20    7\n 2016-01-21    7\n 2016-01-22    7\n 2016-01-23    7\n 2016-01-24    8\n\n[16 rows x 1 columns] \n```", "```py\nIn [125]: speeds\nOut[125]: \n class           order  max_speed\nfalcon     bird   Falconiformes      389.0\nparrot     bird  Psittaciformes       24.0\nlion     mammal       Carnivora       80.2\nmonkey   mammal        Primates        NaN\nleopard  mammal       Carnivora       58.0\n\nIn [126]: grouped = speeds.groupby(\"class\")[[\"max_speed\"]]\n\nIn [127]: grouped.transform(\"cumsum\")\nOut[127]: \n max_speed\nfalcon       389.0\nparrot       413.0\nlion          80.2\nmonkey         NaN\nleopard      138.2\n\nIn [128]: grouped.transform(\"sum\")\nOut[128]: \n max_speed\nfalcon       413.0\nparrot       413.0\nlion         138.2\nmonkey       138.2\nleopard      138.2 \n```", "```py\nIn [129]: index = pd.date_range(\"10/1/1999\", periods=1100)\n\nIn [130]: ts = pd.Series(np.random.normal(0.5, 2, 1100), index)\n\nIn [131]: ts = ts.rolling(window=100, min_periods=100).mean().dropna()\n\nIn [132]: ts.head()\nOut[132]: \n2000-01-08    0.779333\n2000-01-09    0.778852\n2000-01-10    0.786476\n2000-01-11    0.782797\n2000-01-12    0.798110\nFreq: D, dtype: float64\n\nIn [133]: ts.tail()\nOut[133]: \n2002-09-30    0.660294\n2002-10-01    0.631095\n2002-10-02    0.673601\n2002-10-03    0.709213\n2002-10-04    0.719369\nFreq: D, dtype: float64\n\nIn [134]: transformed = ts.groupby(lambda x: x.year).transform(\n .....:    lambda x: (x - x.mean()) / x.std()\n .....: )\n .....: \n```", "```py\n# Original Data\nIn [135]: grouped = ts.groupby(lambda x: x.year)\n\nIn [136]: grouped.mean()\nOut[136]: \n2000    0.442441\n2001    0.526246\n2002    0.459365\ndtype: float64\n\nIn [137]: grouped.std()\nOut[137]: \n2000    0.131752\n2001    0.210945\n2002    0.128753\ndtype: float64\n\n# Transformed Data\nIn [138]: grouped_trans = transformed.groupby(lambda x: x.year)\n\nIn [139]: grouped_trans.mean()\nOut[139]: \n2000   -4.870756e-16\n2001   -1.545187e-16\n2002    4.136282e-16\ndtype: float64\n\nIn [140]: grouped_trans.std()\nOut[140]: \n2000    1.0\n2001    1.0\n2002    1.0\ndtype: float64 \n```", "```py\nIn [141]: compare = pd.DataFrame({\"Original\": ts, \"Transformed\": transformed})\n\nIn [142]: compare.plot()\nOut[142]: <Axes: > \n```", "```py\nIn [143]: ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())\nOut[143]: \n2000-01-08    0.623893\n2000-01-09    0.623893\n2000-01-10    0.623893\n2000-01-11    0.623893\n2000-01-12    0.623893\n ... \n2002-09-30    0.558275\n2002-10-01    0.558275\n2002-10-02    0.558275\n2002-10-03    0.558275\n2002-10-04    0.558275\nFreq: D, Length: 1001, dtype: float64 \n```", "```py\nIn [144]: cols = [\"A\", \"B\", \"C\"]\n\nIn [145]: values = np.random.randn(1000, 3)\n\nIn [146]: values[np.random.randint(0, 1000, 100), 0] = np.nan\n\nIn [147]: values[np.random.randint(0, 1000, 50), 1] = np.nan\n\nIn [148]: values[np.random.randint(0, 1000, 200), 2] = np.nan\n\nIn [149]: data_df = pd.DataFrame(values, columns=cols)\n\nIn [150]: data_df\nOut[150]: \n A         B         C\n0    1.539708 -1.166480  0.533026\n1    1.302092 -0.505754       NaN\n2   -0.371983  1.104803 -0.651520\n3   -1.309622  1.118697 -1.161657\n4   -1.924296  0.396437  0.812436\n..        ...       ...       ...\n995 -0.093110  0.683847 -0.774753\n996 -0.185043  1.438572       NaN\n997 -0.394469 -0.642343  0.011374\n998 -1.174126  1.857148       NaN\n999  0.234564  0.517098  0.393534\n\n[1000 rows x 3 columns]\n\nIn [151]: countries = np.array([\"US\", \"UK\", \"GR\", \"JP\"])\n\nIn [152]: key = countries[np.random.randint(0, 4, 1000)]\n\nIn [153]: grouped = data_df.groupby(key)\n\n# Non-NA count in each group\nIn [154]: grouped.count()\nOut[154]: \n A    B    C\nGR  209  217  189\nJP  240  255  217\nUK  216  231  193\nUS  239  250  217\n\nIn [155]: transformed = grouped.transform(lambda x: x.fillna(x.mean())) \n```", "```py\nIn [156]: grouped_trans = transformed.groupby(key)\n\nIn [157]: grouped.mean()  # original group means\nOut[157]: \n A         B         C\nGR -0.098371 -0.015420  0.068053\nJP  0.069025  0.023100 -0.077324\nUK  0.034069 -0.052580 -0.116525\nUS  0.058664 -0.020399  0.028603\n\nIn [158]: grouped_trans.mean()  # transformation did not change group means\nOut[158]: \n A         B         C\nGR -0.098371 -0.015420  0.068053\nJP  0.069025  0.023100 -0.077324\nUK  0.034069 -0.052580 -0.116525\nUS  0.058664 -0.020399  0.028603\n\nIn [159]: grouped.count()  # original has some missing data points\nOut[159]: \n A    B    C\nGR  209  217  189\nJP  240  255  217\nUK  216  231  193\nUS  239  250  217\n\nIn [160]: grouped_trans.count()  # counts after transformation\nOut[160]: \n A    B    C\nGR  228  228  228\nJP  267  267  267\nUK  247  247  247\nUS  258  258  258\n\nIn [161]: grouped_trans.size()  # Verify non-NA count equals group size\nOut[161]: \nGR    228\nJP    267\nUK    247\nUS    258\ndtype: int64 \n```", "```py\n# result = ts.groupby(lambda x: x.year).transform(\n#     lambda x: (x - x.mean()) / x.std()\n# )\nIn [162]: grouped = ts.groupby(lambda x: x.year)\n\nIn [163]: result = (ts - grouped.transform(\"mean\")) / grouped.transform(\"std\")\n\n# result = ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())\nIn [164]: grouped = ts.groupby(lambda x: x.year)\n\nIn [165]: result = grouped.transform(\"max\") - grouped.transform(\"min\")\n\n# grouped = data_df.groupby(key)\n# result = grouped.transform(lambda x: x.fillna(x.mean()))\nIn [166]: grouped = data_df.groupby(key)\n\nIn [167]: result = data_df.fillna(grouped.transform(\"mean\")) \n```", "```py\nIn [168]: df_re = pd.DataFrame({\"A\": [1] * 10 + [5] * 10, \"B\": np.arange(20)})\n\nIn [169]: df_re\nOut[169]: \n A   B\n0   1   0\n1   1   1\n2   1   2\n3   1   3\n4   1   4\n.. ..  ..\n15  5  15\n16  5  16\n17  5  17\n18  5  18\n19  5  19\n\n[20 rows x 2 columns]\n\nIn [170]: df_re.groupby(\"A\").rolling(4).B.mean()\nOut[170]: \nA \n1  0      NaN\n 1      NaN\n 2      NaN\n 3      1.5\n 4      2.5\n ... \n5  15    13.5\n 16    14.5\n 17    15.5\n 18    16.5\n 19    17.5\nName: B, Length: 20, dtype: float64 \n```", "```py\nIn [171]: df_re.groupby(\"A\").expanding().sum()\nOut[171]: \n B\nA \n1 0     0.0\n 1     1.0\n 2     3.0\n 3     6.0\n 4    10.0\n...     ...\n5 15   75.0\n 16   91.0\n 17  108.0\n 18  126.0\n 19  145.0\n\n[20 rows x 1 columns] \n```", "```py\nIn [172]: df_re = pd.DataFrame(\n .....:    {\n .....:        \"date\": pd.date_range(start=\"2016-01-01\", periods=4, freq=\"W\"),\n .....:        \"group\": [1, 1, 2, 2],\n .....:        \"val\": [5, 6, 7, 8],\n .....:    }\n .....: ).set_index(\"date\")\n .....: \n\nIn [173]: df_re\nOut[173]: \n group  val\ndate \n2016-01-03      1    5\n2016-01-10      1    6\n2016-01-17      2    7\n2016-01-24      2    8\n\nIn [174]: df_re.groupby(\"group\").resample(\"1D\", include_groups=False).ffill()\nOut[174]: \n val\ngroup date \n1     2016-01-03    5\n 2016-01-04    5\n 2016-01-05    5\n 2016-01-06    5\n 2016-01-07    5\n...               ...\n2     2016-01-20    7\n 2016-01-21    7\n 2016-01-22    7\n 2016-01-23    7\n 2016-01-24    8\n\n[16 rows x 1 columns] \n```", "```py\nIn [175]: speeds\nOut[175]: \n class           order  max_speed\nfalcon     bird   Falconiformes      389.0\nparrot     bird  Psittaciformes       24.0\nlion     mammal       Carnivora       80.2\nmonkey   mammal        Primates        NaN\nleopard  mammal       Carnivora       58.0\n\nIn [176]: speeds.groupby(\"class\").nth(1)\nOut[176]: \n class           order  max_speed\nparrot    bird  Psittaciformes       24.0\nmonkey  mammal        Primates        NaN \n```", "```py\nIn [177]: speeds.groupby(\"class\")[[\"order\", \"max_speed\"]].nth(1)\nOut[177]: \n order  max_speed\nparrot  Psittaciformes       24.0\nmonkey        Primates        NaN \n```", "```py\nIn [178]: product_volumes = pd.DataFrame(\n .....:    {\n .....:        \"group\": list(\"xxxxyyy\"),\n .....:        \"product\": list(\"abcdefg\"),\n .....:        \"volume\": [10, 30, 20, 15, 40, 10, 20],\n .....:    }\n .....: )\n .....: \n\nIn [179]: product_volumes\nOut[179]: \n group product  volume\n0     x       a      10\n1     x       b      30\n2     x       c      20\n3     x       d      15\n4     y       e      40\n5     y       f      10\n6     y       g      20\n\n# Sort by volume to select the largest products first\nIn [180]: product_volumes = product_volumes.sort_values(\"volume\", ascending=False)\n\nIn [181]: grouped = product_volumes.groupby(\"group\")[\"volume\"]\n\nIn [182]: cumpct = grouped.cumsum() / grouped.transform(\"sum\")\n\nIn [183]: cumpct\nOut[183]: \n4    0.571429\n1    0.400000\n2    0.666667\n6    0.857143\n3    0.866667\n0    1.000000\n5    1.000000\nName: volume, dtype: float64\n\nIn [184]: significant_products = product_volumes[cumpct <= 0.9]\n\nIn [185]: significant_products.sort_values([\"group\", \"product\"])\nOut[185]: \n group product  volume\n1     x       b      30\n2     x       c      20\n3     x       d      15\n4     y       e      40\n6     y       g      20 \n```", "```py\nIn [186]: sf = pd.Series([1, 1, 2, 3, 3, 3])\n\nIn [187]: sf.groupby(sf).filter(lambda x: x.sum() > 2)\nOut[187]: \n3    3\n4    3\n5    3\ndtype: int64 \n```", "```py\nIn [188]: dff = pd.DataFrame({\"A\": np.arange(8), \"B\": list(\"aabbbbcc\")})\n\nIn [189]: dff.groupby(\"B\").filter(lambda x: len(x) > 2)\nOut[189]: \n A  B\n2  2  b\n3  3  b\n4  4  b\n5  5  b \n```", "```py\nIn [190]: dff.groupby(\"B\").filter(lambda x: len(x) > 2, dropna=False)\nOut[190]: \n A    B\n0  NaN  NaN\n1  NaN  NaN\n2  2.0    b\n3  3.0    b\n4  4.0    b\n5  5.0    b\n6  NaN  NaN\n7  NaN  NaN \n```", "```py\nIn [191]: dff[\"C\"] = np.arange(8)\n\nIn [192]: dff.groupby(\"B\").filter(lambda x: len(x[\"C\"]) > 2)\nOut[192]: \n A  B  C\n2  2  b  2\n3  3  b  3\n4  4  b  4\n5  5  b  5 \n```", "```py\nIn [178]: product_volumes = pd.DataFrame(\n .....:    {\n .....:        \"group\": list(\"xxxxyyy\"),\n .....:        \"product\": list(\"abcdefg\"),\n .....:        \"volume\": [10, 30, 20, 15, 40, 10, 20],\n .....:    }\n .....: )\n .....: \n\nIn [179]: product_volumes\nOut[179]: \n group product  volume\n0     x       a      10\n1     x       b      30\n2     x       c      20\n3     x       d      15\n4     y       e      40\n5     y       f      10\n6     y       g      20\n\n# Sort by volume to select the largest products first\nIn [180]: product_volumes = product_volumes.sort_values(\"volume\", ascending=False)\n\nIn [181]: grouped = product_volumes.groupby(\"group\")[\"volume\"]\n\nIn [182]: cumpct = grouped.cumsum() / grouped.transform(\"sum\")\n\nIn [183]: cumpct\nOut[183]: \n4    0.571429\n1    0.400000\n2    0.666667\n6    0.857143\n3    0.866667\n0    1.000000\n5    1.000000\nName: volume, dtype: float64\n\nIn [184]: significant_products = product_volumes[cumpct <= 0.9]\n\nIn [185]: significant_products.sort_values([\"group\", \"product\"])\nOut[185]: \n group product  volume\n1     x       b      30\n2     x       c      20\n3     x       d      15\n4     y       e      40\n6     y       g      20 \n```", "```py\nIn [186]: sf = pd.Series([1, 1, 2, 3, 3, 3])\n\nIn [187]: sf.groupby(sf).filter(lambda x: x.sum() > 2)\nOut[187]: \n3    3\n4    3\n5    3\ndtype: int64 \n```", "```py\nIn [188]: dff = pd.DataFrame({\"A\": np.arange(8), \"B\": list(\"aabbbbcc\")})\n\nIn [189]: dff.groupby(\"B\").filter(lambda x: len(x) > 2)\nOut[189]: \n A  B\n2  2  b\n3  3  b\n4  4  b\n5  5  b \n```", "```py\nIn [190]: dff.groupby(\"B\").filter(lambda x: len(x) > 2, dropna=False)\nOut[190]: \n A    B\n0  NaN  NaN\n1  NaN  NaN\n2  2.0    b\n3  3.0    b\n4  4.0    b\n5  5.0    b\n6  NaN  NaN\n7  NaN  NaN \n```", "```py\nIn [191]: dff[\"C\"] = np.arange(8)\n\nIn [192]: dff.groupby(\"B\").filter(lambda x: len(x[\"C\"]) > 2)\nOut[192]: \n A  B  C\n2  2  b  2\n3  3  b  3\n4  4  b  4\n5  5  b  5 \n```", "```py\nIn [193]: df\nOut[193]: \n A      B         C         D\n0  foo    one -0.575247  1.346061\n1  bar    one  0.254161  1.511763\n2  foo    two -1.143704  1.627081\n3  bar  three  0.215897 -0.990582\n4  foo    two  1.193555 -0.441652\n5  bar    two -0.077118  1.211526\n6  foo    one -0.408530  0.268520\n7  foo  three -0.862495  0.024580\n\nIn [194]: grouped = df.groupby(\"A\")\n\n# could also just call .describe()\nIn [195]: grouped[\"C\"].apply(lambda x: x.describe())\nOut[195]: \nA \nbar  count    3.000000\n mean     0.130980\n std      0.181231\n min     -0.077118\n 25%      0.069390\n ... \nfoo  min     -1.143704\n 25%     -0.862495\n 50%     -0.575247\n 75%     -0.408530\n max      1.193555\nName: C, Length: 16, dtype: float64 \n```", "```py\nIn [196]: grouped = df.groupby('A')['C']\n\nIn [197]: def f(group):\n .....:    return pd.DataFrame({'original': group,\n .....:                         'demeaned': group - group.mean()})\n .....: \n\nIn [198]: grouped.apply(f)\nOut[198]: \n original  demeaned\nA \nbar 1  0.254161  0.123181\n 3  0.215897  0.084917\n 5 -0.077118 -0.208098\nfoo 0 -0.575247 -0.215962\n 2 -1.143704 -0.784420\n 4  1.193555  1.552839\n 6 -0.408530 -0.049245\n 7 -0.862495 -0.503211 \n```", "```py\nIn [199]: def f(x):\n .....:    return pd.Series([x, x ** 2], index=[\"x\", \"x^2\"])\n .....: \n\nIn [200]: s = pd.Series(np.random.rand(5))\n\nIn [201]: s\nOut[201]: \n0    0.582898\n1    0.098352\n2    0.001438\n3    0.009420\n4    0.815826\ndtype: float64\n\nIn [202]: s.apply(f)\nOut[202]: \n x       x^2\n0  0.582898  0.339770\n1  0.098352  0.009673\n2  0.001438  0.000002\n3  0.009420  0.000089\n4  0.815826  0.665572 \n```", "```py\nIn [203]: df.groupby(\"A\", group_keys=True).apply(lambda x: x, include_groups=False)\nOut[203]: \n B         C         D\nA \nbar 1    one  0.254161  1.511763\n 3  three  0.215897 -0.990582\n 5    two -0.077118  1.211526\nfoo 0    one -0.575247  1.346061\n 2    two -1.143704  1.627081\n 4    two  1.193555 -0.441652\n 6    one -0.408530  0.268520\n 7  three -0.862495  0.024580 \n```", "```py\nIn [204]: df.groupby(\"A\", group_keys=False).apply(lambda x: x, include_groups=False)\nOut[204]: \n B         C         D\n0    one -0.575247  1.346061\n1    one  0.254161  1.511763\n2    two -1.143704  1.627081\n3  three  0.215897 -0.990582\n4    two  1.193555 -0.441652\n5    two -0.077118  1.211526\n6    one -0.408530  0.268520\n7  three -0.862495  0.024580 \n```", "```py\nIn [203]: df.groupby(\"A\", group_keys=True).apply(lambda x: x, include_groups=False)\nOut[203]: \n B         C         D\nA \nbar 1    one  0.254161  1.511763\n 3  three  0.215897 -0.990582\n 5    two -0.077118  1.211526\nfoo 0    one -0.575247  1.346061\n 2    two -1.143704  1.627081\n 4    two  1.193555 -0.441652\n 6    one -0.408530  0.268520\n 7  three -0.862495  0.024580 \n```", "```py\nIn [204]: df.groupby(\"A\", group_keys=False).apply(lambda x: x, include_groups=False)\nOut[204]: \n B         C         D\n0    one -0.575247  1.346061\n1    one  0.254161  1.511763\n2    two -1.143704  1.627081\n3  three  0.215897 -0.990582\n4    two  1.193555 -0.441652\n5    two -0.077118  1.211526\n6    one -0.408530  0.268520\n7  three -0.862495  0.024580 \n```", "```py\nIn [205]: df\nOut[205]: \n A      B         C         D\n0  foo    one -0.575247  1.346061\n1  bar    one  0.254161  1.511763\n2  foo    two -1.143704  1.627081\n3  bar  three  0.215897 -0.990582\n4  foo    two  1.193555 -0.441652\n5  bar    two -0.077118  1.211526\n6  foo    one -0.408530  0.268520\n7  foo  three -0.862495  0.024580 \n```", "```py\nIn [206]: df.groupby(\"A\").std(numeric_only=True)\nOut[206]: \n C         D\nA \nbar  0.181231  1.366330\nfoo  0.912265  0.884785 \n```", "```py\nIn [207]: from decimal import Decimal\n\nIn [208]: df_dec = pd.DataFrame(\n .....:    {\n .....:        \"id\": [1, 2, 1, 2],\n .....:        \"int_column\": [1, 2, 3, 4],\n .....:        \"dec_column\": [\n .....:            Decimal(\"0.50\"),\n .....:            Decimal(\"0.15\"),\n .....:            Decimal(\"0.25\"),\n .....:            Decimal(\"0.40\"),\n .....:        ],\n .....:    }\n .....: )\n .....: \n\nIn [209]: df_dec.groupby([\"id\"])[[\"dec_column\"]].sum()\nOut[209]: \n dec_column\nid \n1        0.75\n2        0.55 \n```", "```py\nIn [210]: pd.Series([1, 1, 1]).groupby(\n .....:    pd.Categorical([\"a\", \"a\", \"a\"], categories=[\"a\", \"b\"]), observed=False\n .....: ).count()\n .....: \nOut[210]: \na    3\nb    0\ndtype: int64 \n```", "```py\nIn [211]: pd.Series([1, 1, 1]).groupby(\n .....:    pd.Categorical([\"a\", \"a\", \"a\"], categories=[\"a\", \"b\"]), observed=True\n .....: ).count()\n .....: \nOut[211]: \na    3\ndtype: int64 \n```", "```py\nIn [212]: s = (\n .....:    pd.Series([1, 1, 1])\n .....:    .groupby(pd.Categorical([\"a\", \"a\", \"a\"], categories=[\"a\", \"b\"]), observed=True)\n .....:    .count()\n .....: )\n .....: \n\nIn [213]: s.index.dtype\nOut[213]: CategoricalDtype(categories=['a', 'b'], ordered=False, categories_dtype=object) \n```", "```py\nIn [214]: df = pd.DataFrame({\"key\": [1.0, 1.0, np.nan, 2.0, np.nan], \"A\": [1, 2, 3, 4, 5]})\n\nIn [215]: df\nOut[215]: \n key  A\n0  1.0  1\n1  1.0  2\n2  NaN  3\n3  2.0  4\n4  NaN  5\n\nIn [216]: df.groupby(\"key\", dropna=True).sum()\nOut[216]: \n A\nkey \n1.0  3\n2.0  4\n\nIn [217]: df.groupby(\"key\", dropna=False).sum()\nOut[217]: \n A\nkey \n1.0  3\n2.0  4\nNaN  8 \n```", "```py\nIn [218]: days = pd.Categorical(\n .....:    values=[\"Wed\", \"Mon\", \"Thu\", \"Mon\", \"Wed\", \"Sat\"],\n .....:    categories=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"],\n .....: )\n .....: \n\nIn [219]: data = pd.DataFrame(\n .....:   {\n .....:       \"day\": days,\n .....:       \"workers\": [3, 4, 1, 4, 2, 2],\n .....:   }\n .....: )\n .....: \n\nIn [220]: data\nOut[220]: \n day  workers\n0  Wed        3\n1  Mon        4\n2  Thu        1\n3  Mon        4\n4  Wed        2\n5  Sat        2\n\nIn [221]: data.groupby(\"day\", observed=False, sort=True).sum()\nOut[221]: \n workers\nday \nMon        8\nTue        0\nWed        5\nThu        1\nFri        0\nSat        2\nSun        0\n\nIn [222]: data.groupby(\"day\", observed=False, sort=False).sum()\nOut[222]: \n workers\nday \nWed        5\nMon        8\nThu        1\nSat        2\nTue        0\nFri        0\nSun        0 \n```", "```py\nIn [223]: import datetime\n\nIn [224]: df = pd.DataFrame(\n .....:    {\n .....:        \"Branch\": \"A A A A A A A B\".split(),\n .....:        \"Buyer\": \"Carl Mark Carl Carl Joe Joe Joe Carl\".split(),\n .....:        \"Quantity\": [1, 3, 5, 1, 8, 1, 9, 3],\n .....:        \"Date\": [\n .....:            datetime.datetime(2013, 1, 1, 13, 0),\n .....:            datetime.datetime(2013, 1, 1, 13, 5),\n .....:            datetime.datetime(2013, 10, 1, 20, 0),\n .....:            datetime.datetime(2013, 10, 2, 10, 0),\n .....:            datetime.datetime(2013, 10, 1, 20, 0),\n .....:            datetime.datetime(2013, 10, 2, 10, 0),\n .....:            datetime.datetime(2013, 12, 2, 12, 0),\n .....:            datetime.datetime(2013, 12, 2, 14, 0),\n .....:        ],\n .....:    }\n .....: )\n .....: \n\nIn [225]: df\nOut[225]: \n Branch Buyer  Quantity                Date\n0      A  Carl         1 2013-01-01 13:00:00\n1      A  Mark         3 2013-01-01 13:05:00\n2      A  Carl         5 2013-10-01 20:00:00\n3      A  Carl         1 2013-10-02 10:00:00\n4      A   Joe         8 2013-10-01 20:00:00\n5      A   Joe         1 2013-10-02 10:00:00\n6      A   Joe         9 2013-12-02 12:00:00\n7      B  Carl         3 2013-12-02 14:00:00 \n```", "```py\nIn [226]: df.groupby([pd.Grouper(freq=\"1ME\", key=\"Date\"), \"Buyer\"])[[\"Quantity\"]].sum()\nOut[226]: \n Quantity\nDate       Buyer \n2013-01-31 Carl          1\n Mark          3\n2013-10-31 Carl          6\n Joe           9\n2013-12-31 Carl          3\n Joe           9 \n```", "```py\nIn [227]: df = df.set_index(\"Date\")\n\nIn [228]: df[\"Date\"] = df.index + pd.offsets.MonthEnd(2)\n\nIn [229]: df.groupby([pd.Grouper(freq=\"6ME\", key=\"Date\"), \"Buyer\"])[[\"Quantity\"]].sum()\nOut[229]: \n Quantity\nDate       Buyer \n2013-02-28 Carl          1\n Mark          3\n2014-02-28 Carl          9\n Joe          18\n\nIn [230]: df.groupby([pd.Grouper(freq=\"6ME\", level=\"Date\"), \"Buyer\"])[[\"Quantity\"]].sum()\nOut[230]: \n Quantity\nDate       Buyer \n2013-01-31 Carl          1\n Mark          3\n2014-01-31 Carl          9\n Joe          18 \n```", "```py\nIn [231]: df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=[\"A\", \"B\"])\n\nIn [232]: df\nOut[232]: \n A  B\n0  1  2\n1  1  4\n2  5  6\n\nIn [233]: g = df.groupby(\"A\")\n\nIn [234]: g.head(1)\nOut[234]: \n A  B\n0  1  2\n2  5  6\n\nIn [235]: g.tail(1)\nOut[235]: \n A  B\n1  1  4\n2  5  6 \n```", "```py\nIn [236]: df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=[\"A\", \"B\"])\n\nIn [237]: g = df.groupby(\"A\")\n\nIn [238]: g.nth(0)\nOut[238]: \n A    B\n0  1  NaN\n2  5  6.0\n\nIn [239]: g.nth(-1)\nOut[239]: \n A    B\n1  1  4.0\n2  5  6.0\n\nIn [240]: g.nth(1)\nOut[240]: \n A    B\n1  1  4.0 \n```", "```py\nIn [241]: g.nth(5)\nOut[241]: \nEmpty DataFrame\nColumns: [A, B]\nIndex: [] \n```", "```py\n# nth(0) is the same as g.first()\nIn [242]: g.nth(0, dropna=\"any\")\nOut[242]: \n A    B\n1  1  4.0\n2  5  6.0\n\nIn [243]: g.first()\nOut[243]: \n B\nA \n1  4.0\n5  6.0\n\n# nth(-1) is the same as g.last()\nIn [244]: g.nth(-1, dropna=\"any\")\nOut[244]: \n A    B\n1  1  4.0\n2  5  6.0\n\nIn [245]: g.last()\nOut[245]: \n B\nA \n1  4.0\n5  6.0\n\nIn [246]: g.B.nth(0, dropna=\"all\")\nOut[246]: \n1    4.0\n2    6.0\nName: B, dtype: float64 \n```", "```py\nIn [247]: business_dates = pd.date_range(start=\"4/1/2014\", end=\"6/30/2014\", freq=\"B\")\n\nIn [248]: df = pd.DataFrame(1, index=business_dates, columns=[\"a\", \"b\"])\n\n# get the first, 4th, and last date index for each month\nIn [249]: df.groupby([df.index.year, df.index.month]).nth([0, 3, -1])\nOut[249]: \n a  b\n2014-04-01  1  1\n2014-04-04  1  1\n2014-04-30  1  1\n2014-05-01  1  1\n2014-05-06  1  1\n2014-05-30  1  1\n2014-06-02  1  1\n2014-06-05  1  1\n2014-06-30  1  1 \n```", "```py\nIn [250]: df.groupby([df.index.year, df.index.month]).nth[1:]\nOut[250]: \n a  b\n2014-04-02  1  1\n2014-04-03  1  1\n2014-04-04  1  1\n2014-04-07  1  1\n2014-04-08  1  1\n...        .. ..\n2014-06-24  1  1\n2014-06-25  1  1\n2014-06-26  1  1\n2014-06-27  1  1\n2014-06-30  1  1\n\n[62 rows x 2 columns]\n\nIn [251]: df.groupby([df.index.year, df.index.month]).nth[1:, :-1]\nOut[251]: \n a  b\n2014-04-01  1  1\n2014-04-02  1  1\n2014-04-03  1  1\n2014-04-04  1  1\n2014-04-07  1  1\n...        .. ..\n2014-06-24  1  1\n2014-06-25  1  1\n2014-06-26  1  1\n2014-06-27  1  1\n2014-06-30  1  1\n\n[65 rows x 2 columns] \n```", "```py\nIn [252]: dfg = pd.DataFrame(list(\"aaabba\"), columns=[\"A\"])\n\nIn [253]: dfg\nOut[253]: \n A\n0  a\n1  a\n2  a\n3  b\n4  b\n5  a\n\nIn [254]: dfg.groupby(\"A\").cumcount()\nOut[254]: \n0    0\n1    1\n2    2\n3    0\n4    1\n5    3\ndtype: int64\n\nIn [255]: dfg.groupby(\"A\").cumcount(ascending=False)\nOut[255]: \n0    3\n1    2\n2    1\n3    1\n4    0\n5    0\ndtype: int64 \n```", "```py\nIn [256]: dfg = pd.DataFrame(list(\"aaabba\"), columns=[\"A\"])\n\nIn [257]: dfg\nOut[257]: \n A\n0  a\n1  a\n2  a\n3  b\n4  b\n5  a\n\nIn [258]: dfg.groupby(\"A\").ngroup()\nOut[258]: \n0    0\n1    0\n2    0\n3    1\n4    1\n5    0\ndtype: int64\n\nIn [259]: dfg.groupby(\"A\").ngroup(ascending=False)\nOut[259]: \n0    1\n1    1\n2    1\n3    0\n4    0\n5    1\ndtype: int64 \n```", "```py\nIn [260]: np.random.seed(1234)\n\nIn [261]: df = pd.DataFrame(np.random.randn(50, 2))\n\nIn [262]: df[\"g\"] = np.random.choice([\"A\", \"B\"], size=50)\n\nIn [263]: df.loc[df[\"g\"] == \"B\", 1] += 3 \n```", "```py\nIn [264]: df.groupby(\"g\").boxplot()\nOut[264]: \nA         Axes(0.1,0.15;0.363636x0.75)\nB    Axes(0.536364,0.15;0.363636x0.75)\ndtype: object \n```", "```py\nIn [265]: n = 1000\n\nIn [266]: df = pd.DataFrame(\n .....:    {\n .....:        \"Store\": np.random.choice([\"Store_1\", \"Store_2\"], n),\n .....:        \"Product\": np.random.choice([\"Product_1\", \"Product_2\"], n),\n .....:        \"Revenue\": (np.random.random(n) * 50 + 10).round(2),\n .....:        \"Quantity\": np.random.randint(1, 10, size=n),\n .....:    }\n .....: )\n .....: \n\nIn [267]: df.head(2)\nOut[267]: \n Store    Product  Revenue  Quantity\n0  Store_2  Product_1    26.12         1\n1  Store_2  Product_1    28.86         1 \n```", "```py\nIn [268]: (\n .....:    df.groupby([\"Store\", \"Product\"])\n .....:    .pipe(lambda grp: grp.Revenue.sum() / grp.Quantity.sum())\n .....:    .unstack()\n .....:    .round(2)\n .....: )\n .....: \nOut[268]: \nProduct  Product_1  Product_2\nStore \nStore_1       6.82       7.05\nStore_2       6.30       6.64 \n```", "```py\nIn [269]: def mean(groupby):\n .....:    return groupby.mean()\n .....: \n\nIn [270]: df.groupby([\"Store\", \"Product\"]).pipe(mean)\nOut[270]: \n Revenue  Quantity\nStore   Product \nStore_1 Product_1  34.622727  5.075758\n Product_2  35.482815  5.029630\nStore_2 Product_1  32.972837  5.237589\n Product_2  34.684360  5.224000 \n```", "```py\nIn [205]: df\nOut[205]: \n A      B         C         D\n0  foo    one -0.575247  1.346061\n1  bar    one  0.254161  1.511763\n2  foo    two -1.143704  1.627081\n3  bar  three  0.215897 -0.990582\n4  foo    two  1.193555 -0.441652\n5  bar    two -0.077118  1.211526\n6  foo    one -0.408530  0.268520\n7  foo  three -0.862495  0.024580 \n```", "```py\nIn [206]: df.groupby(\"A\").std(numeric_only=True)\nOut[206]: \n C         D\nA \nbar  0.181231  1.366330\nfoo  0.912265  0.884785 \n```", "```py\nIn [207]: from decimal import Decimal\n\nIn [208]: df_dec = pd.DataFrame(\n .....:    {\n .....:        \"id\": [1, 2, 1, 2],\n .....:        \"int_column\": [1, 2, 3, 4],\n .....:        \"dec_column\": [\n .....:            Decimal(\"0.50\"),\n .....:            Decimal(\"0.15\"),\n .....:            Decimal(\"0.25\"),\n .....:            Decimal(\"0.40\"),\n .....:        ],\n .....:    }\n .....: )\n .....: \n\nIn [209]: df_dec.groupby([\"id\"])[[\"dec_column\"]].sum()\nOut[209]: \n dec_column\nid \n1        0.75\n2        0.55 \n```", "```py\nIn [210]: pd.Series([1, 1, 1]).groupby(\n .....:    pd.Categorical([\"a\", \"a\", \"a\"], categories=[\"a\", \"b\"]), observed=False\n .....: ).count()\n .....: \nOut[210]: \na    3\nb    0\ndtype: int64 \n```", "```py\nIn [211]: pd.Series([1, 1, 1]).groupby(\n .....:    pd.Categorical([\"a\", \"a\", \"a\"], categories=[\"a\", \"b\"]), observed=True\n .....: ).count()\n .....: \nOut[211]: \na    3\ndtype: int64 \n```", "```py\nIn [212]: s = (\n .....:    pd.Series([1, 1, 1])\n .....:    .groupby(pd.Categorical([\"a\", \"a\", \"a\"], categories=[\"a\", \"b\"]), observed=True)\n .....:    .count()\n .....: )\n .....: \n\nIn [213]: s.index.dtype\nOut[213]: CategoricalDtype(categories=['a', 'b'], ordered=False, categories_dtype=object) \n```", "```py\nIn [214]: df = pd.DataFrame({\"key\": [1.0, 1.0, np.nan, 2.0, np.nan], \"A\": [1, 2, 3, 4, 5]})\n\nIn [215]: df\nOut[215]: \n key  A\n0  1.0  1\n1  1.0  2\n2  NaN  3\n3  2.0  4\n4  NaN  5\n\nIn [216]: df.groupby(\"key\", dropna=True).sum()\nOut[216]: \n A\nkey \n1.0  3\n2.0  4\n\nIn [217]: df.groupby(\"key\", dropna=False).sum()\nOut[217]: \n A\nkey \n1.0  3\n2.0  4\nNaN  8 \n```", "```py\nIn [218]: days = pd.Categorical(\n .....:    values=[\"Wed\", \"Mon\", \"Thu\", \"Mon\", \"Wed\", \"Sat\"],\n .....:    categories=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"],\n .....: )\n .....: \n\nIn [219]: data = pd.DataFrame(\n .....:   {\n .....:       \"day\": days,\n .....:       \"workers\": [3, 4, 1, 4, 2, 2],\n .....:   }\n .....: )\n .....: \n\nIn [220]: data\nOut[220]: \n day  workers\n0  Wed        3\n1  Mon        4\n2  Thu        1\n3  Mon        4\n4  Wed        2\n5  Sat        2\n\nIn [221]: data.groupby(\"day\", observed=False, sort=True).sum()\nOut[221]: \n workers\nday \nMon        8\nTue        0\nWed        5\nThu        1\nFri        0\nSat        2\nSun        0\n\nIn [222]: data.groupby(\"day\", observed=False, sort=False).sum()\nOut[222]: \n workers\nday \nWed        5\nMon        8\nThu        1\nSat        2\nTue        0\nFri        0\nSun        0 \n```", "```py\nIn [223]: import datetime\n\nIn [224]: df = pd.DataFrame(\n .....:    {\n .....:        \"Branch\": \"A A A A A A A B\".split(),\n .....:        \"Buyer\": \"Carl Mark Carl Carl Joe Joe Joe Carl\".split(),\n .....:        \"Quantity\": [1, 3, 5, 1, 8, 1, 9, 3],\n .....:        \"Date\": [\n .....:            datetime.datetime(2013, 1, 1, 13, 0),\n .....:            datetime.datetime(2013, 1, 1, 13, 5),\n .....:            datetime.datetime(2013, 10, 1, 20, 0),\n .....:            datetime.datetime(2013, 10, 2, 10, 0),\n .....:            datetime.datetime(2013, 10, 1, 20, 0),\n .....:            datetime.datetime(2013, 10, 2, 10, 0),\n .....:            datetime.datetime(2013, 12, 2, 12, 0),\n .....:            datetime.datetime(2013, 12, 2, 14, 0),\n .....:        ],\n .....:    }\n .....: )\n .....: \n\nIn [225]: df\nOut[225]: \n Branch Buyer  Quantity                Date\n0      A  Carl         1 2013-01-01 13:00:00\n1      A  Mark         3 2013-01-01 13:05:00\n2      A  Carl         5 2013-10-01 20:00:00\n3      A  Carl         1 2013-10-02 10:00:00\n4      A   Joe         8 2013-10-01 20:00:00\n5      A   Joe         1 2013-10-02 10:00:00\n6      A   Joe         9 2013-12-02 12:00:00\n7      B  Carl         3 2013-12-02 14:00:00 \n```", "```py\nIn [226]: df.groupby([pd.Grouper(freq=\"1ME\", key=\"Date\"), \"Buyer\"])[[\"Quantity\"]].sum()\nOut[226]: \n Quantity\nDate       Buyer \n2013-01-31 Carl          1\n Mark          3\n2013-10-31 Carl          6\n Joe           9\n2013-12-31 Carl          3\n Joe           9 \n```", "```py\nIn [227]: df = df.set_index(\"Date\")\n\nIn [228]: df[\"Date\"] = df.index + pd.offsets.MonthEnd(2)\n\nIn [229]: df.groupby([pd.Grouper(freq=\"6ME\", key=\"Date\"), \"Buyer\"])[[\"Quantity\"]].sum()\nOut[229]: \n Quantity\nDate       Buyer \n2013-02-28 Carl          1\n Mark          3\n2014-02-28 Carl          9\n Joe          18\n\nIn [230]: df.groupby([pd.Grouper(freq=\"6ME\", level=\"Date\"), \"Buyer\"])[[\"Quantity\"]].sum()\nOut[230]: \n Quantity\nDate       Buyer \n2013-01-31 Carl          1\n Mark          3\n2014-01-31 Carl          9\n Joe          18 \n```", "```py\nIn [231]: df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=[\"A\", \"B\"])\n\nIn [232]: df\nOut[232]: \n A  B\n0  1  2\n1  1  4\n2  5  6\n\nIn [233]: g = df.groupby(\"A\")\n\nIn [234]: g.head(1)\nOut[234]: \n A  B\n0  1  2\n2  5  6\n\nIn [235]: g.tail(1)\nOut[235]: \n A  B\n1  1  4\n2  5  6 \n```", "```py\nIn [236]: df = pd.DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=[\"A\", \"B\"])\n\nIn [237]: g = df.groupby(\"A\")\n\nIn [238]: g.nth(0)\nOut[238]: \n A    B\n0  1  NaN\n2  5  6.0\n\nIn [239]: g.nth(-1)\nOut[239]: \n A    B\n1  1  4.0\n2  5  6.0\n\nIn [240]: g.nth(1)\nOut[240]: \n A    B\n1  1  4.0 \n```", "```py\nIn [241]: g.nth(5)\nOut[241]: \nEmpty DataFrame\nColumns: [A, B]\nIndex: [] \n```", "```py\n# nth(0) is the same as g.first()\nIn [242]: g.nth(0, dropna=\"any\")\nOut[242]: \n A    B\n1  1  4.0\n2  5  6.0\n\nIn [243]: g.first()\nOut[243]: \n B\nA \n1  4.0\n5  6.0\n\n# nth(-1) is the same as g.last()\nIn [244]: g.nth(-1, dropna=\"any\")\nOut[244]: \n A    B\n1  1  4.0\n2  5  6.0\n\nIn [245]: g.last()\nOut[245]: \n B\nA \n1  4.0\n5  6.0\n\nIn [246]: g.B.nth(0, dropna=\"all\")\nOut[246]: \n1    4.0\n2    6.0\nName: B, dtype: float64 \n```", "```py\nIn [247]: business_dates = pd.date_range(start=\"4/1/2014\", end=\"6/30/2014\", freq=\"B\")\n\nIn [248]: df = pd.DataFrame(1, index=business_dates, columns=[\"a\", \"b\"])\n\n# get the first, 4th, and last date index for each month\nIn [249]: df.groupby([df.index.year, df.index.month]).nth([0, 3, -1])\nOut[249]: \n a  b\n2014-04-01  1  1\n2014-04-04  1  1\n2014-04-30  1  1\n2014-05-01  1  1\n2014-05-06  1  1\n2014-05-30  1  1\n2014-06-02  1  1\n2014-06-05  1  1\n2014-06-30  1  1 \n```", "```py\nIn [250]: df.groupby([df.index.year, df.index.month]).nth[1:]\nOut[250]: \n a  b\n2014-04-02  1  1\n2014-04-03  1  1\n2014-04-04  1  1\n2014-04-07  1  1\n2014-04-08  1  1\n...        .. ..\n2014-06-24  1  1\n2014-06-25  1  1\n2014-06-26  1  1\n2014-06-27  1  1\n2014-06-30  1  1\n\n[62 rows x 2 columns]\n\nIn [251]: df.groupby([df.index.year, df.index.month]).nth[1:, :-1]\nOut[251]: \n a  b\n2014-04-01  1  1\n2014-04-02  1  1\n2014-04-03  1  1\n2014-04-04  1  1\n2014-04-07  1  1\n...        .. ..\n2014-06-24  1  1\n2014-06-25  1  1\n2014-06-26  1  1\n2014-06-27  1  1\n2014-06-30  1  1\n\n[65 rows x 2 columns] \n```", "```py\nIn [252]: dfg = pd.DataFrame(list(\"aaabba\"), columns=[\"A\"])\n\nIn [253]: dfg\nOut[253]: \n A\n0  a\n1  a\n2  a\n3  b\n4  b\n5  a\n\nIn [254]: dfg.groupby(\"A\").cumcount()\nOut[254]: \n0    0\n1    1\n2    2\n3    0\n4    1\n5    3\ndtype: int64\n\nIn [255]: dfg.groupby(\"A\").cumcount(ascending=False)\nOut[255]: \n0    3\n1    2\n2    1\n3    1\n4    0\n5    0\ndtype: int64 \n```", "```py\nIn [256]: dfg = pd.DataFrame(list(\"aaabba\"), columns=[\"A\"])\n\nIn [257]: dfg\nOut[257]: \n A\n0  a\n1  a\n2  a\n3  b\n4  b\n5  a\n\nIn [258]: dfg.groupby(\"A\").ngroup()\nOut[258]: \n0    0\n1    0\n2    0\n3    1\n4    1\n5    0\ndtype: int64\n\nIn [259]: dfg.groupby(\"A\").ngroup(ascending=False)\nOut[259]: \n0    1\n1    1\n2    1\n3    0\n4    0\n5    1\ndtype: int64 \n```", "```py\nIn [260]: np.random.seed(1234)\n\nIn [261]: df = pd.DataFrame(np.random.randn(50, 2))\n\nIn [262]: df[\"g\"] = np.random.choice([\"A\", \"B\"], size=50)\n\nIn [263]: df.loc[df[\"g\"] == \"B\", 1] += 3 \n```", "```py\nIn [264]: df.groupby(\"g\").boxplot()\nOut[264]: \nA         Axes(0.1,0.15;0.363636x0.75)\nB    Axes(0.536364,0.15;0.363636x0.75)\ndtype: object \n```", "```py\nIn [265]: n = 1000\n\nIn [266]: df = pd.DataFrame(\n .....:    {\n .....:        \"Store\": np.random.choice([\"Store_1\", \"Store_2\"], n),\n .....:        \"Product\": np.random.choice([\"Product_1\", \"Product_2\"], n),\n .....:        \"Revenue\": (np.random.random(n) * 50 + 10).round(2),\n .....:        \"Quantity\": np.random.randint(1, 10, size=n),\n .....:    }\n .....: )\n .....: \n\nIn [267]: df.head(2)\nOut[267]: \n Store    Product  Revenue  Quantity\n0  Store_2  Product_1    26.12         1\n1  Store_2  Product_1    28.86         1 \n```", "```py\nIn [268]: (\n .....:    df.groupby([\"Store\", \"Product\"])\n .....:    .pipe(lambda grp: grp.Revenue.sum() / grp.Quantity.sum())\n .....:    .unstack()\n .....:    .round(2)\n .....: )\n .....: \nOut[268]: \nProduct  Product_1  Product_2\nStore \nStore_1       6.82       7.05\nStore_2       6.30       6.64 \n```", "```py\nIn [269]: def mean(groupby):\n .....:    return groupby.mean()\n .....: \n\nIn [270]: df.groupby([\"Store\", \"Product\"]).pipe(mean)\nOut[270]: \n Revenue  Quantity\nStore   Product \nStore_1 Product_1  34.622727  5.075758\n Product_2  35.482815  5.029630\nStore_2 Product_1  32.972837  5.237589\n Product_2  34.684360  5.224000 \n```", "```py\nIn [271]: dfg = pd.DataFrame({\"A\": [1, 1, 2, 3, 2], \"B\": list(\"aaaba\")})\n\nIn [272]: dfg\nOut[272]: \n A  B\n0  1  a\n1  1  a\n2  2  a\n3  3  b\n4  2  a\n\nIn [273]: dfg.groupby([\"A\", \"B\"]).ngroup()\nOut[273]: \n0    0\n1    0\n2    1\n3    2\n4    1\ndtype: int64\n\nIn [274]: dfg.groupby([\"A\", [0, 0, 0, 1, 1]]).ngroup()\nOut[274]: \n0    0\n1    0\n2    1\n3    3\n4    2\ndtype: int64 \n```", "```py\nIn [275]: df = pd.DataFrame(np.random.randn(10, 2))\n\nIn [276]: df\nOut[276]: \n 0         1\n0 -0.793893  0.321153\n1  0.342250  1.618906\n2 -0.975807  1.918201\n3 -0.810847 -1.405919\n4 -1.977759  0.461659\n5  0.730057 -1.316938\n6 -0.751328  0.528290\n7 -0.257759 -1.081009\n8  0.505895 -1.701948\n9 -1.006349  0.020208\n\nIn [277]: df.index // 5\nOut[277]: Index([0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype='int64')\n\nIn [278]: df.groupby(df.index // 5).std()\nOut[278]: \n 0         1\n0  0.823647  1.312912\n1  0.760109  0.942941 \n```", "```py\nIn [279]: df = pd.DataFrame(\n .....:    {\n .....:        \"a\": [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],\n .....:        \"b\": [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n .....:        \"c\": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n .....:        \"d\": [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n .....:    }\n .....: )\n .....: \n\nIn [280]: def compute_metrics(x):\n .....:    result = {\"b_sum\": x[\"b\"].sum(), \"c_mean\": x[\"c\"].mean()}\n .....:    return pd.Series(result, name=\"metrics\")\n .....: \n\nIn [281]: result = df.groupby(\"a\").apply(compute_metrics, include_groups=False)\n\nIn [282]: result\nOut[282]: \nmetrics  b_sum  c_mean\na \n0          2.0     0.5\n1          2.0     0.5\n2          2.0     0.5\n\nIn [283]: result.stack(future_stack=True)\nOut[283]: \na  metrics\n0  b_sum      2.0\n c_mean     0.5\n1  b_sum      2.0\n c_mean     0.5\n2  b_sum      2.0\n c_mean     0.5\ndtype: float64 \n```", "```py\nIn [271]: dfg = pd.DataFrame({\"A\": [1, 1, 2, 3, 2], \"B\": list(\"aaaba\")})\n\nIn [272]: dfg\nOut[272]: \n A  B\n0  1  a\n1  1  a\n2  2  a\n3  3  b\n4  2  a\n\nIn [273]: dfg.groupby([\"A\", \"B\"]).ngroup()\nOut[273]: \n0    0\n1    0\n2    1\n3    2\n4    1\ndtype: int64\n\nIn [274]: dfg.groupby([\"A\", [0, 0, 0, 1, 1]]).ngroup()\nOut[274]: \n0    0\n1    0\n2    1\n3    3\n4    2\ndtype: int64 \n```", "```py\nIn [275]: df = pd.DataFrame(np.random.randn(10, 2))\n\nIn [276]: df\nOut[276]: \n 0         1\n0 -0.793893  0.321153\n1  0.342250  1.618906\n2 -0.975807  1.918201\n3 -0.810847 -1.405919\n4 -1.977759  0.461659\n5  0.730057 -1.316938\n6 -0.751328  0.528290\n7 -0.257759 -1.081009\n8  0.505895 -1.701948\n9 -1.006349  0.020208\n\nIn [277]: df.index // 5\nOut[277]: Index([0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype='int64')\n\nIn [278]: df.groupby(df.index // 5).std()\nOut[278]: \n 0         1\n0  0.823647  1.312912\n1  0.760109  0.942941 \n```", "```py\nIn [279]: df = pd.DataFrame(\n .....:    {\n .....:        \"a\": [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],\n .....:        \"b\": [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n .....:        \"c\": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n .....:        \"d\": [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n .....:    }\n .....: )\n .....: \n\nIn [280]: def compute_metrics(x):\n .....:    result = {\"b_sum\": x[\"b\"].sum(), \"c_mean\": x[\"c\"].mean()}\n .....:    return pd.Series(result, name=\"metrics\")\n .....: \n\nIn [281]: result = df.groupby(\"a\").apply(compute_metrics, include_groups=False)\n\nIn [282]: result\nOut[282]: \nmetrics  b_sum  c_mean\na \n0          2.0     0.5\n1          2.0     0.5\n2          2.0     0.5\n\nIn [283]: result.stack(future_stack=True)\nOut[283]: \na  metrics\n0  b_sum      2.0\n c_mean     0.5\n1  b_sum      2.0\n c_mean     0.5\n2  b_sum      2.0\n c_mean     0.5\ndtype: float64 \n```"]