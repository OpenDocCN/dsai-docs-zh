# ä½¿ç”¨ Ultralytics YOLOv8 è¿›è¡Œ VisionEye è§†å›¾å¯¹è±¡æ˜ å°„ ğŸš€

> åŸæ–‡ï¼š[`docs.ultralytics.com/guides/vision-eye/`](https://docs.ultralytics.com/guides/vision-eye/)

## ä»€ä¹ˆæ˜¯ VisionEye å¯¹è±¡æ˜ å°„ï¼Ÿ

[Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics/) VisionEye æä¾›äº†è®¡ç®—æœºè¯†åˆ«å’Œå®šä½ç‰©ä½“çš„èƒ½åŠ›ï¼Œæ¨¡æ‹Ÿäººçœ¼è§‚å¯Ÿçš„ç²¾ç¡®æ€§ã€‚è¯¥åŠŸèƒ½ä½¿è®¡ç®—æœºèƒ½å¤Ÿåƒäººçœ¼ä¸€æ ·åˆ†è¾¨å¹¶é›†ä¸­æ³¨æ„ç‰¹å®šå¯¹è±¡çš„ç»†èŠ‚ã€‚

## ç¤ºä¾‹

| VisionEye è§†å›¾ | å¸¦å¯¹è±¡è·Ÿè¸ªçš„ VisionEye è§†å›¾ | å¸¦è·ç¦»è®¡ç®—çš„ VisionEye è§†å›¾ |
| --- | --- | --- |
| ![ä½¿ç”¨ Ultralytics YOLOv8 è¿›è¡Œ VisionEye è§†å›¾å¯¹è±¡æ˜ å°„](img/660722b7ba935331fcc1384805fbdbb1.png) | ![ä½¿ç”¨ Ultralytics YOLOv8 è¿›è¡Œå¸¦å¯¹è±¡è·Ÿè¸ªçš„ VisionEye è§†å›¾å¯¹è±¡æ˜ å°„](img/b4363e33522e4f87d96966876ac3fbdc.png) | ![ä½¿ç”¨ Ultralytics YOLOv8 è¿›è¡Œå¸¦è·ç¦»è®¡ç®—çš„ VisionEye è§†å›¾](img/effe982fdcf6558076f275d871662324.png) |
| ä½¿ç”¨ Ultralytics YOLOv8 è¿›è¡Œ VisionEye è§†å›¾å¯¹è±¡æ˜ å°„ | ä½¿ç”¨ Ultralytics YOLOv8 è¿›è¡Œå¸¦å¯¹è±¡è·Ÿè¸ªçš„ VisionEye è§†å›¾å¯¹è±¡æ˜ å°„ | ä½¿ç”¨ Ultralytics YOLOv8 è¿›è¡Œå¸¦è·ç¦»è®¡ç®—çš„ VisionEye è§†å›¾ |

ä½¿ç”¨ YOLOv8 è¿›è¡Œ VisionEye å¯¹è±¡æ˜ å°„

```py
import cv2

from ultralytics import YOLO
from ultralytics.utils.plotting import Annotator, colors

model = YOLO("yolov8n.pt")
names = model.model.names
cap = cv2.VideoCapture("path/to/video/file.mp4")
w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))

out = cv2.VideoWriter("visioneye-pinpoint.avi", cv2.VideoWriter_fourcc(*"MJPG"), fps, (w, h))

center_point = (-10, h)

while True:
    ret, im0 = cap.read()
    if not ret:
        print("Video frame is empty or video processing has been successfully completed.")
        break

    results = model.predict(im0)
    boxes = results[0].boxes.xyxy.cpu()
    clss = results[0].boxes.cls.cpu().tolist()

    annotator = Annotator(im0, line_width=2)

    for box, cls in zip(boxes, clss):
        annotator.box_label(box, label=names[int(cls)], color=colors(int(cls)))
        annotator.visioneye(box, center_point)

    out.write(im0)
    cv2.imshow("visioneye-pinpoint", im0)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

out.release()
cap.release()
cv2.destroyAllWindows() 
```

```py
import cv2

from ultralytics import YOLO
from ultralytics.utils.plotting import Annotator, colors

model = YOLO("yolov8n.pt")
cap = cv2.VideoCapture("path/to/video/file.mp4")
w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))

out = cv2.VideoWriter("visioneye-pinpoint.avi", cv2.VideoWriter_fourcc(*"MJPG"), fps, (w, h))

center_point = (-10, h)

while True:
    ret, im0 = cap.read()
    if not ret:
        print("Video frame is empty or video processing has been successfully completed.")
        break

    annotator = Annotator(im0, line_width=2)

    results = model.track(im0, persist=True)
    boxes = results[0].boxes.xyxy.cpu()

    if results[0].boxes.id is not None:
        track_ids = results[0].boxes.id.int().cpu().tolist()

        for box, track_id in zip(boxes, track_ids):
            annotator.box_label(box, label=str(track_id), color=colors(int(track_id)))
            annotator.visioneye(box, center_point)

    out.write(im0)
    cv2.imshow("visioneye-pinpoint", im0)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

out.release()
cap.release()
cv2.destroyAllWindows() 
```

```py
import math

import cv2

from ultralytics import YOLO
from ultralytics.utils.plotting import Annotator

model = YOLO("yolov8s.pt")
cap = cv2.VideoCapture("Path/to/video/file.mp4")

w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))

out = cv2.VideoWriter("visioneye-distance-calculation.avi", cv2.VideoWriter_fourcc(*"MJPG"), fps, (w, h))

center_point = (0, h)
pixel_per_meter = 10

txt_color, txt_background, bbox_clr = ((0, 0, 0), (255, 255, 255), (255, 0, 255))

while True:
    ret, im0 = cap.read()
    if not ret:
        print("Video frame is empty or video processing has been successfully completed.")
        break

    annotator = Annotator(im0, line_width=2)

    results = model.track(im0, persist=True)
    boxes = results[0].boxes.xyxy.cpu()

    if results[0].boxes.id is not None:
        track_ids = results[0].boxes.id.int().cpu().tolist()

        for box, track_id in zip(boxes, track_ids):
            annotator.box_label(box, label=str(track_id), color=bbox_clr)
            annotator.visioneye(box, center_point)

            x1, y1 = int((box[0] + box[2]) // 2), int((box[1] + box[3]) // 2)  # Bounding box centroid

            distance = (math.sqrt((x1 - center_point[0]) ** 2 + (y1 - center_point[1]) ** 2)) / pixel_per_meter

            text_size, _ = cv2.getTextSize(f"Distance: {distance:.2f} m", cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)
            cv2.rectangle(im0, (x1, y1 - text_size[1] - 10), (x1 + text_size[0] + 10, y1), txt_background, -1)
            cv2.putText(im0, f"Distance: {distance:.2f} m", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 1.2, txt_color, 3)

    out.write(im0)
    cv2.imshow("visioneye-distance-calculation", im0)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

out.release()
cap.release()
cv2.destroyAllWindows() 
```

### `visioneye` å‚æ•°

| åç§° | ç±»å‹ | é»˜è®¤å€¼ | æè¿° |
| --- | --- | --- | --- |
| `color` | `tuple` | `(235, 219, 11)` | çº¿æ¡å’Œå¯¹è±¡è´¨å¿ƒçš„é¢œè‰² |
| `pin_color` | `tuple` | `(255, 0, 255)` | VisionEye çš„æ ‡è®°é¢œè‰² |

## æ³¨æ„

å¦‚æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·éšæ—¶åœ¨ [Ultralytics é—®é¢˜éƒ¨åˆ†](https://github.com/ultralytics/ultralytics/issues/new/choose) æˆ–ä¸‹é¢æåˆ°çš„è®¨è®ºéƒ¨åˆ†å‘è¡¨æ‚¨çš„é—®é¢˜ã€‚

## å¸¸è§é—®é¢˜è§£ç­”

### å¦‚ä½•å¼€å§‹ä½¿ç”¨ Ultralytics YOLOv8 è¿›è¡Œ VisionEye å¯¹è±¡æ˜ å°„ï¼Ÿ

è¦å¼€å§‹ä½¿ç”¨ Ultralytics YOLOv8 è¿›è¡Œ VisionEye å¯¹è±¡æ˜ å°„ï¼Œé¦–å…ˆéœ€è¦é€šè¿‡ pip å®‰è£… Ultralytics YOLO åŒ…ã€‚ç„¶åï¼Œå¯ä»¥ä½¿ç”¨æ–‡æ¡£ä¸­æä¾›çš„ç¤ºä¾‹ä»£ç è®¾ç½® VisionEye çš„å¯¹è±¡æ£€æµ‹ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼Œå¸®åŠ©æ‚¨å…¥é—¨ï¼š

```py
import cv2

from ultralytics import YOLO

model = YOLO("yolov8n.pt")
cap = cv2.VideoCapture("path/to/video/file.mp4")

while True:
    ret, frame = cap.read()
    if not ret:
        break

    results = model.predict(frame)
    for result in results:
        # Perform custom logic with result
        pass

    cv2.imshow("visioneye", frame)
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows() 
```

### ä½¿ç”¨ Ultralytics YOLOv8 çš„ VisionEye å¯¹è±¡è·Ÿè¸ªåŠŸèƒ½çš„å…³é”®ç‰¹æ€§æ˜¯ä»€ä¹ˆï¼Ÿ

VisionEye ä½¿ç”¨ Ultralytics YOLOv8 çš„å¯¹è±¡è·Ÿè¸ªåŠŸèƒ½å…è®¸ç”¨æˆ·åœ¨è§†é¢‘å¸§å†…è·Ÿè¸ªç‰©ä½“çš„ç§»åŠ¨ã€‚å…³é”®åŠŸèƒ½åŒ…æ‹¬ï¼š

1.  **å®æ—¶å¯¹è±¡è·Ÿè¸ª**ï¼šè·Ÿè¸ªç‰©ä½“ç§»åŠ¨çš„è¿‡ç¨‹ã€‚

1.  **å¯¹è±¡è¯†åˆ«**ï¼šåˆ©ç”¨ YOLOv8 å¼ºå¤§çš„æ£€æµ‹ç®—æ³•ã€‚

1.  **è·ç¦»è®¡ç®—**ï¼šè®¡ç®—å¯¹è±¡å’ŒæŒ‡å®šç‚¹ä¹‹é—´çš„è·ç¦»ã€‚

1.  **æ³¨é‡Šå’Œå¯è§†åŒ–**ï¼šä¸ºè¢«è·Ÿè¸ªçš„å¯¹è±¡æä¾›è§†è§‰æ ‡è®°ã€‚

è¿™é‡Œæ˜¯æ¼”ç¤ºä½¿ç”¨ VisionEye è¿›è¡Œè·Ÿè¸ªçš„ç®€çŸ­ä»£ç ç‰‡æ®µï¼š

```py
import cv2

from ultralytics import YOLO

model = YOLO("yolov8n.pt")
cap = cv2.VideoCapture("path/to/video/file.mp4")

while True:
    ret, frame = cap.read()
    if not ret:
        break

    results = model.track(frame, persist=True)
    for result in results:
        # Annotate and visualize tracking
        pass

    cv2.imshow("visioneye-tracking", frame)
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows() 
```

å¯¹äºå…¨é¢çš„æŒ‡å—ï¼Œè¯·è®¿é—® VisionEye å¯¹è±¡æ˜ å°„ä¸å¯¹è±¡è·Ÿè¸ªã€‚

### å¦‚ä½•ä½¿ç”¨ VisionEye çš„ YOLOv8 æ¨¡å‹è®¡ç®—è·ç¦»ï¼Ÿ

VisionEye å’Œ Ultralytics YOLOv8 çš„è·ç¦»è®¡ç®—æ¶‰åŠç¡®å®šå¸§ä¸­æ£€æµ‹åˆ°çš„å¯¹è±¡ä¸æŒ‡å®šç‚¹çš„è·ç¦»ã€‚å®ƒå¢å¼ºäº†ç©ºé—´åˆ†æèƒ½åŠ›ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶å’Œç›‘æ§ç­‰åº”ç”¨ä¸­éå¸¸æœ‰ç”¨ã€‚

è¿™é‡Œæœ‰ä¸€ä¸ªç®€åŒ–çš„ä¾‹å­ï¼š

```py
import math

import cv2

from ultralytics import YOLO

model = YOLO("yolov8s.pt")
cap = cv2.VideoCapture("path/to/video/file.mp4")
center_point = (0, 480)  # Example center point
pixel_per_meter = 10

while True:
    ret, frame = cap.read()
    if not ret:
        break

    results = model.track(frame, persist=True)
    for result in results:
        # Calculate distance logic
        distances = [
            (math.sqrt((box[0] - center_point[0]) ** 2 + (box[1] - center_point[1]) ** 2)) / pixel_per_meter
            for box in results
        ]

    cv2.imshow("visioneye-distance", frame)
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows() 
```

è¯¦ç»†æŒ‡å—ï¼Œè¯·å‚é˜…å¸¦æœ‰è·ç¦»è®¡ç®—çš„ VisionEyeã€‚

### æˆ‘ä¸ºä»€ä¹ˆè¦ä½¿ç”¨ Ultralytics YOLOv8 è¿›è¡Œå¯¹è±¡æ˜ å°„å’Œè·Ÿè¸ªï¼Ÿ

Ultralytics YOLOv8 ä»¥å…¶é€Ÿåº¦ã€å‡†ç¡®æ€§å’Œæ˜“é›†æˆæ€§è€Œé—»åï¼Œæˆä¸ºå¯¹è±¡æ˜ å°„å’Œè·Ÿè¸ªçš„é¦–é€‰ã€‚ä¸»è¦ä¼˜åŠ¿åŒ…æ‹¬ï¼š

1.  **æœ€å…ˆè¿›çš„æ€§èƒ½**ï¼šåœ¨å®æ—¶ç‰©ä½“æ£€æµ‹ä¸­æä¾›é«˜ç²¾åº¦ã€‚

1.  **çµæ´»æ€§**ï¼šæ”¯æŒæ£€æµ‹ã€è·Ÿè¸ªå’Œè·ç¦»è®¡ç®—ç­‰å„ç§ä»»åŠ¡ã€‚

1.  **ç¤¾åŒºä¸æ”¯æŒ**ï¼šæä¾›å¹¿æ³›çš„æ–‡æ¡£å’Œæ´»è·ƒçš„ GitHub ç¤¾åŒºï¼Œç”¨äºæ•…éšœæ’é™¤å’Œå¢å¼ºã€‚

1.  **æ˜“ç”¨æ€§**ï¼šç›´è§‚çš„ API ç®€åŒ–äº†å¤æ‚ä»»åŠ¡ï¼Œå¯ä»¥å¿«é€Ÿéƒ¨ç½²å’Œè¿­ä»£ã€‚

æœ‰å…³åº”ç”¨å’Œä¼˜åŠ¿çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·è®¿é—®[Ultralytics YOLOv8 æ–‡æ¡£](https://docs.ultralytics.com/models/yolov8/)ã€‚

### å¦‚ä½•å°† VisionEye ä¸ Comet æˆ– ClearML ç­‰å…¶ä»–æœºå™¨å­¦ä¹ å·¥å…·é›†æˆï¼Ÿ

Ultralytics YOLOv8 å¯ä»¥ä¸ Comet å’Œ ClearML ç­‰å¤šç§æœºå™¨å­¦ä¹ å·¥å…·æ— ç¼é›†æˆï¼Œå¢å¼ºå®éªŒè·Ÿè¸ªã€åä½œå’Œå¯å¤ç°æ€§ã€‚è¯·æŸ¥é˜…[å¦‚ä½•ä½¿ç”¨ YOLOv5 ä¸ Comet](https://www.ultralytics.com/blog/how-to-use-yolov5-with-comet)å’Œ[å°† YOLOv8 ä¸ ClearML é›†æˆ](https://docs.ultralytics.com/integrations/clearml/)çš„è¯¦ç»†æŒ‡å—ä»¥å¼€å§‹ã€‚

æœ‰å…³è¿›ä¸€æ­¥æ¢ç´¢å’Œé›†æˆç¤ºä¾‹ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„[Ultralytics é›†æˆæŒ‡å—](https://docs.ultralytics.com/integrations/)ã€‚
