# `scipy.optimize.fmin`

> 原文链接：[`docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.fmin.html#scipy.optimize.fmin`](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.fmin.html#scipy.optimize.fmin)

```py
scipy.optimize.fmin(func, x0, args=(), xtol=0.0001, ftol=0.0001, maxiter=None, maxfun=None, full_output=0, disp=1, retall=0, callback=None, initial_simplex=None)
```

使用下山单纯形算法最小化函数。

该算法仅使用函数值，不使用导数或二阶导数。

参数：

**func**callable func(x,*args)

要最小化的目标函数。

**x0**ndarray

初始猜测。

**args**tuple，可选

传递给 func 的额外参数，即`f(x,*args)`。

**xtol**float，可选

在迭代之间可接受的 xopt 中的绝对误差，以收敛为目标。

**ftol**number，可选

在迭代之间 func(xopt)的绝对误差，以收敛为目标。

**maxiter**int，可选

执行的最大迭代次数。

**maxfun**number，可选

最大函数评估次数。

**full_output**bool，可选

如果需要 fopt 和 warnflag 输出，则设置为 True。

**disp**bool，可选

设置为 True 以打印收敛消息。

**retall**bool, 可选

设置为 True 以返回每次迭代的解列表。

**callback**callable，可选

在每次迭代后调用，作为 callback(xk)，其中 xk 为当前的参数向量。

**initial_simplex**array_like，形状为(N + 1, N)，可选

初始单纯形。如果提供，则覆盖*x0*。`initial_simplex[j,:]`应包含单纯形中第 j 个顶点的 N+1 个顶点的坐标，其中 N 是维度。

返回：

**xopt**ndarray

最小化函数的参数。

**fopt**float

函数在最小值处的值：`fopt = func(xopt)`。

**iter**int

执行的迭代次数。

**funcalls**int

执行的函数调用次数。

**warnflag**int

1：执行的最大函数评估次数。2：达到的最大迭代次数。

**allvecs**list

每次迭代的解。

另见

[`minimize`](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize)

多元函数最小化算法接口。特别参见‘Nelder-Mead’ *方法*。

注意

使用 Nelder-Mead 单纯形算法寻找一个或多个变量函数的最小值。

该算法在应用中有着悠久的成功历史。但通常比使用一阶或二阶导数信息的算法慢。在实践中，它在高维问题中表现不佳，并且不适用于最小化复杂函数。此外，目前没有完整的理论描述算法何时会成功收敛到最小值，或者如果成功收敛，收敛速度如何。必须同时满足 ftol 和 xtol 标准以实现收敛。

参考文献

[1]

Nelder, J.A. 和 Mead, R. (1965), “A simplex method for function minimization”, The Computer Journal, 7, pp. 308-313

[2]

Wright, M.H. (1996), “Direct Search Methods: Once Scorned, Now Respectable”, in Numerical Analysis 1995, Proceedings of the 1995 Dundee Biennial Conference in Numerical Analysis, D.F. Griffiths and G.A. Watson (Eds.), Addison Wesley Longman, Harlow, UK, pp. 191-208.

示例

```py
>>> def f(x):
...     return x**2 
```

```py
>>> from scipy import optimize 
```

```py
>>> minimum = optimize.fmin(f, 1)
Optimization terminated successfully.
 Current function value: 0.000000
 Iterations: 17
 Function evaluations: 34
>>> minimum[0]
-8.8817841970012523e-16 
```
