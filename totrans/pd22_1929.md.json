["```py\nIn [1]: ser = pd.Series([1, \"abc\", np.nan], dtype=\"string\")\n\nIn [2]: ser\nOut[2]: \n0       1\n1     abc\n2    <NA>\ndtype: string\n\nIn [3]: ser[0]\nOut[3]: '1'\n\nIn [4]: pd.Series([1, 2, np.nan], dtype=\"Int64\").astype(\"string\")\nOut[4]: \n0       1\n1       2\n2    <NA>\ndtype: string \n```", "```py\nIn [5]: dti = pd.date_range(\"2014-01-01\", periods=30, freq=\"30D\")\n\nIn [6]: pi = dti.to_period(\"D\")\n\nIn [7]: ser_monotonic = pd.Series(np.arange(30), index=pi)\n\nIn [8]: shuffler = list(range(0, 30, 2)) + list(range(1, 31, 2))\n\nIn [9]: ser = ser_monotonic.iloc[shuffler]\n\nIn [10]: ser\nOut[10]: \n2014-01-01     0\n2014-03-02     2\n2014-05-01     4\n2014-06-30     6\n2014-08-29     8\n ..\n2015-09-23    21\n2015-11-22    23\n2016-01-21    25\n2016-03-21    27\n2016-05-20    29\nFreq: D, Length: 30, dtype: int64 \n```", "```py\nIn [11]: ser[\"2014\"]\nOut[11]: \n2014-01-01     0\n2014-03-02     2\n2014-05-01     4\n2014-06-30     6\n2014-08-29     8\n2014-10-28    10\n2014-12-27    12\n2014-01-31     1\n2014-04-01     3\n2014-05-31     5\n2014-07-30     7\n2014-09-28     9\n2014-11-27    11\nFreq: D, dtype: int64\n\nIn [12]: ser.loc[\"May 2015\"]\nOut[12]: \n2015-05-26    17\nFreq: D, dtype: int64 \n```", "```py\nIn [13]: df = pd.DataFrame(\n ....:    {\n ....:        \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n ....:        \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\n ....:        \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\n ....:    },\n ....:    columns=[\"col1\", \"col2\", \"col3\"],\n ....: )\n ....: \n\nIn [14]: df\nOut[14]: \n col1  col2  col3\n0    a   1.0   1.0\n1    a   2.0   2.0\n2    b   3.0   3.0\n3    b   NaN   4.0\n4    a   5.0   5.0 \n```", "```py\nIn [15]: df2 = df.copy()\n\nIn [16]: df2.loc[0, 'col1'] = 'c'\n\nIn [17]: df2.loc[2, 'col3'] = 4.0\n\nIn [18]: df2\nOut[18]: \n col1  col2  col3\n0    c   1.0   1.0\n1    a   2.0   2.0\n2    b   3.0   4.0\n3    b   NaN   4.0\n4    a   5.0   5.0 \n```", "```py\nIn [19]: df.compare(df2)\nOut[19]: \n col1       col3 \n self other self other\n0    a     c  NaN   NaN\n2  NaN   NaN  3.0   4.0 \n```", "```py\nIn [20]: df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n\nIn [21]: df_dropna = pd.DataFrame(df_list, columns=[\"a\", \"b\", \"c\"])\n\nIn [22]: df_dropna\nOut[22]: \n a    b  c\n0  1  2.0  3\n1  1  NaN  4\n2  2  1.0  3\n3  1  2.0  2 \n```", "```py\n# Default ``dropna`` is set to True, which will exclude NaNs in keys\nIn [23]: df_dropna.groupby(by=[\"b\"], dropna=True).sum()\nOut[23]: \n a  c\nb \n1.0  2  3\n2.0  2  5\n\n# In order to allow NaN in keys, set ``dropna`` to False\nIn [24]: df_dropna.groupby(by=[\"b\"], dropna=False).sum()\nOut[24]: \n a  c\nb \n1.0  2  3\n2.0  2  5\nNaN  1  4 \n```", "```py\nIn [25]: s = pd.Series(['C', 'a', 'B'])\n\nIn [26]: s\nOut[26]: \n0    C\n1    a\n2    B\ndtype: object \n```", "```py\nIn [27]: s.sort_values()\nOut[27]: \n2    B\n0    C\n1    a\ndtype: object \n```", "```py\nIn [28]: s.sort_values(key=lambda x: x.str.lower())\nOut[28]: \n1    a\n2    B\n0    C\ndtype: object \n```", "```py\nIn [29]: df = pd.DataFrame({'a': ['C', 'C', 'a', 'a', 'B', 'B'],\n ....:                   'b': [1, 2, 3, 4, 5, 6]})\n ....: \n\nIn [30]: df\nOut[30]: \n a  b\n0  C  1\n1  C  2\n2  a  3\n3  a  4\n4  B  5\n5  B  6 \n```", "```py\nIn [31]: df.sort_values(by=['a'], key=lambda col: col.str.lower())\nOut[31]: \n a  b\n2  a  3\n3  a  4\n4  B  5\n5  B  6\n0  C  1\n1  C  2 \n```", "```py\nIn [32]: ts = pd.Timestamp(\"2019-10-27 01:30:00+00:00\")\n\nIn [33]: ts.fold\nOut[33]: 0 \n```", "```py\nIn [34]: ts = pd.Timestamp(year=2019, month=10, day=27, hour=1, minute=30,\n ....:                  tz=\"dateutil/Europe/London\", fold=1)\n ....: \n\nIn [35]: ts\nOut[35]: Timestamp('2019-10-27 01:30:00+0000', tz='dateutil//usr/share/zoneinfo/Europe/London') \n```", "```py\nIn [36]: tz_strs = [\"2010-01-01 12:00:00 +0100\", \"2010-01-01 12:00:00 -0100\",\n ....:           \"2010-01-01 12:00:00 +0300\", \"2010-01-01 12:00:00 +0400\"]\n ....: \n\nIn [37]: pd.to_datetime(tz_strs, format='%Y-%m-%d %H:%M:%S %z', utc=True)\nOut[37]: \nDatetimeIndex(['2010-01-01 11:00:00+00:00', '2010-01-01 13:00:00+00:00',\n '2010-01-01 09:00:00+00:00', '2010-01-01 08:00:00+00:00'],\n dtype='datetime64[ns, UTC]', freq=None) \n```", "```py\nIn[37]: pd.to_datetime(tz_strs, format='%Y-%m-%d %H:%M:%S %z')\nOut[37]:\nIndex([2010-01-01 12:00:00+01:00, 2010-01-01 12:00:00-01:00,\n       2010-01-01 12:00:00+03:00, 2010-01-01 12:00:00+04:00],\n      dtype='object') \n```", "```py\nIn [38]: start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n\nIn [39]: middle = '2000-10-02 00:00:00'\n\nIn [40]: rng = pd.date_range(start, end, freq='7min')\n\nIn [41]: ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n\nIn [42]: ts\nOut[42]: \n2000-10-01 23:30:00     0\n2000-10-01 23:37:00     3\n2000-10-01 23:44:00     6\n2000-10-01 23:51:00     9\n2000-10-01 23:58:00    12\n2000-10-02 00:05:00    15\n2000-10-02 00:12:00    18\n2000-10-02 00:19:00    21\n2000-10-02 00:26:00    24\nFreq: 7min, dtype: int64 \n```", "```py\nIn [43]: ts.resample('17min').sum()\nOut[43]: \n2000-10-01 23:14:00     0\n2000-10-01 23:31:00     9\n2000-10-01 23:48:00    21\n2000-10-02 00:05:00    54\n2000-10-02 00:22:00    24\nFreq: 17min, dtype: int64\n\nIn [44]: ts.resample('17min', origin='start_day').sum()\nOut[44]: \n2000-10-01 23:14:00     0\n2000-10-01 23:31:00     9\n2000-10-01 23:48:00    21\n2000-10-02 00:05:00    54\n2000-10-02 00:22:00    24\nFreq: 17min, dtype: int64 \n```", "```py\nIn [45]: ts.resample('17min', origin='epoch').sum()\nOut[45]: \n2000-10-01 23:18:00     0\n2000-10-01 23:35:00    18\n2000-10-01 23:52:00    27\n2000-10-02 00:09:00    39\n2000-10-02 00:26:00    24\nFreq: 17min, dtype: int64\n\nIn [46]: ts.resample('17min', origin='2000-01-01').sum()\nOut[46]: \n2000-10-01 23:24:00     3\n2000-10-01 23:41:00    15\n2000-10-01 23:58:00    45\n2000-10-02 00:15:00    45\nFreq: 17min, dtype: int64 \n```", "```py\nIn [47]: df = pd.DataFrame({\n ....:    'a': [0, 0, 0, 0],\n ....:    'b': [0, 2, 3, 4],\n ....:    'c': ['A', 'B', 'C', 'D'],\n ....: }).set_index(['a', 'b'])\n ....: \n\nIn [48]: mi_2 = pd.MultiIndex.from_product([[0], [-1, 0, 1, 3, 4, 5]]) \n```", "```py\nIn [1]: df.reindex(mi_2, method='backfill')\nOut[1]:\n c\n0 -1  A\n 0  A\n 1  D\n 3  A\n 4  A\n 5  C \n```", "```py\nIn [49]: df.reindex(mi_2, method='backfill')\nOut[49]: \n c\n0 -1    A\n 0    A\n 1    B\n 3    C\n 4    D\n 5  NaN \n```", "```py\nIn [1]: df.reindex(mi_2, method='pad')\nOut[1]:\n c\n0 -1  NaN\n 0  NaN\n 1    D\n 3  NaN\n 4    A\n 5    C \n```", "```py\nIn [50]: df.reindex(mi_2, method='pad')\nOut[50]: \n c\n0 -1  NaN\n 0    A\n 1    A\n 3    C\n 4    D\n 5    D \n```", "```py\nIn [51]: ser1 = pd.Series(range(3), index=[0, 1, 2])\n\nIn [52]: ser2 = pd.Series(range(3), index=pd.date_range(\"2020-02-01\", periods=3)) \n```", "```py\nIn [3]: ser1[1.5]\n...\nTypeError: cannot do label indexing on Int64Index with these indexers [1.5] of type float\n\nIn [4] ser1[\"foo\"]\n...\nKeyError: 'foo'\n\nIn [5]: ser1.loc[1.5]\n...\nTypeError: cannot do label indexing on Int64Index with these indexers [1.5] of type float\n\nIn [6]: ser1.loc[\"foo\"]\n...\nKeyError: 'foo'\n\nIn [7]: ser2.loc[1]\n...\nTypeError: cannot do label indexing on DatetimeIndex with these indexers [1] of type int\n\nIn [8]: ser2.loc[pd.Timestamp(0)]\n...\nKeyError: Timestamp('1970-01-01 00:00:00') \n```", "```py\nIn [3]: ser1[1.5]\n...\nKeyError: 1.5\n\nIn [4] ser1[\"foo\"]\n...\nKeyError: 'foo'\n\nIn [5]: ser1.loc[1.5]\n...\nKeyError: 1.5\n\nIn [6]: ser1.loc[\"foo\"]\n...\nKeyError: 'foo'\n\nIn [7]: ser2.loc[1]\n...\nKeyError: 1\n\nIn [8]: ser2.loc[pd.Timestamp(0)]\n...\nKeyError: Timestamp('1970-01-01 00:00:00') \n```", "```py\nIn [53]: idx = pd.Index(range(4))\n\nIn [54]: dti = pd.date_range(\"2000-01-03\", periods=3)\n\nIn [55]: mi = pd.MultiIndex.from_product([idx, dti])\n\nIn [56]: ser = pd.Series(range(len(mi)), index=mi) \n```", "```py\nIn [5]: ser[[5]]\nOut[5]: Series([], dtype: int64) \n```", "```py\nIn [5]: ser[[5]]\n...\nKeyError: '[5] not in index' \n```", "```py\nIn [57]: left_df = pd.DataFrame({'animal': ['dog', 'pig'],\n ....:                       'max_speed': [40, 11]})\n ....: \n\nIn [58]: right_df = pd.DataFrame({'animal': ['quetzal', 'pig'],\n ....:                        'max_speed': [80, 11]})\n ....: \n\nIn [59]: left_df\nOut[59]: \n animal  max_speed\n0    dog         40\n1    pig         11\n\nIn [60]: right_df\nOut[60]: \n animal  max_speed\n0  quetzal         80\n1      pig         11 \n```", "```py\n>>> left_df.merge(right_df, on=['animal', 'max_speed'], how=\"right\")\n animal  max_speed\n0      pig         11\n1  quetzal         80 \n```", "```py\nIn [61]: left_df.merge(right_df, on=['animal', 'max_speed'], how=\"right\")\nOut[61]: \n animal  max_speed\n0  quetzal         80\n1      pig         11 \n```", "```py\nIn [62]: df = pd.DataFrame({'a': [0, 1, 2], 'b': [3, 4, 5]})\n\nIn [63]: df\nOut[63]: \n a  b\n0  0  3\n1  1  4\n2  2  5 \n```", "```py\nIn [3]: df[['a', 'c']] = 1\nIn [4]: df\nOut[4]:\n a  b\n0  1  1\n1  1  1\n2  1  1 \n```", "```py\nIn [64]: df[['a', 'c']] = 1\n\nIn [65]: df\nOut[65]: \n a  b  c\n0  1  3  1\n1  1  4  1\n2  1  5  1 \n```", "```py\nIn [66]: df = pd.DataFrame({\"a\": [\"x\", \"x\", \"y\", \"y\"], \"b\": [1, 1, 2, 3]})\n\nIn [67]: df\nOut[67]: \n a  b\n0  x  1\n1  x  1\n2  y  2\n3  y  3 \n```", "```py\nIn [3]: df.groupby(\"a\", as_index=True).nunique()\nOut[4]:\n a  b\na\nx  1  1\ny  1  2 \n```", "```py\nIn [68]: df.groupby(\"a\", as_index=True).nunique()\nOut[68]: \n b\na \nx  1\ny  2 \n```", "```py\nIn [3]: df.groupby(\"a\", as_index=False).nunique()\nOut[4]:\n a  b\n0  1  1\n1  1  2 \n```", "```py\nIn [69]: df.groupby(\"a\", as_index=False).nunique()\nOut[69]: \n a  b\n0  x  1\n1  y  2 \n```", "```py\nIn [3]: df.groupby(\"a\", as_index=False).size()\nOut[4]:\na\nx    2\ny    2\ndtype: int64 \n```", "```py\nIn [70]: df.groupby(\"a\", as_index=False).size()\nOut[70]: \n a  size\n0  x     2\n1  y     2 \n```", "```py\nIn [71]: df = pd.DataFrame({\"key\": [\"x\", \"y\", \"z\", \"x\", \"y\", \"z\"],\n ....:                   \"val\": [1.0, 0.8, 2.0, 3.0, 3.6, 0.75]})\n ....: \n\nIn [72]: df\nOut[72]: \n key   val\n0   x  1.00\n1   y  0.80\n2   z  2.00\n3   x  3.00\n4   y  3.60\n5   z  0.75 \n```", "```py\nIn [2]: grouped = df.groupby(\"key\", as_index=False)\nIn [3]: result = grouped.agg(min_val=pd.NamedAgg(column=\"val\", aggfunc=\"min\"))\nIn [4]: result\nOut[4]:\n min_val\n 0   x\n 1   y\n 2   z \n```", "```py\nIn [73]: grouped = df.groupby(\"key\", as_index=False)\n\nIn [74]: result = grouped.agg(min_val=pd.NamedAgg(column=\"val\", aggfunc=\"min\"))\n\nIn [75]: result\nOut[75]: \n key  min_val\n0   x     1.00\n1   y     0.80\n2   z     0.75 \n```", "```py\nIn [76]: df = pd.DataFrame({'a': [1, 2], 'b': [3, 6]})\n\nIn [77]: def func(row):\n ....:    print(row)\n ....:    return row\n ....: \n```", "```py\nIn [4]: df.apply(func, axis=1)\na    1\nb    3\nName: 0, dtype: int64\na    1\nb    3\nName: 0, dtype: int64\na    2\nb    6\nName: 1, dtype: int64\nOut[4]:\n a  b\n0  1  3\n1  2  6 \n```", "```py\nIn [78]: df.apply(func, axis=1)\na    1\nb    3\nName: 0, dtype: int64\na    2\nb    6\nName: 1, dtype: int64\nOut[78]: \n a  b\n0  1  3\n1  2  6 \n```", "```py\nIn [79]: df = pd.DataFrame(np.arange(4),\n ....:                  index=[[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]])\n ....: \n\n# Rows are now ordered as the requested keys\nIn [80]: df.loc[(['b', 'a'], [2, 1]), :]\nOut[80]: \n 0\nb 2  3\n 1  2\na 2  1\n 1  0 \n```", "```py\nIn [81]: left = pd.MultiIndex.from_arrays([[\"b\", \"a\"], [2, 1]])\n\nIn [82]: right = pd.MultiIndex.from_arrays([[\"a\", \"b\", \"c\"], [1, 2, 3]])\n\n# Common elements are now guaranteed to be ordered by the left side\nIn [83]: left.intersection(right, sort=False)\nOut[83]: \nMultiIndex([('b', 2),\n ('a', 1)],\n ) \n```", "```py\nIn [1]: ser = pd.Series([1, \"abc\", np.nan], dtype=\"string\")\n\nIn [2]: ser\nOut[2]: \n0       1\n1     abc\n2    <NA>\ndtype: string\n\nIn [3]: ser[0]\nOut[3]: '1'\n\nIn [4]: pd.Series([1, 2, np.nan], dtype=\"Int64\").astype(\"string\")\nOut[4]: \n0       1\n1       2\n2    <NA>\ndtype: string \n```", "```py\nIn [5]: dti = pd.date_range(\"2014-01-01\", periods=30, freq=\"30D\")\n\nIn [6]: pi = dti.to_period(\"D\")\n\nIn [7]: ser_monotonic = pd.Series(np.arange(30), index=pi)\n\nIn [8]: shuffler = list(range(0, 30, 2)) + list(range(1, 31, 2))\n\nIn [9]: ser = ser_monotonic.iloc[shuffler]\n\nIn [10]: ser\nOut[10]: \n2014-01-01     0\n2014-03-02     2\n2014-05-01     4\n2014-06-30     6\n2014-08-29     8\n ..\n2015-09-23    21\n2015-11-22    23\n2016-01-21    25\n2016-03-21    27\n2016-05-20    29\nFreq: D, Length: 30, dtype: int64 \n```", "```py\nIn [11]: ser[\"2014\"]\nOut[11]: \n2014-01-01     0\n2014-03-02     2\n2014-05-01     4\n2014-06-30     6\n2014-08-29     8\n2014-10-28    10\n2014-12-27    12\n2014-01-31     1\n2014-04-01     3\n2014-05-31     5\n2014-07-30     7\n2014-09-28     9\n2014-11-27    11\nFreq: D, dtype: int64\n\nIn [12]: ser.loc[\"May 2015\"]\nOut[12]: \n2015-05-26    17\nFreq: D, dtype: int64 \n```", "```py\nIn [13]: df = pd.DataFrame(\n ....:    {\n ....:        \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n ....:        \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\n ....:        \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\n ....:    },\n ....:    columns=[\"col1\", \"col2\", \"col3\"],\n ....: )\n ....: \n\nIn [14]: df\nOut[14]: \n col1  col2  col3\n0    a   1.0   1.0\n1    a   2.0   2.0\n2    b   3.0   3.0\n3    b   NaN   4.0\n4    a   5.0   5.0 \n```", "```py\nIn [15]: df2 = df.copy()\n\nIn [16]: df2.loc[0, 'col1'] = 'c'\n\nIn [17]: df2.loc[2, 'col3'] = 4.0\n\nIn [18]: df2\nOut[18]: \n col1  col2  col3\n0    c   1.0   1.0\n1    a   2.0   2.0\n2    b   3.0   4.0\n3    b   NaN   4.0\n4    a   5.0   5.0 \n```", "```py\nIn [19]: df.compare(df2)\nOut[19]: \n col1       col3 \n self other self other\n0    a     c  NaN   NaN\n2  NaN   NaN  3.0   4.0 \n```", "```py\nIn [20]: df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n\nIn [21]: df_dropna = pd.DataFrame(df_list, columns=[\"a\", \"b\", \"c\"])\n\nIn [22]: df_dropna\nOut[22]: \n a    b  c\n0  1  2.0  3\n1  1  NaN  4\n2  2  1.0  3\n3  1  2.0  2 \n```", "```py\n# Default ``dropna`` is set to True, which will exclude NaNs in keys\nIn [23]: df_dropna.groupby(by=[\"b\"], dropna=True).sum()\nOut[23]: \n a  c\nb \n1.0  2  3\n2.0  2  5\n\n# In order to allow NaN in keys, set ``dropna`` to False\nIn [24]: df_dropna.groupby(by=[\"b\"], dropna=False).sum()\nOut[24]: \n a  c\nb \n1.0  2  3\n2.0  2  5\nNaN  1  4 \n```", "```py\nIn [25]: s = pd.Series(['C', 'a', 'B'])\n\nIn [26]: s\nOut[26]: \n0    C\n1    a\n2    B\ndtype: object \n```", "```py\nIn [27]: s.sort_values()\nOut[27]: \n2    B\n0    C\n1    a\ndtype: object \n```", "```py\nIn [28]: s.sort_values(key=lambda x: x.str.lower())\nOut[28]: \n1    a\n2    B\n0    C\ndtype: object \n```", "```py\nIn [29]: df = pd.DataFrame({'a': ['C', 'C', 'a', 'a', 'B', 'B'],\n ....:                   'b': [1, 2, 3, 4, 5, 6]})\n ....: \n\nIn [30]: df\nOut[30]: \n a  b\n0  C  1\n1  C  2\n2  a  3\n3  a  4\n4  B  5\n5  B  6 \n```", "```py\nIn [31]: df.sort_values(by=['a'], key=lambda col: col.str.lower())\nOut[31]: \n a  b\n2  a  3\n3  a  4\n4  B  5\n5  B  6\n0  C  1\n1  C  2 \n```", "```py\nIn [32]: ts = pd.Timestamp(\"2019-10-27 01:30:00+00:00\")\n\nIn [33]: ts.fold\nOut[33]: 0 \n```", "```py\nIn [34]: ts = pd.Timestamp(year=2019, month=10, day=27, hour=1, minute=30,\n ....:                  tz=\"dateutil/Europe/London\", fold=1)\n ....: \n\nIn [35]: ts\nOut[35]: Timestamp('2019-10-27 01:30:00+0000', tz='dateutil//usr/share/zoneinfo/Europe/London') \n```", "```py\nIn [36]: tz_strs = [\"2010-01-01 12:00:00 +0100\", \"2010-01-01 12:00:00 -0100\",\n ....:           \"2010-01-01 12:00:00 +0300\", \"2010-01-01 12:00:00 +0400\"]\n ....: \n\nIn [37]: pd.to_datetime(tz_strs, format='%Y-%m-%d %H:%M:%S %z', utc=True)\nOut[37]: \nDatetimeIndex(['2010-01-01 11:00:00+00:00', '2010-01-01 13:00:00+00:00',\n '2010-01-01 09:00:00+00:00', '2010-01-01 08:00:00+00:00'],\n dtype='datetime64[ns, UTC]', freq=None) \n```", "```py\nIn[37]: pd.to_datetime(tz_strs, format='%Y-%m-%d %H:%M:%S %z')\nOut[37]:\nIndex([2010-01-01 12:00:00+01:00, 2010-01-01 12:00:00-01:00,\n       2010-01-01 12:00:00+03:00, 2010-01-01 12:00:00+04:00],\n      dtype='object') \n```", "```py\nIn [38]: start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n\nIn [39]: middle = '2000-10-02 00:00:00'\n\nIn [40]: rng = pd.date_range(start, end, freq='7min')\n\nIn [41]: ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n\nIn [42]: ts\nOut[42]: \n2000-10-01 23:30:00     0\n2000-10-01 23:37:00     3\n2000-10-01 23:44:00     6\n2000-10-01 23:51:00     9\n2000-10-01 23:58:00    12\n2000-10-02 00:05:00    15\n2000-10-02 00:12:00    18\n2000-10-02 00:19:00    21\n2000-10-02 00:26:00    24\nFreq: 7min, dtype: int64 \n```", "```py\nIn [43]: ts.resample('17min').sum()\nOut[43]: \n2000-10-01 23:14:00     0\n2000-10-01 23:31:00     9\n2000-10-01 23:48:00    21\n2000-10-02 00:05:00    54\n2000-10-02 00:22:00    24\nFreq: 17min, dtype: int64\n\nIn [44]: ts.resample('17min', origin='start_day').sum()\nOut[44]: \n2000-10-01 23:14:00     0\n2000-10-01 23:31:00     9\n2000-10-01 23:48:00    21\n2000-10-02 00:05:00    54\n2000-10-02 00:22:00    24\nFreq: 17min, dtype: int64 \n```", "```py\nIn [45]: ts.resample('17min', origin='epoch').sum()\nOut[45]: \n2000-10-01 23:18:00     0\n2000-10-01 23:35:00    18\n2000-10-01 23:52:00    27\n2000-10-02 00:09:00    39\n2000-10-02 00:26:00    24\nFreq: 17min, dtype: int64\n\nIn [46]: ts.resample('17min', origin='2000-01-01').sum()\nOut[46]: \n2000-10-01 23:24:00     3\n2000-10-01 23:41:00    15\n2000-10-01 23:58:00    45\n2000-10-02 00:15:00    45\nFreq: 17min, dtype: int64 \n```", "```py\nIn [1]: ser = pd.Series([1, \"abc\", np.nan], dtype=\"string\")\n\nIn [2]: ser\nOut[2]: \n0       1\n1     abc\n2    <NA>\ndtype: string\n\nIn [3]: ser[0]\nOut[3]: '1'\n\nIn [4]: pd.Series([1, 2, np.nan], dtype=\"Int64\").astype(\"string\")\nOut[4]: \n0       1\n1       2\n2    <NA>\ndtype: string \n```", "```py\nIn [5]: dti = pd.date_range(\"2014-01-01\", periods=30, freq=\"30D\")\n\nIn [6]: pi = dti.to_period(\"D\")\n\nIn [7]: ser_monotonic = pd.Series(np.arange(30), index=pi)\n\nIn [8]: shuffler = list(range(0, 30, 2)) + list(range(1, 31, 2))\n\nIn [9]: ser = ser_monotonic.iloc[shuffler]\n\nIn [10]: ser\nOut[10]: \n2014-01-01     0\n2014-03-02     2\n2014-05-01     4\n2014-06-30     6\n2014-08-29     8\n ..\n2015-09-23    21\n2015-11-22    23\n2016-01-21    25\n2016-03-21    27\n2016-05-20    29\nFreq: D, Length: 30, dtype: int64 \n```", "```py\nIn [11]: ser[\"2014\"]\nOut[11]: \n2014-01-01     0\n2014-03-02     2\n2014-05-01     4\n2014-06-30     6\n2014-08-29     8\n2014-10-28    10\n2014-12-27    12\n2014-01-31     1\n2014-04-01     3\n2014-05-31     5\n2014-07-30     7\n2014-09-28     9\n2014-11-27    11\nFreq: D, dtype: int64\n\nIn [12]: ser.loc[\"May 2015\"]\nOut[12]: \n2015-05-26    17\nFreq: D, dtype: int64 \n```", "```py\nIn [13]: df = pd.DataFrame(\n ....:    {\n ....:        \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n ....:        \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\n ....:        \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\n ....:    },\n ....:    columns=[\"col1\", \"col2\", \"col3\"],\n ....: )\n ....: \n\nIn [14]: df\nOut[14]: \n col1  col2  col3\n0    a   1.0   1.0\n1    a   2.0   2.0\n2    b   3.0   3.0\n3    b   NaN   4.0\n4    a   5.0   5.0 \n```", "```py\nIn [15]: df2 = df.copy()\n\nIn [16]: df2.loc[0, 'col1'] = 'c'\n\nIn [17]: df2.loc[2, 'col3'] = 4.0\n\nIn [18]: df2\nOut[18]: \n col1  col2  col3\n0    c   1.0   1.0\n1    a   2.0   2.0\n2    b   3.0   4.0\n3    b   NaN   4.0\n4    a   5.0   5.0 \n```", "```py\nIn [19]: df.compare(df2)\nOut[19]: \n col1       col3 \n self other self other\n0    a     c  NaN   NaN\n2  NaN   NaN  3.0   4.0 \n```", "```py\nIn [20]: df_list = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n\nIn [21]: df_dropna = pd.DataFrame(df_list, columns=[\"a\", \"b\", \"c\"])\n\nIn [22]: df_dropna\nOut[22]: \n a    b  c\n0  1  2.0  3\n1  1  NaN  4\n2  2  1.0  3\n3  1  2.0  2 \n```", "```py\n# Default ``dropna`` is set to True, which will exclude NaNs in keys\nIn [23]: df_dropna.groupby(by=[\"b\"], dropna=True).sum()\nOut[23]: \n a  c\nb \n1.0  2  3\n2.0  2  5\n\n# In order to allow NaN in keys, set ``dropna`` to False\nIn [24]: df_dropna.groupby(by=[\"b\"], dropna=False).sum()\nOut[24]: \n a  c\nb \n1.0  2  3\n2.0  2  5\nNaN  1  4 \n```", "```py\nIn [25]: s = pd.Series(['C', 'a', 'B'])\n\nIn [26]: s\nOut[26]: \n0    C\n1    a\n2    B\ndtype: object \n```", "```py\nIn [27]: s.sort_values()\nOut[27]: \n2    B\n0    C\n1    a\ndtype: object \n```", "```py\nIn [28]: s.sort_values(key=lambda x: x.str.lower())\nOut[28]: \n1    a\n2    B\n0    C\ndtype: object \n```", "```py\nIn [29]: df = pd.DataFrame({'a': ['C', 'C', 'a', 'a', 'B', 'B'],\n ....:                   'b': [1, 2, 3, 4, 5, 6]})\n ....: \n\nIn [30]: df\nOut[30]: \n a  b\n0  C  1\n1  C  2\n2  a  3\n3  a  4\n4  B  5\n5  B  6 \n```", "```py\nIn [31]: df.sort_values(by=['a'], key=lambda col: col.str.lower())\nOut[31]: \n a  b\n2  a  3\n3  a  4\n4  B  5\n5  B  6\n0  C  1\n1  C  2 \n```", "```py\nIn [32]: ts = pd.Timestamp(\"2019-10-27 01:30:00+00:00\")\n\nIn [33]: ts.fold\nOut[33]: 0 \n```", "```py\nIn [34]: ts = pd.Timestamp(year=2019, month=10, day=27, hour=1, minute=30,\n ....:                  tz=\"dateutil/Europe/London\", fold=1)\n ....: \n\nIn [35]: ts\nOut[35]: Timestamp('2019-10-27 01:30:00+0000', tz='dateutil//usr/share/zoneinfo/Europe/London') \n```", "```py\nIn [36]: tz_strs = [\"2010-01-01 12:00:00 +0100\", \"2010-01-01 12:00:00 -0100\",\n ....:           \"2010-01-01 12:00:00 +0300\", \"2010-01-01 12:00:00 +0400\"]\n ....: \n\nIn [37]: pd.to_datetime(tz_strs, format='%Y-%m-%d %H:%M:%S %z', utc=True)\nOut[37]: \nDatetimeIndex(['2010-01-01 11:00:00+00:00', '2010-01-01 13:00:00+00:00',\n '2010-01-01 09:00:00+00:00', '2010-01-01 08:00:00+00:00'],\n dtype='datetime64[ns, UTC]', freq=None) \n```", "```py\nIn[37]: pd.to_datetime(tz_strs, format='%Y-%m-%d %H:%M:%S %z')\nOut[37]:\nIndex([2010-01-01 12:00:00+01:00, 2010-01-01 12:00:00-01:00,\n       2010-01-01 12:00:00+03:00, 2010-01-01 12:00:00+04:00],\n      dtype='object') \n```", "```py\nIn [38]: start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n\nIn [39]: middle = '2000-10-02 00:00:00'\n\nIn [40]: rng = pd.date_range(start, end, freq='7min')\n\nIn [41]: ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n\nIn [42]: ts\nOut[42]: \n2000-10-01 23:30:00     0\n2000-10-01 23:37:00     3\n2000-10-01 23:44:00     6\n2000-10-01 23:51:00     9\n2000-10-01 23:58:00    12\n2000-10-02 00:05:00    15\n2000-10-02 00:12:00    18\n2000-10-02 00:19:00    21\n2000-10-02 00:26:00    24\nFreq: 7min, dtype: int64 \n```", "```py\nIn [43]: ts.resample('17min').sum()\nOut[43]: \n2000-10-01 23:14:00     0\n2000-10-01 23:31:00     9\n2000-10-01 23:48:00    21\n2000-10-02 00:05:00    54\n2000-10-02 00:22:00    24\nFreq: 17min, dtype: int64\n\nIn [44]: ts.resample('17min', origin='start_day').sum()\nOut[44]: \n2000-10-01 23:14:00     0\n2000-10-01 23:31:00     9\n2000-10-01 23:48:00    21\n2000-10-02 00:05:00    54\n2000-10-02 00:22:00    24\nFreq: 17min, dtype: int64 \n```", "```py\nIn [45]: ts.resample('17min', origin='epoch').sum()\nOut[45]: \n2000-10-01 23:18:00     0\n2000-10-01 23:35:00    18\n2000-10-01 23:52:00    27\n2000-10-02 00:09:00    39\n2000-10-02 00:26:00    24\nFreq: 17min, dtype: int64\n\nIn [46]: ts.resample('17min', origin='2000-01-01').sum()\nOut[46]: \n2000-10-01 23:24:00     3\n2000-10-01 23:41:00    15\n2000-10-01 23:58:00    45\n2000-10-02 00:15:00    45\nFreq: 17min, dtype: int64 \n```", "```py\nIn [47]: df = pd.DataFrame({\n ....:    'a': [0, 0, 0, 0],\n ....:    'b': [0, 2, 3, 4],\n ....:    'c': ['A', 'B', 'C', 'D'],\n ....: }).set_index(['a', 'b'])\n ....: \n\nIn [48]: mi_2 = pd.MultiIndex.from_product([[0], [-1, 0, 1, 3, 4, 5]]) \n```", "```py\nIn [1]: df.reindex(mi_2, method='backfill')\nOut[1]:\n c\n0 -1  A\n 0  A\n 1  D\n 3  A\n 4  A\n 5  C \n```", "```py\nIn [49]: df.reindex(mi_2, method='backfill')\nOut[49]: \n c\n0 -1    A\n 0    A\n 1    B\n 3    C\n 4    D\n 5  NaN \n```", "```py\nIn [1]: df.reindex(mi_2, method='pad')\nOut[1]:\n c\n0 -1  NaN\n 0  NaN\n 1    D\n 3  NaN\n 4    A\n 5    C \n```", "```py\nIn [50]: df.reindex(mi_2, method='pad')\nOut[50]: \n c\n0 -1  NaN\n 0    A\n 1    A\n 3    C\n 4    D\n 5    D \n```", "```py\nIn [51]: ser1 = pd.Series(range(3), index=[0, 1, 2])\n\nIn [52]: ser2 = pd.Series(range(3), index=pd.date_range(\"2020-02-01\", periods=3)) \n```", "```py\nIn [3]: ser1[1.5]\n...\nTypeError: cannot do label indexing on Int64Index with these indexers [1.5] of type float\n\nIn [4] ser1[\"foo\"]\n...\nKeyError: 'foo'\n\nIn [5]: ser1.loc[1.5]\n...\nTypeError: cannot do label indexing on Int64Index with these indexers [1.5] of type float\n\nIn [6]: ser1.loc[\"foo\"]\n...\nKeyError: 'foo'\n\nIn [7]: ser2.loc[1]\n...\nTypeError: cannot do label indexing on DatetimeIndex with these indexers [1] of type int\n\nIn [8]: ser2.loc[pd.Timestamp(0)]\n...\nKeyError: Timestamp('1970-01-01 00:00:00') \n```", "```py\nIn [3]: ser1[1.5]\n...\nKeyError: 1.5\n\nIn [4] ser1[\"foo\"]\n...\nKeyError: 'foo'\n\nIn [5]: ser1.loc[1.5]\n...\nKeyError: 1.5\n\nIn [6]: ser1.loc[\"foo\"]\n...\nKeyError: 'foo'\n\nIn [7]: ser2.loc[1]\n...\nKeyError: 1\n\nIn [8]: ser2.loc[pd.Timestamp(0)]\n...\nKeyError: Timestamp('1970-01-01 00:00:00') \n```", "```py\nIn [53]: idx = pd.Index(range(4))\n\nIn [54]: dti = pd.date_range(\"2000-01-03\", periods=3)\n\nIn [55]: mi = pd.MultiIndex.from_product([idx, dti])\n\nIn [56]: ser = pd.Series(range(len(mi)), index=mi) \n```", "```py\nIn [5]: ser[[5]]\nOut[5]: Series([], dtype: int64) \n```", "```py\nIn [5]: ser[[5]]\n...\nKeyError: '[5] not in index' \n```", "```py\nIn [57]: left_df = pd.DataFrame({'animal': ['dog', 'pig'],\n ....:                       'max_speed': [40, 11]})\n ....: \n\nIn [58]: right_df = pd.DataFrame({'animal': ['quetzal', 'pig'],\n ....:                        'max_speed': [80, 11]})\n ....: \n\nIn [59]: left_df\nOut[59]: \n animal  max_speed\n0    dog         40\n1    pig         11\n\nIn [60]: right_df\nOut[60]: \n animal  max_speed\n0  quetzal         80\n1      pig         11 \n```", "```py\n>>> left_df.merge(right_df, on=['animal', 'max_speed'], how=\"right\")\n animal  max_speed\n0      pig         11\n1  quetzal         80 \n```", "```py\nIn [61]: left_df.merge(right_df, on=['animal', 'max_speed'], how=\"right\")\nOut[61]: \n animal  max_speed\n0  quetzal         80\n1      pig         11 \n```", "```py\nIn [62]: df = pd.DataFrame({'a': [0, 1, 2], 'b': [3, 4, 5]})\n\nIn [63]: df\nOut[63]: \n a  b\n0  0  3\n1  1  4\n2  2  5 \n```", "```py\nIn [3]: df[['a', 'c']] = 1\nIn [4]: df\nOut[4]:\n a  b\n0  1  1\n1  1  1\n2  1  1 \n```", "```py\nIn [64]: df[['a', 'c']] = 1\n\nIn [65]: df\nOut[65]: \n a  b  c\n0  1  3  1\n1  1  4  1\n2  1  5  1 \n```", "```py\nIn [66]: df = pd.DataFrame({\"a\": [\"x\", \"x\", \"y\", \"y\"], \"b\": [1, 1, 2, 3]})\n\nIn [67]: df\nOut[67]: \n a  b\n0  x  1\n1  x  1\n2  y  2\n3  y  3 \n```", "```py\nIn [3]: df.groupby(\"a\", as_index=True).nunique()\nOut[4]:\n a  b\na\nx  1  1\ny  1  2 \n```", "```py\nIn [68]: df.groupby(\"a\", as_index=True).nunique()\nOut[68]: \n b\na \nx  1\ny  2 \n```", "```py\nIn [3]: df.groupby(\"a\", as_index=False).nunique()\nOut[4]:\n a  b\n0  1  1\n1  1  2 \n```", "```py\nIn [69]: df.groupby(\"a\", as_index=False).nunique()\nOut[69]: \n a  b\n0  x  1\n1  y  2 \n```", "```py\nIn [3]: df.groupby(\"a\", as_index=False).size()\nOut[4]:\na\nx    2\ny    2\ndtype: int64 \n```", "```py\nIn [70]: df.groupby(\"a\", as_index=False).size()\nOut[70]: \n a  size\n0  x     2\n1  y     2 \n```", "```py\nIn [71]: df = pd.DataFrame({\"key\": [\"x\", \"y\", \"z\", \"x\", \"y\", \"z\"],\n ....:                   \"val\": [1.0, 0.8, 2.0, 3.0, 3.6, 0.75]})\n ....: \n\nIn [72]: df\nOut[72]: \n key   val\n0   x  1.00\n1   y  0.80\n2   z  2.00\n3   x  3.00\n4   y  3.60\n5   z  0.75 \n```", "```py\nIn [2]: grouped = df.groupby(\"key\", as_index=False)\nIn [3]: result = grouped.agg(min_val=pd.NamedAgg(column=\"val\", aggfunc=\"min\"))\nIn [4]: result\nOut[4]:\n min_val\n 0   x\n 1   y\n 2   z \n```", "```py\nIn [73]: grouped = df.groupby(\"key\", as_index=False)\n\nIn [74]: result = grouped.agg(min_val=pd.NamedAgg(column=\"val\", aggfunc=\"min\"))\n\nIn [75]: result\nOut[75]: \n key  min_val\n0   x     1.00\n1   y     0.80\n2   z     0.75 \n```", "```py\nIn [76]: df = pd.DataFrame({'a': [1, 2], 'b': [3, 6]})\n\nIn [77]: def func(row):\n ....:    print(row)\n ....:    return row\n ....: \n```", "```py\nIn [4]: df.apply(func, axis=1)\na    1\nb    3\nName: 0, dtype: int64\na    1\nb    3\nName: 0, dtype: int64\na    2\nb    6\nName: 1, dtype: int64\nOut[4]:\n a  b\n0  1  3\n1  2  6 \n```", "```py\nIn [78]: df.apply(func, axis=1)\na    1\nb    3\nName: 0, dtype: int64\na    2\nb    6\nName: 1, dtype: int64\nOut[78]: \n a  b\n0  1  3\n1  2  6 \n```", "```py\nIn [47]: df = pd.DataFrame({\n ....:    'a': [0, 0, 0, 0],\n ....:    'b': [0, 2, 3, 4],\n ....:    'c': ['A', 'B', 'C', 'D'],\n ....: }).set_index(['a', 'b'])\n ....: \n\nIn [48]: mi_2 = pd.MultiIndex.from_product([[0], [-1, 0, 1, 3, 4, 5]]) \n```", "```py\nIn [1]: df.reindex(mi_2, method='backfill')\nOut[1]:\n c\n0 -1  A\n 0  A\n 1  D\n 3  A\n 4  A\n 5  C \n```", "```py\nIn [49]: df.reindex(mi_2, method='backfill')\nOut[49]: \n c\n0 -1    A\n 0    A\n 1    B\n 3    C\n 4    D\n 5  NaN \n```", "```py\nIn [1]: df.reindex(mi_2, method='pad')\nOut[1]:\n c\n0 -1  NaN\n 0  NaN\n 1    D\n 3  NaN\n 4    A\n 5    C \n```", "```py\nIn [50]: df.reindex(mi_2, method='pad')\nOut[50]: \n c\n0 -1  NaN\n 0    A\n 1    A\n 3    C\n 4    D\n 5    D \n```", "```py\nIn [51]: ser1 = pd.Series(range(3), index=[0, 1, 2])\n\nIn [52]: ser2 = pd.Series(range(3), index=pd.date_range(\"2020-02-01\", periods=3)) \n```", "```py\nIn [3]: ser1[1.5]\n...\nTypeError: cannot do label indexing on Int64Index with these indexers [1.5] of type float\n\nIn [4] ser1[\"foo\"]\n...\nKeyError: 'foo'\n\nIn [5]: ser1.loc[1.5]\n...\nTypeError: cannot do label indexing on Int64Index with these indexers [1.5] of type float\n\nIn [6]: ser1.loc[\"foo\"]\n...\nKeyError: 'foo'\n\nIn [7]: ser2.loc[1]\n...\nTypeError: cannot do label indexing on DatetimeIndex with these indexers [1] of type int\n\nIn [8]: ser2.loc[pd.Timestamp(0)]\n...\nKeyError: Timestamp('1970-01-01 00:00:00') \n```", "```py\nIn [3]: ser1[1.5]\n...\nKeyError: 1.5\n\nIn [4] ser1[\"foo\"]\n...\nKeyError: 'foo'\n\nIn [5]: ser1.loc[1.5]\n...\nKeyError: 1.5\n\nIn [6]: ser1.loc[\"foo\"]\n...\nKeyError: 'foo'\n\nIn [7]: ser2.loc[1]\n...\nKeyError: 1\n\nIn [8]: ser2.loc[pd.Timestamp(0)]\n...\nKeyError: Timestamp('1970-01-01 00:00:00') \n```", "```py\nIn [53]: idx = pd.Index(range(4))\n\nIn [54]: dti = pd.date_range(\"2000-01-03\", periods=3)\n\nIn [55]: mi = pd.MultiIndex.from_product([idx, dti])\n\nIn [56]: ser = pd.Series(range(len(mi)), index=mi) \n```", "```py\nIn [5]: ser[[5]]\nOut[5]: Series([], dtype: int64) \n```", "```py\nIn [5]: ser[[5]]\n...\nKeyError: '[5] not in index' \n```", "```py\nIn [57]: left_df = pd.DataFrame({'animal': ['dog', 'pig'],\n ....:                       'max_speed': [40, 11]})\n ....: \n\nIn [58]: right_df = pd.DataFrame({'animal': ['quetzal', 'pig'],\n ....:                        'max_speed': [80, 11]})\n ....: \n\nIn [59]: left_df\nOut[59]: \n animal  max_speed\n0    dog         40\n1    pig         11\n\nIn [60]: right_df\nOut[60]: \n animal  max_speed\n0  quetzal         80\n1      pig         11 \n```", "```py\n>>> left_df.merge(right_df, on=['animal', 'max_speed'], how=\"right\")\n animal  max_speed\n0      pig         11\n1  quetzal         80 \n```", "```py\nIn [61]: left_df.merge(right_df, on=['animal', 'max_speed'], how=\"right\")\nOut[61]: \n animal  max_speed\n0  quetzal         80\n1      pig         11 \n```", "```py\nIn [62]: df = pd.DataFrame({'a': [0, 1, 2], 'b': [3, 4, 5]})\n\nIn [63]: df\nOut[63]: \n a  b\n0  0  3\n1  1  4\n2  2  5 \n```", "```py\nIn [3]: df[['a', 'c']] = 1\nIn [4]: df\nOut[4]:\n a  b\n0  1  1\n1  1  1\n2  1  1 \n```", "```py\nIn [64]: df[['a', 'c']] = 1\n\nIn [65]: df\nOut[65]: \n a  b  c\n0  1  3  1\n1  1  4  1\n2  1  5  1 \n```", "```py\nIn [66]: df = pd.DataFrame({\"a\": [\"x\", \"x\", \"y\", \"y\"], \"b\": [1, 1, 2, 3]})\n\nIn [67]: df\nOut[67]: \n a  b\n0  x  1\n1  x  1\n2  y  2\n3  y  3 \n```", "```py\nIn [3]: df.groupby(\"a\", as_index=True).nunique()\nOut[4]:\n a  b\na\nx  1  1\ny  1  2 \n```", "```py\nIn [68]: df.groupby(\"a\", as_index=True).nunique()\nOut[68]: \n b\na \nx  1\ny  2 \n```", "```py\nIn [3]: df.groupby(\"a\", as_index=False).nunique()\nOut[4]:\n a  b\n0  1  1\n1  1  2 \n```", "```py\nIn [69]: df.groupby(\"a\", as_index=False).nunique()\nOut[69]: \n a  b\n0  x  1\n1  y  2 \n```", "```py\nIn [3]: df.groupby(\"a\", as_index=False).size()\nOut[4]:\na\nx    2\ny    2\ndtype: int64 \n```", "```py\nIn [70]: df.groupby(\"a\", as_index=False).size()\nOut[70]: \n a  size\n0  x     2\n1  y     2 \n```", "```py\nIn [71]: df = pd.DataFrame({\"key\": [\"x\", \"y\", \"z\", \"x\", \"y\", \"z\"],\n ....:                   \"val\": [1.0, 0.8, 2.0, 3.0, 3.6, 0.75]})\n ....: \n\nIn [72]: df\nOut[72]: \n key   val\n0   x  1.00\n1   y  0.80\n2   z  2.00\n3   x  3.00\n4   y  3.60\n5   z  0.75 \n```", "```py\nIn [2]: grouped = df.groupby(\"key\", as_index=False)\nIn [3]: result = grouped.agg(min_val=pd.NamedAgg(column=\"val\", aggfunc=\"min\"))\nIn [4]: result\nOut[4]:\n min_val\n 0   x\n 1   y\n 2   z \n```", "```py\nIn [73]: grouped = df.groupby(\"key\", as_index=False)\n\nIn [74]: result = grouped.agg(min_val=pd.NamedAgg(column=\"val\", aggfunc=\"min\"))\n\nIn [75]: result\nOut[75]: \n key  min_val\n0   x     1.00\n1   y     0.80\n2   z     0.75 \n```", "```py\nIn [76]: df = pd.DataFrame({'a': [1, 2], 'b': [3, 6]})\n\nIn [77]: def func(row):\n ....:    print(row)\n ....:    return row\n ....: \n```", "```py\nIn [4]: df.apply(func, axis=1)\na    1\nb    3\nName: 0, dtype: int64\na    1\nb    3\nName: 0, dtype: int64\na    2\nb    6\nName: 1, dtype: int64\nOut[4]:\n a  b\n0  1  3\n1  2  6 \n```", "```py\nIn [78]: df.apply(func, axis=1)\na    1\nb    3\nName: 0, dtype: int64\na    2\nb    6\nName: 1, dtype: int64\nOut[78]: \n a  b\n0  1  3\n1  2  6 \n```", "```py\nIn [79]: df = pd.DataFrame(np.arange(4),\n ....:                  index=[[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]])\n ....: \n\n# Rows are now ordered as the requested keys\nIn [80]: df.loc[(['b', 'a'], [2, 1]), :]\nOut[80]: \n 0\nb 2  3\n 1  2\na 2  1\n 1  0 \n```", "```py\nIn [81]: left = pd.MultiIndex.from_arrays([[\"b\", \"a\"], [2, 1]])\n\nIn [82]: right = pd.MultiIndex.from_arrays([[\"a\", \"b\", \"c\"], [1, 2, 3]])\n\n# Common elements are now guaranteed to be ordered by the left side\nIn [83]: left.intersection(right, sort=False)\nOut[83]: \nMultiIndex([('b', 2),\n ('a', 1)],\n ) \n```", "```py\nIn [79]: df = pd.DataFrame(np.arange(4),\n ....:                  index=[[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]])\n ....: \n\n# Rows are now ordered as the requested keys\nIn [80]: df.loc[(['b', 'a'], [2, 1]), :]\nOut[80]: \n 0\nb 2  3\n 1  2\na 2  1\n 1  0 \n```", "```py\nIn [81]: left = pd.MultiIndex.from_arrays([[\"b\", \"a\"], [2, 1]])\n\nIn [82]: right = pd.MultiIndex.from_arrays([[\"a\", \"b\", \"c\"], [1, 2, 3]])\n\n# Common elements are now guaranteed to be ordered by the left side\nIn [83]: left.intersection(right, sort=False)\nOut[83]: \nMultiIndex([('b', 2),\n ('a', 1)],\n ) \n```"]