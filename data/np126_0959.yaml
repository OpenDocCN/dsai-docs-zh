- en: Upgrading PCG64 with PCG64DXSM
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 升级 PCG64 为 PCG64DXSM
- en: 原文：[https://numpy.org/doc/1.26/reference/random/upgrading-pcg64.html](https://numpy.org/doc/1.26/reference/random/upgrading-pcg64.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://numpy.org/doc/1.26/reference/random/upgrading-pcg64.html](https://numpy.org/doc/1.26/reference/random/upgrading-pcg64.html)
- en: Uses of the [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64")
    [`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator") in a massively-parallel context have been shown to
    have statistical weaknesses that were not apparent at the first release in numpy
    1.17\. Most users will never observe this weakness and are safe to continue to
    use [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64").
    We have introduced a new [`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM") [`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator") that will eventually become the new default [`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator") implementation used by [`default_rng`](generator.html#numpy.random.default_rng
    "numpy.random.default_rng") in future releases. [`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM") solves the statistical weakness while preserving the
    performance and the features of [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64").
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在大规模并行上下文中使用[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64")
    [`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator") 已经显示出了统计上的弱点，在 numpy 1.17 发布时并不明显。大多数用户永远不会观察到这个弱点，并且可以继续安全使用
    [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64").
    我们引入了一个新的 [`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM "numpy.random.PCG64DXSM")
    [`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator")，它最终将成为将来版本中由 [`default_rng`](generator.html#numpy.random.default_rng
    "numpy.random.default_rng") 使用的新默认 [`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator") 实现。 [`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM") 解决了统计上的弱点，同时保留了 [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64") 的性能和特性。
- en: Does this affect me?
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这会对我产生影响吗？
- en: If you
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您
- en: only use a single [`Generator`](generator.html#numpy.random.Generator "numpy.random.Generator")
    instance,
  id: totrans-5
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只使用单个[`Generator`](generator.html#numpy.random.Generator "numpy.random.Generator")实例，
- en: ''
  id: totrans-6
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: only use [`RandomState`](legacy.html#numpy.random.RandomState "numpy.random.RandomState")
    or the functions in [`numpy.random`](index.html#module-numpy.random "numpy.random"),
  id: totrans-8
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只使用[`RandomState`](legacy.html#numpy.random.RandomState "numpy.random.RandomState")或[`numpy.random`](index.html#module-numpy.random
    "numpy.random")中的函数，
- en: ''
  id: totrans-9
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-10
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: only use the [`PCG64.jumped`](bit_generators/generated/numpy.random.PCG64.jumped.html#numpy.random.PCG64.jumped
    "numpy.random.PCG64.jumped") method to generate parallel streams,
  id: totrans-11
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只使用[`PCG64.jumped`](bit_generators/generated/numpy.random.PCG64.jumped.html#numpy.random.PCG64.jumped
    "numpy.random.PCG64.jumped")方法来生成并行流，
- en: ''
  id: totrans-12
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: explicitly use a [`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator") other than [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64"),
  id: totrans-14
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 明确使用[`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator")而非[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64"),
- en: then this weakness does not affect you at all. Carry on.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这个弱点对你没有任何影响。继续进行。
- en: If you use moderate numbers of parallel streams created with [`default_rng`](generator.html#numpy.random.default_rng
    "numpy.random.default_rng") or [`SeedSequence.spawn`](bit_generators/generated/numpy.random.SeedSequence.spawn.html#numpy.random.SeedSequence.spawn
    "numpy.random.SeedSequence.spawn"), in the 1000s, then the chance of observing
    this weakness is negligibly small. You can continue to use [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64") comfortably.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用 [`default_rng`](generator.html#numpy.random.default_rng "numpy.random.default_rng")或
    [`SeedSequence.spawn`](bit_generators/generated/numpy.random.SeedSequence.spawn.html#numpy.random.SeedSequence.spawn
    "numpy.random.SeedSequence.spawn") 创建的适量并行流，在 1000s 范围内，那么观察到这个弱点的机会是微乎其微的。您可以继续舒适地使用
    [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64")。
- en: If you use very large numbers of parallel streams, in the millions, and draw
    large amounts of numbers from each, then the chance of observing this weakness
    can become non-negligible, if still small. An example of such a use case would
    be a very large distributed reinforcement learning problem with millions of long
    Monte Carlo playouts each generating billions of random number draws. Such use
    cases should consider using [`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM") explicitly or another modern [`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator") like [`SFC64`](bit_generators/sfc64.html#numpy.random.SFC64
    "numpy.random.SFC64") or [`Philox`](bit_generators/philox.html#numpy.random.Philox
    "numpy.random.Philox"), but it is unlikely that any old results you may have calculated
    are invalid. In any case, the weakness is a kind of [Birthday Paradox](https://en.wikipedia.org/wiki/Birthday_problem)
    collision. That is, a single pair of parallel streams out of the millions, considered
    together, might fail a stringent set of statistical tests of randomness. The remaining
    millions of streams would all be perfectly fine, and the effect of the bad pair
    in the whole calculation is very likely to be swamped by the remaining streams
    in most applications.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用了大量的并行流，数量达到百万级，并且从每个流中抽取了大量的数字，那么观察到这种弱点的机会就会变得不可忽略，尽管仍然很小。这样的用例示例可能是一个非常大的分布式强化学习问题，每个问题都有数百万次长的蒙特卡洛模拟，每个模拟都生成了数十亿次的随机数。这种用例应该明确地考虑使用[`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM")或者另一个现代的[`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator")，比如[`SFC64`](bit_generators/sfc64.html#numpy.random.SFC64
    "numpy.random.SFC64")或[`Philox`](bit_generators/philox.html#numpy.random.Philox
    "numpy.random.Philox")，但是几乎可以肯定你可能计算过的任何旧结果都是无效的。无论如何，这种弱点属于一种[生日悖论](https://en.wikipedia.org/wiki/Birthday_problem)的碰撞。也就是说，几百万个并行流中的一对，考虑在一起，可能不会通过一套严格的随机性检验。其余数百万个流都会完全正常，而在大多数应用中，坏对在整个计算中剩余流的影响很可能会被淹没。
- en: '## Technical Details'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '## 技术细节'
- en: Like many PRNG algorithms, [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64") is constructed from a transition function, which advances
    a 128-bit state, and an output function, that mixes the 128-bit state into a 64-bit
    integer to be output. One of the guiding design principles of the PCG family of
    PRNGs is to balance the computational cost (and pseudorandomness strength) between
    the transition function and the output function. The transition function is a
    128-bit linear congruential generator (LCG), which consists of multiplying the
    128-bit state with a fixed multiplication constant and then adding a user-chosen
    increment, in 128-bit modular arithmetic. LCGs are well-analyzed PRNGs with known
    weaknesses, though 128-bit LCGs are large enough to pass stringent statistical
    tests on their own, with only the trivial output function. The output function
    of [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64")
    is intended to patch up some of those known weaknesses by doing “just enough”
    scrambling of the bits to assist in the statistical properties without adding
    too much computational cost.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 像许多伪随机数生成算法一样，[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64")是由一个转换函数构建的，这个函数会推进一个128位的状态，以及一个输出函数，将128位的状态混合成一个64位整数输出。PCG系列伪随机数生成器的一个指导设计原则之一是在转换函数和输出函数之间平衡计算成本（和伪随机性强度）。转换函数是一个128位线性同余生成器（LCG），它包括将128位状态与固定乘法常数相乘，然后加上用户选择的增量，在128位模算术中。尽管128位LCG本身足够大，可以通过简单的输出函数在自身上通过严格的统计测试，但LCG是已知有弱点的伪随机数生成器。[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64")的输出函数旨在通过“恰到好处”的位混合来修补一些已知的弱点，以帮助在不增加太多计算成本的情况下提高统计特性。
- en: One of these known weaknesses is that advancing the state of the LCG by steps
    numbering a power of two (`bg.advance(2**N)`) will leave the lower `N` bits identical
    to the state that was just left. For a single stream drawn from sequentially,
    this is of little consequence. The remaining \(128-N\) bits provide plenty of
    pseudorandomness that will be mixed in for any practical `N` that can be observed
    in a single stream, which is why one does not need to worry about this if you
    only use a single stream in your application. Similarly, the [`PCG64.jumped`](bit_generators/generated/numpy.random.PCG64.jumped.html#numpy.random.PCG64.jumped
    "numpy.random.PCG64.jumped") method uses a carefully chosen number of steps to
    avoid creating these collisions. However, once you start creating “randomly-initialized”
    parallel streams, either using OS entropy by calling [`default_rng`](generator.html#numpy.random.default_rng
    "numpy.random.default_rng") repeatedly or using [`SeedSequence.spawn`](bit_generators/generated/numpy.random.SeedSequence.spawn.html#numpy.random.SeedSequence.spawn
    "numpy.random.SeedSequence.spawn"), then we need to consider how many lower bits
    need to “collide” in order to create a bad pair of streams, and then evaluate
    the probability of creating such a collision. [Empirically](https://github.com/numpy/numpy/issues/16313),
    it has been determined that if one shares the lower 58 bits of state and shares
    an increment, then the pair of streams, when interleaved, will fail [PractRand](http://pracrand.sourceforge.net/)
    in a reasonable amount of time, after drawing a few gigabytes of data. Following
    the standard Birthday Paradox calculations for a collision of 58 bits, we can
    see that we can create \(2^{29}\), or about half a billion, streams which is when
    the probability of such a collision becomes high. Half a billion streams is quite
    high, and the amount of data each stream needs to draw before the statistical
    correlations become apparent to even the strict `PractRand` tests is in the gigabytes.
    But this is on the horizon for very large applications like distributed reinforcement
    learning. There are reasons to expect that even in these applications a collision
    probably will not have a practical effect in the total result, since the statistical
    problem is constrained to just the colliding pair.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 已知这个随机数发生器（LCG）的一个弱点是，使用步数为2的N次方(`bg.advance(2**N)`)会使低位的N个bit与上一状态相同。对于一个逐个生成的单一流而言，这只会产生微不足道的影响。剩下的\(128-N\)个bit会提供足够的伪随机性，对于在单一流中观察到的任何实际N而言，这些bit都会被混合在一起。这就是为什么如果你的应用中只使用单一流，那你就不用担心这个问题。类似地，[`PCG64.jumped`](bit_generators/generated/numpy.random.PCG64.jumped.html#numpy.random.PCG64.jumped
    "numpy.random.PCG64.jumped")方法使用了经过精心选择的步数来避免这些冲突。然而，一旦你开始创建“随机初始化”的并行流，要么通过多次调用[`default_rng`](generator.html#numpy.random.default_rng
    "numpy.random.default_rng")来使用操作系统熵，要么通过使用[`SeedSequence.spawn`](bit_generators/generated/numpy.random.SeedSequence.spawn.html#numpy.random.SeedSequence.spawn
    "numpy.random.SeedSequence.spawn")，那么我们就需要考虑有多少低位需要“冲突”才能创建一对糟糕的流，然后评估创建这种冲突的概率。[根据经验确定](https://github.com/numpy/numpy/issues/16313)，如果共享状态的低58位和共享增量，那么当这对流相互交错时，在绘制了数GB的数据后，会在合理的时间内使`PractRand`失败。根据生日悖论的标准计算，对于58位的冲突，我们可以看到我们可以创建\(2^{29}\)，或者大约五亿个流，这是冲突概率变得很高的时候。五亿个流是相当多的，而且每个流需要绘制大量的数据才能使统计相关性显现在甚至是严格的`PractRand`测试中。但是，对于分布式强化学习等非常大型的应用程序来说，这些都是可能会出现的问题。我们有理由期待，即使在这些应用程序中，冲突可能也不会对最终结果产生实际影响，因为统计问题只局限于发生冲突的那一对。
- en: Now, let us consider the case when the increment is not constrained to be the
    same. Our implementation of [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64") seeds both the state and the increment; that is, two calls
    to [`default_rng`](generator.html#numpy.random.default_rng "numpy.random.default_rng")
    (almost certainly) have different states and increments. Upon our first release,
    we believed that having the seeded increment would provide a certain amount of
    extra protection, that one would have to be “close” in both the state space and
    increment space in order to observe correlations (`PractRand` failures) in a pair
    of streams. If that were true, then the “bottleneck” for collisions would be the
    128-bit entropy pool size inside of [`SeedSequence`](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence
    "numpy.random.SeedSequence") (and 128-bit collisions are in the “preposterously
    unlikely” category). Unfortunately, this is not true.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑增量不受限制的情况。我们的[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64")实现同时对状态和增量进行种子化；也就是说，两次调用[`default_rng`](generator.html#numpy.random.default_rng
    "numpy.random.default_rng")（几乎肯定）具有不同的状态和增量。在我们第一次发布时，我们认为有种子增量会提供一定程度的额外保护，即在一对流中观察到相关性（`PractRand`失败）需要在状态空间和增量空间中都“接近”。如果这是真的，那么碰撞的“瓶颈”就是[`SeedSequence`](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence
    "numpy.random.SeedSequence")内部的128位熵池大小（128位的碰撞属于“天方夜谭般不可能发生”类别）。不幸的是，这不是真的。
- en: One of the known properties of an LCG is that different increments create *distinct*
    streams, but with a known relationship. Each LCG has an orbit that traverses all
    \(2^{128}\) different 128-bit states. Two LCGs with different increments are related
    in that one can “rotate” the orbit of the first LCG (advance it by a number of
    steps that we can compute from the two increments) such that then both LCGs will
    always then have the same state, up to an additive constant and maybe an inversion
    of the bits. If you then iterate both streams in lockstep, then the states will
    *always* remain related by that same additive constant (and the inversion, if
    present). Recall that [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64")
    is constructed from both a transition function (the LCG) and an output function.
    It was expected that the scrambling effect of the output function would have been
    strong enough to make the distinct streams practically independent (i.e. “passing
    the `PractRand` tests”) unless the two increments were pathologically related
    to each other (e.g. 1 and 3). The output function XSL-RR of the then-standard
    PCG algorithm that we implemented in [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64") turns out to be too weak to cover up for the 58-bit collision
    of the underlying LCG that we described above. For any given pair of increments,
    the size of the “colliding” space of states is the same, so for this weakness,
    the extra distinctness provided by the increments does not translate into extra
    protection from statistical correlations that `PractRand` can detect.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: LCG（线性同余发生器）的一个已知特性是不同的增量会创建*不同*的流，但它们之间存在已知关系。每个LCG都有一个遍历所有\(2^{128}\)个不同的128位状态的轨道。具有不同增量的两个LCG之间是相关的，因为可以“旋转”第一个LCG的轨道（将其前进若干步，这些步数可以从两个增量计算出来），以便两个LCG始终具有相同的状态，同时可能会有一个加法常数和比特的反转。然后，如果同时迭代两个流，状态将始终由相同的加法常数（和反转，如果存在的话）相关联。请记住，[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64")由转移函数（LCG）和输出函数构成。人们预期输出函数的混淆效果足以使不同的流在实践中独立（即“通过`PractRand`测试”），除非两个增量在路径上出现了病态关系（例如1和3）。我们在[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64")中实现的当时标准的PCG算法的输出函数XSL-RR事实证明对掩盖我们上述描述的基础LCG的58位冲突太弱。对于任何给定的增量对，状态的“冲突”空间的大小是相同的，因此对于这种弱点，增量提供的额外独立性并不能转化为对`PractRand`可以检测到的统计相关性的额外保护。
- en: 'Fortunately, strengthening the output function is able to correct this weakness
    and *does* turn the extra distinctness provided by differing increments into additional
    protection from these low-bit collisions. To the [PCG author’s credit](https://github.com/numpy/numpy/issues/13635#issuecomment-506088698),
    she had developed a stronger output function in response to related discussions
    during the long birth of the new [`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator") system. We NumPy developers chose to be “conservative”
    and use the XSL-RR variant that had undergone a longer period of testing at that
    time. The DXSM output function adopts a “xorshift-multiply” construction used
    in strong integer hashes that has much better avalanche properties than the XSL-RR
    output function. While there are “pathological” pairs of increments that induce
    “bad” additive constants that relate the two streams, the vast majority of pairs
    induce “good” additive constants that make the merely-distinct streams of LCG
    states into practically-independent output streams. Indeed, now the claim we once
    made about [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64")
    is actually true of [`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM"): collisions are possible, but both streams have to simultaneously
    be both “close” in the 128 bit state space *and* “close” in the 127-bit increment
    space, so that would be less likely than the negligible chance of colliding in
    the 128-bit internal [`SeedSequence`](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence
    "numpy.random.SeedSequence") pool. The DXSM output function is more computationally
    intensive than XSL-RR, but some optimizations in the LCG more than make up for
    the performance hit on most machines, so [`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM") is a good, safe upgrade. There are, of course, an infinite
    number of stronger output functions that one could consider, but most will have
    a greater computational cost, and the DXSM output function has now received many
    CPU cycles of testing via `PractRand` at this time.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '幸运的是，加强输出功能能够纠正这个弱点，并*确实*将不同的增量提供的额外差异转化为对低位碰撞的额外保护。 要归功于[PCG作者](https://github.com/numpy/numpy/issues/13635#issuecomment-506088698)，在新的[`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator")系统的长期诞生过程中，她根据相关讨论开发了更为强大的输出功能。在那个时候，我们NumPy开发人员选择“保守”，并使用了经过更长时间测试的XSL-RR变体。
    DXSM输出功能采用了在强整数哈希中使用的“xorshift-multiply”构造，其雪崩特性比XSL-RR输出功能好得多。虽然存在能够诱导“坏”加法常数的“病态”增量对，使得两个流相关联，但绝大多数对会诱导“好”加法常数，使得LCG状态的仅有差异流几乎成为独立的输出流。事实上，现在我们曾经关于[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64")所做的声明实际上也适用于[`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM")：碰撞是可能的，但两个流必须同时在128位状态空间中“接近”*且*在127位增量空间中“接近”，因此这比在128位内部[`SeedSequence`](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence
    "numpy.random.SeedSequence")池中发生碰撞的微不足道的机会更不太可能。 DXSM输出功能比XSL-RR更具计算密集性，在大多数机器上，LCG中的一些优化可以弥补性能损失，因此[`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM")是一个很好、安全的升级。当然，还有无数更强大的输出功能可以考虑，但大多数会有更大的计算成本，而DXSM输出功能现在已经通过`PractRand`进行了大量的CPU周期测试。  '
- en: Does this affect me?
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这会影响我吗？
- en: If you
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '如果您    '
- en: only use a single [`Generator`](generator.html#numpy.random.Generator "numpy.random.Generator")
    instance,
  id: totrans-26
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只使用单个[`Generator`](generator.html#numpy.random.Generator "numpy.random.Generator")实例，
- en: ''
  id: totrans-27
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-28
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: only use [`RandomState`](legacy.html#numpy.random.RandomState "numpy.random.RandomState")
    or the functions in [`numpy.random`](index.html#module-numpy.random "numpy.random"),
  id: totrans-29
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只使用[`RandomState`](legacy.html#numpy.random.RandomState "numpy.random.RandomState")或[`numpy.random`](index.html#module-numpy.random
    "numpy.random")中的函数，
- en: ''
  id: totrans-30
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-31
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: only use the [`PCG64.jumped`](bit_generators/generated/numpy.random.PCG64.jumped.html#numpy.random.PCG64.jumped
    "numpy.random.PCG64.jumped") method to generate parallel streams,
  id: totrans-32
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只使用[`PCG64.jumped`](bit_generators/generated/numpy.random.PCG64.jumped.html#numpy.random.PCG64.jumped
    "numpy.random.PCG64.jumped")方法生成并行流，
- en: ''
  id: totrans-33
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-34
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: explicitly use a [`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator") other than [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64"),
  id: totrans-35
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果明确使用[`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator")而不是[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64")，
- en: then this weakness does not affect you at all. Carry on.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这个弱点对你完全没有影响。继续进行。
- en: If you use moderate numbers of parallel streams created with [`default_rng`](generator.html#numpy.random.default_rng
    "numpy.random.default_rng") or [`SeedSequence.spawn`](bit_generators/generated/numpy.random.SeedSequence.spawn.html#numpy.random.SeedSequence.spawn
    "numpy.random.SeedSequence.spawn"), in the 1000s, then the chance of observing
    this weakness is negligibly small. You can continue to use [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64") comfortably.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用了适度数量的由[`default_rng`](generator.html#numpy.random.default_rng "numpy.random.default_rng")或[`SeedSequence.spawn`](bit_generators/generated/numpy.random.SeedSequence.spawn.html#numpy.random.SeedSequence.spawn
    "numpy.random.SeedSequence.spawn")创建的并行流，数量在1000左右，那么观察到这个弱点的机会几乎可以忽略不计。您可以继续舒适地使用[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64")。
- en: If you use very large numbers of parallel streams, in the millions, and draw
    large amounts of numbers from each, then the chance of observing this weakness
    can become non-negligible, if still small. An example of such a use case would
    be a very large distributed reinforcement learning problem with millions of long
    Monte Carlo playouts each generating billions of random number draws. Such use
    cases should consider using [`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM") explicitly or another modern [`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator") like [`SFC64`](bit_generators/sfc64.html#numpy.random.SFC64
    "numpy.random.SFC64") or [`Philox`](bit_generators/philox.html#numpy.random.Philox
    "numpy.random.Philox"), but it is unlikely that any old results you may have calculated
    are invalid. In any case, the weakness is a kind of [Birthday Paradox](https://en.wikipedia.org/wiki/Birthday_problem)
    collision. That is, a single pair of parallel streams out of the millions, considered
    together, might fail a stringent set of statistical tests of randomness. The remaining
    millions of streams would all be perfectly fine, and the effect of the bad pair
    in the whole calculation is very likely to be swamped by the remaining streams
    in most applications.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用了非常大数量的并行流，数量在百万级，并且每个流中抽取了大量的数字，那么观察到这个弱点的机会可能会变得不可忽略，尽管仍然很小。这样一个使用案例的例子是一个非常大的分布式强化学习问题，每个都生成了数亿次随机数抽取的长蒙特卡洛模拟。这样的使用情况应该明确考虑使用[`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM")或另一个现代[`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator")，如[`SFC64`](bit_generators/sfc64.html#numpy.random.SFC64
    "numpy.random.SFC64")或[`Philox`](bit_generators/philox.html#numpy.random.Philox
    "numpy.random.Philox")，但是您可能计算的任何旧结果都不太可能无效。无论如何，这个弱点是一种[生日悖论](https://en.wikipedia.org/wiki/Birthday_problem)碰撞。也就是说，数百万个并行流中的一对考虑在一起，可能无法通过一组严格的随机性检验。剩下的数百万个流都是完全正常的，并且在大多数应用中，剩余流的影响很可能会淹没整个计算中的坏对的效果。
- en: '## Technical Details'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '## 技术细节'
- en: Like many PRNG algorithms, [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64") is constructed from a transition function, which advances
    a 128-bit state, and an output function, that mixes the 128-bit state into a 64-bit
    integer to be output. One of the guiding design principles of the PCG family of
    PRNGs is to balance the computational cost (and pseudorandomness strength) between
    the transition function and the output function. The transition function is a
    128-bit linear congruential generator (LCG), which consists of multiplying the
    128-bit state with a fixed multiplication constant and then adding a user-chosen
    increment, in 128-bit modular arithmetic. LCGs are well-analyzed PRNGs with known
    weaknesses, though 128-bit LCGs are large enough to pass stringent statistical
    tests on their own, with only the trivial output function. The output function
    of [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64")
    is intended to patch up some of those known weaknesses by doing “just enough”
    scrambling of the bits to assist in the statistical properties without adding
    too much computational cost.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 像许多PRNG算法一样，[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64")是由一个转换函数构造的，它推进一个128位状态，以及一个输出函数，将128位状态混合成一个64位整数进行输出。PCG系列PRNG的一个指导性设计原则之一是在转换函数和输出函数之间平衡计算成本（和伪随机强度）。转换函数是一个128位线性同余生成器（LCG），它包括将128位状态与固定乘法常数相乘，然后在128位模算术中加上用户选择的增量。LCGs是经过深入分析的PRNG，已知存在一些弱点，尽管128位LCGs足够大，足以单独通过严格的统计测试，仅使用微不足道的输出函数。[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64")的输出函数旨在通过“恰到好处”的比特位混淆，修复一些已知的弱点，以协助统计特性，而不增加过多的计算成本。
- en: One of these known weaknesses is that advancing the state of the LCG by steps
    numbering a power of two (`bg.advance(2**N)`) will leave the lower `N` bits identical
    to the state that was just left. For a single stream drawn from sequentially,
    this is of little consequence. The remaining \(128-N\) bits provide plenty of
    pseudorandomness that will be mixed in for any practical `N` that can be observed
    in a single stream, which is why one does not need to worry about this if you
    only use a single stream in your application. Similarly, the [`PCG64.jumped`](bit_generators/generated/numpy.random.PCG64.jumped.html#numpy.random.PCG64.jumped
    "numpy.random.PCG64.jumped") method uses a carefully chosen number of steps to
    avoid creating these collisions. However, once you start creating “randomly-initialized”
    parallel streams, either using OS entropy by calling [`default_rng`](generator.html#numpy.random.default_rng
    "numpy.random.default_rng") repeatedly or using [`SeedSequence.spawn`](bit_generators/generated/numpy.random.SeedSequence.spawn.html#numpy.random.SeedSequence.spawn
    "numpy.random.SeedSequence.spawn"), then we need to consider how many lower bits
    need to “collide” in order to create a bad pair of streams, and then evaluate
    the probability of creating such a collision. [Empirically](https://github.com/numpy/numpy/issues/16313),
    it has been determined that if one shares the lower 58 bits of state and shares
    an increment, then the pair of streams, when interleaved, will fail [PractRand](http://pracrand.sourceforge.net/)
    in a reasonable amount of time, after drawing a few gigabytes of data. Following
    the standard Birthday Paradox calculations for a collision of 58 bits, we can
    see that we can create \(2^{29}\), or about half a billion, streams which is when
    the probability of such a collision becomes high. Half a billion streams is quite
    high, and the amount of data each stream needs to draw before the statistical
    correlations become apparent to even the strict `PractRand` tests is in the gigabytes.
    But this is on the horizon for very large applications like distributed reinforcement
    learning. There are reasons to expect that even in these applications a collision
    probably will not have a practical effect in the total result, since the statistical
    problem is constrained to just the colliding pair.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个已知的弱点是，通过步数为2的幂（`bg.advance(2**N)`）推进 LCG 的状态将使刚离开的较低的 `N` 位与当前状态相同。对于按顺序抽取的单个流，这影响不大。剩下的
    \(128-N\) 位提供了足够的伪随机性，对于任何在单个流中可以观察到的实际 `N` 来说，都会混合其中，这就是为什么如果你的应用程序只使用单个流，则不需要担心这一点。同样地，[`PCG64.jumped`](bit_generators/generated/numpy.random.PCG64.jumped.html#numpy.random.PCG64.jumped
    "numpy.random.PCG64.jumped") 方法使用了精心选择的步数，以避免创建这些冲突。但是，一旦开始创建“随机初始化”的并行流，无论是通过反复调用
    [`default_rng`](generator.html#numpy.random.default_rng "numpy.random.default_rng")
    使用操作系统熵，还是使用 [`SeedSequence.spawn`](bit_generators/generated/numpy.random.SeedSequence.spawn.html#numpy.random.SeedSequence.spawn
    "numpy.random.SeedSequence.spawn")，那么我们就需要考虑需要“碰撞”多少较低的位，以创建一对糟糕的流，然后评估创建这种碰撞的概率。[经验上](https://github.com/numpy/numpy/issues/16313)，已经确定如果共享状态的较低
    58 位并共享增量，则这对流，在交错时，将在抽取几吉字节的数据后合理时间内失败 [`PractRand`](http://pracrand.sourceforge.net/)
    测试。根据 58 位碰撞的生日悖论标准计算，我们可以看到可以创建 \(2^{29}\)，或约半十亿个流，这是碰撞概率变高的时候。半十亿个流是非常多的，甚至在严格的
    `PractRand` 测试中，每个流需要抽取的数据量变得明显相关之前，统计学上的相关性变得明显之前。但是这是对于非常大的应用程序（如分布式强化学习）的前景。有理由期望，即使在这些应用中，碰撞可能对总体结果产生实际影响，因为统计问题仅限于碰撞对。
- en: Now, let us consider the case when the increment is not constrained to be the
    same. Our implementation of [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64") seeds both the state and the increment; that is, two calls
    to [`default_rng`](generator.html#numpy.random.default_rng "numpy.random.default_rng")
    (almost certainly) have different states and increments. Upon our first release,
    we believed that having the seeded increment would provide a certain amount of
    extra protection, that one would have to be “close” in both the state space and
    increment space in order to observe correlations (`PractRand` failures) in a pair
    of streams. If that were true, then the “bottleneck” for collisions would be the
    128-bit entropy pool size inside of [`SeedSequence`](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence
    "numpy.random.SeedSequence") (and 128-bit collisions are in the “preposterously
    unlikely” category). Unfortunately, this is not true.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑当增量不受限制时的情况。我们的[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64")的实现同时对状态和增量进行种子化；也就是说，两次调用[`default_rng`](generator.html#numpy.random.default_rng
    "numpy.random.default_rng")（几乎可以确定）具有不同的状态和增量。在我们的第一个发布版本中，我们认为拥有种子增量会提供一定程度的额外保护，即必须在状态空间和增量空间中“接近”，才能观察到一对流的相关性（`PractRand`失败）。如果这是真的，那么碰撞的“瓶颈”将是[`SeedSequence`](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence
    "numpy.random.SeedSequence")内的128位熵池大小（128位碰撞属于“不可思议的罕见”类别）。不幸的是，这并不是真的。
- en: One of the known properties of an LCG is that different increments create *distinct*
    streams, but with a known relationship. Each LCG has an orbit that traverses all
    \(2^{128}\) different 128-bit states. Two LCGs with different increments are related
    in that one can “rotate” the orbit of the first LCG (advance it by a number of
    steps that we can compute from the two increments) such that then both LCGs will
    always then have the same state, up to an additive constant and maybe an inversion
    of the bits. If you then iterate both streams in lockstep, then the states will
    *always* remain related by that same additive constant (and the inversion, if
    present). Recall that [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64")
    is constructed from both a transition function (the LCG) and an output function.
    It was expected that the scrambling effect of the output function would have been
    strong enough to make the distinct streams practically independent (i.e. “passing
    the `PractRand` tests”) unless the two increments were pathologically related
    to each other (e.g. 1 and 3). The output function XSL-RR of the then-standard
    PCG algorithm that we implemented in [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64") turns out to be too weak to cover up for the 58-bit collision
    of the underlying LCG that we described above. For any given pair of increments,
    the size of the “colliding” space of states is the same, so for this weakness,
    the extra distinctness provided by the increments does not translate into extra
    protection from statistical correlations that `PractRand` can detect.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: LCG的已知特性之一是不同的增量会创建*不同的*流，但具有已知的关系。每个LCG都有一个轨道，遍历所有\(2^{128}\)个不同的128位状态。具有不同增量的两个LCG相关联，因为可以“旋转”第一个LCG的轨道（将其前进一个我们可以从两个增量计算出的步骤数），以便然后两个LCG将始终具有相同的状态，最多一个加法常数和可能位的反转。然后，如果同时迭代两个流，则状态将*始终*保持由相同的加法常数（如果存在）和位反转相关。请记住，[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64")由转换函数（LCG）和输出函数构成。人们预期输出函数的混淆效果足够强大，使得不同的流在实践上相互独立（即“通过`PractRand`测试”），除非两个增量与彼此病态相关（例如1和3）。我们在[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64")中实现的当时标准PCG算法的输出函数XSL-RR事实证明对上述我们描述的基础LCG的58位碰撞太弱。对于任何给定的增量对，状态的“碰撞”空间大小是相同的，因此对于这种弱点，增量提供的额外差异性并不能转化为`PractRand`能够检测到的统计相关性的额外保护。
- en: 'Fortunately, strengthening the output function is able to correct this weakness
    and *does* turn the extra distinctness provided by differing increments into additional
    protection from these low-bit collisions. To the [PCG author’s credit](https://github.com/numpy/numpy/issues/13635#issuecomment-506088698),
    she had developed a stronger output function in response to related discussions
    during the long birth of the new [`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator") system. We NumPy developers chose to be “conservative”
    and use the XSL-RR variant that had undergone a longer period of testing at that
    time. The DXSM output function adopts a “xorshift-multiply” construction used
    in strong integer hashes that has much better avalanche properties than the XSL-RR
    output function. While there are “pathological” pairs of increments that induce
    “bad” additive constants that relate the two streams, the vast majority of pairs
    induce “good” additive constants that make the merely-distinct streams of LCG
    states into practically-independent output streams. Indeed, now the claim we once
    made about [`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64 "numpy.random.PCG64")
    is actually true of [`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM"): collisions are possible, but both streams have to simultaneously
    be both “close” in the 128 bit state space *and* “close” in the 127-bit increment
    space, so that would be less likely than the negligible chance of colliding in
    the 128-bit internal [`SeedSequence`](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence
    "numpy.random.SeedSequence") pool. The DXSM output function is more computationally
    intensive than XSL-RR, but some optimizations in the LCG more than make up for
    the performance hit on most machines, so [`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM") is a good, safe upgrade. There are, of course, an infinite
    number of stronger output functions that one could consider, but most will have
    a greater computational cost, and the DXSM output function has now received many
    CPU cycles of testing via `PractRand` at this time.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，加强输出功能能够纠正这一弱点，*确实*将由不同增量提供的额外清晰度转化为对这些低位冲突的额外保护。要赞扬[PCG作者](https://github.com/numpy/numpy/issues/13635#issuecomment-506088698)的是，她在新的[`BitGenerator`](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator
    "numpy.random.BitGenerator")系统漫长的诞生过程中，根据相关讨论开发了一个更强大的输出功能。我们NumPy开发人员选择“保守”，使用了在那个时候经过更长时间测试的XSL-RR变体。DXSM输出功能采用了在强整数哈希中使用的“xorshift-multiply”构造，其具有比XSL-RR输出功能更好的雪崩特性。虽然有一些“病态”的增量对，会引发与两个流相关的“不好”的加法常量，但绝大多数对会引发“好”的加法常量，使简单区分的LCG状态流变成实际上独立的输出流。事实上，我们曾经关于[`PCG64`](bit_generators/pcg64.html#numpy.random.PCG64
    "numpy.random.PCG64")提出的声明现在实际上也适用于[`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM")：碰撞是可能的，但两个流必须同时在128位状态空间*和*127位增量空间内“接近”，这比在128位内部[`SeedSequence`](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence
    "numpy.random.SeedSequence")池内碰撞的微不足道的机会更不太可能。DXSM输出功能比XSL-RR更耗计算资源，但在大多数机器上通过LCG的一些优化弥补了性能损失，因此[`PCG64DXSM`](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM
    "numpy.random.PCG64DXSM")是一个不错、安全的升级选择。当然，有无限多种更强大的输出功能可供考虑，但大多数将具有更大的计算成本，而DXSM输出功能目前已经通过`PractRand`获得了许多CPU周期的测试。
