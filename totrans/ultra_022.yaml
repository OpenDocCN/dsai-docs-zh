- en: YOLOv8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/models/yolov8/`](https://docs.ultralytics.com/models/yolov8/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: YOLOv8 is the latest iteration in the YOLO series of real-time object detectors,
    offering cutting-edge performance in terms of accuracy and speed. Building upon
    the advancements of previous YOLO versions, YOLOv8 introduces new features and
    optimizations that make it an ideal choice for various object detection tasks
    in a wide range of applications.
  prefs: []
  type: TYPE_NORMAL
- en: '![Ultralytics YOLOv8](img/ceeef27fc01c2eb25ee99a7364e044f5.png)'
  prefs: []
  type: TYPE_IMG
- en: '[`www.youtube.com/embed/Na0HvJ4hkk0`](https://www.youtube.com/embed/Na0HvJ4hkk0)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch:** Ultralytics YOLOv8 Model Overview'
  prefs: []
  type: TYPE_NORMAL
- en: Key Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Advanced Backbone and Neck Architectures:** YOLOv8 employs state-of-the-art
    backbone and neck architectures, resulting in improved feature extraction and
    object detection performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anchor-free Split Ultralytics Head:** YOLOv8 adopts an anchor-free split
    Ultralytics head, which contributes to better accuracy and a more efficient detection
    process compared to anchor-based approaches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimized Accuracy-Speed Tradeoff:** With a focus on maintaining an optimal
    balance between accuracy and speed, YOLOv8 is suitable for real-time object detection
    tasks in diverse application areas.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variety of Pre-trained Models:** YOLOv8 offers a range of pre-trained models
    to cater to various tasks and performance requirements, making it easier to find
    the right model for your specific use case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supported Tasks and Modes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The YOLOv8 series offers a diverse range of models, each specialized for specific
    tasks in computer vision. These models are designed to cater to various requirements,
    from object detection to more complex tasks like instance segmentation, pose/keypoints
    detection, oriented object detection, and classification.
  prefs: []
  type: TYPE_NORMAL
- en: Each variant of the YOLOv8 series is optimized for its respective task, ensuring
    high performance and accuracy. Additionally, these models are compatible with
    various operational modes including Inference, Validation, Training, and Export,
    facilitating their use in different stages of deployment and development.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Filenames | Task | Inference | Validation | Training | Export |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8 | `yolov8n.pt` `yolov8s.pt` `yolov8m.pt` `yolov8l.pt` `yolov8x.pt`
    | Detection | ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-seg | `yolov8n-seg.pt` `yolov8s-seg.pt` `yolov8m-seg.pt` `yolov8l-seg.pt`
    `yolov8x-seg.pt` | Instance Segmentation | ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-pose | `yolov8n-pose.pt` `yolov8s-pose.pt` `yolov8m-pose.pt` `yolov8l-pose.pt`
    `yolov8x-pose.pt` `yolov8x-pose-p6.pt` | Pose/Keypoints | ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-obb | `yolov8n-obb.pt` `yolov8s-obb.pt` `yolov8m-obb.pt` `yolov8l-obb.pt`
    `yolov8x-obb.pt` | Oriented Detection | ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-cls | `yolov8n-cls.pt` `yolov8s-cls.pt` `yolov8m-cls.pt` `yolov8l-cls.pt`
    `yolov8x-cls.pt` | Classification | ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: This table provides an overview of the YOLOv8 model variants, highlighting their
    applicability in specific tasks and their compatibility with various operational
    modes such as Inference, Validation, Training, and Export. It showcases the versatility
    and robustness of the YOLOv8 series, making them suitable for a variety of applications
    in computer vision.
  prefs: []
  type: TYPE_NORMAL
- en: Performance Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Performance
  prefs: []
  type: TYPE_NORMAL
- en: See Detection Docs for usage examples with these models trained on COCO, which
    include 80 pre-trained classes.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)
    | 640 | 37.3 | 80.4 | 0.99 | 3.2 | 8.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)
    | 640 | 44.9 | 128.4 | 1.20 | 11.2 | 28.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)
    | 640 | 50.2 | 234.7 | 1.83 | 25.9 | 78.9 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt)
    | 640 | 52.9 | 375.2 | 2.39 | 43.7 | 165.2 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt)
    | 640 | 53.9 | 479.1 | 3.53 | 68.2 | 257.8 |'
  prefs: []
  type: TYPE_TB
- en: See Detection Docs for usage examples with these models trained on Open Image
    V7, which include 600 pre-trained classes.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-oiv7.pt)
    | 640 | 18.4 | 142.4 | 1.21 | 3.5 | 10.5 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-oiv7.pt)
    | 640 | 27.7 | 183.1 | 1.40 | 11.4 | 29.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-oiv7.pt)
    | 640 | 33.6 | 408.5 | 2.26 | 26.2 | 80.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-oiv7.pt)
    | 640 | 34.9 | 596.9 | 2.43 | 44.1 | 167.4 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-oiv7.pt)
    | 640 | 36.3 | 860.6 | 3.56 | 68.7 | 260.6 |'
  prefs: []
  type: TYPE_TB
- en: See Segmentation Docs for usage examples with these models trained on COCO,
    which include 80 pre-trained classes.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(box 50-95) | mAP^(mask 50-95) | Speed ^(CPU
    ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-seg.pt)
    | 640 | 36.7 | 30.5 | 96.1 | 1.21 | 3.4 | 12.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-seg.pt)
    | 640 | 44.6 | 36.8 | 155.7 | 1.47 | 11.8 | 42.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-seg.pt)
    | 640 | 49.9 | 40.8 | 317.0 | 2.18 | 27.3 | 110.2 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-seg.pt)
    | 640 | 52.3 | 42.6 | 572.4 | 2.79 | 46.0 | 220.5 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-seg.pt)
    | 640 | 53.4 | 43.4 | 712.1 | 4.02 | 71.8 | 344.1 |'
  prefs: []
  type: TYPE_TB
- en: See Classification Docs for usage examples with these models trained on ImageNet,
    which include 1000 pre-trained classes.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | acc ^(top1) | acc ^(top5) | Speed ^(CPU ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B) at 640) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-cls.pt)
    | 224 | 69.0 | 88.3 | 12.9 | 0.31 | 2.7 | 4.3 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-cls.pt)
    | 224 | 73.8 | 91.7 | 23.4 | 0.35 | 6.4 | 13.5 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-cls.pt)
    | 224 | 76.8 | 93.5 | 85.4 | 0.62 | 17.0 | 42.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-cls.pt)
    | 224 | 76.8 | 93.5 | 163.0 | 0.87 | 37.5 | 99.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-cls.pt)
    | 224 | 79.0 | 94.6 | 232.0 | 1.01 | 57.4 | 154.8 |'
  prefs: []
  type: TYPE_TB
- en: See Pose Estimation Docs for usage examples with these models trained on COCO,
    which include 1 pre-trained class, 'person'.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(pose 50-95) | mAP^(pose 50) | Speed ^(CPU
    ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-pose.pt)
    | 640 | 50.4 | 80.1 | 131.8 | 1.18 | 3.3 | 9.2 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-pose.pt)
    | 640 | 60.0 | 86.2 | 233.2 | 1.42 | 11.6 | 30.2 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-pose.pt)
    | 640 | 65.0 | 88.8 | 456.3 | 2.00 | 26.4 | 81.0 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-pose.pt)
    | 640 | 67.6 | 90.0 | 784.5 | 2.59 | 44.4 | 168.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-pose.pt)
    | 640 | 69.2 | 90.2 | 1607.1 | 3.73 | 69.4 | 263.2 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-pose-p6](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-pose-p6.pt)
    | 1280 | 71.6 | 91.2 | 4088.7 | 10.04 | 99.1 | 1066.4 |'
  prefs: []
  type: TYPE_TB
- en: See Oriented Detection Docs for usage examples with these models trained on
    DOTAv1, which include 15 pre-trained classes.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(test 50) | Speed ^(CPU ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n-obb](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-obb.pt)
    | 1024 | 78.0 | 204.77 | 3.57 | 3.1 | 23.3 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s-obb](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-obb.pt)
    | 1024 | 79.5 | 424.88 | 4.07 | 11.4 | 76.3 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m-obb](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-obb.pt)
    | 1024 | 80.5 | 763.48 | 7.61 | 26.4 | 208.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l-obb](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-obb.pt)
    | 1024 | 80.7 | 1278.42 | 11.83 | 44.5 | 433.8 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-obb](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-obb.pt)
    | 1024 | 81.36 | 1759.10 | 13.23 | 69.5 | 676.7 |'
  prefs: []
  type: TYPE_TB
- en: Usage Examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This example provides simple YOLOv8 training and inference examples. For full
    documentation on these and other modes see the Predict, Train, Val and Export
    docs pages.
  prefs: []
  type: TYPE_NORMAL
- en: Note the below example is for YOLOv8 Detect models for object detection. For
    additional supported tasks see the Segment, Classify, OBB docs and Pose docs.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: 'PyTorch pretrained `*.pt` models as well as configuration `*.yaml` files can
    be passed to the `YOLO()` class to create a model instance in python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'CLI commands are available to directly run the models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Citations and Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you use the YOLOv8 model or any other software from this repository in your
    work, please cite it using the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Please note that the DOI is pending and will be added to the citation once it
    is available. YOLOv8 models are provided under [AGPL-3.0](https://github.com/ultralytics/ultralytics/blob/main/LICENSE)
    and [Enterprise](https://ultralytics.com/license) licenses.
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is YOLOv8 and how does it differ from previous YOLO versions?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv8 is the latest iteration in the Ultralytics YOLO series, designed to improve
    real-time object detection performance with advanced features. Unlike earlier
    versions, YOLOv8 incorporates an **anchor-free split Ultralytics head**, state-of-the-art
    backbone and neck architectures, and offers optimized accuracy-speed tradeoff,
    making it ideal for diverse applications. For more details, check the Overview
    and Key Features sections.
  prefs: []
  type: TYPE_NORMAL
- en: How can I use YOLOv8 for different computer vision tasks?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv8 supports a wide range of computer vision tasks, including object detection,
    instance segmentation, pose/keypoints detection, oriented object detection, and
    classification. Each model variant is optimized for its specific task and compatible
    with various operational modes like Inference, Validation, Training, and Export.
    Refer to the Supported Tasks and Modes section for more information.
  prefs: []
  type: TYPE_NORMAL
- en: What are the performance metrics for YOLOv8 models?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv8 models achieve state-of-the-art performance across various benchmarking
    datasets. For instance, the YOLOv8n model achieves a mAP (mean Average Precision)
    of 37.3 on the COCO dataset and a speed of 0.99 ms on A100 TensorRT. Detailed
    performance metrics for each model variant across different tasks and datasets
    can be found in the Performance Metrics section.
  prefs: []
  type: TYPE_NORMAL
- en: How do I train a YOLOv8 model?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Training a YOLOv8 model can be done using either Python or CLI. Below are examples
    for training a model using a COCO-pretrained YOLOv8 model on the COCO8 dataset
    for 100 epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: For further details, visit the Training documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Can I benchmark YOLOv8 models for performance?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Yes, YOLOv8 models can be benchmarked for performance in terms of speed and
    accuracy across various export formats. You can use PyTorch, ONNX, TensorRT, and
    more for benchmarking. Below are example commands for benchmarking using Python
    and CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: For additional information, check the Performance Metrics section.
  prefs: []
  type: TYPE_NORMAL
