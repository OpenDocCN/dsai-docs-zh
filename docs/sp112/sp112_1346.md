# scipy.stats.permutation_test

> 原文链接：[https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.stats.permutation_test.html#scipy.stats.permutation_test](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.stats.permutation_test.html#scipy.stats.permutation_test)

```py
scipy.stats.permutation_test(data, statistic, *, permutation_type='independent', vectorized=None, n_resamples=9999, batch=None, alternative='two-sided', axis=0, random_state=None)
```

在提供的数据上对给定统计量进行置换检验。

对于独立样本统计量，零假设是数据是从相同分布中随机抽取的。对于配对样本统计量，可以测试两个零假设：数据被随机配对，或者数据被随机分配到样本中。

参数：

**data**类数组的可迭代对象

包含样本的数组，每个样本都是一组观测值。样本数组的维度必须与广播兼容，除了 *axis* 外。

**statistic**可调用对象

用于计算假设检验的 p 值的统计量。*statistic* 必须是一个可调用的函数，接受样本作为单独的参数（例如 `statistic(*data)`），并返回结果统计量。如果设置了 *vectorized* 为 `True`，则 *statistic* 还必须接受一个关键字参数 *axis* 并进行向量化以沿着样本数组的提供的 *axis* 计算统计量。

**permutation_type**{'independent', 'samples', 'pairings'}，可选

要执行的置换类型，符合零假设的要求。前两种置换类型适用于配对样本统计量，其中所有样本包含相同数量的观测值，并且沿着 *axis* 具有相应索引的观测值被认为是配对的；第三种适用于独立样本统计量。

+   `'samples'`：观测值被分配到不同的样本，但与其他样本中相同的观测值保持配对。这种置换类型适用于配对样本假设检验，如威尔科克森符号秩检验和配对 t 检验。

+   `'pairings'`：观测值与不同的观测值配对，但它们仍然在同一样本内。这种置换类型适用于具有统计量如斯皮尔曼相关系数 \(\rho\)、肯德尔 \(\tau\) 和皮尔逊 \(r\) 的关联/相关性检验。

+   `'independent'`（默认）：观测值被分配到不同的样本中。样本可以包含不同数量的观测值。这种置换类型适用于独立样本假设检验，如曼-惠特尼 U 检验和独立样本 t 检验。

    请参阅下面的注释部分以获取有关置换类型更详细的描述。

**vectorized**布尔值，可选

如果将 *vectorized* 设置为 `False`，则不会传递关键字参数 *axis* 给 *statistic*，并且期望它仅为 1D 样本计算统计量。如果为 `True`，则在传递 ND 样本数组时，将传递关键字参数 *axis* 给 *statistic* 并且期望沿着 *axis* 计算统计量。如果为 `None`（默认），如果 *axis* 是 *statistic* 的参数，则 *vectorized* 将设置为 `True`。使用矢量化统计量通常可以减少计算时间。

**n_resamples**int 或 np.inf，默认值：9999

用于近似空值分布的随机排列（重新取样）的数量。如果大于或等于不同排列的数量，则将计算精确的空值分布。注意，随着样本大小的增长，不同排列的数量会非常迅速地增加，因此仅对非常小的数据集适用精确测试。

**batch**int，可选

每次调用*statistic*时处理的排列数量。内存使用量为 O(*batch* * `n` )，其中 `n` 是所有样本的总大小，不管 *vectorized* 的值如何。默认为 `None`，此时 `batch` 是排列的数量。

**alternative**{‘two-sided’, ‘less’, ‘greater’}，可选

用于计算 p 值的备择假设。对于每个备择假设，p 值的定义如下。

+   `'greater'`：空值分布中大于或等于测试统计量观察值的百分比。

+   `'less'`：空值分布中小于或等于测试统计量观察值的百分比。

+   `'two-sided'`（默认）：上述 p 值之一的两倍较小的值。

注意，随机化测试的 p 值是根据[[2]](#r5641c5b1ce56-2)和[[3]](#r5641c5b1ce56-3)中建议的保守（过估计）近似计算的，而不是建议的无偏估计器[[4]](#r5641c5b1ce56-4)。也就是说，在计算随机化空值分布中与测试统计量观察值一样极端的比例时，分子和分母的值都增加了一。这种调整的解释是，测试统计量的观察值总是作为随机化空值分布的一个元素。用于双边 p 值的约定不是普遍适用的；如果喜欢不同的定义，则返回观察到的测试统计量和空值分布。

**axis**int，默认值：0

(广播)样本的轴，用于计算统计量。如果样本具有不同维数，则在考虑 *axis* 之前，对具有较少维度的样本前置单例维度。

**random_state**{None, int, [`numpy.random.Generator`](https://numpy.org/devdocs/reference/random/generator.html#numpy.random.Generator "(in NumPy v2.0.dev0)")，

> [`numpy.random.RandomState`](https://numpy.org/devdocs/reference/random/legacy.html#numpy.random.RandomState "(in NumPy v2.0.dev0)")，可选

用于生成排列的伪随机数生成器状态。

如果 *random_state* 为 `None`（默认），则使用 [`numpy.random.RandomState`](https://numpy.org/devdocs/reference/random/legacy.html#numpy.random.RandomState "(在 NumPy v2.0.dev0 中)") 单例。如果 *random_state* 是整数，则使用一个新的 `RandomState` 实例，并以 *random_state* 为种子。如果 *random_state* 已经是 `Generator` 或 `RandomState` 实例，则使用该实例。

返回：

**res**PermutationTestResult

具有以下属性的对象：

statisticfloat 或 ndarray

数据的观察检验统计量。

pvaluefloat 或 ndarray

给定备择假设的 p 值。

`null_distribution`ndarray

在零假设下生成的检验统计量值。

注意事项

此函数支持的三种排列检验类型如下所述。

**非配对统计量** (`permutation_type='independent'`):

与此排列类型相关联的零假设是，所有观察值都从相同的基础分布中抽取，并且它们被随机分配到一个样本中。

假设 `data` 包含两个样本；例如 `a, b = data`。当 `1 < n_resamples < binom(n, k)` 时，其中

+   `k` 是 `a` 中观测值的数量，

+   `n` 是 `a` 和 `b` 中观测值的总数，以及

+   `binom(n, k)` 是二项式系数 (`n` 选择 `k`)，

数据被合并（串联），随机分配到第一或第二个样本，并计算统计量。此过程重复执行 *permutation* 次，生成零假设下统计量的分布。将原始数据的统计量与该分布进行比较，以确定 p 值。

当 `n_resamples >= binom(n, k)` 时，执行精确检验：数据在每种不同的方式下精确地一次性分配到样本中，并形成精确的零假设分布。请注意，对于给定数据在样本之间的分区方式，仅考虑数据在每个样本内的一种排序/排列。对于不依赖于数据顺序在样本内的统计量来说，这显著降低了计算成本，而不会影响零分布的形状（因为每个值的频率/计数受相同因素影响）。

对于 `a = [a1, a2, a3, a4]` 和 `b = [b1, b2, b3]`，此排列类型的示例是 `x = [b3, a1, a2, b2]` 和 `y = [a4, b1, a3]`。因为精确检验仅考虑数据在每个样本内的一种排序/排列，所以像 `x = [b3, a1, b2, a2]` 和 `y = [a4, a3, b1]` 这样的重新采样不被视为与上述示例不同。

`permutation_type='independent'` 不支持单样本统计量，但可应用于具有超过两个样本的统计量。在这种情况下，如果 `n` 是每个样本中观测值数量的数组，则不同分区的数量是：

```py
np.prod([binom(sum(n[i:]), sum(n[i+1:])) for i in range(len(n)-1)]) 
```

**配对统计量，排列配对** (`permutation_type='pairings'`):

与此置换类型相关的零假设是，每个样本内的观测值都来自相同的基础分布，并且与其他样本元素的配对是随机的。

假设 `data` 只包含一个样本；例如 `a, = data`，我们希望考虑将 `a` 的元素与第二个样本 `b` 的元素的所有可能配对。设 `n` 是 `a` 中的观测数，也必须等于 `b` 中的观测数。

当 `1 < n_resamples < factorial(n)` 时，对 `a` 中的元素进行随机置换。用户提供的统计量接受一个数据参数，例如 `a_perm`，并计算考虑 `a_perm` 和 `b` 的统计量。重复执行这一过程，*permutation* 次，生成零假设下统计量的分布。将原始数据的统计量与该分布进行比较，以确定 p 值。

当 `n_resamples >= factorial(n)` 时，执行精确检验：对 `a` 按每种不同方式精确置换一次。因此，对 `a` 和 `b` 之间的每个唯一配对样本计算*统计量*一次。

对于 `a = [a1, a2, a3]` 和 `b = [b1, b2, b3]`，这种置换类型的示例是 `a_perm = [a3, a1, a2]`，而 `b` 保持原始顺序。

`permutation_type='pairings'` 支持包含任意数量样本的 `data`，每个样本必须包含相同数量的观测值。`data` 中提供的所有样本都独立进行置换。因此，如果 `m` 是样本数，`n` 是每个样本中的观测数，则精确检验的置换数为：

```py
factorial(n)**m 
```

请注意，如果例如双样本统计量并不直接依赖于提供观测值的顺序 - 只依赖于观测值的*配对*，那么在 `data` 中只需提供其中一个样本。这大大降低了计算成本，但不影响零分布的形状（因为每个值的频率/计数受相同因素影响）。

**配对统计，样本置换** (`permutation_type='samples'`):

与此置换类型相关的零假设是，每对观测值都来自相同的基础分布，并且它们被分配到的样本是随机的。

假设 `data` 包含两个样本；例如 `a, b = data`。设 `n` 是 `a` 中的观测数，也必须等于 `b` 中的观测数。

当 `1 < n_resamples < 2**n` 时，对 `a` 和 `b` 中的元素进行随机交换（保持它们的配对关系），并计算统计量。重复执行这一过程，*permutation* 次，生成零假设下统计量的分布。将原始数据的统计量与该分布进行比较，以确定 p 值。

当 `n_resamples >= 2**n` 时，执行精确检验：观察值被准确地分配到两个样本中的每一种不同方式（同时保持配对）一次。

对于 `a = [a1, a2, a3]` 和 `b = [b1, b2, b3]`，这种排列类型的一个示例是 `x = [b1, a2, b3]` 和 `y = [a1, b2, a3]`。

`permutation_type='samples'` 支持 `data` 包含任意数量的样本，每个样本必须包含相同数量的观测值。如果 `data` 包含多个样本，则 `data` 内的配对观测值在样本之间*独立*交换。因此，在精确检验中，如果 `m` 是样本数，`n` 是每个样本中的观测数，则排列数为：

```py
factorial(m)**n 
```

几种配对样本的统计检验，如威尔科克森符号秩检验和配对样本t检验，仅考虑两个配对元素之间的*差异*。因此，如果`data`只包含一个样本，则零假设分布是通过独立改变每个观测值的*符号*形成的。

警告

p值通过计算零假设分布中与统计量观察值一样极端或更极端的元素来计算。由于使用有限精度算术，某些统计函数在理论值完全相等时返回数值上不同的值。在某些情况下，这可能导致计算p值时的大误差。[`permutation_test`](#scipy.stats.permutation_test "scipy.stats.permutation_test")通过考虑与检验统计量观测值“接近”（在因子`1+1e-14`范围内）的零假设分布元素来防范这种情况。然而，建议用户检查零假设分布，以评估此比较方法是否合适；如果不合适，则手动计算p值。请参阅下面的示例。

参考文献

[1]

1.  1.  Fisher. 《实验设计》，第六版（1951）。

[[2](#id1)]

B. Phipson 和 G. K. Smyth. “随机抽取排列p值不应为零：在随机绘制排列时计算精确p值。”《统计应用于遗传学和分子生物学》9.1（2010）。

[[3](#id2)]

M. D. Ernst. “排列方法：精确推断的基础”。《统计科学》（2004）。

[[4](#id3)]

B. Efron 和 R. J. Tibshirani. 《Bootstrap的介绍》（1993）。

示例

假设我们希望测试两个样本是否来自同一分布。假设我们对底层分布一无所知，并且在观察数据之前，我们假设第一个样本的均值将小于第二个样本的均值。我们决定使用样本均值之差作为检验统计量，并且我们将认为p值为0.05具有统计显著性。

为了效率，我们以向量化的方式编写了定义测试统计量的函数：样本 `x` 和 `y` 可以是 ND 数组，统计量将沿着 *axis* 轴片段计算。

```py
>>> import numpy as np
>>> def statistic(x, y, axis):
...     return np.mean(x, axis=axis) - np.mean(y, axis=axis) 
```

在收集数据后，我们计算检验统计量的观察值。

```py
>>> from scipy.stats import norm
>>> rng = np.random.default_rng()
>>> x = norm.rvs(size=5, random_state=rng)
>>> y = norm.rvs(size=6, loc = 3, random_state=rng)
>>> statistic(x, y, 0)
-3.5411688580987266 
```

确实，检验统计量为负，表明 `x` 底层分布的真实均值小于 `y` 底层分布的真实均值。为了确定这种情况的概率是否由于两个样本从相同分布中抽取而偶然发生，我们执行了排列检验。

```py
>>> from scipy.stats import permutation_test
>>> # because our statistic is vectorized, we pass `vectorized=True`
>>> # `n_resamples=np.inf` indicates that an exact test is to be performed
>>> res = permutation_test((x, y), statistic, vectorized=True,
...                        n_resamples=np.inf, alternative='less')
>>> print(res.statistic)
-3.5411688580987266
>>> print(res.pvalue)
0.004329004329004329 
```

在零假设下获得小于或等于观察值的检验统计量的概率为 0.4329%。这比我们选择的5%阈值小，因此我们认为这是支持备择假设反对零假设的显著证据。

因为上述样本大小较小，[`permutation_test`](#scipy.stats.permutation_test "scipy.stats.permutation_test") 可以执行精确检验。对于较大的样本，我们采用随机排列检验。

```py
>>> x = norm.rvs(size=100, random_state=rng)
>>> y = norm.rvs(size=120, loc=0.3, random_state=rng)
>>> res = permutation_test((x, y), statistic, n_resamples=100000,
...                        vectorized=True, alternative='less',
...                        random_state=rng)
>>> print(res.statistic)
-0.5230459671240913
>>> print(res.pvalue)
0.00016999830001699983 
```

在零假设下获得小于或等于观察值的检验统计量的近似概率为 0.0225%。这同样小于我们选择的5%阈值，因此我们再次有足够的证据来拒绝零假设，支持备择假设。

对于大样本和排列次数，结果与相应的渐近检验——独立样本 t 检验相比可比较。

```py
>>> from scipy.stats import ttest_ind
>>> res_asymptotic = ttest_ind(x, y, alternative='less')
>>> print(res_asymptotic.pvalue)
0.00012688101537979522 
```

提供了进一步调查的测试统计量的排列分布。

```py
>>> import matplotlib.pyplot as plt
>>> plt.hist(res.null_distribution, bins=50)
>>> plt.title("Permutation distribution of test statistic")
>>> plt.xlabel("Value of Statistic")
>>> plt.ylabel("Frequency")
>>> plt.show() 
```

![../../_images/scipy-stats-permutation_test-1_00_00.png](../Images/620be306f2224245fb92e2c81f248fd1.png)

如果统计量由于有限的机器精度而不准确，检查空分布至关重要。考虑以下情况：

```py
>>> from scipy.stats import pearsonr
>>> x = [1, 2, 4, 3]
>>> y = [2, 4, 6, 8]
>>> def statistic(x, y):
...     return pearsonr(x, y).statistic
>>> res = permutation_test((x, y), statistic, vectorized=False,
...                        permutation_type='pairings',
...                        alternative='greater')
>>> r, pvalue, null = res.statistic, res.pvalue, res.null_distribution 
```

在这种情况下，由于数值噪声，空分布中的一些元素与检验统计量 `r` 的观察值不同。我们手动检查了空分布中接近检验统计量观察值的元素。

```py
>>> r
0.8
>>> unique = np.unique(null)
>>> unique
array([-1\. , -0.8, -0.8, -0.6, -0.4, -0.2, -0.2,  0\. ,  0.2,  0.2,  0.4,
 0.6,  0.8,  0.8,  1\. ]) # may vary
>>> unique[np.isclose(r, unique)].tolist()
[0.7999999999999999, 0.8] 
```

如果[`permutation_test`](#scipy.stats.permutation_test "scipy.stats.permutation_test") 在比较时过于天真，空分布中值为 `0.7999999999999999` 的元素将不被视为与统计量的观察值一样极端或更极端，因此计算得到的 p 值将会过小。

```py
>>> incorrect_pvalue = np.count_nonzero(null >= r) / len(null)
>>> incorrect_pvalue
0.1111111111111111  # may vary 
```

相反，[`permutation_test`](#scipy.stats.permutation_test "scipy.stats.permutation_test") 将空分布中与统计量 `r` 的观察值在 `max(1e-14, abs(r)*1e-14)` 范围内的元素视为等于 `r`。

```py
>>> correct_pvalue = np.count_nonzero(null >= r - 1e-14) / len(null)
>>> correct_pvalue
0.16666666666666666
>>> res.pvalue == correct_pvalue
True 
```

这种比较方法预计在大多数实际情况下都是准确的，但建议用户通过检查与统计量观察值接近的空分布元素来评估此准确性。另外，考虑使用可以使用精确算术计算的统计量（例如整数统计）。
