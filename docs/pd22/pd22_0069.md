# pandas.read_json

> 原文：[`pandas.pydata.org/docs/reference/api/pandas.read_json.html`](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html)

```py
pandas.read_json(path_or_buf, *, orient=None, typ='frame', dtype=None, convert_axes=None, convert_dates=True, keep_default_dates=True, precise_float=False, date_unit=None, encoding=None, encoding_errors='strict', lines=False, chunksize=None, compression='infer', nrows=None, storage_options=None, dtype_backend=_NoDefault.no_default, engine='ujson')
```

将 JSON 字符串转换为 pandas 对象。

参数：

**path_or_buf**有效的 JSON 字符串、路径对象或类文件对象

任何有效的字符串路径都可以接受。字符串可以是 URL。有效的 URL 方案包括 http、ftp、s3 和 file。对于文件 URL，期望有一个主机。本地文件可以是：`file://localhost/path/to/table.json`。

如果要传递路径对象，pandas 接受任何`os.PathLike`。

通过类文件对象，我们指的是具有`read()`方法的对象，例如文件句柄（例如通过内置的`open`函数）或`StringIO`。

自 2.1.0 版本起已弃用：传递 json 文字字符串已弃用。

**orient**字符串，可选

预期的 JSON 字符串格式指示。兼容的 JSON 字符串可以通过具有相应 orient 值的`to_json()`生成。可能的 orient 集合是：

+   `'split'`：类似于`{index -> [index], columns -> [columns], data -> [values]}`

+   `'records'`：类似于`[{column -> value}, ... , {column -> value}]`

+   `'index'`：类似于`{index -> {column -> value}}`

+   `'columns'`：类似于`{column -> {index -> value}}`

+   `'values'`：仅值数组

+   `'table'`：类似于`{'schema': {schema}, 'data': {data}}`

允许的默认值取决于 typ 参数的值。

+   当`typ == 'series'`时，

    +   允许的方向是`{'split','records','index'}`

    +   默认为`'index'`

    +   对于`'index'`，Series 索引必须是唯一的。

+   当`typ == 'frame'`时，

    +   允许的方向是`{'split','records','index', 'columns','values', 'table'}`

    +   默认为`'columns'`

    +   对于`'index'`和`'columns'`，DataFrame 索引必须是唯一的。

    +   对于`'index'`、`'columns'`和`'records'`，DataFrame 列必须是唯一的。

**typ**{‘frame’, ‘series’}，默认为‘frame’

要恢复的对象类型。

**dtype**布尔值或字典，默认为 None

如果为 True，则推断数据类型；如果为列到数据类型的字典，则使用这些数据类型；如果为 False，则根本不推断数据类型，仅适用于数据。

对于除了`'table'`之外的所有`orient`值，默认为 True。

**convert_axes**布尔值，默认为 None

尝试将轴转换为适当的数据类型。

对于除了`'table'`之外的所有`orient`值，默认为 True。

**convert_dates**布尔值或字符串列表，默认为 True

如果为 True，则默认的日期列可能会被转换（取决于 keep_default_dates）。如果为 False，则不会转换任何日期。如果是列名称列表，则这些列将被转换，同时默认的日期列也可能会被转换（取决于 keep_default_dates）。

**keep_default_dates**布尔值，默认为 True

如果解析日期（convert_dates 不为 False），则尝试解析默认的日期列。如果列标签是日期样式的，则为日期样式。

+   以`'_at'`结尾，

+   以`'_time'`结尾，

+   以`'timestamp'`开头，

+   它是`'modified'`，或

+   它是`'date'`。

**precise_float**布尔值，默认为 False

设置为启用更高精度（strtod）函数在将字符串解码为双精度值时。默认（False）是使用快速但不太精确的内置功能。

**date_unit**str，默认为 None

时间戳单位，用于检测日期转换。默认行为是尝试检测正确的精度，但如果不需要，则传递‘s’、‘ms’、‘us’或‘ns’中的一个，以强制仅解析秒、毫秒、微秒或纳秒。

**encoding**str，默认为‘utf-8’

用于解码 py3 字节的编码。

**encoding_errors**str，可选，默认为“strict”

如何处理编码错误。[可能值的列表](https://docs.python.org/3/library/codecs.html#error-handlers)。

在 1.3.0 版本中新增。

**lines**bool，默认为 False

按行读取文件作为 json 对象。

**chunksize**int，可选

返回 JsonReader 对象以进行迭代。有关`chunksize`的更多信息，请参阅[行分隔的 json 文档](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#line-delimited-json)。只有在 lines=True 时才能传递此参数。如果为 None，则文件将一次性全部读入内存。

**compression**str 或 dict，默认为‘infer’

用于在磁盘上的数据进行即时解压缩。如果‘infer’和‘path_or_buf’是类似路径的，则从以下扩展名中检测压缩：‘.gz’、‘.bz2’、‘.zip’、‘.xz’、‘.zst’、‘.tar’、‘.tar.gz’、‘.tar.xz’或‘.tar.bz2’（否则不压缩）。如果使用`'zip'`或`'tar'`，ZIP 文件必须只包含一个要读取的数据文件。设置为`None`表示不解压缩。也可以是一个字典，其中键`'method'`设置为其中之一{`'zip'`、`'gzip'`、`'bz2'`、`'zstd'`、`'xz'`、`'tar'`}，其他键值对转发到`zipfile.ZipFile`、`gzip.GzipFile`、`bz2.BZ2File`、`zstandard.ZstdDecompressor`、`lzma.LZMAFile`或`tarfile.TarFile`。例如，可以通过传递以下内容来进行 Zstandard 解压缩，使用自定义压缩字典：`compression={'method': 'zstd', 'dict_data': my_compression_dict}`。

在 1.5.0 版本中新增：对.tar 文件的支持。

在 1.4.0 版本中更改：Zstandard 支持。

**nrows**int，可选

必须读取的行数，来自行分隔的 json 文件。只有在 lines=True 时才能传递此参数。如果为 None，则将返回所有行。

**storage_options**dict，可选

适用于特定存储连接的额外选项，例如主机、端口、用户名、密码等。对于 HTTP(S) URL，键值对将作为标头选项转发到`urllib.request.Request`。对于其他 URL（例如以“s3://”和“gcs://”开头的 URL），键值对将转发到`fsspec.open`。请参阅`fsspec`和`urllib`以获取更多详细信息，并有关存储选项的更多示例，请参考[这里](https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files)。

**dtype_backend**{‘numpy_nullable’、‘pyarrow’}，默认为‘numpy_nullable’

应用于结果 `DataFrame` 的后端数据类型（仍处于试验阶段）。行为如下：

+   `"numpy_nullable"`：返回支持可空 dtype 的 `DataFrame`（默认值）。

+   `"pyarrow"`：返回支持 pyarrow 的可空 `ArrowDtype` DataFrame。

从 2.0 版本开始新增。

**engine**{“ujson”, “pyarrow”}，默认为 “ujson”

要使用的解析引擎。当 `lines=True` 时才可用 `"pyarrow"` 引擎。

从 2.0 版本开始新增。

返回：

Series、DataFrame 或 pandas.api.typing.JsonReader

当 `chunksize` 不为 `0` 或 `None` 时返回一个 JsonReader。否则，返回的类型取决于 `typ` 的值。

另请参阅

`DataFrame.to_json`

将 DataFrame 转换为 JSON 字符串。

`Series.to_json`

将 Series 转换为 JSON 字符串。

`json_normalize`

将半结构化的 JSON 数据规范化为平面表格。

注意事项

关于 `orient='table'`，如果一个带有文字 `Index` 名称为 index 的 `DataFrame` 被写入 `to_json()`，后续的读操作会错误地将 `Index` 名称设置为 `None`。这是因为 index 也被 `DataFrame.to_json()` 用来表示缺少的 `Index` 名称，后续的 `read_json()` 操作无法区分两者。对于 `MultiIndex` 和任何以 `'level_'` 开头的名称，也会遇到相同的限制。

示例

```py
>>> from io import StringIO
>>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],
...                   index=['row 1', 'row 2'],
...                   columns=['col 1', 'col 2']) 
```

使用 `'split'` 格式化的 JSON 对 Dataframe 进行编码/解码：

```py
>>> df.to_json(orient='split')
 '{"columns":["col 1","col 2"],"index":["row 1","row 2"],"data":[["a","b"],["c","d"]]}'
>>> pd.read_json(StringIO(_), orient='split')
 col 1 col 2
row 1     a     b
row 2     c     d 
```

使用 `'index'` 格式化的 JSON 对 Dataframe 进行编码/解码：

```py
>>> df.to_json(orient='index')
'{"row 1":{"col 1":"a","col 2":"b"},"row 2":{"col 1":"c","col 2":"d"}}' 
```

```py
>>> pd.read_json(StringIO(_), orient='index')
 col 1 col 2
row 1     a     b
row 2     c     d 
```

使用 `'records'` 格式化的 JSON 对 Dataframe 进行编码/解码。请注意，此编码不会保留索引标签。

```py
>>> df.to_json(orient='records')
'[{"col 1":"a","col 2":"b"},{"col 1":"c","col 2":"d"}]'
>>> pd.read_json(StringIO(_), orient='records')
 col 1 col 2
0     a     b
1     c     d 
```

使用 Table Schema 进行编码

```py
>>> df.to_json(orient='table')
 '{"schema":{"fields":[{"name":"index","type":"string"},{"name":"col 1","type":"string"},{"name":"col 2","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":"row 1","col 1":"a","col 2":"b"},{"index":"row 2","col 1":"c","col 2":"d"}]}' 
```

以下示例使用 `dtype_backend="numpy_nullable"`

```py
>>> data = '''{"index": {"0": 0, "1": 1},
...        "a": {"0": 1, "1": null},
...        "b": {"0": 2.5, "1": 4.5},
...        "c": {"0": true, "1": false},
...        "d": {"0": "a", "1": "b"},
...        "e": {"0": 1577.2, "1": 1577.1}}'''
>>> pd.read_json(StringIO(data), dtype_backend="numpy_nullable")
 index     a    b      c  d       e
0      0     1  2.5   True  a  1577.2
1      1  <NA>  4.5  False  b  1577.1 
```
