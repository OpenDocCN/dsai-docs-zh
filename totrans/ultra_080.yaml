- en: Object Cropping using Ultralytics YOLOv8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/guides/object-cropping/`](https://docs.ultralytics.com/guides/object-cropping/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What is Object Cropping?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Object cropping with [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics/)
    involves isolating and extracting specific detected objects from an image or video.
    The YOLOv8 model capabilities are utilized to accurately identify and delineate
    objects, enabling precise cropping for further analysis or manipulation.
  prefs: []
  type: TYPE_NORMAL
- en: '[`www.youtube.com/embed/ydGdibB5Mds`](https://www.youtube.com/embed/ydGdibB5Mds)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch:** Object Cropping using Ultralytics YOLOv8'
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of Object Cropping?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Focused Analysis**: YOLOv8 facilitates targeted object cropping, allowing
    for in-depth examination or processing of individual items within a scene.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduced Data Volume**: By extracting only relevant objects, object cropping
    helps in minimizing data size, making it efficient for storage, transmission,
    or subsequent computational tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhanced Precision**: YOLOv8''s object detection accuracy ensures that the
    cropped objects maintain their spatial relationships, preserving the integrity
    of the visual information for detailed analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visuals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Airport Luggage |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| ![Conveyor Belt at Airport Suitcases Cropping using Ultralytics YOLOv8](img/3df7a95189bccb12135569c559617251.png)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Suitcases Cropping at airport conveyor belt using Ultralytics YOLOv8 |'
  prefs: []
  type: TYPE_TB
- en: Object Cropping using YOLOv8 Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Arguments `model.predict`
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Argument | Type | Default | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `source` | `str` | `''ultralytics/assets''` | Specifies the data source for
    inference. Can be an image path, video file, directory, URL, or device ID for
    live feeds. Supports a wide range of formats and sources, enabling flexible application
    across different types of input. |'
  prefs: []
  type: TYPE_TB
- en: '| `conf` | `float` | `0.25` | Sets the minimum confidence threshold for detections.
    Objects detected with confidence below this threshold will be disregarded. Adjusting
    this value can help reduce false positives. |'
  prefs: []
  type: TYPE_TB
- en: '| `iou` | `float` | `0.7` | Intersection Over Union (IoU) threshold for Non-Maximum
    Suppression (NMS). Lower values result in fewer detections by eliminating overlapping
    boxes, useful for reducing duplicates. |'
  prefs: []
  type: TYPE_TB
- en: '| `imgsz` | `int or tuple` | `640` | Defines the image size for inference.
    Can be a single integer `640` for square resizing or a (height, width) tuple.
    Proper sizing can improve detection accuracy and processing speed. |'
  prefs: []
  type: TYPE_TB
- en: '| `half` | `bool` | `False` | Enables half-precision (FP16) inference, which
    can speed up model inference on supported GPUs with minimal impact on accuracy.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `device` | `str` | `None` | Specifies the device for inference (e.g., `cpu`,
    `cuda:0` or `0`). Allows users to select between CPU, a specific GPU, or other
    compute devices for model execution. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_det` | `int` | `300` | Maximum number of detections allowed per image.
    Limits the total number of objects the model can detect in a single inference,
    preventing excessive outputs in dense scenes. |'
  prefs: []
  type: TYPE_TB
- en: '| `vid_stride` | `int` | `1` | Frame stride for video inputs. Allows skipping
    frames in videos to speed up processing at the cost of temporal resolution. A
    value of 1 processes every frame, higher values skip frames. |'
  prefs: []
  type: TYPE_TB
- en: '| `stream_buffer` | `bool` | `False` | Determines if all frames should be buffered
    when processing video streams (`True`), or if the model should return the most
    recent frame (`False`). Useful for real-time applications. |'
  prefs: []
  type: TYPE_TB
- en: '| `visualize` | `bool` | `False` | Activates visualization of model features
    during inference, providing insights into what the model is "seeing". Useful for
    debugging and model interpretation. |'
  prefs: []
  type: TYPE_TB
- en: '| `augment` | `bool` | `False` | Enables test-time augmentation (TTA) for predictions,
    potentially improving detection robustness at the cost of inference speed. |'
  prefs: []
  type: TYPE_TB
- en: '| `agnostic_nms` | `bool` | `False` | Enables class-agnostic Non-Maximum Suppression
    (NMS), which merges overlapping boxes of different classes. Useful in multi-class
    detection scenarios where class overlap is common. |'
  prefs: []
  type: TYPE_TB
- en: '| `classes` | `list[int]` | `None` | Filters predictions to a set of class
    IDs. Only detections belonging to the specified classes will be returned. Useful
    for focusing on relevant objects in multi-class detection tasks. |'
  prefs: []
  type: TYPE_TB
- en: '| `retina_masks` | `bool` | `False` | Uses high-resolution segmentation masks
    if available in the model. This can enhance mask quality for segmentation tasks,
    providing finer detail. |'
  prefs: []
  type: TYPE_TB
- en: '| `embed` | `list[int]` | `None` | Specifies the layers from which to extract
    feature vectors or embeddings. Useful for downstream tasks like clustering or
    similarity search. |'
  prefs: []
  type: TYPE_TB
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is object cropping in Ultralytics YOLOv8 and how does it work?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Object cropping using [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)
    involves isolating and extracting specific objects from an image or video based
    on YOLOv8's detection capabilities. This process allows for focused analysis,
    reduced data volume, and enhanced precision by leveraging YOLOv8 to identify objects
    with high accuracy and crop them accordingly. For an in-depth tutorial, refer
    to the object cropping example.
  prefs: []
  type: TYPE_NORMAL
- en: Why should I use Ultralytics YOLOv8 for object cropping over other solutions?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ultralytics YOLOv8 stands out due to its precision, speed, and ease of use.
    It allows detailed and accurate object detection and cropping, essential for focused
    analysis and applications needing high data integrity. Moreover, YOLOv8 integrates
    seamlessly with tools like OpenVINO and TensorRT for deployments requiring real-time
    capabilities and optimization on diverse hardware. Explore the benefits in the
    guide on model export.
  prefs: []
  type: TYPE_NORMAL
- en: How can I reduce the data volume of my dataset using object cropping?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By using Ultralytics YOLOv8 to crop only relevant objects from your images or
    videos, you can significantly reduce the data size, making it more efficient for
    storage and processing. This process involves training the model to detect specific
    objects and then using the results to crop and save these portions only. For more
    information on exploiting Ultralytics YOLOv8's capabilities, visit our quickstart
    guide.
  prefs: []
  type: TYPE_NORMAL
- en: Can I use Ultralytics YOLOv8 for real-time video analysis and object cropping?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Yes, Ultralytics YOLOv8 can process real-time video feeds to detect and crop
    objects dynamically. The model's high-speed inference capabilities make it ideal
    for real-time applications such as surveillance, sports analysis, and automated
    inspection systems. Check out the tracking and prediction modes to understand
    how to implement real-time processing.
  prefs: []
  type: TYPE_NORMAL
- en: What are the hardware requirements for efficiently running YOLOv8 for object
    cropping?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ultralytics YOLOv8 is optimized for both CPU and GPU environments, but to achieve
    optimal performance, especially for real-time or high-volume inference, a dedicated
    GPU (e.g., NVIDIA Tesla, RTX series) is recommended. For deployment on lightweight
    devices, consider using CoreML for iOS or TFLite for Android. More details on
    supported devices and formats can be found in our model deployment options.
  prefs: []
  type: TYPE_NORMAL
