- en: Duplicate Labels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pandas.pydata.org/docs/user_guide/duplicates.html](https://pandas.pydata.org/docs/user_guide/duplicates.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Index` objects are not required to be unique; you can have duplicate row or
    column labels. This may be a bit confusing at first. If you’re familiar with SQL,
    you know that row labels are similar to a primary key on a table, and you would
    never want duplicates in a SQL table. But one of pandas’ roles is to clean messy,
    real-world data before it goes to some downstream system. And real-world data
    has duplicates, even in fields that are supposed to be unique.'
  prefs: []
  type: TYPE_NORMAL
- en: This section describes how duplicate labels change the behavior of certain operations,
    and how prevent duplicates from arising during operations, or to detect them if
    they do.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Consequences of Duplicate Labels
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some pandas methods (`Series.reindex()` for example) just don’t work with duplicates
    present. The output can’t be determined, and so pandas raises.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Other methods, like indexing, can give very surprising results. Typically indexing
    with a scalar will *reduce dimensionality*. Slicing a `DataFrame` with a scalar
    will return a `Series`. Slicing a `Series` with a scalar will return a scalar.
    But with duplicates, this isn’t the case.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We have duplicates in the columns. If we slice `'B'`, we get back a `Series`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: But slicing `'A'` returns a `DataFrame`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This applies to row labels as well
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Duplicate Label Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can check whether an `Index` (storing the row or column labels) is unique
    with `Index.is_unique`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Checking whether an index is unique is somewhat expensive for large datasets.
    pandas does cache this result, so re-checking on the same index is very fast.
  prefs: []
  type: TYPE_NORMAL
- en: '`Index.duplicated()` will return a boolean ndarray indicating whether a label
    is repeated.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Which can be used as a boolean filter to drop duplicate rows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: If you need additional logic to handle duplicate labels, rather than just dropping
    the repeats, using `groupby()` on the index is a common trick. For example, we’ll
    resolve duplicates by taking the average of all rows with the same label.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '## Disallowing Duplicate Labels'
  prefs: []
  type: TYPE_NORMAL
- en: New in version 1.2.0.
  prefs: []
  type: TYPE_NORMAL
- en: As noted above, handling duplicates is an important feature when reading in
    raw data. That said, you may want to avoid introducing duplicates as part of a
    data processing pipeline (from methods like [`pandas.concat()`](../reference/api/pandas.concat.html#pandas.concat
    "pandas.concat"), `rename()`, etc.). Both `Series` and `DataFrame` *disallow*
    duplicate labels by calling `.set_flags(allows_duplicate_labels=False)`. (the
    default is to allow them). If there are duplicate labels, an exception will be
    raised.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This applies to both row and column labels for a `DataFrame`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This attribute can be checked or set with `allows_duplicate_labels`, which indicates
    whether that object can have duplicate labels.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '`DataFrame.set_flags()` can be used to return a new `DataFrame` with attributes
    like `allows_duplicate_labels` set to some value'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The new `DataFrame` returned is a view on the same data as the old `DataFrame`.
    Or the property can just be set directly on the same object
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: When processing raw, messy data you might initially read in the messy data (which
    potentially has duplicate labels), deduplicate, and then disallow duplicates going
    forward, to ensure that your data pipeline doesn’t introduce duplicates.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Setting `allows_duplicate_labels=False` on a `Series` or `DataFrame` with duplicate
    labels or performing an operation that introduces duplicate labels on a `Series`
    or `DataFrame` that disallows duplicates will raise an `errors.DuplicateLabelError`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This error message contains the labels that are duplicated, and the numeric
    positions of all the duplicates (including the “original”) in the `Series` or
    `DataFrame`
  prefs: []
  type: TYPE_NORMAL
- en: Duplicate Label Propagation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In general, disallowing duplicates is “sticky”. It’s preserved through operations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Warning
  prefs: []
  type: TYPE_NORMAL
- en: This is an experimental feature. Currently, many methods fail to propagate the
    `allows_duplicate_labels` value. In future versions it is expected that every
    method taking or returning one or more DataFrame or Series objects will propagate
    `allows_duplicate_labels`.
  prefs: []
  type: TYPE_NORMAL
- en: Consequences of Duplicate Labels
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some pandas methods (`Series.reindex()` for example) just don’t work with duplicates
    present. The output can’t be determined, and so pandas raises.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Other methods, like indexing, can give very surprising results. Typically indexing
    with a scalar will *reduce dimensionality*. Slicing a `DataFrame` with a scalar
    will return a `Series`. Slicing a `Series` with a scalar will return a scalar.
    But with duplicates, this isn’t the case.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We have duplicates in the columns. If we slice `'B'`, we get back a `Series`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: But slicing `'A'` returns a `DataFrame`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This applies to row labels as well
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Duplicate Label Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can check whether an `Index` (storing the row or column labels) is unique
    with `Index.is_unique`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Checking whether an index is unique is somewhat expensive for large datasets.
    pandas does cache this result, so re-checking on the same index is very fast.
  prefs: []
  type: TYPE_NORMAL
- en: '`Index.duplicated()` will return a boolean ndarray indicating whether a label
    is repeated.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Which can be used as a boolean filter to drop duplicate rows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: If you need additional logic to handle duplicate labels, rather than just dropping
    the repeats, using `groupby()` on the index is a common trick. For example, we’ll
    resolve duplicates by taking the average of all rows with the same label.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '## Disallowing Duplicate Labels'
  prefs: []
  type: TYPE_NORMAL
- en: New in version 1.2.0.
  prefs: []
  type: TYPE_NORMAL
- en: As noted above, handling duplicates is an important feature when reading in
    raw data. That said, you may want to avoid introducing duplicates as part of a
    data processing pipeline (from methods like [`pandas.concat()`](../reference/api/pandas.concat.html#pandas.concat
    "pandas.concat"), `rename()`, etc.). Both `Series` and `DataFrame` *disallow*
    duplicate labels by calling `.set_flags(allows_duplicate_labels=False)`. (the
    default is to allow them). If there are duplicate labels, an exception will be
    raised.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This applies to both row and column labels for a `DataFrame`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This attribute can be checked or set with `allows_duplicate_labels`, which indicates
    whether that object can have duplicate labels.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '`DataFrame.set_flags()` can be used to return a new `DataFrame` with attributes
    like `allows_duplicate_labels` set to some value'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The new `DataFrame` returned is a view on the same data as the old `DataFrame`.
    Or the property can just be set directly on the same object
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: When processing raw, messy data you might initially read in the messy data (which
    potentially has duplicate labels), deduplicate, and then disallow duplicates going
    forward, to ensure that your data pipeline doesn’t introduce duplicates.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Setting `allows_duplicate_labels=False` on a `Series` or `DataFrame` with duplicate
    labels or performing an operation that introduces duplicate labels on a `Series`
    or `DataFrame` that disallows duplicates will raise an `errors.DuplicateLabelError`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This error message contains the labels that are duplicated, and the numeric
    positions of all the duplicates (including the “original”) in the `Series` or
    `DataFrame`
  prefs: []
  type: TYPE_NORMAL
- en: Duplicate Label Propagation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In general, disallowing duplicates is “sticky”. It’s preserved through operations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Warning
  prefs: []
  type: TYPE_NORMAL
- en: This is an experimental feature. Currently, many methods fail to propagate the
    `allows_duplicate_labels` value. In future versions it is expected that every
    method taking or returning one or more DataFrame or Series objects will propagate
    `allows_duplicate_labels`.
  prefs: []
  type: TYPE_NORMAL
- en: Duplicate Label Propagation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In general, disallowing duplicates is “sticky”. It’s preserved through operations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Warning
  prefs: []
  type: TYPE_NORMAL
- en: This is an experimental feature. Currently, many methods fail to propagate the
    `allows_duplicate_labels` value. In future versions it is expected that every
    method taking or returning one or more DataFrame or Series objects will propagate
    `allows_duplicate_labels`.
  prefs: []
  type: TYPE_NORMAL
