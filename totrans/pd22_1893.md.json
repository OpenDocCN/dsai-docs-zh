["```py\npd.options.mode.copy_on_write = True \n```", "```py\npd.options.mode.copy_on_write = \"warn\" \n```", "```py\nIn [1]: ser = pd.Series([\"a\", \"b\"])\nOut[1]:\n0    a\n1    b\ndtype: object \n```", "```py\nIn [1]: ser = pd.Series([\"a\", \"b\"])\nOut[1]:\n0    a\n1    b\ndtype: string \n```", "```py\npd.options.future.infer_string = True \n```", "```py\nimport adbc_driver_postgresql.dbapi as pg_dbapi\n\ndf = pd.DataFrame(\n    [\n        [1, 2, 3],\n        [4, 5, 6],\n    ],\n    columns=['a', 'b', 'c']\n)\nuri = \"postgresql://postgres:postgres@localhost/postgres\"\nwith pg_dbapi.connect(uri) as conn:\n    df.to_sql(\"pandas_table\", conn, index=False)\n\n# for round-tripping\nwith pg_dbapi.connect(uri) as conn:\n    df2 = pd.read_sql(\"pandas_table\", conn) \n```", "```py\n# for round-tripping\nwith pg_dbapi.connect(uri) as conn:\n    df2 = pd.read_sql(\"pandas_table\", conn, dtype_backend=\"pyarrow\") \n```", "```py\nIn [1]: import pandas as pd\n\nIn [2]: df = pd.DataFrame(dict(a=[1, 2, 3], b=[4, 5, 6]))\n\nIn [3]: default=pd.Series('default', index=df.index)\n\nIn [4]: default.case_when(\n ...:     caselist=[\n ...:         (df.a == 1, 'first'),                              # condition, replacement\n ...:         (df.a.gt(1) & df.b.eq(5), 'second'),  # condition, replacement\n ...:     ],\n ...: )\n ...: \nOut[4]: \n0      first\n1     second\n2    default\ndtype: object \n```", "```py\nIn [1]: ser = pd.Series([1, 2, 3], dtype=\"Int64\")\nIn [2]: ser.to_numpy()\nOut[2]: array([1, 2, 3], dtype=object) \n```", "```py\nIn [5]: ser = pd.Series([1, 2, 3], dtype=\"Int64\")\n\nIn [6]: ser.to_numpy()\nOut[6]: array([1, 2, 3])\n\nIn [7]: ser = pd.Series([1, 2, 3], dtype=\"timestamp[ns][pyarrow]\")\n\nIn [8]: ser.to_numpy()\nOut[8]: \narray(['1970-01-01T00:00:00.000000001', '1970-01-01T00:00:00.000000002',\n '1970-01-01T00:00:00.000000003'], dtype='datetime64[ns]') \n```", "```py\nIn [9]: import pyarrow as pa\n\nIn [10]: series = pd.Series(\n ....:    [\n ....:        {\"project\": \"pandas\", \"version\": \"2.2.0\"},\n ....:        {\"project\": \"numpy\", \"version\": \"1.25.2\"},\n ....:        {\"project\": \"pyarrow\", \"version\": \"13.0.0\"},\n ....:    ],\n ....:    dtype=pd.ArrowDtype(\n ....:        pa.struct([\n ....:            (\"project\", pa.string()),\n ....:            (\"version\", pa.string()),\n ....:        ])\n ....:    ),\n ....: )\n ....: \n\nIn [11]: series.struct.explode()\nOut[11]: \n project version\n0   pandas   2.2.0\n1    numpy  1.25.2\n2  pyarrow  13.0.0 \n```", "```py\nIn [12]: series.struct.field(\"project\")\nOut[12]: \n0     pandas\n1      numpy\n2    pyarrow\nName: project, dtype: string[pyarrow] \n```", "```py\nIn [13]: import pyarrow as pa\n\nIn [14]: series = pd.Series(\n ....:    [\n ....:        [1, 2, 3],\n ....:        [4, 5],\n ....:        [6],\n ....:    ],\n ....:    dtype=pd.ArrowDtype(\n ....:        pa.list_(pa.int64())\n ....:    ),\n ....: )\n ....: \n\nIn [15]: series.list[0]\nOut[15]: \n0    1\n1    4\n2    6\ndtype: int64[pyarrow] \n```", "```py\npd.read_excel(\"path_to_file.xlsb\", engine=\"calamine\") \n```", "```py\nIn [16]: left = pd.DataFrame({\"a\": [1, 2, 1]})\n\nIn [17]: right = pd.DataFrame({\"a\": [1, 2]})\n\nIn [18]: result = pd.merge(left, right, how=\"inner\", on=\"a\", sort=False) \n```", "```py\nIn [5]: result\nOut[5]:\n a\n0  1\n1  1\n2  2 \n```", "```py\nIn [19]: result\nOut[19]: \n a\n0  1\n1  2\n2  1 \n```", "```py\nIn [20]: left = pd.DataFrame({\"left\": 1}, index=pd.MultiIndex.from_tuples([(\"x\", 1), (\"x\", 2)], names=[\"A\", \"B\"]))\n\nIn [21]: right = pd.DataFrame({\"right\": 2}, index=pd.MultiIndex.from_tuples([(1, 1), (2, 2)], names=[\"B\", \"C\"]))\n\nIn [22]: left\nOut[22]: \n left\nA B \nx 1     1\n 2     1\n\nIn [23]: right\nOut[23]: \n right\nB C \n1 1      2\n2 2      2\n\nIn [24]: result = left.join(right) \n```", "```py\nIn [5]: result\nOut[5]:\n left  right\nB A C\n1 x 1     1      2\n2 x 2     1      2 \n```", "```py\nIn [25]: result\nOut[25]: \n left  right\nA B C \nx 1 1     1      2\n 2 2     1      2 \n```", "```py\ndf = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n\n# first selecting rows with a mask, then assigning values to a column\n# -> this has never worked and raises a SettingWithCopyWarning\ndf[df[\"bar\"] > 5][\"foo\"] = 100\n\n# first selecting the column, and then assigning to a subset of that column\n# -> this currently works\ndf[\"foo\"][df[\"bar\"] > 5] = 100 \n```", "```py\n>>> df[\"foo\"][df[\"bar\"] > 5] = 100\nFutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy \n```", "```py\ndf.loc[df[\"bar\"] > 5, \"foo\"] = 100 \n```", "```py\n>>> df[\"foo\"].fillna(0, inplace=True)\nFutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0\\. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. \n```", "```py\nIn [8]: pd.date_range('2020-01-01', periods=3, freq='Q-NOV')\nOut[8]:\nDatetimeIndex(['2020-02-29', '2020-05-31', '2020-08-31'],\n dtype='datetime64[ns]', freq='Q-NOV') \n```", "```py\nIn [26]: pd.date_range('2020-01-01', periods=3, freq='QE-NOV')\nOut[26]: DatetimeIndex(['2020-02-29', '2020-05-31', '2020-08-31'], dtype='datetime64[ns]', freq='QE-NOV') \n```", "```py\nresult = result.infer_objects(copy=False) \n```", "```py\nIn [9]: pd.set_option(\"future.no_silent_downcasting\", True) \n```", "```py\npd.options.mode.copy_on_write = True \n```", "```py\npd.options.mode.copy_on_write = \"warn\" \n```", "```py\nIn [1]: ser = pd.Series([\"a\", \"b\"])\nOut[1]:\n0    a\n1    b\ndtype: object \n```", "```py\nIn [1]: ser = pd.Series([\"a\", \"b\"])\nOut[1]:\n0    a\n1    b\ndtype: string \n```", "```py\npd.options.future.infer_string = True \n```", "```py\npd.options.mode.copy_on_write = True \n```", "```py\npd.options.mode.copy_on_write = \"warn\" \n```", "```py\nIn [1]: ser = pd.Series([\"a\", \"b\"])\nOut[1]:\n0    a\n1    b\ndtype: object \n```", "```py\nIn [1]: ser = pd.Series([\"a\", \"b\"])\nOut[1]:\n0    a\n1    b\ndtype: string \n```", "```py\npd.options.future.infer_string = True \n```", "```py\nimport adbc_driver_postgresql.dbapi as pg_dbapi\n\ndf = pd.DataFrame(\n    [\n        [1, 2, 3],\n        [4, 5, 6],\n    ],\n    columns=['a', 'b', 'c']\n)\nuri = \"postgresql://postgres:postgres@localhost/postgres\"\nwith pg_dbapi.connect(uri) as conn:\n    df.to_sql(\"pandas_table\", conn, index=False)\n\n# for round-tripping\nwith pg_dbapi.connect(uri) as conn:\n    df2 = pd.read_sql(\"pandas_table\", conn) \n```", "```py\n# for round-tripping\nwith pg_dbapi.connect(uri) as conn:\n    df2 = pd.read_sql(\"pandas_table\", conn, dtype_backend=\"pyarrow\") \n```", "```py\nIn [1]: import pandas as pd\n\nIn [2]: df = pd.DataFrame(dict(a=[1, 2, 3], b=[4, 5, 6]))\n\nIn [3]: default=pd.Series('default', index=df.index)\n\nIn [4]: default.case_when(\n ...:     caselist=[\n ...:         (df.a == 1, 'first'),                              # condition, replacement\n ...:         (df.a.gt(1) & df.b.eq(5), 'second'),  # condition, replacement\n ...:     ],\n ...: )\n ...: \nOut[4]: \n0      first\n1     second\n2    default\ndtype: object \n```", "```py\nIn [1]: ser = pd.Series([1, 2, 3], dtype=\"Int64\")\nIn [2]: ser.to_numpy()\nOut[2]: array([1, 2, 3], dtype=object) \n```", "```py\nIn [5]: ser = pd.Series([1, 2, 3], dtype=\"Int64\")\n\nIn [6]: ser.to_numpy()\nOut[6]: array([1, 2, 3])\n\nIn [7]: ser = pd.Series([1, 2, 3], dtype=\"timestamp[ns][pyarrow]\")\n\nIn [8]: ser.to_numpy()\nOut[8]: \narray(['1970-01-01T00:00:00.000000001', '1970-01-01T00:00:00.000000002',\n '1970-01-01T00:00:00.000000003'], dtype='datetime64[ns]') \n```", "```py\nIn [9]: import pyarrow as pa\n\nIn [10]: series = pd.Series(\n ....:    [\n ....:        {\"project\": \"pandas\", \"version\": \"2.2.0\"},\n ....:        {\"project\": \"numpy\", \"version\": \"1.25.2\"},\n ....:        {\"project\": \"pyarrow\", \"version\": \"13.0.0\"},\n ....:    ],\n ....:    dtype=pd.ArrowDtype(\n ....:        pa.struct([\n ....:            (\"project\", pa.string()),\n ....:            (\"version\", pa.string()),\n ....:        ])\n ....:    ),\n ....: )\n ....: \n\nIn [11]: series.struct.explode()\nOut[11]: \n project version\n0   pandas   2.2.0\n1    numpy  1.25.2\n2  pyarrow  13.0.0 \n```", "```py\nIn [12]: series.struct.field(\"project\")\nOut[12]: \n0     pandas\n1      numpy\n2    pyarrow\nName: project, dtype: string[pyarrow] \n```", "```py\nIn [13]: import pyarrow as pa\n\nIn [14]: series = pd.Series(\n ....:    [\n ....:        [1, 2, 3],\n ....:        [4, 5],\n ....:        [6],\n ....:    ],\n ....:    dtype=pd.ArrowDtype(\n ....:        pa.list_(pa.int64())\n ....:    ),\n ....: )\n ....: \n\nIn [15]: series.list[0]\nOut[15]: \n0    1\n1    4\n2    6\ndtype: int64[pyarrow] \n```", "```py\npd.read_excel(\"path_to_file.xlsb\", engine=\"calamine\") \n```", "```py\nimport adbc_driver_postgresql.dbapi as pg_dbapi\n\ndf = pd.DataFrame(\n    [\n        [1, 2, 3],\n        [4, 5, 6],\n    ],\n    columns=['a', 'b', 'c']\n)\nuri = \"postgresql://postgres:postgres@localhost/postgres\"\nwith pg_dbapi.connect(uri) as conn:\n    df.to_sql(\"pandas_table\", conn, index=False)\n\n# for round-tripping\nwith pg_dbapi.connect(uri) as conn:\n    df2 = pd.read_sql(\"pandas_table\", conn) \n```", "```py\n# for round-tripping\nwith pg_dbapi.connect(uri) as conn:\n    df2 = pd.read_sql(\"pandas_table\", conn, dtype_backend=\"pyarrow\") \n```", "```py\nIn [1]: import pandas as pd\n\nIn [2]: df = pd.DataFrame(dict(a=[1, 2, 3], b=[4, 5, 6]))\n\nIn [3]: default=pd.Series('default', index=df.index)\n\nIn [4]: default.case_when(\n ...:     caselist=[\n ...:         (df.a == 1, 'first'),                              # condition, replacement\n ...:         (df.a.gt(1) & df.b.eq(5), 'second'),  # condition, replacement\n ...:     ],\n ...: )\n ...: \nOut[4]: \n0      first\n1     second\n2    default\ndtype: object \n```", "```py\nIn [1]: ser = pd.Series([1, 2, 3], dtype=\"Int64\")\nIn [2]: ser.to_numpy()\nOut[2]: array([1, 2, 3], dtype=object) \n```", "```py\nIn [5]: ser = pd.Series([1, 2, 3], dtype=\"Int64\")\n\nIn [6]: ser.to_numpy()\nOut[6]: array([1, 2, 3])\n\nIn [7]: ser = pd.Series([1, 2, 3], dtype=\"timestamp[ns][pyarrow]\")\n\nIn [8]: ser.to_numpy()\nOut[8]: \narray(['1970-01-01T00:00:00.000000001', '1970-01-01T00:00:00.000000002',\n '1970-01-01T00:00:00.000000003'], dtype='datetime64[ns]') \n```", "```py\nIn [9]: import pyarrow as pa\n\nIn [10]: series = pd.Series(\n ....:    [\n ....:        {\"project\": \"pandas\", \"version\": \"2.2.0\"},\n ....:        {\"project\": \"numpy\", \"version\": \"1.25.2\"},\n ....:        {\"project\": \"pyarrow\", \"version\": \"13.0.0\"},\n ....:    ],\n ....:    dtype=pd.ArrowDtype(\n ....:        pa.struct([\n ....:            (\"project\", pa.string()),\n ....:            (\"version\", pa.string()),\n ....:        ])\n ....:    ),\n ....: )\n ....: \n\nIn [11]: series.struct.explode()\nOut[11]: \n project version\n0   pandas   2.2.0\n1    numpy  1.25.2\n2  pyarrow  13.0.0 \n```", "```py\nIn [12]: series.struct.field(\"project\")\nOut[12]: \n0     pandas\n1      numpy\n2    pyarrow\nName: project, dtype: string[pyarrow] \n```", "```py\nIn [13]: import pyarrow as pa\n\nIn [14]: series = pd.Series(\n ....:    [\n ....:        [1, 2, 3],\n ....:        [4, 5],\n ....:        [6],\n ....:    ],\n ....:    dtype=pd.ArrowDtype(\n ....:        pa.list_(pa.int64())\n ....:    ),\n ....: )\n ....: \n\nIn [15]: series.list[0]\nOut[15]: \n0    1\n1    4\n2    6\ndtype: int64[pyarrow] \n```", "```py\npd.read_excel(\"path_to_file.xlsb\", engine=\"calamine\") \n```", "```py\nIn [16]: left = pd.DataFrame({\"a\": [1, 2, 1]})\n\nIn [17]: right = pd.DataFrame({\"a\": [1, 2]})\n\nIn [18]: result = pd.merge(left, right, how=\"inner\", on=\"a\", sort=False) \n```", "```py\nIn [5]: result\nOut[5]:\n a\n0  1\n1  1\n2  2 \n```", "```py\nIn [19]: result\nOut[19]: \n a\n0  1\n1  2\n2  1 \n```", "```py\nIn [20]: left = pd.DataFrame({\"left\": 1}, index=pd.MultiIndex.from_tuples([(\"x\", 1), (\"x\", 2)], names=[\"A\", \"B\"]))\n\nIn [21]: right = pd.DataFrame({\"right\": 2}, index=pd.MultiIndex.from_tuples([(1, 1), (2, 2)], names=[\"B\", \"C\"]))\n\nIn [22]: left\nOut[22]: \n left\nA B \nx 1     1\n 2     1\n\nIn [23]: right\nOut[23]: \n right\nB C \n1 1      2\n2 2      2\n\nIn [24]: result = left.join(right) \n```", "```py\nIn [5]: result\nOut[5]:\n left  right\nB A C\n1 x 1     1      2\n2 x 2     1      2 \n```", "```py\nIn [25]: result\nOut[25]: \n left  right\nA B C \nx 1 1     1      2\n 2 2     1      2 \n```", "```py\nIn [16]: left = pd.DataFrame({\"a\": [1, 2, 1]})\n\nIn [17]: right = pd.DataFrame({\"a\": [1, 2]})\n\nIn [18]: result = pd.merge(left, right, how=\"inner\", on=\"a\", sort=False) \n```", "```py\nIn [5]: result\nOut[5]:\n a\n0  1\n1  1\n2  2 \n```", "```py\nIn [19]: result\nOut[19]: \n a\n0  1\n1  2\n2  1 \n```", "```py\nIn [20]: left = pd.DataFrame({\"left\": 1}, index=pd.MultiIndex.from_tuples([(\"x\", 1), (\"x\", 2)], names=[\"A\", \"B\"]))\n\nIn [21]: right = pd.DataFrame({\"right\": 2}, index=pd.MultiIndex.from_tuples([(1, 1), (2, 2)], names=[\"B\", \"C\"]))\n\nIn [22]: left\nOut[22]: \n left\nA B \nx 1     1\n 2     1\n\nIn [23]: right\nOut[23]: \n right\nB C \n1 1      2\n2 2      2\n\nIn [24]: result = left.join(right) \n```", "```py\nIn [5]: result\nOut[5]:\n left  right\nB A C\n1 x 1     1      2\n2 x 2     1      2 \n```", "```py\nIn [25]: result\nOut[25]: \n left  right\nA B C \nx 1 1     1      2\n 2 2     1      2 \n```", "```py\ndf = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n\n# first selecting rows with a mask, then assigning values to a column\n# -> this has never worked and raises a SettingWithCopyWarning\ndf[df[\"bar\"] > 5][\"foo\"] = 100\n\n# first selecting the column, and then assigning to a subset of that column\n# -> this currently works\ndf[\"foo\"][df[\"bar\"] > 5] = 100 \n```", "```py\n>>> df[\"foo\"][df[\"bar\"] > 5] = 100\nFutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy \n```", "```py\ndf.loc[df[\"bar\"] > 5, \"foo\"] = 100 \n```", "```py\n>>> df[\"foo\"].fillna(0, inplace=True)\nFutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0\\. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. \n```", "```py\nIn [8]: pd.date_range('2020-01-01', periods=3, freq='Q-NOV')\nOut[8]:\nDatetimeIndex(['2020-02-29', '2020-05-31', '2020-08-31'],\n dtype='datetime64[ns]', freq='Q-NOV') \n```", "```py\nIn [26]: pd.date_range('2020-01-01', periods=3, freq='QE-NOV')\nOut[26]: DatetimeIndex(['2020-02-29', '2020-05-31', '2020-08-31'], dtype='datetime64[ns]', freq='QE-NOV') \n```", "```py\nresult = result.infer_objects(copy=False) \n```", "```py\nIn [9]: pd.set_option(\"future.no_silent_downcasting\", True) \n```", "```py\ndf = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n\n# first selecting rows with a mask, then assigning values to a column\n# -> this has never worked and raises a SettingWithCopyWarning\ndf[df[\"bar\"] > 5][\"foo\"] = 100\n\n# first selecting the column, and then assigning to a subset of that column\n# -> this currently works\ndf[\"foo\"][df[\"bar\"] > 5] = 100 \n```", "```py\n>>> df[\"foo\"][df[\"bar\"] > 5] = 100\nFutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy \n```", "```py\ndf.loc[df[\"bar\"] > 5, \"foo\"] = 100 \n```", "```py\n>>> df[\"foo\"].fillna(0, inplace=True)\nFutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0\\. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. \n```", "```py\nIn [8]: pd.date_range('2020-01-01', periods=3, freq='Q-NOV')\nOut[8]:\nDatetimeIndex(['2020-02-29', '2020-05-31', '2020-08-31'],\n dtype='datetime64[ns]', freq='Q-NOV') \n```", "```py\nIn [26]: pd.date_range('2020-01-01', periods=3, freq='QE-NOV')\nOut[26]: DatetimeIndex(['2020-02-29', '2020-05-31', '2020-08-31'], dtype='datetime64[ns]', freq='QE-NOV') \n```", "```py\nresult = result.infer_objects(copy=False) \n```", "```py\nIn [9]: pd.set_option(\"future.no_silent_downcasting\", True) \n```"]