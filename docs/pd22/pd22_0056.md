# `pandas.read_csv`

> 原文：[`pandas.pydata.org/docs/reference/api/pandas.read_csv.html`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)

```py
pandas.read_csv(filepath_or_buffer, *, sep=_NoDefault.no_default, delimiter=None, header='infer', names=_NoDefault.no_default, index_col=None, usecols=None, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=_NoDefault.no_default, skip_blank_lines=True, parse_dates=None, infer_datetime_format=_NoDefault.no_default, keep_date_col=_NoDefault.no_default, date_parser=_NoDefault.no_default, date_format=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors='strict', dialect=None, on_bad_lines='error', delim_whitespace=_NoDefault.no_default, low_memory=True, memory_map=False, float_precision=None, storage_options=None, dtype_backend=_NoDefault.no_default)
```

将逗号分隔值（csv）文件读入 DataFrame。

还支持将文件迭代或分块。

在[IO 工具](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)的在线文档中可以找到其他帮助。

参数：

**filepath_or_buffer**str，路径对象或类文件对象

任何有效的字符串路径均可接受。字符串可以是 URL。有效的 URL 方案包括 http、ftp、s3、gs 和 file。对于文件 URL，期望有一个主机。本地文件可以是：file://localhost/path/to/table.csv。

如果要传递路径对象，则 pandas 接受任何 `os.PathLike`。

通过类文件对象，我们指的是具有 `read()` 方法的对象，例如文件句柄（例如通过内置的 `open` 函数）或 `StringIO`。

**sep**str，默认为‘,’

字符或正则表达式模式，用于视为分隔符。如果`sep=None`，C 引擎无法自动检测分隔符，但 Python 解析引擎可以，这意味着后者将被使用，并且 Python 的内置嗅探工具 `csv.Sniffer` 可以从文件的第一行自动检测到分隔符。此外，长度大于 1 且不同于 `'\s+'` 的分隔符将被解释为正则表达式，并且还会强制使用 Python 解析引擎。请注意，正则表达式分隔符容易忽略带引号的数据。正则表达式示例：`'\r\t'`。

**delimiter**str，可选

`sep` 的别名。

**header**int、int 序列、‘infer’ 或 None，默认为‘infer’

包含列标签并标记数据开始的行号（从零开始计数）。默认行为是推断列名：如果没有传递`names`，则行为与 `header=0` 相同，并且列名从文件的第一行推断出来；如果列名明确传递给 `names`，则行为与 `header=None` 相同。显式传递 `header=0` 以能够替换现有名称。标头可以是指定列的 `MultiIndex` 的行位置的整数列表，例如 `[0, 1, 3]`。未指定的中间行将被跳过（例如在此示例中跳过了 2）。请注意，如果 `skip_blank_lines=True`，则此参数将忽略注释行和空行，因此 `header=0` 表示数据的第一行而不是文件的第一行。

**names**可哈希序列，可选

应用的列标签序列。如果文件包含标题行，则应显式传递 `header=0` 以覆盖列名。此列表中不允许重复项。

**index_col**可哈希、可哈希序列或 False，可选

列作为行标签使用的列，可以用列标签或列索引表示。如果给定一系列标签或索引，将为行标签形成`MultiIndex`。

注意：`index_col=False`可用于强制 pandas*不*使用第一列作为索引，例如，当您有一个每行末尾带有分隔符的格式不正确的文件时。

**usecols**可哈希序列或可调用对象，可选

要选择的列的子集，可以用列标签或列索引表示。如果类似列表，所有元素必须是位置的（即整数索引到文档列）或与用户在`names`中提供的列名对应的字符串，或从文档标题行中推断出来的。如果给定了`names`，则不考虑文档标题行。例如，一个有效的类似列表的`usecols`参数可以是`[0, 1, 2]`或`['foo', 'bar', 'baz']`。元素顺序被忽略，因此`usecols=[0, 1]`与`[1, 0]`相同。要保留元素顺序实例化`DataFrame`，请使用`pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`以`['foo', 'bar']`顺序的列或`pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]`以`['bar', 'foo']`顺序。

如果可调用，将对列名评估可调用函数，返回可调用函数评估为`True`的名称。一个有效的可调用参数示例是`lambda x: x.upper() in ['AAA', 'BBB', 'DDD']`。使用此参数会导致更快的解析时间和更低的内存使用。

**dtype**dtype 或{可哈希 dtype}字典，可选

要应用于整个数据集或单独列的数据类型。例如，`{'a': np.float64, 'b': np.int32, 'c': 'Int64'}`使用`str`或`object`与适当的`na_values`设置一起，以保留并不解释`dtype`。如果指定了`converters`，它们将被应用于`dtype`转换的*替代*。

新版本 1.5.0 中：添加了对`defaultdict`的支持。指定一个`defaultdict`作为输入，其中默认值确定未明确列出的列的`dtype`。

**engine**{‘c’, ‘python’, ‘pyarrow’}，可选

要使用的解析引擎。C 和 pyarrow 引擎更快，而 python 引擎目前更完整。目前只有 pyarrow 引擎支持多线程。

新版本 1.4.0 中：添加了‘pyarrow’引擎作为*实验性*引擎，并且某些功能不受支持，或者在此引擎下可能无法正常工作。

**converters**{可哈希可调用}字典，可选

用于转换指定列中的值的函数。键可以是列标签或列索引。

**true_values**列表，可选

除了不区分大小写的`True`的变体外，要考虑为`True`的值。

**false_values**列表，可选

除了不区分大小写的`False`的变体外，要考虑为`False`的值。

**skipinitialspace**bool，默认为 False

在分隔符后跳过空格。

**skiprows**int、int 列表或可调用对象，可选

要跳过的行号（从 0 开始索引）或文件开头要跳过的行数（`int`）。

如果是可调用的，可调用函数将根据行索引进行评估，如果应跳过该行则返回`True`，否则返回`False`。一个有效的可调用参数示例是`lambda x: x in [0, 2]`。

**skipfooter**int，默认为 0

要跳过文件底部的行数（不支持`engine='c'`）。

**nrows**int，可选

要读取的文件行数。用于读取大文件的片段。

**na_values**Hashable、Hashable 的 Iterable 或{HashableIterable}字典，可选

要识别为`NA`/`NaN`的其他字符串。如果传递了`dict`，则为每列指定特定的`NA`值。默认情况下，以下值被解释为`NaN`：“ “, “#N/A”, “#N/A N/A”, “#NA”, “-1.#IND”, “-1.#QNAN”, “-NaN”, “-nan”, “1.#IND”, “1.#QNAN”, “<NA>”, “N/A”, `NA`, “NULL”, `NaN`, “None”, “n/a”, “nan”, “null “。

**keep_default_na**bool，默认为 True

在解析数据时是否包括默认的`NaN`值。根据是否传入`na_values`，行为如下：

+   如果`keep_default_na`为`True`，并且指定了`na_values`，则`na_values`将附加到用于解析的默认`NaN`值。

+   如果`keep_default_na`为`True`，并且未指定`na_values`，则只使用默认的`NaN`值进行解析。

+   如果`keep_default_na`为`False`，并且指定了`na_values`，则只有指定的`na_values`值会被用于解析。

+   如果`keep_default_na`为`False`，并且未指定`na_values`，则不会将任何字符串解析为`NaN`。

请注意，如果将`na_filter`传入为`False`，则`keep_default_na`和`na_values`参数将被忽略。

**na_filter**bool，默认为 True

检测缺失值标记（空字符串和`na_values`的值）。在没有任何`NA`值的数据中，传入`na_filter=False`可以提高读取大文件的性能。

**verbose**bool，默认为 False

指示非数字列中放置的`NA`值的数量。

自版本 2.2.0 起已弃用。

**skip_blank_lines**bool，默认为 True

如果为`True`，则跳过空行而不是解释为`NaN`值。

**parse_dates**bool、Hashable 列表、列表的列表或{Hashablelist}字典，默认为 False

行为如下：

+   `bool`。如果为`True` -> 尝试解析索引。注意：如果传递了`date_format`或`date_parser`参数，则会自动设置为`True`。

+   `int`或名称的`list`。例如，如果`[1, 2, 3]` -> 尝试将列 1、2、3 分别解析为单独的日期列。

+   `list`的`list`。例如，如果`[[1, 3]]` -> 将列 1 和 3 组合并解析为单个日期列。在解析之前，值将用空格连接起来。

+   `dict`，例如`{'foo' : [1, 3]}` -> 将列 1、3 解析为日期并命名为‘foo’。在解析之前，值将用空格连接起来。

如果某列或索引无法表示为`datetime`数组，例如因为存在无法解析的值或时区混合，该列或索引将按原样返回为`object`数据类型。对于非标准`datetime`解析，请在`read_csv()`之后使用`to_datetime()`。

注意：存在用于 iso8601 格式的快速路径。

**infer_datetime_format**bool，默认值为 False

如果`True`并且启用了`parse_dates`，pandas 将尝试推断列中`datetime`字符串的格式，并且如果可以推断，则切换到更快的解析方法。在某些情况下，这可能会将解析速度提高 5-10 倍。

自 2.0.0 版本起已弃用：该参数的严格版本现在是默认值，传递它将不会产生任何效果。

**keep_date_col**bool，默认值为 False

如果`True`并且`parse_dates`指定合并多个列，则保留原始列。

**date_parser**Callable，可选

用于将字符串列序列转换为`datetime`实例数组的函数。默认使用`dateutil.parser.parser`进行转换。 pandas 将尝试以三种不同的方式调用`date_parser`，如果发生异常，则继续下一个：1)将一个或多个数组（如`parse_dates`定义的）作为参数传递；2)将由`parse_dates`定义的列中的字符串值（按行）串联成单个数组并传递；并且 3)对每一行使用一个或多个字符串（对应于由`parse_dates`定义的列）调用一次`date_parser`。

自 2.0.0 版本起已弃用：请改用`date_format`，或者读取为`object`然后根据需要应用`to_datetime()`。

**date_format**str 或列->格式的字典，可选

与`parse_dates`一起使用时用于解析日期的格式。解析时间的 strftime，例如`"%d/%m/%Y"`。有关选项的更多信息，请参阅[strftime documentation](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior)，尽管请注意`"%f"`将解析直到纳秒。您还可以传递：

+   “ISO8601”，以解析任何[ISO8601](https://en.wikipedia.org/wiki/ISO_8601)

    时间字符串（不一定完全相同的格式）；

+   “mixed”，为每个元素单独推断格式。这很冒险，

    您应该与 dayfirst 一起使用它。

2.0.0 版本中的新功能。

**dayfirst**bool，默认值为 False

DD/MM 格式日期，国际和欧洲格式。

**cache_dates**bool，默认值为 True

如果为`True`，则使用唯一的转换日期缓存应用`datetime`转换。当解析重复的日期字符串时，特别是带有时区偏移的日期字符串，可能会产生显着的加速。

**iterator**bool，默认值为 False

返回用于迭代或使用`get_chunk()`获取块的`TextFileReader`对象。

**chunksize**int，可选

从文件中每块读取的行数。传递一个值将导致函数返回一个`TextFileReader`对象进行迭代。有关`iterator`和`chunksize`的更多信息，请参阅[IO 工具文档](https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking)。

**compression**str 或 dict，默认‘infer’

用于在磁盘上的数据进行即时解压缩。如果‘infer’和‘filepath_or_buffer’类似路径，则从以下扩展名检测压缩：‘.gz’、‘.bz2’、‘.zip’、‘.xz’、‘.zst’、‘.tar’、‘.tar.gz’、‘.tar.xz’或‘.tar.bz2’（否则不压缩）。如果使用`'zip'`或`'tar'`，ZIP 文件必须只包含一个要读取的数据文件。设置为`None`表示不解压缩。也可以是一个字典，其中键`'method'`设置为其中之一{`'zip'`、`'gzip'`、`'bz2'`、`'zstd'`、`'xz'`、`'tar'`}，其他键值对转发到`zipfile.ZipFile`、`gzip.GzipFile`、`bz2.BZ2File`、`zstandard.ZstdDecompressor`、`lzma.LZMAFile`或`tarfile.TarFile`。例如，可以通过以下方式传递用于 Zstandard 解压缩的自定义压缩字典：`compression={'method': 'zstd', 'dict_data': my_compression_dict}`。

1.5.0 版本中的新功能：添加对.tar 文件的支持。

1.4.0 版本中的更改：Zstandard 支持。

**thousands**str (length 1), optional

用作数字值中的千位分隔符的字符。

**decimal**str (length 1), default ‘.’

用作小数点的字符（例如，对于欧洲数据使用‘,’）。

**lineterminator**str (length 1), optional

用于表示换行的字符。仅与 C 解析器有效。

**quotechar**str (length 1), optional

用于表示引用项的起始和结束的字符。引用项可以包括`delimiter`，并且将被忽略。

**quoting**{0 或 csv.QUOTE_MINIMAL，1 或 csv.QUOTE_ALL，2 或 csv.QUOTE_NONNUMERIC，3 或 csv.QUOTE_NONE}，默认 csv.QUOTE_MINIMAL

控制字段引用行为的`csv.QUOTE_*`常量。默认值为`csv.QUOTE_MINIMAL`（即 0），这意味着只有包含特殊字符的字段被引用（例如，在`quotechar`、`delimiter`或`lineterminator`中定义的字符）。 

**doublequote**bool, default True

当指定`quotechar`且`quoting`不是`QUOTE_NONE`时，指示是否将字段内连续的两个`quotechar`元素解释为单个`quotechar`元素。

**escapechar**str (length 1), optional

用于转义其他字符的字符。

**comment**str (length 1), optional

表示该行剩余部分不应解析的字符。如果在行的开头找到该字符，则整行将被忽略。此参数必须是单个字符。与空行一样（只要`skip_blank_lines=True`），完全注释的行被参数`header`忽略，但不被`skiprows`忽略。例如，如果`comment='#'`，使用`header=0`解析`#empty\na,b,c\n1,2,3`将导致将`'a,b,c'`视为标题。

**encoding**str, optional, default ‘utf-8’

读取/写入时要使用的 UTF 编码（例如'utf-8'）。[Python 标准编码列表](https://docs.python.org/3/library/codecs.html#standard-encodings)。

**编码错误**str，可选，默认为'strict'

处理编码错误的方式。[可能的值列表](https://docs.python.org/3/library/codecs.html#error-handlers)。

自版本 1.3.0 起新功能。

**方言**str 或 csv.Dialect，可选

如果提供了此参数，它将覆盖以下参数的值（默认值或非默认值）：`delimiter`、`doublequote`、`escapechar`、`skipinitialspace`、`quotechar`和`quoting`。如果需要覆盖值，将发出`ParserWarning`。有关更多详细信息，请参阅`csv.Dialect`文档。

**on_bad_lines**{‘error’, ‘warn’, ‘skip’}或可调用，默认为'error'

指定在遇到坏行（字段过多的行）时要执行的操作。允许的值为：

+   `'error'`，遇到坏行时引发异常。

+   `'warn'`，遇到坏行时发出警告并跳过该行。

+   `'skip'`，遇到坏行时跳过而不发出或警告。

自版本 1.3.0 起新功能。

自版本 1.4.0 起新功能：

+   具有签名`(bad_line: list[str]) -> list[str] | None`的可调用函数，将处理单个坏行。`bad_line`是由`sep`分割的字符串列表。如果函数返回`None`，则将忽略坏行。如果函数返回具有比预期更多元素的新`list`字符串，则将发出`ParserWarning`，同时丢弃额外的元素。仅在`engine='python'`时支持

自版本 2.2.0 起更改：

+   当`engine='pyarrow'`时，具有[pyarrow 文档](https://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html#pyarrow.csv.ParseOptions.invalid_row_handler)中描述的签名的可调用函数。

**delim_whitespace**bool，默认为 False

指定是否使用空格（例如`' '`或`'\t'`）作为`sep`分隔符。等同于设置`sep='\s+'`。如果将此选项设置为`True`，则不应为`delimiter`参数传递任何内容。

自版本 2.2.0 起弃用：改用`sep="\s+"`。

**low_memory**bool，默认为 True

在块中内部处理文件，导致解析时使用更少的内存，但可能混合类型推断。为确保没有混合类型，要么设置为`False`，要么使用`dtype`参数指定类型。请注意，整个文件都会被读入单个`DataFrame`中，使用`chunksize`或`iterator`参数以返回以块形式返回数据。 （仅与 C 解析器有效）。

**memory_map**bool，默认为 False

如果为`filepath_or_buffer`提供了文件路径，则将文件对象直接映射到内存并直接从中访问数据。使用此选项可以提高性能，因为不再有任何 I/O 开销。

**float_precision**{‘high’, ‘legacy’, ‘round_trip’}，可选

指定 C 引擎应使用哪个转换器处理浮点值。选项为 `None` 或 `'high'` 表示普通转换器，`'legacy'` 表示原始的较低精度 pandas 转换器，`'round_trip'` 表示往返转换器。

**storage_options**dict，可选

适用于特定存储连接的额外选项，例如主机、端口、用户名、密码等。对于 HTTP(S) URL，键值对将作为标头选项转发给 `urllib.request.Request`。对于其他 URL（例如以 “s3://” 和 “gcs://” 开头的 URL），键值对将转发给 `fsspec.open`。请参阅 `fsspec` 和 `urllib` 以获取更多详细信息，并有关存储选项的更多示例，请参考[这里](https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files)。

**dtype_backend**{‘numpy_nullable’, ‘pyarrow’}，默认为 ‘numpy_nullable’

应用于生成的 `DataFrame` 的后端数据类型（仍处于实验阶段）。行为如下：

+   `"numpy_nullable"`：返回由可空数据类型支持的 `DataFrame`（默认）。

+   `"pyarrow"`：返回由 pyarrow 支持的可空 `ArrowDtype` DataFrame。

版本 2.0 中的新功能。

返回：

DataFrame 或 TextFileReader

逗号分隔值（csv）文件作为带有标记轴的二维数据结构返回。

另请参阅

`DataFrame.to_csv`

将 DataFrame 写入逗号分隔值（csv）文件。

`read_table`

将通用分隔文件读入 DataFrame。

`read_fwf`

将固定宽度格式行的表读入 DataFrame。

示例

```py
>>> pd.read_csv('data.csv') 
```
