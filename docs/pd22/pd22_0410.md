# `pandas.DataFrame.to_hdf`

> 原文：[`pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_hdf.html`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_hdf.html)

```py
DataFrame.to_hdf(path_or_buf, *, key, mode='a', complevel=None, complib=None, append=False, format=None, index=True, min_itemsize=None, nan_rep=None, dropna=None, data_columns=None, errors='strict', encoding='UTF-8')
```

使用 HDFStore 将包含的数据写入 HDF5 文件。

分层数据格式（HDF）是自描述的，允许应用程序解释文件的结构和内容，而无需外部信息。一个 HDF 文件可以保存一组相关对象，可以作为一组或单独对象访问。

要将另一个 DataFrame 或 Series 添加到现有的 HDF 文件中，请使用追加模式和不同的键。

警告

可以将 `DataFrame` 或 `Series` 的子类存储到 HDF5 中，但在存储时会丢失子类的类型。

有关更多信息，请参阅用户指南。

参数：

**path_or_buf**str 或 pandas.HDFStore

文件路径或 HDFStore 对象。

**key**str

存储中的组的标识符。

**mode**{‘a’, ‘w’, ‘r+’}，默认为 ‘a’

打开文件的模式：

+   ‘w’：写入，创建一个新文件（同名的现有文件将被删除）。

+   ‘a’：追加，打开现有文件进行读取和写入，如果文件不存在，则创建它。

+   ‘r+’：类似于 ‘a’，但文件必须已经存在。

**complevel**{0-9}，默认为 None

为数据指定一个压缩级别。值为 0 或 None 禁用压缩。

**complib**{‘zlib’, ‘lzo’, ‘bzip2’, ‘blosc’}，默认为 ‘zlib’

指定要使用的压缩库。支持这些额外的 Blosc 压缩器（如果未指定压缩器，则默认为 ‘blosc:blosclz’）：{‘blosc:blosclz’, ‘blosc:lz4’, ‘blosc:lz4hc’, ‘blosc:snappy’, ‘blosc:zlib’, ‘blosc:zstd’}。指定不可用的压缩库会引发 ValueError。

**append**bool，默认为 False

对于表格格式，将输入数据追加到现有数据中。

**format**{‘fixed’, ‘table’, None}，默认为 ‘fixed’

可能的值：

+   ‘fixed’：固定格式。快速写入/读取。不可追加，也不可搜索。

+   ‘table’：表格格式。写入 PyTables 表结构，可能性能较差，但允许更灵活的操作，如搜索/选择数据子集。

+   如果为 None，则检查 pd.get_option(‘io.hdf.default_format’)，然后回退到“fixed”。

**index**bool，默认为 True

将 DataFrame 索引写入作为一列。

**min_itemsize**dict 或 int，可选

将列名映射到列的最小字符串大小。

**nan_rep**任意，可选

如何将空值表示为字符串。不允许与 append=True 一起使用。

**dropna**bool，默认为 False，可选

删除缺失值。

**data_columns**列的列表或 True，可选

要创建为磁盘查询的索引数据列的列列表，或者为 True 以使用所有列。默认情况下，只有对象的轴被索引。有关更多信息，请参见通过数据列进行查询。

**errors**str，默认为 ‘strict’

指定如何处理编码和解码错误。查看 [`open()`](https://docs.python.org/3/library/functions.html#open "(in Python v3.12)") 的 errors 参数以获取完整的选项列表。

**encoding**str，默认为“UTF-8”

另请参阅

`read_hdf`

从 HDF 文件中读取。

`DataFrame.to_orc`

将 DataFrame 写入二进制 Orc 格式。

`DataFrame.to_parquet`

将 DataFrame 写入二进制 Parquet 格式。

`DataFrame.to_sql`

将数据写入 SQL 表格。

`DataFrame.to_feather`

为 DataFrame 写出羽毛格式。

`DataFrame.to_csv`

将数据写入 csv 文件。

示例

```py
>>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},
...                   index=['a', 'b', 'c'])  
>>> df.to_hdf('data.h5', key='df', mode='w') 
```

我们可以将另一个对象添加到同一个文件中：

```py
>>> s = pd.Series([1, 2, 3, 4])  
>>> s.to_hdf('data.h5', key='s') 
```

从 HDF 文件中读取：

```py
>>> pd.read_hdf('data.h5', 'df')  
A  B
a  1  4
b  2  5
c  3  6
>>> pd.read_hdf('data.h5', 's')  
0    1
1    2
2    3
3    4
dtype: int64 
```
