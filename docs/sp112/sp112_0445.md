# scipy.optimize.shgo

> 原文链接：[https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.shgo.html#scipy.optimize.shgo](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.shgo.html#scipy.optimize.shgo)

```py
scipy.optimize.shgo(func, bounds, args=(), constraints=None, n=100, iters=1, callback=None, minimizer_kwargs=None, options=None, sampling_method='simplicial', *, workers=1)
```

使用SHG优化找到函数的全局最小值。

SHGO代表“单纯同调全局优化”。

参数：

**func**可调用

要最小化的目标函数。必须以`f(x, *args)`形式，其中`x`是一个1-D数组的参数，而`args`是完全指定函数所需的额外固定参数的元组。

**bounds**序列或[`Bounds`](scipy.optimize.Bounds.html#scipy.optimize.Bounds "scipy.optimize.Bounds")

变量的边界。有两种指定边界的方法：

1.  [`Bounds`](scipy.optimize.Bounds.html#scipy.optimize.Bounds "scipy.optimize.Bounds")类的实例。

1.  *x*的每个元素的`(min, max)`对的序列。

**args**元组，可选

任何完全指定目标函数所需的额外固定参数。

**constraints**{约束，字典}或约束列表，可选

约束定义。仅适用于COBYLA、SLSQP和trust-constr。参见教程[[5]](#rb2e152d227b3-5)以了解有关指定约束的详细信息。

注意

目前仅COBYLA、SLSQP和trust-constr局部最小化方法支持约束参数。如果在本地优化问题中使用的`constraints`序列未在`minimizer_kwargs`中定义，并且使用了约束方法，则将使用全局的`constraints`（在`minimizer_kwargs`中定义了`constraints`序列意味着不会添加`constraints`，因此如果需要添加等式约束等等，则需要将约束函数添加到`minimizer_kwargs`中的不等式函数中）。COBYLA仅支持不等式约束。

从版本1.11.0起：`constraints`接受[`NonlinearConstraint`](scipy.optimize.NonlinearConstraint.html#scipy.optimize.NonlinearConstraint "scipy.optimize.NonlinearConstraint")，[`LinearConstraint`](scipy.optimize.LinearConstraint.html#scipy.optimize.LinearConstraint "scipy.optimize.LinearConstraint")。

**n**整数，可选

在构建单纯复合物时使用的采样点数。对于默认的`simplicial`采样方法，生成2**dim + 1个采样点，而不是默认的*n=100*。对于所有其他指定的值，生成*n*个采样点。对于`sobol`、`halton`和其他任意的*sampling_methods*，生成*n=100*或另一个指定的采样点数。

**iters**整数，可选

用于构建单纯复合物的迭代次数。默认为1。

**callback**可调用，可选

在每次迭代后调用，形式为`callback(xk)`，其中`xk`是当前参数向量。

**minimizer_kwargs**字典，可选

要传递给最小化器`scipy.optimize.minimize`的额外关键字参数。一些重要的选项可能是：

> +   methodstr
> +   
>     最小化方法。如果未指定，则根据问题是否有约束或边界选择为 BFGS、L-BFGS-B、SLSQP 之一。
>     
> +   argstuple
> +   
>     传递给目标函数 (`func`) 及其导数（Jacobian、Hessian）的额外参数。
>     
> +   选项字典，可选
> +   
>     注意，默认情况下容差被指定为 `{ftol: 1e-12}`

**选项**字典，可选

解算器选项字典。许多指定给全局例程的选项也传递给 scipy.optimize.minimize 例程。传递给局部例程的选项标有“(L)”。

停止标准，如果满足任何指定的准则则算法将终止。但是，默认算法不需要指定任何准则：

+   maxfevint (L)

    可行域内的最大函数评估次数。（注意，只有支持此选项的方法才会精确地在指定值处终止例程。否则，准则只会在全局迭代期间终止）

+   f_min

    如果已知，指定最小目标函数值。

+   f_tolfloat

    值 f 的停止准则的精度目标。请注意，如果全局例程中的采样点在此容差内，则全局例程也将终止。

+   maxiterint

    执行的最大迭代次数。

+   maxevint

    最大采样评估次数（包括在不可行点中的搜索）。

+   maxtimefloat

    允许的最大处理运行时

+   minhgrdint

    最小同调群秩差分。在每次迭代期间（大约）计算目标函数的同调群。该群的秩与目标函数中局部凸子域的数量具有一一对应关系（在足够的采样点后，这些子域包含唯一的全局最小值）。如果指定迭代的 `maxhgrd` 中 hgr 的差异为 0，则算法将终止。

目标函数知识：

+   对称性列表或布尔值

    指定目标函数是否包含对称变量。在完全对称的情况下，搜索空间（因此性能）最多减少 O(n!) 倍。如果指定为 *True*，则所有变量将被设置为相对于第一个变量对称。默认设置为 False。

    例如，f(x) = (x_1 + x_2 + x_3) + (x_4)**2 + (x_5)**2 + (x_6)**2

    在此方程中，x_2 和 x_3 对 x_1 对称，而 x_5 和 x_6 对 x_4 对称，可以指定给解算器如下：

    对称性 = [0, # 变量 1

    0, # 对变量 1 对称 0, # 对变量 1 3, # 变量 4 3, # 对变量 4 3, # 对变量 4 ]

+   jacbool 或可调用，可选

    目标函数的Jacobian（梯度）。仅适用于CG、BFGS、Newton-CG、L-BFGS-B、TNC、SLSQP、dogleg和trust-ncg。如果`jac`为布尔值且为True，则假定`fun`返回目标函数的梯度。如果为False，则梯度将以数值方式估计。`jac`也可以是一个返回目标函数梯度的可调用对象。在这种情况下，它必须接受与`fun`相同的参数。（将自动传递给[`scipy.optimize.minimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize "scipy.optimize.minimize")）

+   hess，hesspcallable，可选

    Hessian（二阶导数矩阵）的目标函数或者目标函数的Hessian乘以任意向量p。仅适用于Newton-CG、dogleg和trust-ncg。`hessp`或`hess`中只需提供一个。如果提供了`hess`，则将忽略`hessp`。如果`hess`和`hessp`都未提供，则将在`jac`上使用有限差分近似Hessian乘积。`hessp`必须计算Hessian乘以任意向量。（将自动传递给[`scipy.optimize.minimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize "scipy.optimize.minimize")）

算法设置：

+   minimize_every_iterbool

    如果为True，则有前景的全局采样点将传递给每次迭代的本地最小化程序。如果为False，则仅运行最终的最小化池。默认为True。

+   local_iterint

    每次迭代仅评估少数最佳最小化候选点。如果为False，则所有潜在点都将传递给本地最小化程序。

+   infty_constraintsbool

    如果为True，则生成的任何采样点超出可行域将被保存，并给予目标函数值`inf`。如果为False，则这些点将被丢弃。使用此功能可以在找到全局最小值之前提高函数评估的性能。指定为False将以稍微降低性能的代价节省内存。默认为True。

反馈：

+   dispbool（L）

    设置为True以打印收敛消息。

**sampling_method**str或函数，可选

当前内置的采样方法选项为`halton`、`sobol`和`simplicial`。默认的`simplicial`提供了有限时间内收敛到全局最小值的理论保证。`halton`和`sobol`方法在采样点生成方面更快，但失去了保证收敛性。对于大多数“较简单”的问题，这更为适用。用户定义的采样函数必须每次调用接受`n`个维度为`dim`的采样点，并输出形状为*n x dim*的采样点数组。

**workers**int或类似映射的可调用对象，可选

并行地对样本进行本地串行最小化。提供-1以使用所有可用的CPU核心，或提供一个整数以使用这么多进程（使用[`multiprocessing.Pool`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing "(in Python v3.12)")）。

或者提供一个类似映射的可调用对象，例如*multiprocessing.Pool.map*以进行并行评估。此评估以`workers(func, iterable)`形式进行。要求*func*可被pickle。

从版本1.11.0开始新增。

返回：

**res**OptimizeResult

优化结果表示为[`OptimizeResult`](scipy.optimize.OptimizeResult.html#scipy.optimize.OptimizeResult "scipy.optimize.OptimizeResult")对象。重要属性包括：`x`是对应全局最小值的解数组，`fun`是全局解处的函数输出，`xl`是局部最小解的排序列表，`funl`是相应局部解的函数输出，`success`是一个布尔标志，指示优化器是否成功退出，`message`描述终止原因，`nfev`是包括采样调用在内的总目标函数评估次数，`nlfev`是所有局部搜索优化导致的总目标函数评估次数，`nit`是全局例程执行的迭代次数。

注释

使用单纯同调全局优化进行全局优化 [[1]](#rb2e152d227b3-1)。适用于解决通用NLP和黑盒优化问题以达到全局最优（低维问题）。

一般来说，优化问题的形式为：

```py
minimize f(x) subject to

g_i(x) >= 0,  i = 1,...,m
h_j(x)  = 0,  j = 1,...,p 
```

这里x是一个或多个变量的向量。`f(x)`是目标函数`R^n -> R`，`g_i(x)`是不等式约束，`h_j(x)`是等式约束。

可选地，还可以使用*bounds*参数指定x中每个元素的下限和上限。

虽然SHGO的大部分理论优势仅对`f(x)`为Lipschitz光滑函数时得到证明，但是当`f(x)`是非连续、非凸且非光滑时，如果使用默认的采样方法，该算法也被证明能够收敛到全局最优解 [[1]](#rb2e152d227b3-1)。

可以使用`minimizer_kwargs`参数指定本地搜索方法，该参数传递给`scipy.optimize.minimize`。默认情况下使用`SLSQP`方法。一般建议如果问题定义了不等式约束，则使用`SLSQP`或`COBYLA`本地最小化方法，因为其他方法不使用约束。

使用[`scipy.stats.qmc`](../stats.qmc.html#module-scipy.stats.qmc "scipy.stats.qmc")生成`halton`和`sobol`方法点。还可以使用任何其他QMC方法。

参考文献

[1] ([1](#id2),[2](#id3))

Endres, SC, Sandrock, C, Focke, WW (2018) “一种用于Lipschitz优化的单纯同调算法”，全球优化期刊。

[2]

Joe, SW和Kuo, FY（2008）“用更好的二维投影构建Sobol序列”，SIAM J. Sci. Comput. 30, 2635-2654。

[3] ([1](#id10),[2](#id11))

Hock, W和Schittkowski, K（1981）“非线性规划代码的测试示例”，经济与数学系统讲义，187\. Springer-Verlag，纽约。[http://www.ai7.uni-bayreuth.de/test_problem_coll.pdf](http://www.ai7.uni-bayreuth.de/test_problem_coll.pdf)

[[4](#id9)]

Wales, DJ（2015）“观点：从势能景观中获取反应坐标和动态的洞察”，化学物理学杂志，142(13), 2015。

[[5](#id1)]

[https://docs.scipy.org/doc/scipy/tutorial/optimize.html#constrained-minimization-of-multivariate-scalar-functions-minimize](https://docs.scipy.org/doc/scipy/tutorial/optimize.html#constrained-minimization-of-multivariate-scalar-functions-minimize)

示例

首先考虑最小化Rosenbrock函数的问题，[`rosen`](scipy.optimize.rosen.html#scipy.optimize.rosen "scipy.optimize.rosen")：

```py
>>> from scipy.optimize import rosen, shgo
>>> bounds = [(0,2), (0, 2), (0, 2), (0, 2), (0, 2)]
>>> result = shgo(rosen, bounds)
>>> result.x, result.fun
(array([1., 1., 1., 1., 1.]), 2.920392374190081e-18) 
```

注意，边界确定目标函数的维度，因此是必需的输入，但是您可以使用`None`或类似`np.inf`的对象指定空边界，这些将被转换为大的浮点数。

```py
>>> bounds = [(None, None), ]*4
>>> result = shgo(rosen, bounds)
>>> result.x
array([0.99999851, 0.99999704, 0.99999411, 0.9999882 ]) 
```

接下来，我们考虑Eggholder函数，这是一个具有多个局部极小值和一个全局极小值的问题。我们将演示[`shgo`](#scipy.optimize.shgo "scipy.optimize.shgo")的参数使用和能力。

```py
>>> import numpy as np
>>> def eggholder(x):
...     return (-(x[1] + 47.0)
...             * np.sin(np.sqrt(abs(x[0]/2.0 + (x[1] + 47.0))))
...             - x[0] * np.sin(np.sqrt(abs(x[0] - (x[1] + 47.0))))
...             )
...
>>> bounds = [(-512, 512), (-512, 512)] 
```

[`shgo`](#scipy.optimize.shgo "scipy.optimize.shgo")具有内置的低差异采样序列。首先，我们将输入*Sobol'*序列的64个初始采样点：

```py
>>> result = shgo(eggholder, bounds, n=64, sampling_method='sobol')
>>> result.x, result.fun
(array([512\.        , 404.23180824]), -959.6406627208397) 
```

[`shgo`](#scipy.optimize.shgo "scipy.optimize.shgo")还返回了找到的任何其他局部极小值，可以使用以下方式调用：

```py
>>> result.xl
array([[ 512\.        ,  404.23180824],
 [ 283.0759062 , -487.12565635],
 [-294.66820039, -462.01964031],
 [-105.87688911,  423.15323845],
 [-242.97926   ,  274.38030925],
 [-506.25823477,    6.3131022 ],
 [-408.71980731, -156.10116949],
 [ 150.23207937,  301.31376595],
 [  91.00920901, -391.283763  ],
 [ 202.89662724, -269.38043241],
 [ 361.66623976, -106.96493868],
 [-219.40612786, -244.06020508]]) 
```

```py
>>> result.funl
array([-959.64066272, -718.16745962, -704.80659592, -565.99778097,
 -559.78685655, -557.36868733, -507.87385942, -493.9605115 ,
 -426.48799655, -421.15571437, -419.31194957, -410.98477763]) 
```

这些结果在应用中非常有用，特别是在需要许多全局极小值和其他全局极小值值的情况下，或者在局部极小值可以为系统提供洞察力的情况下（例如物理化学中的形态学[[4]](#rb2e152d227b3-4)）。

如果我们想要找到更多的局部极小值，我们可以增加采样点或迭代次数的数量。我们将增加采样点数到64，并将迭代次数从默认值1增加到3。使用`simplicial`，这将为我们提供64 x 3 = 192个初始采样点。

```py
>>> result_2 = shgo(eggholder,
...                 bounds, n=64, iters=3, sampling_method='sobol')
>>> len(result.xl), len(result_2.xl)
(12, 23) 
```

注意，例如`n=192, iters=1`和`n=64, iters=3`之间的差异。在第一种情况下，仅一次处理最小化池中的有前途点。在后一种情况下，它每64个采样点处理一次，总共3次。

要演示解决具有非线性约束的问题，请考虑Hock和Schittkowski问题73（牛饲料）的以下示例[[3]](#rb2e152d227b3-3)：

```py
minimize: f = 24.55 * x_1 + 26.75 * x_2 + 39 * x_3 + 40.50 * x_4

subject to: 2.3 * x_1 + 5.6 * x_2 + 11.1 * x_3 + 1.3 * x_4 - 5    >= 0,

            12 * x_1 + 11.9 * x_2 + 41.8 * x_3 + 52.1 * x_4 - 21
                -1.645 * sqrt(0.28 * x_1**2 + 0.19 * x_2**2 +
                              20.5 * x_3**2 + 0.62 * x_4**2)      >= 0,

            x_1 + x_2 + x_3 + x_4 - 1                             == 0,

            1 >= x_i >= 0 for all i 
```

在[[3]](#rb2e152d227b3-3)中给出的近似答案是：

```py
f([0.6355216, -0.12e-11, 0.3127019, 0.05177655]) = 29.894378 
```

```py
>>> def f(x):  # (cattle-feed)
...     return 24.55*x[0] + 26.75*x[1] + 39*x[2] + 40.50*x[3]
...
>>> def g1(x):
...     return 2.3*x[0] + 5.6*x[1] + 11.1*x[2] + 1.3*x[3] - 5  # >=0
...
>>> def g2(x):
...     return (12*x[0] + 11.9*x[1] +41.8*x[2] + 52.1*x[3] - 21
...             - 1.645 * np.sqrt(0.28*x[0]**2 + 0.19*x[1]**2
...                             + 20.5*x[2]**2 + 0.62*x[3]**2)
...             ) # >=0
...
>>> def h1(x):
...     return x[0] + x[1] + x[2] + x[3] - 1  # == 0
...
>>> cons = ({'type': 'ineq', 'fun': g1},
...         {'type': 'ineq', 'fun': g2},
...         {'type': 'eq', 'fun': h1})
>>> bounds = [(0, 1.0),]*4
>>> res = shgo(f, bounds, n=150, constraints=cons)
>>> res
 message: Optimization terminated successfully.
 success: True
 fun: 29.894378159142136
 funl: [ 2.989e+01]
 x: [ 6.355e-01  1.137e-13  3.127e-01  5.178e-02] # may vary
 xl: [[ 6.355e-01  1.137e-13  3.127e-01  5.178e-02]] # may vary
 nit: 1
 nfev: 142 # may vary
 nlfev: 35 # may vary
 nljev: 5
 nlhev: 0 
```

```py
>>> g1(res.x), g2(res.x), h1(res.x)
(-5.062616992290714e-14, -2.9594104944408173e-12, 0.0) 
```
