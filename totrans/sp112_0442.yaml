- en: scipy.optimize.basinhopping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.basinhopping.html#scipy.optimize.basinhopping](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.basinhopping.html#scipy.optimize.basinhopping)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Find the global minimum of a function using the basin-hopping algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Basin-hopping is a two-phase method that combines a global stepping algorithm
    with local minimization at each step. Designed to mimic the natural process of
    energy minimization of clusters of atoms, it works well for similar problems with
    “funnel-like, but rugged” energy landscapes [[5]](#r7bc5d3316b4a-5).
  prefs: []
  type: TYPE_NORMAL
- en: As the step-taking, step acceptance, and minimization methods are all customizable,
    this function can also be used to implement other two-phase methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**func**callable `f(x, *args)`'
  prefs: []
  type: TYPE_NORMAL
- en: Function to be optimized. `args` can be passed as an optional item in the dict
    *minimizer_kwargs*
  prefs: []
  type: TYPE_NORMAL
- en: '**x0**array_like'
  prefs: []
  type: TYPE_NORMAL
- en: Initial guess.
  prefs: []
  type: TYPE_NORMAL
- en: '**niter**integer, optional'
  prefs: []
  type: TYPE_NORMAL
- en: The number of basin-hopping iterations. There will be a total of `niter + 1`
    runs of the local minimizer.
  prefs: []
  type: TYPE_NORMAL
- en: '**T**float, optional'
  prefs: []
  type: TYPE_NORMAL
- en: The “temperature” parameter for the acceptance or rejection criterion. Higher
    “temperatures” mean that larger jumps in function value will be accepted. For
    best results *T* should be comparable to the separation (in function value) between
    local minima.
  prefs: []
  type: TYPE_NORMAL
- en: '**stepsize**float, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Maximum step size for use in the random displacement.
  prefs: []
  type: TYPE_NORMAL
- en: '**minimizer_kwargs**dict, optional'
  prefs: []
  type: TYPE_NORMAL
- en: 'Extra keyword arguments to be passed to the local minimizer [`scipy.optimize.minimize`](scipy.optimize.minimize.html#scipy.optimize.minimize
    "scipy.optimize.minimize") Some important options could be:'
  prefs: []
  type: TYPE_NORMAL
- en: methodstr
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The minimization method (e.g. `"L-BFGS-B"`)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: argstuple
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Extra arguments passed to the objective function (*func*) and its derivatives
    (Jacobian, Hessian).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**take_step**callable `take_step(x)`, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Replace the default step-taking routine with this routine. The default step-taking
    routine is a random displacement of the coordinates, but other step-taking algorithms
    may be better for some systems. *take_step* can optionally have the attribute
    `take_step.stepsize`. If this attribute exists, then [`basinhopping`](#scipy.optimize.basinhopping
    "scipy.optimize.basinhopping") will adjust `take_step.stepsize` in order to try
    to optimize the global minimum search.
  prefs: []
  type: TYPE_NORMAL
- en: '**accept_test**callable, `accept_test(f_new=f_new, x_new=x_new, f_old=fold,
    x_old=x_old)`, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Define a test which will be used to judge whether to accept the step. This will
    be used in addition to the Metropolis test based on “temperature” *T*. The acceptable
    return values are True, False, or `"force accept"`. If any of the tests return
    False then the step is rejected. If the latter, then this will override any other
    tests in order to accept the step. This can be used, for example, to forcefully
    escape from a local minimum that [`basinhopping`](#scipy.optimize.basinhopping
    "scipy.optimize.basinhopping") is trapped in.
  prefs: []
  type: TYPE_NORMAL
- en: '**callback**callable, `callback(x, f, accept)`, optional'
  prefs: []
  type: TYPE_NORMAL
- en: A callback function which will be called for all minima found. `x` and `f` are
    the coordinates and function value of the trial minimum, and `accept` is whether
    that minimum was accepted. This can be used, for example, to save the lowest N
    minima found. Also, *callback* can be used to specify a user defined stop criterion
    by optionally returning True to stop the [`basinhopping`](#scipy.optimize.basinhopping
    "scipy.optimize.basinhopping") routine.
  prefs: []
  type: TYPE_NORMAL
- en: '**interval**integer, optional'
  prefs: []
  type: TYPE_NORMAL
- en: interval for how often to update the *stepsize*
  prefs: []
  type: TYPE_NORMAL
- en: '**disp**bool, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Set to True to print status messages
  prefs: []
  type: TYPE_NORMAL
- en: '**niter_success**integer, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Stop the run if the global minimum candidate remains the same for this number
    of iterations.
  prefs: []
  type: TYPE_NORMAL
- en: '**seed**{None, int, [`numpy.random.Generator`](https://numpy.org/devdocs/reference/random/generator.html#numpy.random.Generator
    "(in NumPy v2.0.dev0)"), [`numpy.random.RandomState`](https://numpy.org/devdocs/reference/random/legacy.html#numpy.random.RandomState
    "(in NumPy v2.0.dev0)")}, optional'
  prefs: []
  type: TYPE_NORMAL
- en: If *seed* is None (or *np.random*), the [`numpy.random.RandomState`](https://numpy.org/devdocs/reference/random/legacy.html#numpy.random.RandomState
    "(in NumPy v2.0.dev0)") singleton is used. If *seed* is an int, a new `RandomState`
    instance is used, seeded with *seed*. If *seed* is already a `Generator` or `RandomState`
    instance then that instance is used. Specify *seed* for repeatable minimizations.
    The random numbers generated with this seed only affect the default Metropolis
    *accept_test* and the default *take_step*. If you supply your own *take_step*
    and *accept_test*, and these functions use random number generation, then those
    functions are responsible for the state of their random number generator.
  prefs: []
  type: TYPE_NORMAL
- en: '**target_accept_rate**float, optional'
  prefs: []
  type: TYPE_NORMAL
- en: The target acceptance rate that is used to adjust the *stepsize*. If the current
    acceptance rate is greater than the target, then the *stepsize* is increased.
    Otherwise, it is decreased. Range is (0, 1). Default is 0.5.
  prefs: []
  type: TYPE_NORMAL
- en: New in version 1.8.0.
  prefs: []
  type: TYPE_NORMAL
- en: '**stepwise_factor**float, optional'
  prefs: []
  type: TYPE_NORMAL
- en: The *stepsize* is multiplied or divided by this stepwise factor upon each update.
    Range is (0, 1). Default is 0.9.
  prefs: []
  type: TYPE_NORMAL
- en: New in version 1.8.0.
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: '**res**OptimizeResult'
  prefs: []
  type: TYPE_NORMAL
- en: 'The optimization result represented as a [`OptimizeResult`](scipy.optimize.OptimizeResult.html#scipy.optimize.OptimizeResult
    "scipy.optimize.OptimizeResult") object. Important attributes are: `x` the solution
    array, `fun` the value of the function at the solution, and `message` which describes
    the cause of the termination. The `OptimizeResult` object returned by the selected
    minimizer at the lowest minimum is also contained within this object and can be
    accessed through the `lowest_optimization_result` attribute. See [`OptimizeResult`](scipy.optimize.OptimizeResult.html#scipy.optimize.OptimizeResult
    "scipy.optimize.OptimizeResult") for a description of other attributes.'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs: []
  type: TYPE_NORMAL
- en: '[`minimize`](scipy.optimize.minimize.html#scipy.optimize.minimize "scipy.optimize.minimize")'
  prefs: []
  type: TYPE_NORMAL
- en: The local minimization function called once for each basinhopping step. *minimizer_kwargs*
    is passed to this routine.
  prefs: []
  type: TYPE_NORMAL
- en: Notes
  prefs: []
  type: TYPE_NORMAL
- en: Basin-hopping is a stochastic algorithm which attempts to find the global minimum
    of a smooth scalar function of one or more variables [[1]](#r7bc5d3316b4a-1) [[2]](#r7bc5d3316b4a-2)
    [[3]](#r7bc5d3316b4a-3) [[4]](#r7bc5d3316b4a-4). The algorithm in its current
    form was described by David Wales and Jonathan Doye [[2]](#r7bc5d3316b4a-2) [http://www-wales.ch.cam.ac.uk/](http://www-wales.ch.cam.ac.uk/).
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm is iterative with each cycle composed of the following features
  prefs: []
  type: TYPE_NORMAL
- en: random perturbation of the coordinates
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: local minimization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: accept or reject the new coordinates based on the minimized function value
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The acceptance test used here is the Metropolis criterion of standard Monte
    Carlo algorithms, although there are many other possibilities [[3]](#r7bc5d3316b4a-3).
  prefs: []
  type: TYPE_NORMAL
- en: This global minimization method has been shown to be extremely efficient for
    a wide variety of problems in physics and chemistry. It is particularly useful
    when the function has many minima separated by large barriers. See the [Cambridge
    Cluster Database](https://www-wales.ch.cam.ac.uk/CCD.html) for databases of molecular
    systems that have been optimized primarily using basin-hopping. This database
    includes minimization problems exceeding 300 degrees of freedom.
  prefs: []
  type: TYPE_NORMAL
- en: See the free software program [GMIN](https://www-wales.ch.cam.ac.uk/GMIN) for
    a Fortran implementation of basin-hopping. This implementation has many variations
    of the procedure described above, including more advanced step taking algorithms
    and alternate acceptance criterion.
  prefs: []
  type: TYPE_NORMAL
- en: For stochastic global optimization there is no way to determine if the true
    global minimum has actually been found. Instead, as a consistency check, the algorithm
    can be run from a number of different random starting points to ensure the lowest
    minimum found in each example has converged to the global minimum. For this reason,
    [`basinhopping`](#scipy.optimize.basinhopping "scipy.optimize.basinhopping") will
    by default simply run for the number of iterations *niter* and return the lowest
    minimum found. It is left to the user to ensure that this is in fact the global
    minimum.
  prefs: []
  type: TYPE_NORMAL
- en: 'Choosing *stepsize*: This is a crucial parameter in [`basinhopping`](#scipy.optimize.basinhopping
    "scipy.optimize.basinhopping") and depends on the problem being solved. The step
    is chosen uniformly in the region from x0-stepsize to x0+stepsize, in each dimension.
    Ideally, it should be comparable to the typical separation (in argument values)
    between local minima of the function being optimized. [`basinhopping`](#scipy.optimize.basinhopping
    "scipy.optimize.basinhopping") will, by default, adjust *stepsize* to find an
    optimal value, but this may take many iterations. You will get quicker results
    if you set a sensible initial value for `stepsize`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Choosing *T*: The parameter *T* is the “temperature” used in the Metropolis
    criterion. Basinhopping steps are always accepted if `func(xnew) < func(xold)`.
    Otherwise, they are accepted with probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: So, for best results, *T* should to be comparable to the typical difference
    (in function values) between local minima. (The height of “walls” between local
    minima is irrelevant.)
  prefs: []
  type: TYPE_NORMAL
- en: If *T* is 0, the algorithm becomes Monotonic Basin-Hopping, in which all steps
    that increase energy are rejected.
  prefs: []
  type: TYPE_NORMAL
- en: New in version 0.12.0.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs: []
  type: TYPE_NORMAL
- en: '[[1](#id2)]'
  prefs: []
  type: TYPE_NORMAL
- en: Wales, David J. 2003, Energy Landscapes, Cambridge University Press, Cambridge,
    UK.
  prefs: []
  type: TYPE_NORMAL
- en: '[2] ([1](#id3),[2](#id6))'
  prefs: []
  type: TYPE_NORMAL
- en: Wales, D J, and Doye J P K, Global Optimization by Basin-Hopping and the Lowest
    Energy Structures of Lennard-Jones Clusters Containing up to 110 Atoms. Journal
    of Physical Chemistry A, 1997, 101, 5111.
  prefs: []
  type: TYPE_NORMAL
- en: '[3] ([1](#id4),[2](#id7))'
  prefs: []
  type: TYPE_NORMAL
- en: Li, Z. and Scheraga, H. A., Monte Carlo-minimization approach to the multiple-minima
    problem in protein folding, Proc. Natl. Acad. Sci. USA, 1987, 84, 6611.
  prefs: []
  type: TYPE_NORMAL
- en: '[[4](#id5)]'
  prefs: []
  type: TYPE_NORMAL
- en: Wales, D. J. and Scheraga, H. A., Global optimization of clusters, crystals,
    and biomolecules, Science, 1999, 285, 1368.
  prefs: []
  type: TYPE_NORMAL
- en: '[[5](#id1)]'
  prefs: []
  type: TYPE_NORMAL
- en: Olson, B., Hashmi, I., Molloy, K., and Shehu1, A., Basin Hopping as a General
    and Versatile Optimization Framework for the Characterization of Biological Macromolecules,
    Advances in Artificial Intelligence, Volume 2012 (2012), Article ID 674832, [DOI:10.1155/2012/674832](https://doi.org/10.1155/2012/674832)
  prefs: []
  type: TYPE_NORMAL
- en: Examples
  prefs: []
  type: TYPE_NORMAL
- en: The following example is a 1-D minimization problem, with many local minima
    superimposed on a parabola.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Basinhopping, internally, uses a local minimization algorithm. We will use the
    parameter *minimizer_kwargs* to tell basinhopping which algorithm to use and how
    to set up that minimizer. This parameter will be passed to [`scipy.optimize.minimize`](scipy.optimize.minimize.html#scipy.optimize.minimize
    "scipy.optimize.minimize").
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Next consider a 2-D minimization problem. Also, this time, we will use gradient
    information to significantly speed up the search.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We’ll also use a different local minimization algorithm. Also, we must tell
    the minimizer that our function returns both energy and gradient (Jacobian).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an example using a custom step-taking routine. Imagine you want the
    first coordinate to take larger steps than the rest of the coordinates. This can
    be implemented like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Since `MyTakeStep.stepsize` exists basinhopping will adjust the magnitude of
    *stepsize* to optimize the search. We’ll use the same 2-D function as before
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s do an example using a custom callback function which prints the value
    of every minimum found
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We’ll run it for only 10 basinhopping steps this time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The minimum at -1.0109 is actually the global minimum, found already on the
    8th iteration.
  prefs: []
  type: TYPE_NORMAL
