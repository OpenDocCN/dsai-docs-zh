# 扩展 pandas

> 原文：[`pandas.pydata.org/docs/development/extending.html`](https://pandas.pydata.org/docs/development/extending.html)

虽然 pandas 提供���丰富的方法、容器和数据类型，但您的需求可能无法完全满足。pandas 提供了几种扩展 pandas 的选项。

## 注册自定义访问器

库可以使用装饰器`pandas.api.extensions.register_dataframe_accessor()`、`pandas.api.extensions.register_series_accessor()`和`pandas.api.extensions.register_index_accessor()`，向 pandas 对象添加额外的“命名空间”。所有这些都遵循类似的约定：您装饰一个类，提供要添加的属性名称。类的`__init__`方法获取被装饰的对象。例如：

```py
@pd.api.extensions.register_dataframe_accessor("geo")
class GeoAccessor:
    def __init__(self, pandas_obj):
        self._validate(pandas_obj)
        self._obj = pandas_obj

    @staticmethod
    def _validate(obj):
        # verify there is a column latitude and a column longitude
        if "latitude" not in obj.columns or "longitude" not in obj.columns:
            raise AttributeError("Must have 'latitude' and 'longitude'.")

    @property
    def center(self):
        # return the geographic center point of this DataFrame
        lat = self._obj.latitude
        lon = self._obj.longitude
        return (float(lon.mean()), float(lat.mean()))

    def plot(self):
        # plot this array's data on a map, e.g., using Cartopy
        pass 
```

现在用户可以使用`geo`命名空间访问您的方法：

```py
>>> ds = pd.DataFrame(
...     {"longitude": np.linspace(0, 10), "latitude": np.linspace(0, 20)}
... )
>>> ds.geo.center
(5.0, 10.0)
>>> ds.geo.plot()
# plots data on a map 
```

这可以是一种方便的方式来扩展 pandas 对象，而无需对其进行子类化。如果您编写了自定义访问器，请发起拉取请求将其添加到我们的[生态系统](https://pandas.pydata.org/community/ecosystem.html)页面。

我们强烈建议在访问器的`__init__`中验证数据。在我们的`GeoAccessor`中，我们验证数据是否包含预期的列，当验证失败时会引发`AttributeError`。对于`Series`访问器，如果访问器仅适用于特定的数据类型，应验证`dtype`。  ## 扩展类型

注意

`pandas.api.extensions.ExtensionDtype`和`pandas.api.extensions.ExtensionArray`的 API 在 pandas 1.5 之前是实验性的。从版本 1.5 开始，未来的更改将遵循 pandas 弃用政策。

pandas 定义了一个接口，用于实现扩展 NumPy 类型系统的数据类型和数组。pandas 本身使用扩展系统来处理一些不内置于 NumPy 中的类型（分类、周期、间隔、带时区的日期时间）。

库可以定义自定义数组和数据类型。当 pandas 遇到这些对象时，它们将被正确处理（即不会转换为对象的 ndarray）。许多方法，如`pandas.isna()`，将分派到扩展类型的实现。

如果您正在构建实现该接口的库，请在 [生态系统页面](https://pandas.pydata.org/community/ecosystem.html) 上宣传它。

接口由两个类组成。

### `ExtensionDtype`

`pandas.api.extensions.ExtensionDtype` 类似于 `numpy.dtype` 对象。它描述了数据类型。实现者负责一些独特的项目，比如名称。

特别重要的一项是 `type` 属性。这应该是您数据的标量类型的类。例如，如果您正在为 IP 地址数据编写扩展数组，则可能是 `ipaddress.IPv4Address`。

请参阅 [扩展 dtype 源代码](https://github.com/pandas-dev/pandas/blob/main/pandas/core/dtypes/base.py) 以获取接口定义。

`pandas.api.extensions.ExtensionDtype` 可以注册到 pandas 中，以允许通过字符串 dtype 名称进行创建。这允许使用注册的字符串名称实例化 `Series` 和 `.astype()`，例如，`'category'` 是 `CategoricalDtype` 的注册字符串访问器。

请参阅 [扩展 dtype dtypes](https://github.com/pandas-dev/pandas/blob/main/pandas/core/dtypes/dtypes.py) 以获取有关如何注册 dtypes 的更多信息。

### `ExtensionArray`

此类提供了所有类似数组的功能。ExtensionArrays 限制为 1 维。ExtensionArray 通过 `dtype` 属性与 ExtensionDtype 关联。

pandas 对通过其 `__new__` 或 `__init__` 创建扩展数组的方式没有限制，并且对如何存储数据也没有限制。我们要求您的数组可以转换为 NumPy 数组，即使这可能相对昂贵（就像对于 `Categorical` 一样）。

它们可以由零个、一个或多个 NumPy 数组支持。例如，`pandas.Categorical` 是由两个数组支持的扩展数组，一个用于代码，一个用于类别。IPv6 地址数组可以由具有两个字段的 NumPy 结构化数组支持，一个用于低 64 位，一个用于高 64 位。或者它们可以由其他某种存储类型支持，比如 Python 列表。

请参阅 [扩展数组源代码](https://github.com/pandas-dev/pandas/blob/main/pandas/core/arrays/base.py) 以获取接口定义。文档字符串和注释包含有关正确实现接口的指导。

### `ExtensionArray` 运算符支持

默认情况下，类`ExtensionArray`没有定义任何运算符。提供 ExtensionArray 运算符支持的两种方法：

1.  在你的`ExtensionArray`子类上定义每个运算符。

1.  使用一个依赖于 ExtensionArray 的基础元素（标量）上已经定义的运算符的 pandas 中的运算符实现。

注意

无论采用哪种方法，如果希望在与 NumPy 数组进行二元运算时调用你的实现，可能需要设置`__array_priority__`。

对于第一种方法，你需要定义所选运算符，例如，`__add__`，`__le__`等，你希望你的`ExtensionArray`子类支持。

第二种方法假设`ExtensionArray`的基础元素（即标量类型）已经定义了各自的运算符。换句话说，如果你的名为`MyExtensionArray`的`ExtensionArray`被实现为每个元素都是`MyExtensionElement`类的实例，那么如果为`MyExtensionElement`定义了运算符，第二种方法将自动为`MyExtensionArray`定义运算符。

一个混合类，`ExtensionScalarOpsMixin`支持这第二种方法。如果开发一个`ExtensionArray`子类，例如`MyExtensionArray`，只需将`ExtensionScalarOpsMixin`作为`MyExtensionArray`的父类之一，并调用方法`_add_arithmetic_ops()`和/或`_add_comparison_ops()`将运算符连接到你的`MyExtensionArray`类中，如下所示：

```py
from pandas.api.extensions import ExtensionArray, ExtensionScalarOpsMixin

class MyExtensionArray(ExtensionArray, ExtensionScalarOpsMixin):
    pass

MyExtensionArray._add_arithmetic_ops()
MyExtensionArray._add_comparison_ops() 
```

注意

由于`pandas`会自动逐个元素调用底层运算符，这可能不如直接在`ExtensionArray`上实现相关运算符的性能好。

对于算术运算，此实现将尝试使用元素级操作的结果重建一个新的`ExtensionArray`。是否成功取决于操作是否返回对`ExtensionArray`有效的结果。如果无法重建`ExtensionArray`，则返回包含返回标量的 ndarray。

为了方便实现和与 pandas 和 NumPy ndarray 之间的操作一致性，我们建议*不*在你的二元运算中处理 Series 和 Indexes。相反，你应该检测这些情况并返回`NotImplemented`。当 pandas 遇到像`op(Series, ExtensionArray)`这样的操作时，pandas 会

1.  从`Series`中解包数组（`Series.array`）

1.  调用`result = op(values, ExtensionArray)`

1.  将结果重新封装在`Series`中  ### NumPy 通用函数

`Series`实现了`__array_ufunc__`。作为实现的一部分，pandas 从 `Series`中拆箱`ExtensionArray`，应用 ufunc，并在必要时重新装箱。

如果适用，强烈建议您在扩展数组中实现`__array_ufunc__`，以避免强制转换为 ndarray。参见[NumPy 文档](https://numpy.org/doc/stable/reference/generated/numpy.lib.mixins.NDArrayOperatorsMixin.html)中的示例。

作为您的实现的一部分，当在`inputs`中检测到 pandas 容器（`Series`、`DataFrame`、`Index`）时，我们要求您转交给 pandas。如果有任何一个存在，则应返回`NotImplemented`。pandas 将负责从容器中解包数组并重新调用 ufunc，以解包输入。

我们提供了一个测试套件，用于确保您的扩展数组满足预期的行为。要使用测试套件，您必须提供几个 pytest fixtures 并继承基本测试类。所需的 fixtures 在[pandas-dev/pandas](https://github.com/pandas-dev/pandas/blob/main/pandas/tests/extension/conftest.py)中找到。

要使用测试，必须对其进行子类化：

```py
from pandas.tests.extension import base

class TestConstructors(base.BaseConstructorsTests):
    pass 
```

在[pandas-dev/pandas](https://github.com/pandas-dev/pandas/blob/main/pandas/tests/extension/base/__init__.py)中查看所有可用测试的列表。### 与 Apache Arrow 兼容性

`ExtensionArray`可以通过实现两个方法支持转换为/从`pyarrow`数组（因此支持例如序列化到 Parquet 文件格式）：`ExtensionArray.__arrow_array__`和`ExtensionDtype.__from_arrow__`。

`ExtensionArray.__arrow_array__`确保`pyarrow`知道如何将特定的扩展数组转换为`pyarrow.Array`（即使作为 pandas DataFrame 中的列包含）：

```py
class MyExtensionArray(ExtensionArray):
    ...

    def __arrow_array__(self, type=None):
        # convert the underlying array values to a pyarrow Array
        import pyarrow

        return pyarrow.array(..., type=type) 
```

然后，`ExtensionDtype.__from_arrow__`方法控制从 pyarrow 返回到 pandas ExtensionArray 的转换。该方法仅接收一个 pyarrow `Array`或`ChunkedArray`作为参数，并且预期返回此 dtype 和传递值的适当 pandas`ExtensionArray`：

```py
class ExtensionDtype:
    ...

    def __from_arrow__(self, array: pyarrow.Array/ChunkedArray) -> ExtensionArray:
        ... 
```

在[Arrow 文档](https://arrow.apache.org/docs/python/extending_types.html)中查看更多信息。

这些方法已经为 pandas 中包含的可空整数和字符串扩展 dtype 实现，并确保与 pyarrow 和 Parquet 文件格式的往返。## 子类化 pandas 数据结构

警告

在考虑子类化 `pandas` 数据结构之前，有一些更简单的替代方案。

1.  使用 pipe 进行可扩展的方法链。

1.  使用*组合*。参见[这里](https://en.wikipedia.org/wiki/Composition_over_inheritance)。

1.  通过注册访问器进行扩展

1.  通过扩展类型扩展

本节描述了如何对`pandas`数据结构进行子类化以满足更具体的需求。有两点需要注意：

1.  覆盖构造函数属性。

1.  定义原始属性

注意

你可以在[geopandas](https://github.com/geopandas/geopandas)项目中找到一个很好的例子。

### 覆盖构造函数属性

每个数据结构都有几个*构造函数属性*，用于返回操作的结果作为一个新的数据结构。通过覆盖这些属性，你可以通过`pandas`数据操作保留子类。

子类上可以定义 3 种可能的构造函数属性：

+   `DataFrame/Series._constructor`：当一个操作结果与原始数据具有相同的维度时使用。

+   `DataFrame._constructor_sliced`：当一个`DataFrame`（子类）操作结果应该是一个`Series`（子类）时使用。

+   `Series._constructor_expanddim`：当一个`Series`（子类）操作结果应该是一个`DataFrame`（子类）时使用，例如`Series.to_frame()`。

下面的示例显示了如何定义`SubclassedSeries`和`SubclassedDataFrame`覆盖构造函数属性。

```py
class SubclassedSeries(pd.Series):
    @property
    def _constructor(self):
        return SubclassedSeries

    @property
    def _constructor_expanddim(self):
        return SubclassedDataFrame

class SubclassedDataFrame(pd.DataFrame):
    @property
    def _constructor(self):
        return SubclassedDataFrame

    @property
    def _constructor_sliced(self):
        return SubclassedSeries 
```

```py
>>> s = SubclassedSeries([1, 2, 3])
>>> type(s)
<class '__main__.SubclassedSeries'>

>>> to_framed = s.to_frame()
>>> type(to_framed)
<class '__main__.SubclassedDataFrame'>

>>> df = SubclassedDataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
>>> df
 A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

>>> type(df)
<class '__main__.SubclassedDataFrame'>

>>> sliced1 = df[["A", "B"]]
>>> sliced1
 A  B
0  1  4
1  2  5
2  3  6

>>> type(sliced1)
<class '__main__.SubclassedDataFrame'>

>>> sliced2 = df["A"]
>>> sliced2
0    1
1    2
2    3
Name: A, dtype: int64

>>> type(sliced2)
<class '__main__.SubclassedSeries'> 
```

### 定义原始属性

要让原始数据结构具有额外的属性，你应该让`pandas`知道添加了哪些属性。`pandas`将未知属性映射到数据名称，覆盖`__getattribute__`。定义原始属性可以通过以下两种方式之一完成：

1.  为临时属性定义`_internal_names`和`_internal_names_set`，这些属性不会传递给操作结果。

1.  为普通属性定义`_metadata`，这些属性将传递给操作结果。

下面是一个示例，定义了两个原始属性，“internal_cache”作为临时属性，以及“added_property”作为普通属性

```py
class SubclassedDataFrame2(pd.DataFrame):

    # temporary properties
    _internal_names = pd.DataFrame._internal_names + ["internal_cache"]
    _internal_names_set = set(_internal_names)

    # normal properties
    _metadata = ["added_property"]

    @property
    def _constructor(self):
        return SubclassedDataFrame2 
```

```py
>>> df = SubclassedDataFrame2({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
>>> df
 A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

>>> df.internal_cache = "cached"
>>> df.added_property = "property"

>>> df.internal_cache
cached
>>> df.added_property
property

# properties defined in _internal_names is reset after manipulation
>>> df[["A", "B"]].internal_cache
AttributeError: 'SubclassedDataFrame2' object has no attribute 'internal_cache'

# properties defined in _metadata are retained
>>> df[["A", "B"]].added_property
property 
```## 绘图后端

pandas 可以通过第三方绘图后端进行扩展。主要思想是让用户选择一个基于 Matplotlib 提供的绘图后端之外的绘图后端。例如：

```py
>>> pd.set_option("plotting.backend", "backend.module")
>>> pd.Series([1, 2, 3]).plot() 
```

这将更或多或少等同于：

```py
>>> import backend.module
>>> backend.module.plot(pd.Series([1, 2, 3])) 
```

后端模块可以使用其他可视化工具（Bokeh、Altair 等）来生成图表。

实现绘图后端的库应该使用[入口点](https://setuptools.pypa.io/en/latest/userguide/entry_point.html)来使其后端对 pandas 可发现。关键是`"pandas_plotting_backends"`。例如，pandas 将默认的“matplotlib”后端注册如下。

```py
# in setup.py
setup(  # noqa: F821
    ...,
    entry_points={
        "pandas_plotting_backends": [
            "matplotlib = pandas:plotting._matplotlib",
        ],
    },
) 
```

如何实现第三方绘图后端的更多信息，请参见[pandas-dev/pandas](https://github.com/pandas-dev/pandas/blob/main/pandas/plotting/__init__.py#L1)。## 与第三方类型的算术

为了控制自定义类型与 pandas 类型之间的算术操作方式，实现`__pandas_priority__`。类似于 numpy 的`__array_priority__`语义，`DataFrame`、`Series`和`Index`对象上的算术方法将委托给`other`，如果它具有较高值的`__pandas_priority__`属性。

默认情况下，pandas 对象尝试与其他对象进行操作，即使它们不是 pandas 已知的类型：

```py
>>> pd.Series([1, 2]) + [10, 20]
0    11
1    22
dtype: int64 
```

在上面的例子中，如果`[10, 20]`是可以理解为列表的自定义类型，pandas 对象仍然会以相同的方式与其进行操作。

在某些情况下，将操作委托给另一种类型是有用的。例如，考虑我实现了一个自定义列表对象，并且我希望将我的自定义列表与 pandas `Series` 相加的结果是我的列表的一个实例，而不是前面示例中所见的 `Series`。通过定义我自定义列表的`__pandas_priority__`属性，并将其设置为较高的值，比我想要与之进行操作的 pandas 对象的优先级更高，现在可以实现这一点。

`DataFrame`、`Series`和`Index`的`__pandas_priority__`分别为`4000`、`3000`和`2000`。基本的`ExtensionArray.__pandas_priority__`为`1000`。

```py
class CustomList(list):
    __pandas_priority__ = 5000

    def __radd__(self, other):
        # return `self` and not the addition for simplicity
        return self

custom = CustomList()
series = pd.Series([1, 2, 3])

# Series refuses to add custom, since it's an unknown type with higher priority
assert series.__add__(custom) is NotImplemented

# This will cause the custom class `__radd__` being used instead
assert series + custom is custom 
```  ## 注册自定义访问器

库可以使用装饰器`pandas.api.extensions.register_dataframe_accessor()`、`pandas.api.extensions.register_series_accessor()`和`pandas.api.extensions.register_index_accessor()`来为 pandas 对象添加额外的“命名空间”。所有这些都遵循类似的约定：您装饰一个类，提供要添加的属性名称。类的`__init__`方法获取被装饰的对象。例如：

```py
@pd.api.extensions.register_dataframe_accessor("geo")
class GeoAccessor:
    def __init__(self, pandas_obj):
        self._validate(pandas_obj)
        self._obj = pandas_obj

    @staticmethod
    def _validate(obj):
        # verify there is a column latitude and a column longitude
        if "latitude" not in obj.columns or "longitude" not in obj.columns:
            raise AttributeError("Must have 'latitude' and 'longitude'.")

    @property
    def center(self):
        # return the geographic center point of this DataFrame
        lat = self._obj.latitude
        lon = self._obj.longitude
        return (float(lon.mean()), float(lat.mean()))

    def plot(self):
        # plot this array's data on a map, e.g., using Cartopy
        pass 
```

现在用户可以使用`geo`命名空间访问您的方法：

```py
>>> ds = pd.DataFrame(
...     {"longitude": np.linspace(0, 10), "latitude": np.linspace(0, 20)}
... )
>>> ds.geo.center
(5.0, 10.0)
>>> ds.geo.plot()
# plots data on a map 
```

这可以是一种方便的方法，用于扩展 pandas 对象而不是将它们子类化。如果您编写了一个自定义访问器，请提交一个拉取请求将其添加到我们的 [生态系统](https://pandas.pydata.org/community/ecosystem.html) 页面。

我们强烈建议在访问器的 `__init__` 中验证数据。在我们的 `GeoAccessor` 中，我们验证数据包含预期的列，当验证失败时引发 `AttributeError`。对于 `Series` 访问器，如果访问器仅适用于某些 dtype，则应验证 `dtype`。

## 扩展类型

注意

`pandas.api.extensions.ExtensionDtype` 和 `pandas.api.extensions.ExtensionArray` API 在 pandas 1.5 之前是实验性的。从 1.5 版本开始，未来的更改将遵循 pandas 弃用策略。

pandas 定义了一种接口，用于实现扩展 NumPy 的类型系统的数据类型和数组。pandas 本身使用扩展系统来处理一些不内置于 NumPy 中的类型（分类、周期、区间、带时区的日期时间）。

库可以定义自定义数组和数据类型。当 pandas 遇到这些对象时，它们将被正确处理（即不会转换为对象的 ndarray）。许多方法，如 `pandas.isna()`，将分派到扩展类型的实现。

如果您正在构建一个实现该接口的库，请在 [生态系统页面](https://pandas.pydata.org/community/ecosystem.html) 上宣传它。

接口由两个类组成。

### `ExtensionDtype`

一个 `pandas.api.extensions.ExtensionDtype` 类似于一个 `numpy.dtype` 对象。它描述了数据类型。实现者负责一些唯一的项目，如名称。

特别重要的一项是 `type` 属性。这应该是您数据的标量类型的类。例如，如果您正在为 IP 地址数据编写扩展数组，则可能是 `ipaddress.IPv4Address`。

有关接口定义，请参阅 [扩展 dtype 源](https://github.com/pandas-dev/pandas/blob/main/pandas/core/dtypes/base.py)。

`pandas.api.extensions.ExtensionDtype` 可以注册到 pandas 中，以允许通过字符串 dtype 名称进行创建。这允许使用注册的字符串名称，例如`'category'`是`CategoricalDtype`的注册字符串访问器，来实例化`Series`和`.astype()`。

查看[扩展 dtype dtypes](https://github.com/pandas-dev/pandas/blob/main/pandas/core/dtypes/dtypes.py)以获取有关如何注册 dtypes 的更多信息。

### `ExtensionArray`

此类提供所有类似数组的功能。ExtensionArrays 限制为 1 维。通过`dtype`属性，ExtensionArray 与 ExtensionDtype 相关联。

pandas 对通过其`__new__`或`__init__`创建扩展数组没有任何限制，并且不限制您存储数据的方式。我们要求您的数组可以转换为 NumPy 数组，即使这可能相对昂贵（就像`Categorical`一样）。

它们可以由零个、一个或多个 NumPy 数组支持。例如，`pandas.Categorical`是由两个数组支持的扩展数组，一个用于代码，一个用于类别。一个 IPv6 地址数组可以由一个具有两个字段的 NumPy 结构化数组支持，一个用于低 64 位，一个用于高 64 位。或者它们可以由其他存储类型支持，比如 Python 列表。

查看[扩展数组源代码](https://github.com/pandas-dev/pandas/blob/main/pandas/core/arrays/base.py)以获取接口定义。文档字符串和注释包含了正确实现接口的指导。

### `ExtensionArray` 操作符支持

默认情况下，类`ExtensionArray`没有定义任何操作符。提供 ExtensionArray 操作符支持有两种方法：

1.  在您的`ExtensionArray`子类上定义每个操作符。

1.  使用 pandas 中依赖于底层元素（标量）已定义的操作符的操作符实现。

注意

无论采取哪种方法，如果希望在与 NumPy 数组进行二进制操作时调用您的实现，可能需要设置`__array_priority__`。

对于第一种方法，您需要定义所选操作符，例如`__add__`，`__le__`等，以便您的`ExtensionArray`子类支持。

第二种方法假设`ExtensionArray`的底层元素（即标量类型）已经定义了各个运算符。换句话说，如果你的`ExtensionArray`命名为`MyExtensionArray`，并且每个元素都是`MyExtensionElement`类的一个实例，那么如果为`MyExtensionElement`定义了运算符，第二种方法将自动为`MyExtensionArray`定义运算符。

一个混合类，`ExtensionScalarOpsMixin`支持这第二种方法。如果开发一个`ExtensionArray`子类，例如`MyExtensionArray`，只需将`ExtensionScalarOpsMixin`包含为`MyExtensionArray`的父类，并调用方法`_add_arithmetic_ops()`和/或`_add_comparison_ops()`将运算符挂接到你的`MyExtensionArray`类中，如下所示：

```py
from pandas.api.extensions import ExtensionArray, ExtensionScalarOpsMixin

class MyExtensionArray(ExtensionArray, ExtensionScalarOpsMixin):
    pass

MyExtensionArray._add_arithmetic_ops()
MyExtensionArray._add_comparison_ops() 
```

注意

由于`pandas`自动逐个调用每个元素上的底层运算符，这可能不如直接在`ExtensionArray`上实现相关运算符的版本性能好。

对于算术运算，这个实现将尝试用逐元素操作的结果重构一个新的`ExtensionArray`。是否成功取决于操作是否返回了对`ExtensionArray`有效的结果。如果无法重构`ExtensionArray`，则返回一个包含返回标量的 ndarray。

为了便于实现并与 pandas 和 NumPy ndarrays 之间的操作保持一致，我们建议*不要*在二进制操作中处理 Series 和 Indexes。相反，你应该检测这些情况并返回`NotImplemented`。当 pandas 遇到像`op(Series, ExtensionArray)`这样的操作时，pandas 将

1.  从`Series`中解包数组（`Series.array`）

1.  调用`result = op(values, ExtensionArray)`

1.  在`Series`中重新封装结果  ### NumPy 通用函数

`Series`实现了`__array_ufunc__`。作为实现的一部分，pandas 从`Series`中解包`ExtensionArray`，应用 ufunc，并在必要时重新封装它。

如果适用，我们强烈建议你在你的扩展数组中实现`__array_ufunc__`，以避免强制转换为 ndarray。请参阅[NumPy 文档](https://numpy.org/doc/stable/reference/generated/numpy.lib.mixins.NDArrayOperatorsMixin.html)以获取示例。

作为您实现的一部分，当检测到 pandas 容器（`Series`、`DataFrame`、`Index`）时，我们要求您将其推迟到 pandas。如果其中任何一个存在，则应返回`NotImplemented`。pandas 将负责从容器中解包数组并重新调用 ufunc 以获取未包装的输入。  ### 测试扩展数组

我们提供了一个测试套件，用于确保您的扩展数组满足预期的行为。要使用测试套件，必须提供几个 pytest fixtures 并继承基础测试类。所需的固定装置在[pandas-dev/pandas](https://github.com/pandas-dev/pandas/blob/main/pandas/tests/extension/conftest.py)中找到。

要使用测试，需要对其进行子类化：

```py
from pandas.tests.extension import base

class TestConstructors(base.BaseConstructorsTests):
    pass 
```

参见[pandas-dev/pandas](https://github.com/pandas-dev/pandas/blob/main/pandas/tests/extension/base/__init__.py)以获取所有可用测试的列表。  ### 与 Apache Arrow 的兼容性

通过实现两种方法，`ExtensionArray`可以支持与`pyarrow`数组的转换（因此支持例如序列化为 Parquet 文件格式）：`ExtensionArray.__arrow_array__`和`ExtensionDtype.__from_arrow__`。

`ExtensionArray.__arrow_array__`确保`pyarrow`知道如何将特定扩展数组转换为`pyarrow.Array`（即使作为 pandas DataFrame 中的列包含）：

```py
class MyExtensionArray(ExtensionArray):
    ...

    def __arrow_array__(self, type=None):
        # convert the underlying array values to a pyarrow Array
        import pyarrow

        return pyarrow.array(..., type=type) 
```

`ExtensionDtype.__from_arrow__`方法然后控制了从 pyarrow 回到 pandas ExtensionArray 的转换。此方法仅接收一个 pyarrow `Array`或`ChunkedArray`作为参数，并预期返回此 dtype 和传递值的适当 pandas `ExtensionArray`：

```py
class ExtensionDtype:
    ...

    def __from_arrow__(self, array: pyarrow.Array/ChunkedArray) -> ExtensionArray:
        ... 
```

查看更多内容请参阅[Arrow 文档](https://arrow.apache.org/docs/python/extending_types.html)。

这些方法已经为包含在 pandas 中的可空整数和字符串扩展 dtype 实现，并确保与 pyarrow 和 Parquet 文件格式的往返。

### `ExtensionDtype`

`pandas.api.extensions.ExtensionDtype`类似于`numpy.dtype`对象。它描述了数据类型。实现者需要负责一些独特的项目，如名称。

特别重要的一项是`type`属性。这应该是您的数据的标量类型的类。例如，如果您正在为 IP 地址数据编写扩展数组，则可能是`ipaddress.IPv4Address`。

请参阅[扩展 dtype 源](https://github.com/pandas-dev/pandas/blob/main/pandas/core/dtypes/base.py)以获取接口定义。

`pandas.api.extensions.ExtensionDtype` 可以注册到 pandas 中，以允许通过字符串 dtype 名称进行创建。这允许使用注册的字符串名称实例化 `Series` 和 `.astype()`，例如 `'category'` 是 `CategoricalDtype` 的注册字符串访问器。

查看 [扩展 dtype dtypes](https://github.com/pandas-dev/pandas/blob/main/pandas/core/dtypes/dtypes.py) 以获取有关如何注册 dtypes 的更多信息。

### `ExtensionArray`

该类提供了所有类似数组的功能。ExtensionArrays 限制为 1 维。通过 `dtype` 属性，ExtensionArray 与 ExtensionDtype 相关联。

pandas 对通过其 `__new__` 或 `__init__` 创建扩展数组没有任何限制，并且不对数据存储方式施加任何限制。我们要求您的数组可以转换为 NumPy 数组，即使这可能相对昂贵（比如对于 `Categorical`）。

它们可以由零个、一个或多个 NumPy 数组支持。例如，`pandas.Categorical` 是由两个数组支持的扩展数组，一个用于代码，一个用于类别。一个 IPv6 地址数组可以由一个具有两个字段的 NumPy 结构化数组支持，一个用于低 64 位，一个用于高 64 位。或者它们可以由其他存储类型支持，比如 Python 列表。

查看 [扩展数组源代码](https://github.com/pandas-dev/pandas/blob/main/pandas/core/arrays/base.py) 以获取接口定义。文档字符串和注释包含了正确实现接口的指导。

### `ExtensionArray` 运算符支持

默认情况下，对于类 `ExtensionArray` 没有定义运算符。提供您的 ExtensionArray 运算符支持有两种方法：

1.  在您的 `ExtensionArray` 子类上定义每个运算符。

1.  使用 pandas 中依赖于底层元素（标量）已定义的运算符的运算符实现。

注意

无论采用哪种方法，如果希望在与 NumPy 数组进行二元操作时调用您的实现，可能需要设置 `__array_priority__`。

对于第一种方法，您可以定义所选运算符，例如 `__add__`，`__le__` 等，您希望您的 `ExtensionArray` 子类支持。

第二种方法假定`ExtensionArray`的基础元素（即标量类型）已经定义了各个运算符。换句话说，如果你的`ExtensionArray`名为`MyExtensionArray`，并且实现为每个元素都是`MyExtensionElement`类的实例，那么如果为`MyExtensionElement`定义了运算符，第二种方法将自动为`MyExtensionArray`定义运算符。

混合类`ExtensionScalarOpsMixin`支持这种第二种方法。例如，如果开发一个`ExtensionArray`子类，比如`MyExtensionArray`，只需将`ExtensionScalarOpsMixin`包含为`MyExtensionArray`的父类，并调用方法`_add_arithmetic_ops()`和/或`_add_comparison_ops()`将运算符挂接到你的`MyExtensionArray`类中，如下所示：

```py
from pandas.api.extensions import ExtensionArray, ExtensionScalarOpsMixin

class MyExtensionArray(ExtensionArray, ExtensionScalarOpsMixin):
    pass

MyExtensionArray._add_arithmetic_ops()
MyExtensionArray._add_comparison_ops() 
```

注意

由于`pandas`自动逐个调用每个元素上的基础运算符，这可能不如直接在`ExtensionArray`上实现相关运算符的版本性能好。

对于算术运算，此实现将尝试使用元素级操作的结果重构一个新的`ExtensionArray`。是否成功取决于操作是否返回适用于`ExtensionArray`的结果。如果无法重建`ExtensionArray`，则返回包含返回标量的 ndarray。

为了方便实现和与 pandas 和 NumPy ndarray 之间的操作一致，我们建议*不*在你的二进制运算中处理 Series 和 Indexes。相反，你应该检测这些情况并返回`NotImplemented`。当 pandas 遇到类似`op(Series, ExtensionArray)`的操作时，pandas 将

1.  从`Series`（`Series.array`）中解封数组。

1.  调用`result = op(values, ExtensionArray)`

1.  在`Series`中重新装箱结果。

### NumPy 通用函数

`Series`实现了`__array_ufunc__`。作为实现的一部分，pandas 从`Series`中解封`ExtensionArray`，应用 ufunc，并在必要时重新装箱。

如果适用，我们强烈建议你在扩展数组中实现`__array_ufunc__`以避免强制转换为 ndarray。参见[NumPy 文档](https://numpy.org/doc/stable/reference/generated/numpy.lib.mixins.NDArrayOperatorsMixin.html)中的示例。

作为你实现的一部分，我们要求当在`inputs`中检测到一个 pandas 容器（`Series`、`DataFrame`、`Index`）时，你应该委托给 pandas。如果其中任何一个存在，你应该返回`NotImplemented`。pandas 将负责从容器中解封数组并重新调用 ufunc。

### 测试扩展数组

我们为确保您的扩展数组满足预期行为提供了一个测试套件。要使用测试套件，您必须提供几个 pytest 固定装置并继承基本测试类。所需的固定装置可以在[pandas-dev/pandas](https://github.com/pandas-dev/pandas/blob/main/pandas/tests/extension/conftest.py)中找到。

要使用测试，必须将其子类化：

```py
from pandas.tests.extension import base

class TestConstructors(base.BaseConstructorsTests):
    pass 
```

查看所有可用测试的列表，请参阅[pandas-dev/pandas](https://github.com/pandas-dev/pandas/blob/main/pandas/tests/extension/base/__init__.py)。

### 与 Apache Arrow 的兼容性

一个`ExtensionArray`可以通过实现两种方法来支持与`pyarrow`数组的转换（从而支持例如序列化为 Parquet 文件格式）：`ExtensionArray.__arrow_array__` 和 `ExtensionDtype.__from_arrow__`。

`ExtensionArray.__arrow_array__` 确保 `pyarrow` 知道如何将特定的扩展数组转换为 `pyarrow.Array`（当作为 pandas DataFrame 中的列包含时也是如此）：

```py
class MyExtensionArray(ExtensionArray):
    ...

    def __arrow_array__(self, type=None):
        # convert the underlying array values to a pyarrow Array
        import pyarrow

        return pyarrow.array(..., type=type) 
```

`ExtensionDtype.__from_arrow__` 方法然后控制从 pyarrow 到 pandas ExtensionArray 的转换。此方法接收一个 pyarrow `Array`或`ChunkedArray`作为唯一参数，并期望返回适用于此 dtype 和传递的值的适当 pandas `ExtensionArray`：

```py
class ExtensionDtype:
    ...

    def __from_arrow__(self, array: pyarrow.Array/ChunkedArray) -> ExtensionArray:
        ... 
```

在[Arrow 文档](https://arrow.apache.org/docs/python/extending_types.html)中了解更多信息。

这些方法已经针对 pandas 中包含的可空整数和字符串扩展 dtype 进行了实现，并确保与 pyarrow 和 Parquet 文件格式的往返。

## 子类化 pandas 数据结构

警告

在考虑子类化`pandas`数据结构之前，有一些更简单的替代方法。

1.  使用 pipe 进行可扩展的方法链

1.  使用*组合*。参见[此处](https://en.wikipedia.org/wiki/Composition_over_inheritance)。

1.  通过注册访问器进行扩展

1.  通过扩展类型进行扩展

本节描述如何对`pandas`数据结构进行子类化以满足更具体的需求。有两点需要注意：

1.  覆盖构造函数属性。

1.  定义原始属性

注意

你可以在[geopandas](https://github.com/geopandas/geopandas)项目中找到一个很好的例子。

### 覆盖构造函数属性

每个数据结构都有几个*构造函数属性*，用于返回作为操作结果的新数据结构。通过覆盖这些属性，您可以通过`pandas`数据操作保留子类。

有 3 个可能需要在子类上定义的构造函数属性：

+   `DataFrame/Series._constructor`: 用于当操作结果与原始数据具有相同维度时。

+   `DataFrame._constructor_sliced`: 用于当`DataFrame`（子类）操作的结果应该是一个`Series`（子类）时。

+   `Series._constructor_expanddim`: 用于当`Series`（子类）操作的结果应该是一个`DataFrame`（子类）时，例如`Series.to_frame()`。

以下示例展示了如何定义`SubclassedSeries`和`SubclassedDataFrame`，覆盖构造函数属性。

```py
class SubclassedSeries(pd.Series):
    @property
    def _constructor(self):
        return SubclassedSeries

    @property
    def _constructor_expanddim(self):
        return SubclassedDataFrame

class SubclassedDataFrame(pd.DataFrame):
    @property
    def _constructor(self):
        return SubclassedDataFrame

    @property
    def _constructor_sliced(self):
        return SubclassedSeries 
```

```py
>>> s = SubclassedSeries([1, 2, 3])
>>> type(s)
<class '__main__.SubclassedSeries'>

>>> to_framed = s.to_frame()
>>> type(to_framed)
<class '__main__.SubclassedDataFrame'>

>>> df = SubclassedDataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
>>> df
 A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

>>> type(df)
<class '__main__.SubclassedDataFrame'>

>>> sliced1 = df[["A", "B"]]
>>> sliced1
 A  B
0  1  4
1  2  5
2  3  6

>>> type(sliced1)
<class '__main__.SubclassedDataFrame'>

>>> sliced2 = df["A"]
>>> sliced2
0    1
1    2
2    3
Name: A, dtype: int64

>>> type(sliced2)
<class '__main__.SubclassedSeries'> 
```

### 定义原始属性

要让原始数据结构具有额外属性，你应该让`pandas`知道添加了哪些属性。`pandas`将未知属性映射到数据名称，覆盖`__getattribute__`。定义原始属性可以通过以下两种方式之一完成：

1.  为临时属性定义`_internal_names`和`_internal_names_set`，这些属性**不会**传递给操作结果。

1.  为将传递给操作结果的普通属性定义`_metadata`。

以下是一个示例，定义了两个原始属性，“internal_cache”作为临时属性，“added_property”作为普通属性

```py
class SubclassedDataFrame2(pd.DataFrame):

    # temporary properties
    _internal_names = pd.DataFrame._internal_names + ["internal_cache"]
    _internal_names_set = set(_internal_names)

    # normal properties
    _metadata = ["added_property"]

    @property
    def _constructor(self):
        return SubclassedDataFrame2 
```

```py
>>> df = SubclassedDataFrame2({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
>>> df
 A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

>>> df.internal_cache = "cached"
>>> df.added_property = "property"

>>> df.internal_cache
cached
>>> df.added_property
property

# properties defined in _internal_names is reset after manipulation
>>> df[["A", "B"]].internal_cache
AttributeError: 'SubclassedDataFrame2' object has no attribute 'internal_cache'

# properties defined in _metadata are retained
>>> df[["A", "B"]].added_property
property 
```

### 覆盖构造函数属性

每个数据结构都有几个*构造函数属性*，用于返回操作结果的新数据结构。通过覆盖这些属性，你可以通过`pandas`数据操作保留子类。

子类上可以定义 3 种可能的构造函数属性：

+   `DataFrame/Series._constructor`：当操作结果与原始数据具有相同维度时使用。

+   `DataFrame._constructor_sliced`：当`DataFrame`（子类）操作结果应为`Series`（子类）时使用。

+   `Series._constructor_expanddim`：当`Series`（子类）操作结果应为`DataFrame`（子类），例如`Series.to_frame()`时使用。

以下示例展示了如何定义`SubclassedSeries`和`SubclassedDataFrame`，覆盖构造函数属性。

```py
class SubclassedSeries(pd.Series):
    @property
    def _constructor(self):
        return SubclassedSeries

    @property
    def _constructor_expanddim(self):
        return SubclassedDataFrame

class SubclassedDataFrame(pd.DataFrame):
    @property
    def _constructor(self):
        return SubclassedDataFrame

    @property
    def _constructor_sliced(self):
        return SubclassedSeries 
```

```py
>>> s = SubclassedSeries([1, 2, 3])
>>> type(s)
<class '__main__.SubclassedSeries'>

>>> to_framed = s.to_frame()
>>> type(to_framed)
<class '__main__.SubclassedDataFrame'>

>>> df = SubclassedDataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
>>> df
 A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

>>> type(df)
<class '__main__.SubclassedDataFrame'>

>>> sliced1 = df[["A", "B"]]
>>> sliced1
 A  B
0  1  4
1  2  5
2  3  6

>>> type(sliced1)
<class '__main__.SubclassedDataFrame'>

>>> sliced2 = df["A"]
>>> sliced2
0    1
1    2
2    3
Name: A, dtype: int64

>>> type(sliced2)
<class '__main__.SubclassedSeries'> 
```

### 定义原始属性

要让原始数据结构具有额外属性，你应该让`pandas`知道添加了哪些属性。`pandas`将未知属性映射到数据名称，覆盖`__getattribute__`。定义原始属性可以通过以下两种方式之一完成：

1.  为临时属性定义`_internal_names`和`_internal_names_set`，这些属性**不会**传递给操作结果。

1.  为将传递给操作结果的普通属性定义`_metadata`。

以下是一个示例，定义了两个原始属性，“internal_cache”作为临时属性，“added_property”作为普通属性

```py
class SubclassedDataFrame2(pd.DataFrame):

    # temporary properties
    _internal_names = pd.DataFrame._internal_names + ["internal_cache"]
    _internal_names_set = set(_internal_names)

    # normal properties
    _metadata = ["added_property"]

    @property
    def _constructor(self):
        return SubclassedDataFrame2 
```

```py
>>> df = SubclassedDataFrame2({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})
>>> df
 A  B  C
0  1  4  7
1  2  5  8
2  3  6  9

>>> df.internal_cache = "cached"
>>> df.added_property = "property"

>>> df.internal_cache
cached
>>> df.added_property
property

# properties defined in _internal_names is reset after manipulation
>>> df[["A", "B"]].internal_cache
AttributeError: 'SubclassedDataFrame2' object has no attribute 'internal_cache'

# properties defined in _metadata are retained
>>> df[["A", "B"]].added_property
property 
```

## 绘图后端

pandas 可以通过第三方绘图后端进行扩展。主要思想是让用户选择一个基于 Matplotlib 提供的绘图后端之外的绘图后端。例如：

```py
>>> pd.set_option("plotting.backend", "backend.module")
>>> pd.Series([1, 2, 3]).plot() 
```

这基本上等同于：

```py
>>> import backend.module
>>> backend.module.plot(pd.Series([1, 2, 3])) 
```

然后，后端模块可以使用其他可视化工具（Bokeh、Altair 等）生成图表。

实现绘图后端的库应该使用[入口点](https://setuptools.pypa.io/en/latest/userguide/entry_point.html)来使其后端可被 pandas 发现。关键是`"pandas_plotting_backends"`。例如，pandas 将默认的“matplotlib”后端注册如下。

```py
# in setup.py
setup(  # noqa: F821
    ...,
    entry_points={
        "pandas_plotting_backends": [
            "matplotlib = pandas:plotting._matplotlib",
        ],
    },
) 
```

关于如何实现第三方绘图后端的更多信息，请参阅 [pandas-dev/pandas](https://github.com/pandas-dev/pandas/blob/main/pandas/plotting/__init__.py#L1)。

## 使用第三方类型进行算术运算

为了控制自定义类型与 pandas 类型之间的算术运算方式，请实现 `__pandas_priority__`。类似于 numpy 的 `__array_priority__` 语义，`DataFrame`、`Series` 和 `Index` 对象上的算术方法将委托给 `other`，如果它具有一个属性 `__pandas_priority__`，其值比较高。

默认情况下，pandas 对象尝试与其他对象进行操作，即使它们不是 pandas 所知的类型：

```py
>>> pd.Series([1, 2]) + [10, 20]
0    11
1    22
dtype: int64 
```

在上面的示例中，如果 `[10, 20]` 是一个可以被理解为列表的自定义类型，pandas 对象仍然会以相同的方式与其进行操作。

在某些情况下，将操作委托给另一种类型是有用的。例如，考虑我实现了一个自定义列表对象，我希望将我的自定义列表与 pandas `Series` 相加的结果是我的列表的一个实例，而不是前面示例中看到的 `Series`。通过定义我的自定义列表的 `__pandas_priority__` 属性，并将其设置为比我想要操作的 pandas 对象的优先级更高的值，现在可以实现这一点。

`DataFrame`、`Series` 和 `Index` 的 `__pandas_priority__` 分别为 `4000`、`3000` 和 `2000`。基础的 `ExtensionArray.__pandas_priority__` 是 `1000`。

```py
class CustomList(list):
    __pandas_priority__ = 5000

    def __radd__(self, other):
        # return `self` and not the addition for simplicity
        return self

custom = CustomList()
series = pd.Series([1, 2, 3])

# Series refuses to add custom, since it's an unknown type with higher priority
assert series.__add__(custom) is NotImplemented

# This will cause the custom class `__radd__` being used instead
assert series + custom is custom 
```
