["```py\nIn [1]: s = pd.Series([1, 2, np.nan], dtype='Int64')\n\nIn [2]: s\nOut[2]: \n0       1\n1       2\n2    <NA>\nLength: 3, dtype: Int64 \n```", "```py\n# arithmetic\nIn [3]: s + 1\nOut[3]: \n0       2\n1       3\n2    <NA>\nLength: 3, dtype: Int64\n\n# comparison\nIn [4]: s == 1\nOut[4]: \n0     True\n1    False\n2     <NA>\nLength: 3, dtype: boolean\n\n# indexing\nIn [5]: s.iloc[1:3]\nOut[5]: \n1       2\n2    <NA>\nLength: 2, dtype: Int64\n\n# operate with other dtypes\nIn [6]: s + s.iloc[1:3].astype('Int8')\nOut[6]: \n0    <NA>\n1       4\n2    <NA>\nLength: 3, dtype: Int64\n\n# coerce when needed\nIn [7]: s + 0.01\nOut[7]: \n0    1.01\n1    2.01\n2    <NA>\nLength: 3, dtype: Float64 \n```", "```py\nIn [8]: df = pd.DataFrame({'A': s, 'B': [1, 1, 3], 'C': list('aab')})\n\nIn [9]: df\nOut[9]: \n A  B  C\n0     1  1  a\n1     2  1  a\n2  <NA>  3  b\n\n[3 rows x 3 columns]\n\nIn [10]: df.dtypes\nOut[10]: \nA     Int64\nB     int64\nC    object\nLength: 3, dtype: object \n```", "```py\nIn [11]: pd.concat([df[['A']], df[['B', 'C']]], axis=1).dtypes\nOut[11]: \nA     Int64\nB     int64\nC    object\nLength: 3, dtype: object\n\nIn [12]: df['A'].astype(float)\nOut[12]: \n0    1.0\n1    2.0\n2    NaN\nName: A, Length: 3, dtype: float64 \n```", "```py\nIn [13]: df.sum()\nOut[13]: \nA      3\nB      5\nC    aab\nLength: 3, dtype: object\n\nIn [14]: df.groupby('B').A.sum()\nOut[14]: \nB\n1    3\n3    0\nName: A, Length: 2, dtype: Int64 \n```", "```py\nIn [15]: idx = pd.period_range('2000', periods=4)\n\nIn [16]: idx.array\nOut[16]: \n<PeriodArray>\n['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04']\nLength: 4, dtype: period[D]\n\nIn [17]: pd.Series(idx).array\nOut[17]: \n<PeriodArray>\n['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04']\nLength: 4, dtype: period[D] \n```", "```py\nIn [18]: idx.values\nOut[18]: \narray([Period('2000-01-01', 'D'), Period('2000-01-02', 'D'),\n Period('2000-01-03', 'D'), Period('2000-01-04', 'D')], dtype=object)\n\nIn [19]: id(idx.values)\nOut[19]: 140678188264656\n\nIn [20]: id(idx.values)\nOut[20]: 140678188258896 \n```", "```py\nIn [21]: idx.to_numpy()\nOut[21]: \narray([Period('2000-01-01', 'D'), Period('2000-01-02', 'D'),\n Period('2000-01-03', 'D'), Period('2000-01-04', 'D')], dtype=object)\n\nIn [22]: pd.Series(idx).to_numpy()\nOut[22]: \narray([Period('2000-01-01', 'D'), Period('2000-01-02', 'D'),\n Period('2000-01-03', 'D'), Period('2000-01-04', 'D')], dtype=object) \n```", "```py\nIn [23]: ser = pd.Series([1, 2, 3])\n\nIn [24]: ser.array\nOut[24]: \n<NumpyExtensionArray>\n[1, 2, 3]\nLength: 3, dtype: int64\n\nIn [25]: ser.to_numpy()\nOut[25]: array([1, 2, 3]) \n```", "```py\nIn [26]: pd.array([1, 2, np.nan], dtype='Int64')\nOut[26]: \n<IntegerArray>\n[1, 2, <NA>]\nLength: 3, dtype: Int64\n\nIn [27]: pd.array(['a', 'b', 'c'], dtype='category')\nOut[27]: \n['a', 'b', 'c']\nCategories (3, object): ['a', 'b', 'c'] \n```", "```py\nIn [28]: pd.array([1, 2, 3])\nOut[28]: \n<IntegerArray>\n[1, 2, 3]\nLength: 3, dtype: Int64 \n```", "```py\nIn [29]: pd.array([1, 2, np.nan])\nOut[29]: \n<IntegerArray>\n[1, 2, <NA>]\nLength: 3, dtype: Int64 \n```", "```py\nIn [30]: ser = pd.Series(pd.interval_range(0, 5))\n\nIn [31]: ser\nOut[31]: \n0    (0, 1]\n1    (1, 2]\n2    (2, 3]\n3    (3, 4]\n4    (4, 5]\nLength: 5, dtype: interval\n\nIn [32]: ser.dtype\nOut[32]: interval[int64, right] \n```", "```py\nIn [33]: pser = pd.Series(pd.period_range(\"2000\", freq=\"D\", periods=5))\n\nIn [34]: pser\nOut[34]: \n0    2000-01-01\n1    2000-01-02\n2    2000-01-03\n3    2000-01-04\n4    2000-01-05\nLength: 5, dtype: period[D]\n\nIn [35]: pser.dtype\nOut[35]: period[D] \n```", "```py\nIn [36]: ser.array\nOut[36]: \n<IntervalArray>\n[(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]]\nLength: 5, dtype: interval[int64, right]\n\nIn [37]: pser.array\nOut[37]: \n<PeriodArray>\n['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04', '2000-01-05']\nLength: 5, dtype: period[D] \n```", "```py\nIn [38]: index_left = pd.MultiIndex.from_tuples([('K0', 'X0'), ('K0', 'X1'),\n ....:                                       ('K1', 'X2')],\n ....:                                       names=['key', 'X'])\n ....: \n\nIn [39]: left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n ....:                     'B': ['B0', 'B1', 'B2']}, index=index_left)\n ....: \n\nIn [40]: index_right = pd.MultiIndex.from_tuples([('K0', 'Y0'), ('K1', 'Y1'),\n ....:                                        ('K2', 'Y2'), ('K2', 'Y3')],\n ....:                                        names=['key', 'Y'])\n ....: \n\nIn [41]: right = pd.DataFrame({'C': ['C0', 'C1', 'C2', 'C3'],\n ....:                      'D': ['D0', 'D1', 'D2', 'D3']}, index=index_right)\n ....: \n\nIn [42]: left.join(right)\nOut[42]: \n A   B   C   D\nkey X  Y \nK0  X0 Y0  A0  B0  C0  D0\n X1 Y0  A1  B1  C0  D0\nK1  X2 Y1  A2  B2  C1  D1\n\n[3 rows x 4 columns] \n```", "```py\nIn [43]: pd.merge(left.reset_index(), right.reset_index(),\n ....:         on=['key'], how='inner').set_index(['key', 'X', 'Y'])\n ....: \nOut[43]: \n A   B   C   D\nkey X  Y \nK0  X0 Y0  A0  B0  C0  D0\n X1 Y0  A1  B1  C0  D0\nK1  X2 Y1  A2  B2  C1  D1\n\n[3 rows x 4 columns] \n```", "```py\nIn [44]: from io import StringIO\n\nIn [45]: result = pd.read_html(StringIO(\"\"\"\n ....:  <table>\n ....:    <thead>\n ....:      <tr>\n ....:        <th>A</th><th>B</th><th>C</th>\n ....:      </tr>\n ....:    </thead>\n ....:    <tbody>\n ....:      <tr>\n ....:        <td colspan=\"2\">1</td><td>2</td>\n ....:      </tr>\n ....:    </tbody>\n ....:  </table>\"\"\"))\n ....: \n```", "```py\nIn [13]: result\nOut [13]:\n[   A  B   C\n 0  1  2 NaN] \n```", "```py\nIn [46]: result\nOut[46]: \n[   A  B  C\n 0  1  1  2\n\n [1 rows x 3 columns]] \n```", "```py\nIn [47]: df = pd.DataFrame({'N': [1250, 1500, 1750], 'X': [0.25, 0.35, 0.50]})\n\nIn [48]: def format_and_align(styler):\n ....:    return (styler.format({'N': '{:,}', 'X': '{:.1%}'})\n ....:                  .set_properties(**{'text-align': 'right'}))\n ....: \n\nIn [49]: df.style.pipe(format_and_align).set_caption('Summary of results.')\nOut[49]: <pandas.io.formats.style.Styler at 0x7ff231a272e0> \n```", "```py\nIn [50]: mi = pd.MultiIndex.from_product([list('AB'), list('CD'), list('EF')],\n ....:                                names=['AB', 'CD', 'EF'])\n ....: \n\nIn [51]: df = pd.DataFrame(list(range(len(mi))), index=mi, columns=['N'])\n\nIn [52]: df\nOut[52]: \n N\nAB CD EF \nA  C  E   0\n F   1\n D  E   2\n F   3\nB  C  E   4\n F   5\n D  E   6\n F   7\n\n[8 rows x 1 columns]\n\nIn [53]: df.rename_axis(index={'CD': 'New'})\nOut[53]: \n N\nAB New EF \nA  C   E   0\n F   1\n D   E   2\n F   3\nB  C   E   4\n F   5\n D   E   6\n F   7\n\n[8 rows x 1 columns] \n```", "```py\nIn [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n ...:                     \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\nIn [2]: # When passing file PATH to to_csv,\n ...: # line_terminator does not work, and csv is saved with '\\r\\n'.\n ...: # Also, this converts all '\\n's in the data to '\\r\\n'.\n ...: data.to_csv(\"test.csv\", index=False, line_terminator='\\n')\n\nIn [3]: with open(\"test.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\r\\nbc\",\"a\\r\\r\\nbc\"\\r\\n'\n\nIn [4]: # When passing file OBJECT with newline option to\n ...: # to_csv, line_terminator works.\n ...: with open(\"test2.csv\", mode='w', newline='\\n') as f:\n ...:    data.to_csv(f, index=False, line_terminator='\\n')\n\nIn [5]: with open(\"test2.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[5]: b'string_with_lf,string_with_crlf\\n\"a\\nbc\",\"a\\r\\nbc\"\\n' \n```", "```py\nIn [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n ...:                     \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\nIn [2]: data.to_csv(\"test.csv\", index=False, line_terminator='\\n')\n\nIn [3]: with open(\"test.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[3]: b'string_with_lf,string_with_crlf\\n\"a\\nbc\",\"a\\r\\nbc\"\\n' \n```", "```py\nIn [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n ...:                     \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\nIn [2]: data.to_csv(\"test.csv\", index=False)\n\nIn [3]: with open(\"test.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\nbc\",\"a\\r\\nbc\"\\r\\n' \n```", "```py\nIn [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n ...:                     \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\nIn [2]: with open(\"test2.csv\", mode='w', newline='\\n') as f:\n ...:    data.to_csv(f, index=False)\n\nIn [3]: with open(\"test2.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\nbc\",\"a\\r\\nbc\"\\r\\n' \n```", "```py\nIn [5]: data = 'a,b,c\\n1,,3\\n4,5,6'\nIn [6]: df = pd.read_csv(StringIO(data), engine='python', dtype=str, na_filter=True)\nIn [7]: df.loc[0, 'b']\nOut[7]:\n'nan' \n```", "```py\nIn [54]: data = 'a,b,c\\n1,,3\\n4,5,6'\n\nIn [55]: df = pd.read_csv(StringIO(data), engine='python', dtype=str, na_filter=True)\n\nIn [56]: df.loc[0, 'b']\nOut[56]: nan \n```", "```py\nIn [2]: pd.to_datetime(\"2015-11-18 15:30:00+05:30\")\nOut[2]: Timestamp('2015-11-18 10:00:00')\n\nIn [3]: pd.Timestamp(\"2015-11-18 15:30:00+05:30\")\nOut[3]: Timestamp('2015-11-18 15:30:00+0530', tz='pytz.FixedOffset(330)')\n\n# Different UTC offsets would automatically convert the datetimes to UTC (without a UTC timezone)\nIn [4]: pd.to_datetime([\"2015-11-18 15:30:00+05:30\", \"2015-11-18 16:30:00+06:30\"])\nOut[4]: DatetimeIndex(['2015-11-18 10:00:00', '2015-11-18 10:00:00'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [57]: pd.to_datetime(\"2015-11-18 15:30:00+05:30\")\nOut[57]: Timestamp('2015-11-18 15:30:00+0530', tz='UTC+05:30')\n\nIn [58]: pd.Timestamp(\"2015-11-18 15:30:00+05:30\")\nOut[58]: Timestamp('2015-11-18 15:30:00+0530', tz='UTC+05:30') \n```", "```py\nIn [59]: pd.to_datetime([\"2015-11-18 15:30:00+05:30\"] * 2)\nOut[59]: DatetimeIndex(['2015-11-18 15:30:00+05:30', '2015-11-18 15:30:00+05:30'], dtype='datetime64[ns, UTC+05:30]', freq=None) \n```", "```py\nIn [59]: idx = pd.to_datetime([\"2015-11-18 15:30:00+05:30\",\n \"2015-11-18 16:30:00+06:30\"])\n\nIn[60]: idx\nOut[60]: Index([2015-11-18 15:30:00+05:30, 2015-11-18 16:30:00+06:30], dtype='object')\n\nIn[61]: idx[0]\nOut[61]: Timestamp('2015-11-18 15:30:00+0530', tz='UTC+05:30')\n\nIn[62]: idx[1]\nOut[62]: Timestamp('2015-11-18 16:30:00+0630', tz='UTC+06:30') \n```", "```py\nIn [60]: pd.to_datetime([\"2015-11-18 15:30:00+05:30\",\n ....:                \"2015-11-18 16:30:00+06:30\"], utc=True)\n ....: \nOut[60]: DatetimeIndex(['2015-11-18 10:00:00+00:00', '2015-11-18 10:00:00+00:00'], dtype='datetime64[ns, UTC]', freq=None) \n```", "```py\n>>> import io\n>>> content = \"\"\"\\\n... a\n... 2000-01-01T00:00:00+05:00\n... 2000-01-01T00:00:00+06:00\"\"\"\n>>> df = pd.read_csv(io.StringIO(content), parse_dates=['a'])\n>>> df.a\n0   1999-12-31 19:00:00\n1   1999-12-31 18:00:00\nName: a, dtype: datetime64[ns] \n```", "```py\nIn[64]: import io\n\nIn[65]: content = \"\"\"\\\n ...: a\n ...: 2000-01-01T00:00:00+05:00\n ...: 2000-01-01T00:00:00+06:00\"\"\"\n\nIn[66]: df = pd.read_csv(io.StringIO(content), parse_dates=['a'])\n\nIn[67]: df.a\nOut[67]:\n0   2000-01-01 00:00:00+05:00\n1   2000-01-01 00:00:00+06:00\nName: a, Length: 2, dtype: object \n```", "```py\nIn [3]: df = pd.read_csv(\n ...:    io.StringIO(content),\n ...:    parse_dates=['a'],\n ...:    date_parser=lambda col: pd.to_datetime(col, utc=True),\n ...: )\n\nIn [4]: df.a\nOut[4]:\n0   1999-12-31 19:00:00+00:00\n1   1999-12-31 18:00:00+00:00\nName: a, dtype: datetime64[ns, UTC] \n```", "```py\nIn [2]: p = pd.Period('2017-01-01', 'D')\nIn [3]: pi = pd.PeriodIndex([p])\n\nIn [4]: pd.Series(pi).dt.end_time[0]\nOut[4]: Timestamp(2017-01-01 00:00:00)\n\nIn [5]: p.end_time\nOut[5]: Timestamp(2017-01-01 23:59:59.999999999) \n```", "```py\nIn [61]: p = pd.Period('2017-01-01', 'D')\n\nIn [62]: pi = pd.PeriodIndex([p])\n\nIn [63]: pd.Series(pi).dt.end_time[0]\nOut[63]: Timestamp('2017-01-01 23:59:59.999999999')\n\nIn [64]: p.end_time\nOut[64]: Timestamp('2017-01-01 23:59:59.999999999') \n```", "```py\nIn [65]: ser = pd.Series([pd.Timestamp('2000', tz='UTC'),\n ....:                 pd.Timestamp('2000', tz='UTC')])\n ....: \n```", "```py\nIn [3]: ser.unique()\nOut[3]: array([Timestamp('2000-01-01 00:00:00+0000', tz='UTC')], dtype=object) \n```", "```py\nIn [66]: ser.unique()\nOut[66]: \n<DatetimeArray>\n['2000-01-01 00:00:00+00:00']\nLength: 1, dtype: datetime64[ns, UTC] \n```", "```py\nIn [67]: s = pd.Series([0, 0, 1, 1, 1], dtype='Sparse[int]')\n\nIn [68]: s.sparse.density\nOut[68]: 0.6 \n```", "```py\nIn [2]: df = pd.DataFrame({\"A\": [1, 2], \"B\": ['a', 'b'], \"C\": ['a', 'a']})\n\nIn [3]: type(pd.get_dummies(df, sparse=True))\nOut[3]: pandas.core.frame.DataFrame\n\nIn [4]: type(pd.get_dummies(df[['B', 'C']], sparse=True))\nOut[4]: pandas.core.sparse.frame.SparseDataFrame \n```", "```py\nIn [69]: type(pd.get_dummies(df, sparse=True))\nOut[69]: pandas.core.frame.DataFrame\n\nIn [70]: type(pd.get_dummies(df[['B', 'C']], sparse=True))\nOut[70]: pandas.core.frame.DataFrame \n```", "```py\nIn [71]: df = pd.DataFrame({'a': [1, 2], 'b': [0.5, 0.75]}, index=['A', 'A'])\n\nIn [72]: df\nOut[72]: \n a     b\nA  1  0.50\nA  2  0.75\n\n[2 rows x 2 columns]\n\nIn [73]: df.to_dict(orient='index')\n---------------------------------------------------------------------------\nValueError  Traceback (most recent call last)\nCell In[73], line 1\n----> 1 df.to_dict(orient='index')\n\nFile ~/work/pandas/pandas/pandas/util/_decorators.py:333, in deprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper(*args, **kwargs)\n  327 if len(args) > num_allow_args:\n  328     warnings.warn(\n  329         msg.format(arguments=_format_argument_list(allow_args)),\n  330         FutureWarning,\n  331         stacklevel=find_stack_level(),\n  332     )\n--> 333 return func(*args, **kwargs)\n\nFile ~/work/pandas/pandas/pandas/core/frame.py:2178, in DataFrame.to_dict(self, orient, into, index)\n  2075  \"\"\"\n  2076 Convert the DataFrame to a dictionary.\n  2077  \n (...)\n  2174 defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n  2175 \"\"\"\n  2176 from pandas.core.methods.to_dict import to_dict\n-> 2178 return to_dict(self, orient, into=into, index=index)\n\nFile ~/work/pandas/pandas/pandas/core/methods/to_dict.py:242, in to_dict(df, orient, into, index)\n  240 elif orient == \"index\":\n  241     if not df.index.is_unique:\n--> 242         raise ValueError(\"DataFrame index must be unique for orient='index'.\")\n  243     columns = df.columns.tolist()\n  244     if are_all_object_dtype_cols:\n\nValueError: DataFrame index must be unique for orient='index'. \n```", "```py\nIn [2]: ts = pd.Timestamp('2018-06-11 18:01:14')\n\nIn [3]: ts\nOut[3]: Timestamp('2018-06-11 18:01:14')\n\nIn [4]: tic = pd.offsets.Hour(n=2, normalize=True)\n ...:\n\nIn [5]: tic\nOut[5]: <2 * Hours>\n\nIn [6]: ts + tic\nOut[6]: Timestamp('2018-06-11 00:00:00')\n\nIn [7]: ts + tic + tic + tic == ts + (tic + tic + tic)\nOut[7]: False \n```", "```py\nIn [74]: ts = pd.Timestamp('2018-06-11 18:01:14')\n\nIn [75]: tic = pd.offsets.Hour(n=2)\n\nIn [76]: ts + tic + tic + tic == ts + (tic + tic + tic)\nOut[76]: True \n```", "```py\nIn [2]: june = pd.Period('June 2018')\n\nIn [3]: april = pd.Period('April 2018')\n\nIn [4]: june - april\nOut [4]: 2 \n```", "```py\nIn [77]: june = pd.Period('June 2018')\n\nIn [78]: april = pd.Period('April 2018')\n\nIn [79]: june - april\nOut[79]: <2 * MonthEnds> \n```", "```py\nIn [2]: pi = pd.period_range('June 2018', freq='M', periods=3)\n\nIn [3]: pi - pi[0]\nOut[3]: Int64Index([0, 1, 2], dtype='int64') \n```", "```py\nIn [80]: pi = pd.period_range('June 2018', freq='M', periods=3)\n\nIn [81]: pi - pi[0]\nOut[81]: Index([<0 * MonthEnds>, <MonthEnd>, <2 * MonthEnds>], dtype='object') \n```", "```py\nIn [82]: df = pd.DataFrame([pd.Timedelta(days=1)])\n\nIn [83]: df\nOut[83]: \n 0\n0 1 days\n\n[1 rows x 1 columns] \n```", "```py\nIn [4]: df = pd.DataFrame([pd.Timedelta(days=1)])\n\nIn [5]: df - np.nan\nOut[5]:\n 0\n0 NaT \n```", "```py\nIn [2]: df - np.nan\n...\nTypeError: unsupported operand type(s) for -: 'TimedeltaIndex' and 'float' \n```", "```py\nIn [84]: arr = np.arange(6).reshape(3, 2)\n\nIn [85]: df = pd.DataFrame(arr)\n\nIn [86]: df\nOut[86]: \n 0  1\n0  0  1\n1  2  3\n2  4  5\n\n[3 rows x 2 columns] \n```", "```py\nIn [5]: df == arr[[0], :]\n ...: # comparison previously broadcast where arithmetic would raise\nOut[5]:\n 0      1\n0   True   True\n1  False  False\n2  False  False\nIn [6]: df + arr[[0], :]\n...\nValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (1, 2)\n\nIn [7]: df == (1, 2)\n ...: # length matches number of columns;\n ...: # comparison previously raised where arithmetic would broadcast\n...\nValueError: Invalid broadcasting comparison [(1, 2)] with block values\nIn [8]: df + (1, 2)\nOut[8]:\n 0  1\n0  1  3\n1  3  5\n2  5  7\n\nIn [9]: df == (1, 2, 3)\n ...:  # length matches number of rows\n ...:  # comparison previously broadcast where arithmetic would raise\nOut[9]:\n 0      1\n0  False   True\n1   True  False\n2  False  False\nIn [10]: df + (1, 2, 3)\n...\nValueError: Unable to coerce to Series, length must be 2: given 3 \n```", "```py\n# Comparison operations and arithmetic operations both broadcast.\nIn [87]: df == arr[[0], :]\nOut[87]: \n 0      1\n0   True   True\n1  False  False\n2  False  False\n\n[3 rows x 2 columns]\n\nIn [88]: df + arr[[0], :]\nOut[88]: \n 0  1\n0  0  2\n1  2  4\n2  4  6\n\n[3 rows x 2 columns] \n```", "```py\n# Comparison operations and arithmetic operations both broadcast.\nIn [89]: df == (1, 2)\nOut[89]: \n 0      1\n0  False  False\n1  False  False\n2  False  False\n\n[3 rows x 2 columns]\n\nIn [90]: df + (1, 2)\nOut[90]: \n 0  1\n0  1  3\n1  3  5\n2  5  7\n\n[3 rows x 2 columns] \n```", "```py\n# Comparison operations and arithmetic operations both raise ValueError.\nIn [6]: df == (1, 2, 3)\n...\nValueError: Unable to coerce to Series, length must be 2: given 3\n\nIn [7]: df + (1, 2, 3)\n...\nValueError: Unable to coerce to Series, length must be 2: given 3 \n```", "```py\nIn [91]: arr = np.arange(6).reshape(3, 2)\n\nIn [92]: df = pd.DataFrame(arr)\n\nIn [93]: df\nOut[93]: \n 0  1\n0  0  1\n1  2  3\n2  4  5\n\n[3 rows x 2 columns] \n```", "```py\nIn [5]: df + arr[[0], :]   # 1 row, 2 columns\n...\nValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (1, 2)\nIn [6]: df + arr[:, [1]]   # 1 column, 3 rows\n...\nValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (3, 1) \n```", "```py\nIn [94]: df + arr[[0], :]   # 1 row, 2 columns\nOut[94]: \n 0  1\n0  0  2\n1  2  4\n2  4  6\n\n[3 rows x 2 columns]\n\nIn [95]: df + arr[:, [1]]   # 1 column, 3 rows\nOut[95]: \n 0   1\n0  1   2\n1  5   6\n2  9  10\n\n[3 rows x 2 columns] \n```", "```py\nIn [4]: pd.Series([-1], dtype=\"uint64\")\nOut [4]:\n0    18446744073709551615\ndtype: uint64 \n```", "```py\nIn [4]: pd.Series([-1], dtype=\"uint64\")\nOut [4]:\n...\nOverflowError: Trying to coerce negative values to unsigned integers \n```", "```py\nIn [96]: s = pd.Series([0, 1, np.nan])\n\nIn [97]: c = pd.Series([0, 1, np.nan], dtype=\"category\") \n```", "```py\nIn [3]: pd.concat([s, c])\nOut[3]:\n0    0.0\n1    1.0\n2    NaN\n0    0.0\n1    1.0\n2    NaN\ndtype: float64 \n```", "```py\nIn [98]: pd.concat([s, c])\nOut[98]: \n0    0.0\n1    1.0\n2    NaN\n0    0.0\n1    1.0\n2    NaN\nLength: 6, dtype: float64 \n```", "```py\nIn [5]: ts = pd.Timestamp('1994-05-06 12:15:16', freq=pd.offsets.Hour())\nIn [6]: ts + 2\nOut[6]: Timestamp('1994-05-06 14:15:16', freq='H')\n\nIn [7]: tdi = pd.timedelta_range('1D', periods=2)\nIn [8]: tdi - np.array([2, 1])\nOut[8]: TimedeltaIndex(['-1 days', '1 days'], dtype='timedelta64[ns]', freq=None)\n\nIn [9]: dti = pd.date_range('2001-01-01', periods=2, freq='7D')\nIn [10]: dti + pd.Index([1, 2])\nOut[10]: DatetimeIndex(['2001-01-08', '2001-01-22'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [108]: ts = pd.Timestamp('1994-05-06 12:15:16', freq=pd.offsets.Hour())\n\nIn[109]: ts + 2 * ts.freq\nOut[109]: Timestamp('1994-05-06 14:15:16', freq='H')\n\nIn [110]: tdi = pd.timedelta_range('1D', periods=2)\n\nIn [111]: tdi - np.array([2 * tdi.freq, 1 * tdi.freq])\nOut[111]: TimedeltaIndex(['-1 days', '1 days'], dtype='timedelta64[ns]', freq=None)\n\nIn [112]: dti = pd.date_range('2001-01-01', periods=2, freq='7D')\n\nIn [113]: dti + pd.Index([1 * dti.freq, 2 * dti.freq])\nOut[113]: DatetimeIndex(['2001-01-08', '2001-01-22'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [3]: pd.DatetimeIndex([946684800000000000], tz=\"US/Central\")\n/bin/ipython:1: FutureWarning:\n Passing integer-dtype data and a timezone to DatetimeIndex. Integer values\n will be interpreted differently in a future version of pandas. Previously,\n these were viewed as datetime64[ns] values representing the wall time\n *in the specified timezone*. In the future, these will be viewed as\n datetime64[ns] values representing the wall time *in UTC*. This is similar\n to a nanosecond-precision UNIX epoch. To accept the future behavior, use\n\n pd.to_datetime(integer_data, utc=True).tz_convert(tz)\n\n To keep the previous behavior, use\n\n pd.to_datetime(integer_data).tz_localize(tz)\n\n #!/bin/python3\n Out[3]: DatetimeIndex(['2000-01-01 00:00:00-06:00'], dtype='datetime64[ns, US/Central]', freq=None) \n```", "```py\nIn [99]: pd.to_datetime([946684800000000000], utc=True).tz_convert('US/Central')\nOut[99]: DatetimeIndex(['1999-12-31 18:00:00-06:00'], dtype='datetime64[ns, US/Central]', freq=None) \n```", "```py\nIn [100]: pd.to_datetime([946684800000000000]).tz_localize('US/Central')\nOut[100]: DatetimeIndex(['2000-01-01 00:00:00-06:00'], dtype='datetime64[ns, US/Central]', freq=None) \n```", "```py\nIn [101]: ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n\nIn [102]: ser\nOut[102]: \n0   2000-01-01 00:00:00+01:00\n1   2000-01-02 00:00:00+01:00\nLength: 2, dtype: datetime64[ns, CET] \n```", "```py\nIn [8]: np.asarray(ser)\n/bin/ipython:1: FutureWarning: Converting timezone-aware DatetimeArray to timezone-naive\n      ndarray with 'datetime64[ns]' dtype. In the future, this will return an ndarray\n      with 'object' dtype where each element is a 'pandas.Timestamp' with the correct 'tz'.\n\n        To accept the future behavior, pass 'dtype=object'.\n        To keep the old behavior, pass 'dtype=\"datetime64[ns]\"'.\n  #!/bin/python3\nOut[8]:\narray(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n      dtype='datetime64[ns]') \n```", "```py\nIn [103]: np.asarray(ser, dtype='datetime64[ns]')\nOut[103]: \narray(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n dtype='datetime64[ns]') \n```", "```py\n# New behavior\nIn [104]: np.asarray(ser, dtype=object)\nOut[104]: \narray([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n Timestamp('2000-01-02 00:00:00+0100', tz='CET')], dtype=object) \n```", "```py\nIn [105]: ser.to_numpy()\nOut[105]: \narray([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n Timestamp('2000-01-02 00:00:00+0100', tz='CET')], dtype=object)\n\nIn [106]: ser.to_numpy(dtype=\"datetime64[ns]\")\nOut[106]: \narray(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n dtype='datetime64[ns]') \n```", "```py\nIn [1]: s = pd.Series([1, 2, np.nan], dtype='Int64')\n\nIn [2]: s\nOut[2]: \n0       1\n1       2\n2    <NA>\nLength: 3, dtype: Int64 \n```", "```py\n# arithmetic\nIn [3]: s + 1\nOut[3]: \n0       2\n1       3\n2    <NA>\nLength: 3, dtype: Int64\n\n# comparison\nIn [4]: s == 1\nOut[4]: \n0     True\n1    False\n2     <NA>\nLength: 3, dtype: boolean\n\n# indexing\nIn [5]: s.iloc[1:3]\nOut[5]: \n1       2\n2    <NA>\nLength: 2, dtype: Int64\n\n# operate with other dtypes\nIn [6]: s + s.iloc[1:3].astype('Int8')\nOut[6]: \n0    <NA>\n1       4\n2    <NA>\nLength: 3, dtype: Int64\n\n# coerce when needed\nIn [7]: s + 0.01\nOut[7]: \n0    1.01\n1    2.01\n2    <NA>\nLength: 3, dtype: Float64 \n```", "```py\nIn [8]: df = pd.DataFrame({'A': s, 'B': [1, 1, 3], 'C': list('aab')})\n\nIn [9]: df\nOut[9]: \n A  B  C\n0     1  1  a\n1     2  1  a\n2  <NA>  3  b\n\n[3 rows x 3 columns]\n\nIn [10]: df.dtypes\nOut[10]: \nA     Int64\nB     int64\nC    object\nLength: 3, dtype: object \n```", "```py\nIn [11]: pd.concat([df[['A']], df[['B', 'C']]], axis=1).dtypes\nOut[11]: \nA     Int64\nB     int64\nC    object\nLength: 3, dtype: object\n\nIn [12]: df['A'].astype(float)\nOut[12]: \n0    1.0\n1    2.0\n2    NaN\nName: A, Length: 3, dtype: float64 \n```", "```py\nIn [13]: df.sum()\nOut[13]: \nA      3\nB      5\nC    aab\nLength: 3, dtype: object\n\nIn [14]: df.groupby('B').A.sum()\nOut[14]: \nB\n1    3\n3    0\nName: A, Length: 2, dtype: Int64 \n```", "```py\nIn [15]: idx = pd.period_range('2000', periods=4)\n\nIn [16]: idx.array\nOut[16]: \n<PeriodArray>\n['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04']\nLength: 4, dtype: period[D]\n\nIn [17]: pd.Series(idx).array\nOut[17]: \n<PeriodArray>\n['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04']\nLength: 4, dtype: period[D] \n```", "```py\nIn [18]: idx.values\nOut[18]: \narray([Period('2000-01-01', 'D'), Period('2000-01-02', 'D'),\n Period('2000-01-03', 'D'), Period('2000-01-04', 'D')], dtype=object)\n\nIn [19]: id(idx.values)\nOut[19]: 140678188264656\n\nIn [20]: id(idx.values)\nOut[20]: 140678188258896 \n```", "```py\nIn [21]: idx.to_numpy()\nOut[21]: \narray([Period('2000-01-01', 'D'), Period('2000-01-02', 'D'),\n Period('2000-01-03', 'D'), Period('2000-01-04', 'D')], dtype=object)\n\nIn [22]: pd.Series(idx).to_numpy()\nOut[22]: \narray([Period('2000-01-01', 'D'), Period('2000-01-02', 'D'),\n Period('2000-01-03', 'D'), Period('2000-01-04', 'D')], dtype=object) \n```", "```py\nIn [23]: ser = pd.Series([1, 2, 3])\n\nIn [24]: ser.array\nOut[24]: \n<NumpyExtensionArray>\n[1, 2, 3]\nLength: 3, dtype: int64\n\nIn [25]: ser.to_numpy()\nOut[25]: array([1, 2, 3]) \n```", "```py\nIn [26]: pd.array([1, 2, np.nan], dtype='Int64')\nOut[26]: \n<IntegerArray>\n[1, 2, <NA>]\nLength: 3, dtype: Int64\n\nIn [27]: pd.array(['a', 'b', 'c'], dtype='category')\nOut[27]: \n['a', 'b', 'c']\nCategories (3, object): ['a', 'b', 'c'] \n```", "```py\nIn [28]: pd.array([1, 2, 3])\nOut[28]: \n<IntegerArray>\n[1, 2, 3]\nLength: 3, dtype: Int64 \n```", "```py\nIn [29]: pd.array([1, 2, np.nan])\nOut[29]: \n<IntegerArray>\n[1, 2, <NA>]\nLength: 3, dtype: Int64 \n```", "```py\nIn [30]: ser = pd.Series(pd.interval_range(0, 5))\n\nIn [31]: ser\nOut[31]: \n0    (0, 1]\n1    (1, 2]\n2    (2, 3]\n3    (3, 4]\n4    (4, 5]\nLength: 5, dtype: interval\n\nIn [32]: ser.dtype\nOut[32]: interval[int64, right] \n```", "```py\nIn [33]: pser = pd.Series(pd.period_range(\"2000\", freq=\"D\", periods=5))\n\nIn [34]: pser\nOut[34]: \n0    2000-01-01\n1    2000-01-02\n2    2000-01-03\n3    2000-01-04\n4    2000-01-05\nLength: 5, dtype: period[D]\n\nIn [35]: pser.dtype\nOut[35]: period[D] \n```", "```py\nIn [36]: ser.array\nOut[36]: \n<IntervalArray>\n[(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]]\nLength: 5, dtype: interval[int64, right]\n\nIn [37]: pser.array\nOut[37]: \n<PeriodArray>\n['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04', '2000-01-05']\nLength: 5, dtype: period[D] \n```", "```py\nIn [38]: index_left = pd.MultiIndex.from_tuples([('K0', 'X0'), ('K0', 'X1'),\n ....:                                       ('K1', 'X2')],\n ....:                                       names=['key', 'X'])\n ....: \n\nIn [39]: left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n ....:                     'B': ['B0', 'B1', 'B2']}, index=index_left)\n ....: \n\nIn [40]: index_right = pd.MultiIndex.from_tuples([('K0', 'Y0'), ('K1', 'Y1'),\n ....:                                        ('K2', 'Y2'), ('K2', 'Y3')],\n ....:                                        names=['key', 'Y'])\n ....: \n\nIn [41]: right = pd.DataFrame({'C': ['C0', 'C1', 'C2', 'C3'],\n ....:                      'D': ['D0', 'D1', 'D2', 'D3']}, index=index_right)\n ....: \n\nIn [42]: left.join(right)\nOut[42]: \n A   B   C   D\nkey X  Y \nK0  X0 Y0  A0  B0  C0  D0\n X1 Y0  A1  B1  C0  D0\nK1  X2 Y1  A2  B2  C1  D1\n\n[3 rows x 4 columns] \n```", "```py\nIn [43]: pd.merge(left.reset_index(), right.reset_index(),\n ....:         on=['key'], how='inner').set_index(['key', 'X', 'Y'])\n ....: \nOut[43]: \n A   B   C   D\nkey X  Y \nK0  X0 Y0  A0  B0  C0  D0\n X1 Y0  A1  B1  C0  D0\nK1  X2 Y1  A2  B2  C1  D1\n\n[3 rows x 4 columns] \n```", "```py\nIn [44]: from io import StringIO\n\nIn [45]: result = pd.read_html(StringIO(\"\"\"\n ....:  <table>\n ....:    <thead>\n ....:      <tr>\n ....:        <th>A</th><th>B</th><th>C</th>\n ....:      </tr>\n ....:    </thead>\n ....:    <tbody>\n ....:      <tr>\n ....:        <td colspan=\"2\">1</td><td>2</td>\n ....:      </tr>\n ....:    </tbody>\n ....:  </table>\"\"\"))\n ....: \n```", "```py\nIn [13]: result\nOut [13]:\n[   A  B   C\n 0  1  2 NaN] \n```", "```py\nIn [46]: result\nOut[46]: \n[   A  B  C\n 0  1  1  2\n\n [1 rows x 3 columns]] \n```", "```py\nIn [47]: df = pd.DataFrame({'N': [1250, 1500, 1750], 'X': [0.25, 0.35, 0.50]})\n\nIn [48]: def format_and_align(styler):\n ....:    return (styler.format({'N': '{:,}', 'X': '{:.1%}'})\n ....:                  .set_properties(**{'text-align': 'right'}))\n ....: \n\nIn [49]: df.style.pipe(format_and_align).set_caption('Summary of results.')\nOut[49]: <pandas.io.formats.style.Styler at 0x7ff231a272e0> \n```", "```py\nIn [50]: mi = pd.MultiIndex.from_product([list('AB'), list('CD'), list('EF')],\n ....:                                names=['AB', 'CD', 'EF'])\n ....: \n\nIn [51]: df = pd.DataFrame(list(range(len(mi))), index=mi, columns=['N'])\n\nIn [52]: df\nOut[52]: \n N\nAB CD EF \nA  C  E   0\n F   1\n D  E   2\n F   3\nB  C  E   4\n F   5\n D  E   6\n F   7\n\n[8 rows x 1 columns]\n\nIn [53]: df.rename_axis(index={'CD': 'New'})\nOut[53]: \n N\nAB New EF \nA  C   E   0\n F   1\n D   E   2\n F   3\nB  C   E   4\n F   5\n D   E   6\n F   7\n\n[8 rows x 1 columns] \n```", "```py\nIn [1]: s = pd.Series([1, 2, np.nan], dtype='Int64')\n\nIn [2]: s\nOut[2]: \n0       1\n1       2\n2    <NA>\nLength: 3, dtype: Int64 \n```", "```py\n# arithmetic\nIn [3]: s + 1\nOut[3]: \n0       2\n1       3\n2    <NA>\nLength: 3, dtype: Int64\n\n# comparison\nIn [4]: s == 1\nOut[4]: \n0     True\n1    False\n2     <NA>\nLength: 3, dtype: boolean\n\n# indexing\nIn [5]: s.iloc[1:3]\nOut[5]: \n1       2\n2    <NA>\nLength: 2, dtype: Int64\n\n# operate with other dtypes\nIn [6]: s + s.iloc[1:3].astype('Int8')\nOut[6]: \n0    <NA>\n1       4\n2    <NA>\nLength: 3, dtype: Int64\n\n# coerce when needed\nIn [7]: s + 0.01\nOut[7]: \n0    1.01\n1    2.01\n2    <NA>\nLength: 3, dtype: Float64 \n```", "```py\nIn [8]: df = pd.DataFrame({'A': s, 'B': [1, 1, 3], 'C': list('aab')})\n\nIn [9]: df\nOut[9]: \n A  B  C\n0     1  1  a\n1     2  1  a\n2  <NA>  3  b\n\n[3 rows x 3 columns]\n\nIn [10]: df.dtypes\nOut[10]: \nA     Int64\nB     int64\nC    object\nLength: 3, dtype: object \n```", "```py\nIn [11]: pd.concat([df[['A']], df[['B', 'C']]], axis=1).dtypes\nOut[11]: \nA     Int64\nB     int64\nC    object\nLength: 3, dtype: object\n\nIn [12]: df['A'].astype(float)\nOut[12]: \n0    1.0\n1    2.0\n2    NaN\nName: A, Length: 3, dtype: float64 \n```", "```py\nIn [13]: df.sum()\nOut[13]: \nA      3\nB      5\nC    aab\nLength: 3, dtype: object\n\nIn [14]: df.groupby('B').A.sum()\nOut[14]: \nB\n1    3\n3    0\nName: A, Length: 2, dtype: Int64 \n```", "```py\nIn [15]: idx = pd.period_range('2000', periods=4)\n\nIn [16]: idx.array\nOut[16]: \n<PeriodArray>\n['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04']\nLength: 4, dtype: period[D]\n\nIn [17]: pd.Series(idx).array\nOut[17]: \n<PeriodArray>\n['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04']\nLength: 4, dtype: period[D] \n```", "```py\nIn [18]: idx.values\nOut[18]: \narray([Period('2000-01-01', 'D'), Period('2000-01-02', 'D'),\n Period('2000-01-03', 'D'), Period('2000-01-04', 'D')], dtype=object)\n\nIn [19]: id(idx.values)\nOut[19]: 140678188264656\n\nIn [20]: id(idx.values)\nOut[20]: 140678188258896 \n```", "```py\nIn [21]: idx.to_numpy()\nOut[21]: \narray([Period('2000-01-01', 'D'), Period('2000-01-02', 'D'),\n Period('2000-01-03', 'D'), Period('2000-01-04', 'D')], dtype=object)\n\nIn [22]: pd.Series(idx).to_numpy()\nOut[22]: \narray([Period('2000-01-01', 'D'), Period('2000-01-02', 'D'),\n Period('2000-01-03', 'D'), Period('2000-01-04', 'D')], dtype=object) \n```", "```py\nIn [23]: ser = pd.Series([1, 2, 3])\n\nIn [24]: ser.array\nOut[24]: \n<NumpyExtensionArray>\n[1, 2, 3]\nLength: 3, dtype: int64\n\nIn [25]: ser.to_numpy()\nOut[25]: array([1, 2, 3]) \n```", "```py\nIn [26]: pd.array([1, 2, np.nan], dtype='Int64')\nOut[26]: \n<IntegerArray>\n[1, 2, <NA>]\nLength: 3, dtype: Int64\n\nIn [27]: pd.array(['a', 'b', 'c'], dtype='category')\nOut[27]: \n['a', 'b', 'c']\nCategories (3, object): ['a', 'b', 'c'] \n```", "```py\nIn [28]: pd.array([1, 2, 3])\nOut[28]: \n<IntegerArray>\n[1, 2, 3]\nLength: 3, dtype: Int64 \n```", "```py\nIn [29]: pd.array([1, 2, np.nan])\nOut[29]: \n<IntegerArray>\n[1, 2, <NA>]\nLength: 3, dtype: Int64 \n```", "```py\nIn [30]: ser = pd.Series(pd.interval_range(0, 5))\n\nIn [31]: ser\nOut[31]: \n0    (0, 1]\n1    (1, 2]\n2    (2, 3]\n3    (3, 4]\n4    (4, 5]\nLength: 5, dtype: interval\n\nIn [32]: ser.dtype\nOut[32]: interval[int64, right] \n```", "```py\nIn [33]: pser = pd.Series(pd.period_range(\"2000\", freq=\"D\", periods=5))\n\nIn [34]: pser\nOut[34]: \n0    2000-01-01\n1    2000-01-02\n2    2000-01-03\n3    2000-01-04\n4    2000-01-05\nLength: 5, dtype: period[D]\n\nIn [35]: pser.dtype\nOut[35]: period[D] \n```", "```py\nIn [36]: ser.array\nOut[36]: \n<IntervalArray>\n[(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]]\nLength: 5, dtype: interval[int64, right]\n\nIn [37]: pser.array\nOut[37]: \n<PeriodArray>\n['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04', '2000-01-05']\nLength: 5, dtype: period[D] \n```", "```py\nIn [38]: index_left = pd.MultiIndex.from_tuples([('K0', 'X0'), ('K0', 'X1'),\n ....:                                       ('K1', 'X2')],\n ....:                                       names=['key', 'X'])\n ....: \n\nIn [39]: left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n ....:                     'B': ['B0', 'B1', 'B2']}, index=index_left)\n ....: \n\nIn [40]: index_right = pd.MultiIndex.from_tuples([('K0', 'Y0'), ('K1', 'Y1'),\n ....:                                        ('K2', 'Y2'), ('K2', 'Y3')],\n ....:                                        names=['key', 'Y'])\n ....: \n\nIn [41]: right = pd.DataFrame({'C': ['C0', 'C1', 'C2', 'C3'],\n ....:                      'D': ['D0', 'D1', 'D2', 'D3']}, index=index_right)\n ....: \n\nIn [42]: left.join(right)\nOut[42]: \n A   B   C   D\nkey X  Y \nK0  X0 Y0  A0  B0  C0  D0\n X1 Y0  A1  B1  C0  D0\nK1  X2 Y1  A2  B2  C1  D1\n\n[3 rows x 4 columns] \n```", "```py\nIn [43]: pd.merge(left.reset_index(), right.reset_index(),\n ....:         on=['key'], how='inner').set_index(['key', 'X', 'Y'])\n ....: \nOut[43]: \n A   B   C   D\nkey X  Y \nK0  X0 Y0  A0  B0  C0  D0\n X1 Y0  A1  B1  C0  D0\nK1  X2 Y1  A2  B2  C1  D1\n\n[3 rows x 4 columns] \n```", "```py\nIn [44]: from io import StringIO\n\nIn [45]: result = pd.read_html(StringIO(\"\"\"\n ....:  <table>\n ....:    <thead>\n ....:      <tr>\n ....:        <th>A</th><th>B</th><th>C</th>\n ....:      </tr>\n ....:    </thead>\n ....:    <tbody>\n ....:      <tr>\n ....:        <td colspan=\"2\">1</td><td>2</td>\n ....:      </tr>\n ....:    </tbody>\n ....:  </table>\"\"\"))\n ....: \n```", "```py\nIn [13]: result\nOut [13]:\n[   A  B   C\n 0  1  2 NaN] \n```", "```py\nIn [46]: result\nOut[46]: \n[   A  B  C\n 0  1  1  2\n\n [1 rows x 3 columns]] \n```", "```py\nIn [47]: df = pd.DataFrame({'N': [1250, 1500, 1750], 'X': [0.25, 0.35, 0.50]})\n\nIn [48]: def format_and_align(styler):\n ....:    return (styler.format({'N': '{:,}', 'X': '{:.1%}'})\n ....:                  .set_properties(**{'text-align': 'right'}))\n ....: \n\nIn [49]: df.style.pipe(format_and_align).set_caption('Summary of results.')\nOut[49]: <pandas.io.formats.style.Styler at 0x7ff231a272e0> \n```", "```py\nIn [50]: mi = pd.MultiIndex.from_product([list('AB'), list('CD'), list('EF')],\n ....:                                names=['AB', 'CD', 'EF'])\n ....: \n\nIn [51]: df = pd.DataFrame(list(range(len(mi))), index=mi, columns=['N'])\n\nIn [52]: df\nOut[52]: \n N\nAB CD EF \nA  C  E   0\n F   1\n D  E   2\n F   3\nB  C  E   4\n F   5\n D  E   6\n F   7\n\n[8 rows x 1 columns]\n\nIn [53]: df.rename_axis(index={'CD': 'New'})\nOut[53]: \n N\nAB New EF \nA  C   E   0\n F   1\n D   E   2\n F   3\nB  C   E   4\n F   5\n D   E   6\n F   7\n\n[8 rows x 1 columns] \n```", "```py\nIn [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n ...:                     \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\nIn [2]: # When passing file PATH to to_csv,\n ...: # line_terminator does not work, and csv is saved with '\\r\\n'.\n ...: # Also, this converts all '\\n's in the data to '\\r\\n'.\n ...: data.to_csv(\"test.csv\", index=False, line_terminator='\\n')\n\nIn [3]: with open(\"test.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\r\\nbc\",\"a\\r\\r\\nbc\"\\r\\n'\n\nIn [4]: # When passing file OBJECT with newline option to\n ...: # to_csv, line_terminator works.\n ...: with open(\"test2.csv\", mode='w', newline='\\n') as f:\n ...:    data.to_csv(f, index=False, line_terminator='\\n')\n\nIn [5]: with open(\"test2.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[5]: b'string_with_lf,string_with_crlf\\n\"a\\nbc\",\"a\\r\\nbc\"\\n' \n```", "```py\nIn [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n ...:                     \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\nIn [2]: data.to_csv(\"test.csv\", index=False, line_terminator='\\n')\n\nIn [3]: with open(\"test.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[3]: b'string_with_lf,string_with_crlf\\n\"a\\nbc\",\"a\\r\\nbc\"\\n' \n```", "```py\nIn [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n ...:                     \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\nIn [2]: data.to_csv(\"test.csv\", index=False)\n\nIn [3]: with open(\"test.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\nbc\",\"a\\r\\nbc\"\\r\\n' \n```", "```py\nIn [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n ...:                     \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\nIn [2]: with open(\"test2.csv\", mode='w', newline='\\n') as f:\n ...:    data.to_csv(f, index=False)\n\nIn [3]: with open(\"test2.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\nbc\",\"a\\r\\nbc\"\\r\\n' \n```", "```py\nIn [5]: data = 'a,b,c\\n1,,3\\n4,5,6'\nIn [6]: df = pd.read_csv(StringIO(data), engine='python', dtype=str, na_filter=True)\nIn [7]: df.loc[0, 'b']\nOut[7]:\n'nan' \n```", "```py\nIn [54]: data = 'a,b,c\\n1,,3\\n4,5,6'\n\nIn [55]: df = pd.read_csv(StringIO(data), engine='python', dtype=str, na_filter=True)\n\nIn [56]: df.loc[0, 'b']\nOut[56]: nan \n```", "```py\nIn [2]: pd.to_datetime(\"2015-11-18 15:30:00+05:30\")\nOut[2]: Timestamp('2015-11-18 10:00:00')\n\nIn [3]: pd.Timestamp(\"2015-11-18 15:30:00+05:30\")\nOut[3]: Timestamp('2015-11-18 15:30:00+0530', tz='pytz.FixedOffset(330)')\n\n# Different UTC offsets would automatically convert the datetimes to UTC (without a UTC timezone)\nIn [4]: pd.to_datetime([\"2015-11-18 15:30:00+05:30\", \"2015-11-18 16:30:00+06:30\"])\nOut[4]: DatetimeIndex(['2015-11-18 10:00:00', '2015-11-18 10:00:00'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [57]: pd.to_datetime(\"2015-11-18 15:30:00+05:30\")\nOut[57]: Timestamp('2015-11-18 15:30:00+0530', tz='UTC+05:30')\n\nIn [58]: pd.Timestamp(\"2015-11-18 15:30:00+05:30\")\nOut[58]: Timestamp('2015-11-18 15:30:00+0530', tz='UTC+05:30') \n```", "```py\nIn [59]: pd.to_datetime([\"2015-11-18 15:30:00+05:30\"] * 2)\nOut[59]: DatetimeIndex(['2015-11-18 15:30:00+05:30', '2015-11-18 15:30:00+05:30'], dtype='datetime64[ns, UTC+05:30]', freq=None) \n```", "```py\nIn [59]: idx = pd.to_datetime([\"2015-11-18 15:30:00+05:30\",\n \"2015-11-18 16:30:00+06:30\"])\n\nIn[60]: idx\nOut[60]: Index([2015-11-18 15:30:00+05:30, 2015-11-18 16:30:00+06:30], dtype='object')\n\nIn[61]: idx[0]\nOut[61]: Timestamp('2015-11-18 15:30:00+0530', tz='UTC+05:30')\n\nIn[62]: idx[1]\nOut[62]: Timestamp('2015-11-18 16:30:00+0630', tz='UTC+06:30') \n```", "```py\nIn [60]: pd.to_datetime([\"2015-11-18 15:30:00+05:30\",\n ....:                \"2015-11-18 16:30:00+06:30\"], utc=True)\n ....: \nOut[60]: DatetimeIndex(['2015-11-18 10:00:00+00:00', '2015-11-18 10:00:00+00:00'], dtype='datetime64[ns, UTC]', freq=None) \n```", "```py\n>>> import io\n>>> content = \"\"\"\\\n... a\n... 2000-01-01T00:00:00+05:00\n... 2000-01-01T00:00:00+06:00\"\"\"\n>>> df = pd.read_csv(io.StringIO(content), parse_dates=['a'])\n>>> df.a\n0   1999-12-31 19:00:00\n1   1999-12-31 18:00:00\nName: a, dtype: datetime64[ns] \n```", "```py\nIn[64]: import io\n\nIn[65]: content = \"\"\"\\\n ...: a\n ...: 2000-01-01T00:00:00+05:00\n ...: 2000-01-01T00:00:00+06:00\"\"\"\n\nIn[66]: df = pd.read_csv(io.StringIO(content), parse_dates=['a'])\n\nIn[67]: df.a\nOut[67]:\n0   2000-01-01 00:00:00+05:00\n1   2000-01-01 00:00:00+06:00\nName: a, Length: 2, dtype: object \n```", "```py\nIn [3]: df = pd.read_csv(\n ...:    io.StringIO(content),\n ...:    parse_dates=['a'],\n ...:    date_parser=lambda col: pd.to_datetime(col, utc=True),\n ...: )\n\nIn [4]: df.a\nOut[4]:\n0   1999-12-31 19:00:00+00:00\n1   1999-12-31 18:00:00+00:00\nName: a, dtype: datetime64[ns, UTC] \n```", "```py\nIn [2]: p = pd.Period('2017-01-01', 'D')\nIn [3]: pi = pd.PeriodIndex([p])\n\nIn [4]: pd.Series(pi).dt.end_time[0]\nOut[4]: Timestamp(2017-01-01 00:00:00)\n\nIn [5]: p.end_time\nOut[5]: Timestamp(2017-01-01 23:59:59.999999999) \n```", "```py\nIn [61]: p = pd.Period('2017-01-01', 'D')\n\nIn [62]: pi = pd.PeriodIndex([p])\n\nIn [63]: pd.Series(pi).dt.end_time[0]\nOut[63]: Timestamp('2017-01-01 23:59:59.999999999')\n\nIn [64]: p.end_time\nOut[64]: Timestamp('2017-01-01 23:59:59.999999999') \n```", "```py\nIn [65]: ser = pd.Series([pd.Timestamp('2000', tz='UTC'),\n ....:                 pd.Timestamp('2000', tz='UTC')])\n ....: \n```", "```py\nIn [3]: ser.unique()\nOut[3]: array([Timestamp('2000-01-01 00:00:00+0000', tz='UTC')], dtype=object) \n```", "```py\nIn [66]: ser.unique()\nOut[66]: \n<DatetimeArray>\n['2000-01-01 00:00:00+00:00']\nLength: 1, dtype: datetime64[ns, UTC] \n```", "```py\nIn [67]: s = pd.Series([0, 0, 1, 1, 1], dtype='Sparse[int]')\n\nIn [68]: s.sparse.density\nOut[68]: 0.6 \n```", "```py\nIn [2]: df = pd.DataFrame({\"A\": [1, 2], \"B\": ['a', 'b'], \"C\": ['a', 'a']})\n\nIn [3]: type(pd.get_dummies(df, sparse=True))\nOut[3]: pandas.core.frame.DataFrame\n\nIn [4]: type(pd.get_dummies(df[['B', 'C']], sparse=True))\nOut[4]: pandas.core.sparse.frame.SparseDataFrame \n```", "```py\nIn [69]: type(pd.get_dummies(df, sparse=True))\nOut[69]: pandas.core.frame.DataFrame\n\nIn [70]: type(pd.get_dummies(df[['B', 'C']], sparse=True))\nOut[70]: pandas.core.frame.DataFrame \n```", "```py\nIn [71]: df = pd.DataFrame({'a': [1, 2], 'b': [0.5, 0.75]}, index=['A', 'A'])\n\nIn [72]: df\nOut[72]: \n a     b\nA  1  0.50\nA  2  0.75\n\n[2 rows x 2 columns]\n\nIn [73]: df.to_dict(orient='index')\n---------------------------------------------------------------------------\nValueError  Traceback (most recent call last)\nCell In[73], line 1\n----> 1 df.to_dict(orient='index')\n\nFile ~/work/pandas/pandas/pandas/util/_decorators.py:333, in deprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper(*args, **kwargs)\n  327 if len(args) > num_allow_args:\n  328     warnings.warn(\n  329         msg.format(arguments=_format_argument_list(allow_args)),\n  330         FutureWarning,\n  331         stacklevel=find_stack_level(),\n  332     )\n--> 333 return func(*args, **kwargs)\n\nFile ~/work/pandas/pandas/pandas/core/frame.py:2178, in DataFrame.to_dict(self, orient, into, index)\n  2075  \"\"\"\n  2076 Convert the DataFrame to a dictionary.\n  2077  \n (...)\n  2174 defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n  2175 \"\"\"\n  2176 from pandas.core.methods.to_dict import to_dict\n-> 2178 return to_dict(self, orient, into=into, index=index)\n\nFile ~/work/pandas/pandas/pandas/core/methods/to_dict.py:242, in to_dict(df, orient, into, index)\n  240 elif orient == \"index\":\n  241     if not df.index.is_unique:\n--> 242         raise ValueError(\"DataFrame index must be unique for orient='index'.\")\n  243     columns = df.columns.tolist()\n  244     if are_all_object_dtype_cols:\n\nValueError: DataFrame index must be unique for orient='index'. \n```", "```py\nIn [2]: ts = pd.Timestamp('2018-06-11 18:01:14')\n\nIn [3]: ts\nOut[3]: Timestamp('2018-06-11 18:01:14')\n\nIn [4]: tic = pd.offsets.Hour(n=2, normalize=True)\n ...:\n\nIn [5]: tic\nOut[5]: <2 * Hours>\n\nIn [6]: ts + tic\nOut[6]: Timestamp('2018-06-11 00:00:00')\n\nIn [7]: ts + tic + tic + tic == ts + (tic + tic + tic)\nOut[7]: False \n```", "```py\nIn [74]: ts = pd.Timestamp('2018-06-11 18:01:14')\n\nIn [75]: tic = pd.offsets.Hour(n=2)\n\nIn [76]: ts + tic + tic + tic == ts + (tic + tic + tic)\nOut[76]: True \n```", "```py\nIn [2]: june = pd.Period('June 2018')\n\nIn [3]: april = pd.Period('April 2018')\n\nIn [4]: june - april\nOut [4]: 2 \n```", "```py\nIn [77]: june = pd.Period('June 2018')\n\nIn [78]: april = pd.Period('April 2018')\n\nIn [79]: june - april\nOut[79]: <2 * MonthEnds> \n```", "```py\nIn [2]: pi = pd.period_range('June 2018', freq='M', periods=3)\n\nIn [3]: pi - pi[0]\nOut[3]: Int64Index([0, 1, 2], dtype='int64') \n```", "```py\nIn [80]: pi = pd.period_range('June 2018', freq='M', periods=3)\n\nIn [81]: pi - pi[0]\nOut[81]: Index([<0 * MonthEnds>, <MonthEnd>, <2 * MonthEnds>], dtype='object') \n```", "```py\nIn [82]: df = pd.DataFrame([pd.Timedelta(days=1)])\n\nIn [83]: df\nOut[83]: \n 0\n0 1 days\n\n[1 rows x 1 columns] \n```", "```py\nIn [4]: df = pd.DataFrame([pd.Timedelta(days=1)])\n\nIn [5]: df - np.nan\nOut[5]:\n 0\n0 NaT \n```", "```py\nIn [2]: df - np.nan\n...\nTypeError: unsupported operand type(s) for -: 'TimedeltaIndex' and 'float' \n```", "```py\nIn [84]: arr = np.arange(6).reshape(3, 2)\n\nIn [85]: df = pd.DataFrame(arr)\n\nIn [86]: df\nOut[86]: \n 0  1\n0  0  1\n1  2  3\n2  4  5\n\n[3 rows x 2 columns] \n```", "```py\nIn [5]: df == arr[[0], :]\n ...: # comparison previously broadcast where arithmetic would raise\nOut[5]:\n 0      1\n0   True   True\n1  False  False\n2  False  False\nIn [6]: df + arr[[0], :]\n...\nValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (1, 2)\n\nIn [7]: df == (1, 2)\n ...: # length matches number of columns;\n ...: # comparison previously raised where arithmetic would broadcast\n...\nValueError: Invalid broadcasting comparison [(1, 2)] with block values\nIn [8]: df + (1, 2)\nOut[8]:\n 0  1\n0  1  3\n1  3  5\n2  5  7\n\nIn [9]: df == (1, 2, 3)\n ...:  # length matches number of rows\n ...:  # comparison previously broadcast where arithmetic would raise\nOut[9]:\n 0      1\n0  False   True\n1   True  False\n2  False  False\nIn [10]: df + (1, 2, 3)\n...\nValueError: Unable to coerce to Series, length must be 2: given 3 \n```", "```py\n# Comparison operations and arithmetic operations both broadcast.\nIn [87]: df == arr[[0], :]\nOut[87]: \n 0      1\n0   True   True\n1  False  False\n2  False  False\n\n[3 rows x 2 columns]\n\nIn [88]: df + arr[[0], :]\nOut[88]: \n 0  1\n0  0  2\n1  2  4\n2  4  6\n\n[3 rows x 2 columns] \n```", "```py\n# Comparison operations and arithmetic operations both broadcast.\nIn [89]: df == (1, 2)\nOut[89]: \n 0      1\n0  False  False\n1  False  False\n2  False  False\n\n[3 rows x 2 columns]\n\nIn [90]: df + (1, 2)\nOut[90]: \n 0  1\n0  1  3\n1  3  5\n2  5  7\n\n[3 rows x 2 columns] \n```", "```py\n# Comparison operations and arithmetic operations both raise ValueError.\nIn [6]: df == (1, 2, 3)\n...\nValueError: Unable to coerce to Series, length must be 2: given 3\n\nIn [7]: df + (1, 2, 3)\n...\nValueError: Unable to coerce to Series, length must be 2: given 3 \n```", "```py\nIn [91]: arr = np.arange(6).reshape(3, 2)\n\nIn [92]: df = pd.DataFrame(arr)\n\nIn [93]: df\nOut[93]: \n 0  1\n0  0  1\n1  2  3\n2  4  5\n\n[3 rows x 2 columns] \n```", "```py\nIn [5]: df + arr[[0], :]   # 1 row, 2 columns\n...\nValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (1, 2)\nIn [6]: df + arr[:, [1]]   # 1 column, 3 rows\n...\nValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (3, 1) \n```", "```py\nIn [94]: df + arr[[0], :]   # 1 row, 2 columns\nOut[94]: \n 0  1\n0  0  2\n1  2  4\n2  4  6\n\n[3 rows x 2 columns]\n\nIn [95]: df + arr[:, [1]]   # 1 column, 3 rows\nOut[95]: \n 0   1\n0  1   2\n1  5   6\n2  9  10\n\n[3 rows x 2 columns] \n```", "```py\nIn [4]: pd.Series([-1], dtype=\"uint64\")\nOut [4]:\n0    18446744073709551615\ndtype: uint64 \n```", "```py\nIn [4]: pd.Series([-1], dtype=\"uint64\")\nOut [4]:\n...\nOverflowError: Trying to coerce negative values to unsigned integers \n```", "```py\nIn [96]: s = pd.Series([0, 1, np.nan])\n\nIn [97]: c = pd.Series([0, 1, np.nan], dtype=\"category\") \n```", "```py\nIn [3]: pd.concat([s, c])\nOut[3]:\n0    0.0\n1    1.0\n2    NaN\n0    0.0\n1    1.0\n2    NaN\ndtype: float64 \n```", "```py\nIn [98]: pd.concat([s, c])\nOut[98]: \n0    0.0\n1    1.0\n2    NaN\n0    0.0\n1    1.0\n2    NaN\nLength: 6, dtype: float64 \n```", "```py\nIn [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n ...:                     \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\nIn [2]: # When passing file PATH to to_csv,\n ...: # line_terminator does not work, and csv is saved with '\\r\\n'.\n ...: # Also, this converts all '\\n's in the data to '\\r\\n'.\n ...: data.to_csv(\"test.csv\", index=False, line_terminator='\\n')\n\nIn [3]: with open(\"test.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\r\\nbc\",\"a\\r\\r\\nbc\"\\r\\n'\n\nIn [4]: # When passing file OBJECT with newline option to\n ...: # to_csv, line_terminator works.\n ...: with open(\"test2.csv\", mode='w', newline='\\n') as f:\n ...:    data.to_csv(f, index=False, line_terminator='\\n')\n\nIn [5]: with open(\"test2.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[5]: b'string_with_lf,string_with_crlf\\n\"a\\nbc\",\"a\\r\\nbc\"\\n' \n```", "```py\nIn [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n ...:                     \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\nIn [2]: data.to_csv(\"test.csv\", index=False, line_terminator='\\n')\n\nIn [3]: with open(\"test.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[3]: b'string_with_lf,string_with_crlf\\n\"a\\nbc\",\"a\\r\\nbc\"\\n' \n```", "```py\nIn [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n ...:                     \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\nIn [2]: data.to_csv(\"test.csv\", index=False)\n\nIn [3]: with open(\"test.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\nbc\",\"a\\r\\nbc\"\\r\\n' \n```", "```py\nIn [1]: data = pd.DataFrame({\"string_with_lf\": [\"a\\nbc\"],\n ...:                     \"string_with_crlf\": [\"a\\r\\nbc\"]})\n\nIn [2]: with open(\"test2.csv\", mode='w', newline='\\n') as f:\n ...:    data.to_csv(f, index=False)\n\nIn [3]: with open(\"test2.csv\", mode='rb') as f:\n ...:    print(f.read())\nOut[3]: b'string_with_lf,string_with_crlf\\r\\n\"a\\nbc\",\"a\\r\\nbc\"\\r\\n' \n```", "```py\nIn [5]: data = 'a,b,c\\n1,,3\\n4,5,6'\nIn [6]: df = pd.read_csv(StringIO(data), engine='python', dtype=str, na_filter=True)\nIn [7]: df.loc[0, 'b']\nOut[7]:\n'nan' \n```", "```py\nIn [54]: data = 'a,b,c\\n1,,3\\n4,5,6'\n\nIn [55]: df = pd.read_csv(StringIO(data), engine='python', dtype=str, na_filter=True)\n\nIn [56]: df.loc[0, 'b']\nOut[56]: nan \n```", "```py\nIn [2]: pd.to_datetime(\"2015-11-18 15:30:00+05:30\")\nOut[2]: Timestamp('2015-11-18 10:00:00')\n\nIn [3]: pd.Timestamp(\"2015-11-18 15:30:00+05:30\")\nOut[3]: Timestamp('2015-11-18 15:30:00+0530', tz='pytz.FixedOffset(330)')\n\n# Different UTC offsets would automatically convert the datetimes to UTC (without a UTC timezone)\nIn [4]: pd.to_datetime([\"2015-11-18 15:30:00+05:30\", \"2015-11-18 16:30:00+06:30\"])\nOut[4]: DatetimeIndex(['2015-11-18 10:00:00', '2015-11-18 10:00:00'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [57]: pd.to_datetime(\"2015-11-18 15:30:00+05:30\")\nOut[57]: Timestamp('2015-11-18 15:30:00+0530', tz='UTC+05:30')\n\nIn [58]: pd.Timestamp(\"2015-11-18 15:30:00+05:30\")\nOut[58]: Timestamp('2015-11-18 15:30:00+0530', tz='UTC+05:30') \n```", "```py\nIn [59]: pd.to_datetime([\"2015-11-18 15:30:00+05:30\"] * 2)\nOut[59]: DatetimeIndex(['2015-11-18 15:30:00+05:30', '2015-11-18 15:30:00+05:30'], dtype='datetime64[ns, UTC+05:30]', freq=None) \n```", "```py\nIn [59]: idx = pd.to_datetime([\"2015-11-18 15:30:00+05:30\",\n \"2015-11-18 16:30:00+06:30\"])\n\nIn[60]: idx\nOut[60]: Index([2015-11-18 15:30:00+05:30, 2015-11-18 16:30:00+06:30], dtype='object')\n\nIn[61]: idx[0]\nOut[61]: Timestamp('2015-11-18 15:30:00+0530', tz='UTC+05:30')\n\nIn[62]: idx[1]\nOut[62]: Timestamp('2015-11-18 16:30:00+0630', tz='UTC+06:30') \n```", "```py\nIn [60]: pd.to_datetime([\"2015-11-18 15:30:00+05:30\",\n ....:                \"2015-11-18 16:30:00+06:30\"], utc=True)\n ....: \nOut[60]: DatetimeIndex(['2015-11-18 10:00:00+00:00', '2015-11-18 10:00:00+00:00'], dtype='datetime64[ns, UTC]', freq=None) \n```", "```py\n>>> import io\n>>> content = \"\"\"\\\n... a\n... 2000-01-01T00:00:00+05:00\n... 2000-01-01T00:00:00+06:00\"\"\"\n>>> df = pd.read_csv(io.StringIO(content), parse_dates=['a'])\n>>> df.a\n0   1999-12-31 19:00:00\n1   1999-12-31 18:00:00\nName: a, dtype: datetime64[ns] \n```", "```py\nIn[64]: import io\n\nIn[65]: content = \"\"\"\\\n ...: a\n ...: 2000-01-01T00:00:00+05:00\n ...: 2000-01-01T00:00:00+06:00\"\"\"\n\nIn[66]: df = pd.read_csv(io.StringIO(content), parse_dates=['a'])\n\nIn[67]: df.a\nOut[67]:\n0   2000-01-01 00:00:00+05:00\n1   2000-01-01 00:00:00+06:00\nName: a, Length: 2, dtype: object \n```", "```py\nIn [3]: df = pd.read_csv(\n ...:    io.StringIO(content),\n ...:    parse_dates=['a'],\n ...:    date_parser=lambda col: pd.to_datetime(col, utc=True),\n ...: )\n\nIn [4]: df.a\nOut[4]:\n0   1999-12-31 19:00:00+00:00\n1   1999-12-31 18:00:00+00:00\nName: a, dtype: datetime64[ns, UTC] \n```", "```py\nIn [2]: p = pd.Period('2017-01-01', 'D')\nIn [3]: pi = pd.PeriodIndex([p])\n\nIn [4]: pd.Series(pi).dt.end_time[0]\nOut[4]: Timestamp(2017-01-01 00:00:00)\n\nIn [5]: p.end_time\nOut[5]: Timestamp(2017-01-01 23:59:59.999999999) \n```", "```py\nIn [61]: p = pd.Period('2017-01-01', 'D')\n\nIn [62]: pi = pd.PeriodIndex([p])\n\nIn [63]: pd.Series(pi).dt.end_time[0]\nOut[63]: Timestamp('2017-01-01 23:59:59.999999999')\n\nIn [64]: p.end_time\nOut[64]: Timestamp('2017-01-01 23:59:59.999999999') \n```", "```py\nIn [65]: ser = pd.Series([pd.Timestamp('2000', tz='UTC'),\n ....:                 pd.Timestamp('2000', tz='UTC')])\n ....: \n```", "```py\nIn [3]: ser.unique()\nOut[3]: array([Timestamp('2000-01-01 00:00:00+0000', tz='UTC')], dtype=object) \n```", "```py\nIn [66]: ser.unique()\nOut[66]: \n<DatetimeArray>\n['2000-01-01 00:00:00+00:00']\nLength: 1, dtype: datetime64[ns, UTC] \n```", "```py\nIn [67]: s = pd.Series([0, 0, 1, 1, 1], dtype='Sparse[int]')\n\nIn [68]: s.sparse.density\nOut[68]: 0.6 \n```", "```py\nIn [2]: df = pd.DataFrame({\"A\": [1, 2], \"B\": ['a', 'b'], \"C\": ['a', 'a']})\n\nIn [3]: type(pd.get_dummies(df, sparse=True))\nOut[3]: pandas.core.frame.DataFrame\n\nIn [4]: type(pd.get_dummies(df[['B', 'C']], sparse=True))\nOut[4]: pandas.core.sparse.frame.SparseDataFrame \n```", "```py\nIn [69]: type(pd.get_dummies(df, sparse=True))\nOut[69]: pandas.core.frame.DataFrame\n\nIn [70]: type(pd.get_dummies(df[['B', 'C']], sparse=True))\nOut[70]: pandas.core.frame.DataFrame \n```", "```py\nIn [71]: df = pd.DataFrame({'a': [1, 2], 'b': [0.5, 0.75]}, index=['A', 'A'])\n\nIn [72]: df\nOut[72]: \n a     b\nA  1  0.50\nA  2  0.75\n\n[2 rows x 2 columns]\n\nIn [73]: df.to_dict(orient='index')\n---------------------------------------------------------------------------\nValueError  Traceback (most recent call last)\nCell In[73], line 1\n----> 1 df.to_dict(orient='index')\n\nFile ~/work/pandas/pandas/pandas/util/_decorators.py:333, in deprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper(*args, **kwargs)\n  327 if len(args) > num_allow_args:\n  328     warnings.warn(\n  329         msg.format(arguments=_format_argument_list(allow_args)),\n  330         FutureWarning,\n  331         stacklevel=find_stack_level(),\n  332     )\n--> 333 return func(*args, **kwargs)\n\nFile ~/work/pandas/pandas/pandas/core/frame.py:2178, in DataFrame.to_dict(self, orient, into, index)\n  2075  \"\"\"\n  2076 Convert the DataFrame to a dictionary.\n  2077  \n (...)\n  2174 defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n  2175 \"\"\"\n  2176 from pandas.core.methods.to_dict import to_dict\n-> 2178 return to_dict(self, orient, into=into, index=index)\n\nFile ~/work/pandas/pandas/pandas/core/methods/to_dict.py:242, in to_dict(df, orient, into, index)\n  240 elif orient == \"index\":\n  241     if not df.index.is_unique:\n--> 242         raise ValueError(\"DataFrame index must be unique for orient='index'.\")\n  243     columns = df.columns.tolist()\n  244     if are_all_object_dtype_cols:\n\nValueError: DataFrame index must be unique for orient='index'. \n```", "```py\nIn [2]: ts = pd.Timestamp('2018-06-11 18:01:14')\n\nIn [3]: ts\nOut[3]: Timestamp('2018-06-11 18:01:14')\n\nIn [4]: tic = pd.offsets.Hour(n=2, normalize=True)\n ...:\n\nIn [5]: tic\nOut[5]: <2 * Hours>\n\nIn [6]: ts + tic\nOut[6]: Timestamp('2018-06-11 00:00:00')\n\nIn [7]: ts + tic + tic + tic == ts + (tic + tic + tic)\nOut[7]: False \n```", "```py\nIn [74]: ts = pd.Timestamp('2018-06-11 18:01:14')\n\nIn [75]: tic = pd.offsets.Hour(n=2)\n\nIn [76]: ts + tic + tic + tic == ts + (tic + tic + tic)\nOut[76]: True \n```", "```py\nIn [2]: june = pd.Period('June 2018')\n\nIn [3]: april = pd.Period('April 2018')\n\nIn [4]: june - april\nOut [4]: 2 \n```", "```py\nIn [77]: june = pd.Period('June 2018')\n\nIn [78]: april = pd.Period('April 2018')\n\nIn [79]: june - april\nOut[79]: <2 * MonthEnds> \n```", "```py\nIn [2]: pi = pd.period_range('June 2018', freq='M', periods=3)\n\nIn [3]: pi - pi[0]\nOut[3]: Int64Index([0, 1, 2], dtype='int64') \n```", "```py\nIn [80]: pi = pd.period_range('June 2018', freq='M', periods=3)\n\nIn [81]: pi - pi[0]\nOut[81]: Index([<0 * MonthEnds>, <MonthEnd>, <2 * MonthEnds>], dtype='object') \n```", "```py\nIn [82]: df = pd.DataFrame([pd.Timedelta(days=1)])\n\nIn [83]: df\nOut[83]: \n 0\n0 1 days\n\n[1 rows x 1 columns] \n```", "```py\nIn [4]: df = pd.DataFrame([pd.Timedelta(days=1)])\n\nIn [5]: df - np.nan\nOut[5]:\n 0\n0 NaT \n```", "```py\nIn [2]: df - np.nan\n...\nTypeError: unsupported operand type(s) for -: 'TimedeltaIndex' and 'float' \n```", "```py\nIn [84]: arr = np.arange(6).reshape(3, 2)\n\nIn [85]: df = pd.DataFrame(arr)\n\nIn [86]: df\nOut[86]: \n 0  1\n0  0  1\n1  2  3\n2  4  5\n\n[3 rows x 2 columns] \n```", "```py\nIn [5]: df == arr[[0], :]\n ...: # comparison previously broadcast where arithmetic would raise\nOut[5]:\n 0      1\n0   True   True\n1  False  False\n2  False  False\nIn [6]: df + arr[[0], :]\n...\nValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (1, 2)\n\nIn [7]: df == (1, 2)\n ...: # length matches number of columns;\n ...: # comparison previously raised where arithmetic would broadcast\n...\nValueError: Invalid broadcasting comparison [(1, 2)] with block values\nIn [8]: df + (1, 2)\nOut[8]:\n 0  1\n0  1  3\n1  3  5\n2  5  7\n\nIn [9]: df == (1, 2, 3)\n ...:  # length matches number of rows\n ...:  # comparison previously broadcast where arithmetic would raise\nOut[9]:\n 0      1\n0  False   True\n1   True  False\n2  False  False\nIn [10]: df + (1, 2, 3)\n...\nValueError: Unable to coerce to Series, length must be 2: given 3 \n```", "```py\n# Comparison operations and arithmetic operations both broadcast.\nIn [87]: df == arr[[0], :]\nOut[87]: \n 0      1\n0   True   True\n1  False  False\n2  False  False\n\n[3 rows x 2 columns]\n\nIn [88]: df + arr[[0], :]\nOut[88]: \n 0  1\n0  0  2\n1  2  4\n2  4  6\n\n[3 rows x 2 columns] \n```", "```py\n# Comparison operations and arithmetic operations both broadcast.\nIn [89]: df == (1, 2)\nOut[89]: \n 0      1\n0  False  False\n1  False  False\n2  False  False\n\n[3 rows x 2 columns]\n\nIn [90]: df + (1, 2)\nOut[90]: \n 0  1\n0  1  3\n1  3  5\n2  5  7\n\n[3 rows x 2 columns] \n```", "```py\n# Comparison operations and arithmetic operations both raise ValueError.\nIn [6]: df == (1, 2, 3)\n...\nValueError: Unable to coerce to Series, length must be 2: given 3\n\nIn [7]: df + (1, 2, 3)\n...\nValueError: Unable to coerce to Series, length must be 2: given 3 \n```", "```py\nIn [91]: arr = np.arange(6).reshape(3, 2)\n\nIn [92]: df = pd.DataFrame(arr)\n\nIn [93]: df\nOut[93]: \n 0  1\n0  0  1\n1  2  3\n2  4  5\n\n[3 rows x 2 columns] \n```", "```py\nIn [5]: df + arr[[0], :]   # 1 row, 2 columns\n...\nValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (1, 2)\nIn [6]: df + arr[:, [1]]   # 1 column, 3 rows\n...\nValueError: Unable to coerce to DataFrame, shape must be (3, 2): given (3, 1) \n```", "```py\nIn [94]: df + arr[[0], :]   # 1 row, 2 columns\nOut[94]: \n 0  1\n0  0  2\n1  2  4\n2  4  6\n\n[3 rows x 2 columns]\n\nIn [95]: df + arr[:, [1]]   # 1 column, 3 rows\nOut[95]: \n 0   1\n0  1   2\n1  5   6\n2  9  10\n\n[3 rows x 2 columns] \n```", "```py\nIn [4]: pd.Series([-1], dtype=\"uint64\")\nOut [4]:\n0    18446744073709551615\ndtype: uint64 \n```", "```py\nIn [4]: pd.Series([-1], dtype=\"uint64\")\nOut [4]:\n...\nOverflowError: Trying to coerce negative values to unsigned integers \n```", "```py\nIn [96]: s = pd.Series([0, 1, np.nan])\n\nIn [97]: c = pd.Series([0, 1, np.nan], dtype=\"category\") \n```", "```py\nIn [3]: pd.concat([s, c])\nOut[3]:\n0    0.0\n1    1.0\n2    NaN\n0    0.0\n1    1.0\n2    NaN\ndtype: float64 \n```", "```py\nIn [98]: pd.concat([s, c])\nOut[98]: \n0    0.0\n1    1.0\n2    NaN\n0    0.0\n1    1.0\n2    NaN\nLength: 6, dtype: float64 \n```", "```py\nIn [5]: ts = pd.Timestamp('1994-05-06 12:15:16', freq=pd.offsets.Hour())\nIn [6]: ts + 2\nOut[6]: Timestamp('1994-05-06 14:15:16', freq='H')\n\nIn [7]: tdi = pd.timedelta_range('1D', periods=2)\nIn [8]: tdi - np.array([2, 1])\nOut[8]: TimedeltaIndex(['-1 days', '1 days'], dtype='timedelta64[ns]', freq=None)\n\nIn [9]: dti = pd.date_range('2001-01-01', periods=2, freq='7D')\nIn [10]: dti + pd.Index([1, 2])\nOut[10]: DatetimeIndex(['2001-01-08', '2001-01-22'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [108]: ts = pd.Timestamp('1994-05-06 12:15:16', freq=pd.offsets.Hour())\n\nIn[109]: ts + 2 * ts.freq\nOut[109]: Timestamp('1994-05-06 14:15:16', freq='H')\n\nIn [110]: tdi = pd.timedelta_range('1D', periods=2)\n\nIn [111]: tdi - np.array([2 * tdi.freq, 1 * tdi.freq])\nOut[111]: TimedeltaIndex(['-1 days', '1 days'], dtype='timedelta64[ns]', freq=None)\n\nIn [112]: dti = pd.date_range('2001-01-01', periods=2, freq='7D')\n\nIn [113]: dti + pd.Index([1 * dti.freq, 2 * dti.freq])\nOut[113]: DatetimeIndex(['2001-01-08', '2001-01-22'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [3]: pd.DatetimeIndex([946684800000000000], tz=\"US/Central\")\n/bin/ipython:1: FutureWarning:\n Passing integer-dtype data and a timezone to DatetimeIndex. Integer values\n will be interpreted differently in a future version of pandas. Previously,\n these were viewed as datetime64[ns] values representing the wall time\n *in the specified timezone*. In the future, these will be viewed as\n datetime64[ns] values representing the wall time *in UTC*. This is similar\n to a nanosecond-precision UNIX epoch. To accept the future behavior, use\n\n pd.to_datetime(integer_data, utc=True).tz_convert(tz)\n\n To keep the previous behavior, use\n\n pd.to_datetime(integer_data).tz_localize(tz)\n\n #!/bin/python3\n Out[3]: DatetimeIndex(['2000-01-01 00:00:00-06:00'], dtype='datetime64[ns, US/Central]', freq=None) \n```", "```py\nIn [99]: pd.to_datetime([946684800000000000], utc=True).tz_convert('US/Central')\nOut[99]: DatetimeIndex(['1999-12-31 18:00:00-06:00'], dtype='datetime64[ns, US/Central]', freq=None) \n```", "```py\nIn [100]: pd.to_datetime([946684800000000000]).tz_localize('US/Central')\nOut[100]: DatetimeIndex(['2000-01-01 00:00:00-06:00'], dtype='datetime64[ns, US/Central]', freq=None) \n```", "```py\nIn [101]: ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n\nIn [102]: ser\nOut[102]: \n0   2000-01-01 00:00:00+01:00\n1   2000-01-02 00:00:00+01:00\nLength: 2, dtype: datetime64[ns, CET] \n```", "```py\nIn [8]: np.asarray(ser)\n/bin/ipython:1: FutureWarning: Converting timezone-aware DatetimeArray to timezone-naive\n      ndarray with 'datetime64[ns]' dtype. In the future, this will return an ndarray\n      with 'object' dtype where each element is a 'pandas.Timestamp' with the correct 'tz'.\n\n        To accept the future behavior, pass 'dtype=object'.\n        To keep the old behavior, pass 'dtype=\"datetime64[ns]\"'.\n  #!/bin/python3\nOut[8]:\narray(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n      dtype='datetime64[ns]') \n```", "```py\nIn [103]: np.asarray(ser, dtype='datetime64[ns]')\nOut[103]: \narray(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n dtype='datetime64[ns]') \n```", "```py\n# New behavior\nIn [104]: np.asarray(ser, dtype=object)\nOut[104]: \narray([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n Timestamp('2000-01-02 00:00:00+0100', tz='CET')], dtype=object) \n```", "```py\nIn [105]: ser.to_numpy()\nOut[105]: \narray([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n Timestamp('2000-01-02 00:00:00+0100', tz='CET')], dtype=object)\n\nIn [106]: ser.to_numpy(dtype=\"datetime64[ns]\")\nOut[106]: \narray(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n dtype='datetime64[ns]') \n```", "```py\nIn [5]: ts = pd.Timestamp('1994-05-06 12:15:16', freq=pd.offsets.Hour())\nIn [6]: ts + 2\nOut[6]: Timestamp('1994-05-06 14:15:16', freq='H')\n\nIn [7]: tdi = pd.timedelta_range('1D', periods=2)\nIn [8]: tdi - np.array([2, 1])\nOut[8]: TimedeltaIndex(['-1 days', '1 days'], dtype='timedelta64[ns]', freq=None)\n\nIn [9]: dti = pd.date_range('2001-01-01', periods=2, freq='7D')\nIn [10]: dti + pd.Index([1, 2])\nOut[10]: DatetimeIndex(['2001-01-08', '2001-01-22'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [108]: ts = pd.Timestamp('1994-05-06 12:15:16', freq=pd.offsets.Hour())\n\nIn[109]: ts + 2 * ts.freq\nOut[109]: Timestamp('1994-05-06 14:15:16', freq='H')\n\nIn [110]: tdi = pd.timedelta_range('1D', periods=2)\n\nIn [111]: tdi - np.array([2 * tdi.freq, 1 * tdi.freq])\nOut[111]: TimedeltaIndex(['-1 days', '1 days'], dtype='timedelta64[ns]', freq=None)\n\nIn [112]: dti = pd.date_range('2001-01-01', periods=2, freq='7D')\n\nIn [113]: dti + pd.Index([1 * dti.freq, 2 * dti.freq])\nOut[113]: DatetimeIndex(['2001-01-08', '2001-01-22'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [3]: pd.DatetimeIndex([946684800000000000], tz=\"US/Central\")\n/bin/ipython:1: FutureWarning:\n Passing integer-dtype data and a timezone to DatetimeIndex. Integer values\n will be interpreted differently in a future version of pandas. Previously,\n these were viewed as datetime64[ns] values representing the wall time\n *in the specified timezone*. In the future, these will be viewed as\n datetime64[ns] values representing the wall time *in UTC*. This is similar\n to a nanosecond-precision UNIX epoch. To accept the future behavior, use\n\n pd.to_datetime(integer_data, utc=True).tz_convert(tz)\n\n To keep the previous behavior, use\n\n pd.to_datetime(integer_data).tz_localize(tz)\n\n #!/bin/python3\n Out[3]: DatetimeIndex(['2000-01-01 00:00:00-06:00'], dtype='datetime64[ns, US/Central]', freq=None) \n```", "```py\nIn [99]: pd.to_datetime([946684800000000000], utc=True).tz_convert('US/Central')\nOut[99]: DatetimeIndex(['1999-12-31 18:00:00-06:00'], dtype='datetime64[ns, US/Central]', freq=None) \n```", "```py\nIn [100]: pd.to_datetime([946684800000000000]).tz_localize('US/Central')\nOut[100]: DatetimeIndex(['2000-01-01 00:00:00-06:00'], dtype='datetime64[ns, US/Central]', freq=None) \n```", "```py\nIn [101]: ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n\nIn [102]: ser\nOut[102]: \n0   2000-01-01 00:00:00+01:00\n1   2000-01-02 00:00:00+01:00\nLength: 2, dtype: datetime64[ns, CET] \n```", "```py\nIn [8]: np.asarray(ser)\n/bin/ipython:1: FutureWarning: Converting timezone-aware DatetimeArray to timezone-naive\n      ndarray with 'datetime64[ns]' dtype. In the future, this will return an ndarray\n      with 'object' dtype where each element is a 'pandas.Timestamp' with the correct 'tz'.\n\n        To accept the future behavior, pass 'dtype=object'.\n        To keep the old behavior, pass 'dtype=\"datetime64[ns]\"'.\n  #!/bin/python3\nOut[8]:\narray(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n      dtype='datetime64[ns]') \n```", "```py\nIn [103]: np.asarray(ser, dtype='datetime64[ns]')\nOut[103]: \narray(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n dtype='datetime64[ns]') \n```", "```py\n# New behavior\nIn [104]: np.asarray(ser, dtype=object)\nOut[104]: \narray([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n Timestamp('2000-01-02 00:00:00+0100', tz='CET')], dtype=object) \n```", "```py\nIn [105]: ser.to_numpy()\nOut[105]: \narray([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n Timestamp('2000-01-02 00:00:00+0100', tz='CET')], dtype=object)\n\nIn [106]: ser.to_numpy(dtype=\"datetime64[ns]\")\nOut[106]: \narray(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n dtype='datetime64[ns]') \n```"]