- en: YOLO-World Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: YOLO-World 模型
- en: 原文：[`docs.ultralytics.com/models/yolo-world/`](https://docs.ultralytics.com/models/yolo-world/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/models/yolo-world/`](https://docs.ultralytics.com/models/yolo-world/)
- en: The YOLO-World Model introduces an advanced, real-time [Ultralytics](https://ultralytics.com)
    YOLOv8-based approach for Open-Vocabulary Detection tasks. This innovation enables
    the detection of any object within an image based on descriptive texts. By significantly
    lowering computational demands while preserving competitive performance, YOLO-World
    emerges as a versatile tool for numerous vision-based applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO-World 模型引入了基于 Ultralytics YOLOv8 的先进实时方法，用于开放词汇检测任务。该创新能够根据描述性文本在图像中检测任何对象。通过显著降低计算需求，同时保持竞争性能，YOLO-World
    成为多种基于视觉的应用的多功能工具。
- en: '[`www.youtube.com/embed/cfTKj96TjSE`](https://www.youtube.com/embed/cfTKj96TjSE)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[`www.youtube.com/embed/cfTKj96TjSE`](https://www.youtube.com/embed/cfTKj96TjSE)'
- en: '**Watch:** YOLO World training workflow on custom dataset'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**观看：** YOLO World 自定义数据集的训练工作流程'
- en: '![YOLO-World Model architecture overview](img/87b4fbb7a6b841ad8f9e14443e030b03.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![YOLO-World 模型架构概述](img/87b4fbb7a6b841ad8f9e14443e030b03.png)'
- en: Overview
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概览
- en: YOLO-World tackles the challenges faced by traditional Open-Vocabulary detection
    models, which often rely on cumbersome Transformer models requiring extensive
    computational resources. These models' dependence on pre-defined object categories
    also restricts their utility in dynamic scenarios. YOLO-World revitalizes the
    YOLOv8 framework with open-vocabulary detection capabilities, employing vision-language
    modeling and pre-training on expansive datasets to excel at identifying a broad
    array of objects in zero-shot scenarios with unmatched efficiency.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO-World 解决了传统开放词汇检测模型面临的挑战，这些模型通常依赖于耗费大量计算资源的繁琐 Transformer 模型。这些模型对预定义的物体类别的依赖也限制了它们在动态场景中的实用性。YOLO-World
    通过视觉语言建模和在大规模数据集上的预训练，在零-shot场景中卓越地识别广泛对象。
- en: Key Features
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主要特点
- en: '**Real-time Solution:** Harnessing the computational speed of CNNs, YOLO-World
    delivers a swift open-vocabulary detection solution, catering to industries in
    need of immediate results.'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实时解决方案：** 利用 CNN 的计算速度，YOLO-World 提供了快速的开放词汇检测解决方案，满足需要即时结果的行业需求。'
- en: '**Efficiency and Performance:** YOLO-World slashes computational and resource
    requirements without sacrificing performance, offering a robust alternative to
    models like SAM but at a fraction of the computational cost, enabling real-time
    applications.'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**效率与性能：** YOLO-World 在不牺牲性能的情况下大幅削减了计算和资源需求，提供了 SAM 等模型的强大替代方案，但计算成本仅为其一小部分，支持实时应用。'
- en: '**Inference with Offline Vocabulary:** YOLO-World introduces a "prompt-then-detect"
    strategy, employing an offline vocabulary to enhance efficiency further. This
    approach enables the use of custom prompts computed apriori, including captions
    or categories, to be encoded and stored as offline vocabulary embeddings, streamlining
    the detection process.'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**离线词汇推断：** YOLO-World 引入了一种“提示-检测”策略，采用离线词汇进一步提升效率。这种方法允许使用预先计算的自定义提示，如标题或类别，作为离线词汇嵌入进行编码和存储，从而简化检测过程。'
- en: '**Powered by YOLOv8:** Built upon Ultralytics YOLOv8, YOLO-World leverages
    the latest advancements in real-time object detection to facilitate open-vocabulary
    detection with unparalleled accuracy and speed.'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**由 YOLOv8 驱动：** 基于 Ultralytics YOLOv8 构建的 YOLO-World，利用实时目标检测的最新进展，实现了开放词汇检测，具有无与伦比的准确性和速度。'
- en: '**Benchmark Excellence:** YOLO-World outperforms existing open-vocabulary detectors,
    including MDETR and GLIP series, in terms of speed and efficiency on standard
    benchmarks, showcasing YOLOv8''s superior capability on a single NVIDIA V100 GPU.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**基准卓越：** YOLO-World 在标准基准测试中表现优于现有的开放词汇检测器，包括 MDETR 和 GLIP 系列，展示了 YOLOv8 在单个
    NVIDIA V100 GPU 上的卓越能力。'
- en: '**Versatile Applications:** YOLO-World''s innovative approach unlocks new possibilities
    for a multitude of vision tasks, delivering speed improvements by orders of magnitude
    over existing methods.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多用途应用：** YOLO-World 的创新方法为多种视觉任务开辟了新的可能性，大幅提升了速度，比现有方法快上数个数量级。'
- en: Available Models, Supported Tasks, and Operating Modes
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可用模型、支持的任务和操作模式
- en: This section details the models available with their specific pre-trained weights,
    the tasks they support, and their compatibility with various operating modes such
    as Inference, Validation, Training, and Export, denoted by ✅ for supported modes
    and ❌ for unsupported modes.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 此部分详细介绍了具体预训练权重的可用模型、它们支持的任务以及它们与各种操作模式的兼容性，推理、验证、训练和导出分别用✅表示支持和❌表示不支持。
- en: Note
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Note
- en: All the YOLOv8-World weights have been directly migrated from the official [YOLO-World](https://github.com/AILab-CVC/YOLO-World)
    repository, highlighting their excellent contributions.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 所有YOLOv8-World的权重都直接从官方[YOLO-World](https://github.com/AILab-CVC/YOLO-World)存储库迁移，突显了它们的卓越贡献。
- en: '| Model Type | Pre-trained Weights | Tasks Supported | Inference | Validation
    | Training | Export |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| Model Type | 预训练权重 | 支持的任务 | 推理 | 验证 | 训练 | 导出 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| YOLOv8s-world | [yolov8s-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-world.pt)
    | Object Detection | ✅ | ✅ | ✅ | ❌ |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8s-world | [yolov8s-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-world.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ❌ |'
- en: '| YOLOv8s-worldv2 | [yolov8s-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-worldv2.pt)
    | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8s-worldv2 | [yolov8s-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-worldv2.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ✅ |'
- en: '| YOLOv8m-world | [yolov8m-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-world.pt)
    | Object Detection | ✅ | ✅ | ✅ | ❌ |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8m-world | [yolov8m-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-world.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ❌ |'
- en: '| YOLOv8m-worldv2 | [yolov8m-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-worldv2.pt)
    | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8m-worldv2 | [yolov8m-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-worldv2.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ✅ |'
- en: '| YOLOv8l-world | [yolov8l-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-world.pt)
    | Object Detection | ✅ | ✅ | ✅ | ❌ |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8l-world | [yolov8l-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-world.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ❌ |'
- en: '| YOLOv8l-worldv2 | [yolov8l-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-worldv2.pt)
    | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8l-worldv2 | [yolov8l-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-worldv2.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ✅ |'
- en: '| YOLOv8x-world | [yolov8x-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-world.pt)
    | Object Detection | ✅ | ✅ | ✅ | ❌ |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8x-world | [yolov8x-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-world.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ❌ |'
- en: '| YOLOv8x-worldv2 | [yolov8x-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-worldv2.pt)
    | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8x-worldv2 | [yolov8x-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-worldv2.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ✅ |'
- en: Zero-shot Transfer on COCO Dataset
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在COCO数据集上进行零-shot转移
- en: '| Model Type | mAP | mAP50 | mAP75 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| Model Type | mAP | mAP50 | mAP75 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| yolov8s-world | 37.4 | 52.0 | 40.6 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| yolov8s-world | 37.4 | 52.0 | 40.6 |'
- en: '| yolov8s-worldv2 | 37.7 | 52.2 | 41.0 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| yolov8s-worldv2 | 37.7 | 52.2 | 41.0 |'
- en: '| yolov8m-world | 42.0 | 57.0 | 45.6 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| yolov8m-world | 42.0 | 57.0 | 45.6 |'
- en: '| yolov8m-worldv2 | 43.0 | 58.4 | 46.8 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| yolov8m-worldv2 | 43.0 | 58.4 | 46.8 |'
- en: '| yolov8l-world | 45.7 | 61.3 | 49.8 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| yolov8l-world | 45.7 | 61.3 | 49.8 |'
- en: '| yolov8l-worldv2 | 45.8 | 61.3 | 49.8 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| yolov8l-worldv2 | 45.8 | 61.3 | 49.8 |'
- en: '| yolov8x-world | 47.0 | 63.0 | 51.2 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| yolov8x-world | 47.0 | 63.0 | 51.2 |'
- en: '| yolov8x-worldv2 | 47.1 | 62.8 | 51.4 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| yolov8x-worldv2 | 47.1 | 62.8 | 51.4 |'
- en: Usage Examples
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用法示例
- en: The YOLO-World models are easy to integrate into your Python applications. Ultralytics
    provides user-friendly Python API and CLI commands to streamline development.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO-World模型易于集成到您的Python应用程序中。Ultralytics提供了用户友好的Python API和CLI命令，以简化开发。
- en: Train Usage
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练用法
- en: Tip
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Tip
- en: We strongly recommend to use `yolov8-worldv2` model for custom training, because
    it supports deterministic training and also easy to export other formats i.e onnx/tensorrt.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 强烈推荐使用`yolov8-worldv2`模型进行自定义训练，因为它支持确定性训练，并且容易导出其他格式，例如onnx/tensorrt。
- en: 'Object detection is straightforward with the `train` method, as illustrated
    below:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`train`方法进行目标检测非常简单，如下所示：
- en: Example
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: 'PyTorch pretrained `*.pt` models as well as configuration `*.yaml` files can
    be passed to the `YOLOWorld()` class to create a model instance in python:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将预训练的PyTorch `*.pt`模型以及配置`*.yaml`文件传递给`YOLOWorld()`类，在Python中创建模型实例：
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Predict Usage
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测用法
- en: 'Object detection is straightforward with the `predict` method, as illustrated
    below:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`predict`方法进行目标检测非常简单，如下所示：
- en: Example
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This snippet demonstrates the simplicity of loading a pre-trained model and
    running a prediction on an image.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码片段展示了加载预训练模型并在图像上进行预测的简易性。
- en: Val Usage
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Val 使用
- en: 'Model validation on a dataset is streamlined as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集上进行模型验证的简化步骤如下：
- en: Example
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Track Usage
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跟踪使用情况
- en: 'Object tracking with YOLO-World model on a video/images is streamlined as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用YOLO-World模型在视频/图像上进行对象跟踪的简化步骤如下：
- en: Example
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The YOLO-World models provided by Ultralytics come pre-configured with COCO
    dataset categories as part of their offline vocabulary, enhancing efficiency for
    immediate application. This integration allows the YOLOv8-World models to directly
    recognize and predict the 80 standard categories defined in the COCO dataset without
    requiring additional setup or customization.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由Ultralytics提供的YOLO-World模型已预配置为离线词汇表的COCO数据集类别的一部分，提升了立即应用的效率。这种集成使得YOLOv8-World模型能直接识别和预测COCO数据集定义的80个标准类别，无需额外的设置或定制。
- en: Set prompts
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置提示
- en: '![YOLO-World prompt class names overview](img/37d7ad91fe35a588f5424187c10a95ed.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![YOLO-World提示类名概述](img/37d7ad91fe35a588f5424187c10a95ed.png)'
- en: The YOLO-World framework allows for the dynamic specification of classes through
    custom prompts, empowering users to tailor the model to their specific needs **without
    retraining**. This feature is particularly useful for adapting the model to new
    domains or specific tasks that were not originally part of the training data.
    By setting custom prompts, users can essentially guide the model's focus towards
    objects of interest, enhancing the relevance and accuracy of the detection results.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO-World框架允许通过自定义提示动态指定类别，让用户根据特定需求定制模型，**无需重新训练**。此功能特别适用于将模型适应原始训练数据中未包含的新领域或特定任务。通过设置自定义提示，用户可以引导模型关注感兴趣的对象，从而提高检测结果的相关性和准确性。
- en: 'For instance, if your application only requires detecting ''person'' and ''bus''
    objects, you can specify these classes directly:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您的应用程序只需要检测'人'和'公交车'对象，您可以直接指定这些类别：
- en: Example
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE8]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can also save a model after setting custom classes. By doing this you create
    a version of the YOLO-World model that is specialized for your specific use case.
    This process embeds your custom class definitions directly into the model file,
    making the model ready to use with your specified classes without further adjustments.
    Follow these steps to save and load your custom YOLOv8 model:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置自定义类后，您还可以保存模型。通过这样做，您可以创建一个专门针对特定用例的YOLO-World模型版本。此过程将您的自定义类定义直接嵌入到模型文件中，使得模型准备好使用您指定的类别，无需进一步调整。按照以下步骤保存和加载您的自定义YOLOv8模型：
- en: Example
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: 'First load a YOLO-World model, set custom classes for it and save it:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先加载一个 YOLO-World 模型，为其设置自定义类别并保存：
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After saving, the custom_yolov8s.pt model behaves like any other pre-trained
    YOLOv8 model but with a key difference: it is now optimized to detect only the
    classes you have defined. This customization can significantly improve detection
    performance and efficiency for your specific application scenarios.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 保存后，custom_yolov8s.pt 模型与任何其他预训练的 YOLOv8 模型一样工作，但有一个关键区别：它现在优化为仅检测您定义的类别。这种定制可以显著提高特定应用场景中的检测性能和效率。
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Benefits of Saving with Custom Vocabulary
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保存具有自定义词汇的好处
- en: '**Efficiency**: Streamlines the detection process by focusing on relevant objects,
    reducing computational overhead and speeding up inference.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**：通过专注于相关对象，简化检测过程，减少计算开销并加快推理速度。'
- en: '**Flexibility**: Allows for easy adaptation of the model to new or niche detection
    tasks without the need for extensive retraining or data collection.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活性**：允许轻松调整模型以适应新的或小众检测任务，无需进行大量的重新训练或数据收集。'
- en: '**Simplicity**: Simplifies deployment by eliminating the need to repeatedly
    specify custom classes at runtime, making the model directly usable with its embedded
    vocabulary.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简易性**：通过在运行时消除重复指定自定义类的需要，简化部署，使模型直接可用于其内置词汇表。'
- en: '**Performance**: Enhances detection accuracy for specified classes by focusing
    the model''s attention and resources on recognizing the defined objects.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能**：通过专注于识别定义的对象，增强特定类别的检测精度，优化模型的注意力和资源分配。'
- en: This approach provides a powerful means of customizing state-of-the-art object
    detection models for specific tasks, making advanced AI more accessible and applicable
    to a broader range of practical applications.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法为定制最先进的目标检测模型提供了强大手段，使得先进的 AI 技术更加易于访问和应用于更广泛的实际应用领域。
- en: Reproduce official results from scratch(Experimental)
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从零开始重现官方结果（实验性）
- en: Prepare datasets
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备数据集
- en: Train data
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据
- en: '| Dataset | Type | Samples | Boxes | Annotation Files |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 类型 | 样本数 | 盒数 | 注释文件 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| [Objects365v1](https://opendatalab.com/OpenDataLab/Objects365_v1) | Detection
    | 609k | 9621k | [objects365_train.json](https://opendatalab.com/OpenDataLab/Objects365_v1)
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| [Objects365v1](https://opendatalab.com/OpenDataLab/Objects365_v1) | 检测 |
    609k | 9621k | [objects365_train.json](https://opendatalab.com/OpenDataLab/Objects365_v1)
    |'
- en: '| [GQA](https://nlp.stanford.edu/data/gqa/images.zip) | Grounding | 621k |
    3681k | [final_mixed_train_no_coco.json](https://huggingface.co/GLIPModel/GLIP/blob/main/mdetr_annotations/final_mixed_train_no_coco.json)
    |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| [GQA](https://nlp.stanford.edu/data/gqa/images.zip) | 确定性 | 621k | 3681k
    | [final_mixed_train_no_coco.json](https://huggingface.co/GLIPModel/GLIP/blob/main/mdetr_annotations/final_mixed_train_no_coco.json)
    |'
- en: '| [Flickr30k](https://shannon.cs.illinois.edu/DenotationGraph/) | Grounding
    | 149k | 641k | [final_flickr_separateGT_train.json](https://huggingface.co/GLIPModel/GLIP/blob/main/mdetr_annotations/final_flickr_separateGT_train.json)
    |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| [Flickr30k](https://shannon.cs.illinois.edu/DenotationGraph/) | 确定性 | 149k
    | 641k | [final_flickr_separateGT_train.json](https://huggingface.co/GLIPModel/GLIP/blob/main/mdetr_annotations/final_flickr_separateGT_train.json)
    |'
- en: Val data
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证数据
- en: '| Dataset | Type | Annotation Files |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 类型 | 注释文件 |'
- en: '| --- | --- | --- |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| [LVIS minival](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/lvis.yaml)
    | Detection | [minival.txt](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/lvis.yaml)
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| [LVIS minival](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/lvis.yaml)
    | 检测 | [minival.txt](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/lvis.yaml)
    |'
- en: Launch training from scratch
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从零开始启动训练
- en: Note
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`WorldTrainerFromScratch` is highly customized to allow training yolo-world
    models on both detection datasets and grounding datasets simultaneously. More
    details please checkout [ultralytics.model.yolo.world.train_world.py](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/yolo/world/train_world.py).'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`WorldTrainerFromScratch` 极大地定制化，允许同时在检测数据集和确定性数据集上训练 yolo-world 模型。更多细节请查看
    [ultralytics.model.yolo.world.train_world.py](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/yolo/world/train_world.py)。'
- en: Example
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE11]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Citations and Acknowledgements
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引用和致谢
- en: 'We extend our gratitude to the [Tencent AILab Computer Vision Center](https://ai.tencent.com/)
    for their pioneering work in real-time open-vocabulary object detection with YOLO-World:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对 [腾讯 AI 实验室计算机视觉中心](https://ai.tencent.com/) 在实时开放词汇目标检测领域与 YOLO-World 的开创性工作表示感谢：
- en: '[PRE12]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: For further reading, the original YOLO-World paper is available on [arXiv](https://arxiv.org/pdf/2401.17270v2.pdf).
    The project's source code and additional resources can be accessed via their [GitHub
    repository](https://github.com/AILab-CVC/YOLO-World). We appreciate their commitment
    to advancing the field and sharing their valuable insights with the community.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 想进一步阅读，YOLO-World 的原始论文可在 [arXiv](https://arxiv.org/pdf/2401.17270v2.pdf) 获得。项目的源代码和其他资源可以通过他们的
    [GitHub 仓库](https://github.com/AILab-CVC/YOLO-World) 获取。我们感谢他们在推动领域进步和与社区分享宝贵见解的努力。
- en: FAQ
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题解答
- en: What is the YOLO-World model and how does it work?
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: YOLO-World 模型是什么以及其工作原理？
- en: The YOLO-World model is an advanced, real-time object detection approach based
    on the Ultralytics YOLOv8 framework. It excels in Open-Vocabulary Detection tasks
    by identifying objects within an image based on descriptive texts. Using vision-language
    modeling and pre-training on large datasets, YOLO-World achieves high efficiency
    and performance with significantly reduced computational demands, making it ideal
    for real-time applications across various industries.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO-World 模型是基于 Ultralytics YOLOv8 框架的先进实时目标检测方法。它通过识别基于描述性文本的图像内对象，在开放词汇检测任务中表现出色。利用视觉语言建模和在大型数据集上的预训练，YOLO-World
    实现了高效和性能，并显著减少了计算需求，非常适合各行业的实时应用。
- en: How does YOLO-World handle inference with custom prompts?
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: YOLO-World 如何处理自定义提示的推理？
- en: 'YOLO-World supports a "prompt-then-detect" strategy, which utilizes an offline
    vocabulary to enhance efficiency. Custom prompts like captions or specific object
    categories are pre-encoded and stored as offline vocabulary embeddings. This approach
    streamlines the detection process without the need for retraining. You can dynamically
    set these prompts within the model to tailor it to specific detection tasks, as
    shown below:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO-World支持“提示-检测”策略，利用离线词汇表增强效率。像标题或特定对象类别这样的自定义提示会被预先编码并存储为离线词汇表嵌入。这种方法简化了检测过程，无需重新训练即可动态设置这些提示以适应特定的检测任务，如下所示：
- en: '[PRE13]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Why should I choose YOLO-World over traditional Open-Vocabulary detection models?
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么应该选择YOLO-World而不是传统的开放词汇检测模型？
- en: 'YOLO-World provides several advantages over traditional Open-Vocabulary detection
    models:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO-World相比传统的开放词汇检测模型提供了多个优势：
- en: '**Real-Time Performance:** It leverages the computational speed of CNNs to
    offer quick, efficient detection.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时性能：** 它利用CNN的计算速度提供快速、高效的检测。'
- en: '**Efficiency and Low Resource Requirement:** YOLO-World maintains high performance
    while significantly reducing computational and resource demands.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高效性和低资源需求：** YOLO-World在显著减少计算和资源需求的同时，保持了高性能。'
- en: '**Customizable Prompts:** The model supports dynamic prompt setting, allowing
    users to specify custom detection classes without retraining.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可定制的提示：** 模型支持动态提示设置，允许用户指定自定义检测类别而无需重新训练。'
- en: '**Benchmark Excellence:** It outperforms other open-vocabulary detectors like
    MDETR and GLIP in both speed and efficiency on standard benchmarks.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基准卓越性：** 在标准基准测试中，它在速度和效率上均优于其他开放词汇检测器，如MDETR和GLIP。'
- en: How do I train a YOLO-World model on my dataset?
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何在我的数据集上训练YOLO-World模型？
- en: 'Training a YOLO-World model on your dataset is straightforward through the
    provided Python API or CLI commands. Here''s how to start training using Python:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用提供的Python API或CLI命令，训练YOLO-World模型的数据集非常简单。以下是如何开始使用Python进行训练的示例：
- en: '[PRE14]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Or using CLI:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 或者使用CLI：
- en: '[PRE15]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: What are the available pre-trained YOLO-World models and their supported tasks?
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可用的预训练YOLO-World模型及其支持的任务是什么？
- en: 'Ultralytics offers multiple pre-trained YOLO-World models supporting various
    tasks and operating modes:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics提供多个预训练的YOLO-World模型，支持各种任务和操作模式：
- en: '| Model Type | Pre-trained Weights | Tasks Supported | Inference | Validation
    | Training | Export |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 模型类型 | 预训练权重 | 支持的任务 | 推断 | 验证 | 训练 | 导出 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| YOLOv8s-world | [yolov8s-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-world.pt)
    | Object Detection | ✅ | ✅ | ✅ | ❌ |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8s-world | [yolov8s-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-world.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ❌ |'
- en: '| YOLOv8s-worldv2 | [yolov8s-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-worldv2.pt)
    | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8s-worldv2 | [yolov8s-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-worldv2.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ✅ |'
- en: '| YOLOv8m-world | [yolov8m-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-world.pt)
    | Object Detection | ✅ | ✅ | ✅ | ❌ |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8m-world | [yolov8m-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-world.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ❌ |'
- en: '| YOLOv8m-worldv2 | [yolov8m-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-worldv2.pt)
    | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8m-worldv2 | [yolov8m-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-worldv2.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ✅ |'
- en: '| YOLOv8l-world | [yolov8l-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-world.pt)
    | Object Detection | ✅ | ✅ | ✅ | ❌ |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8l-world | [yolov8l-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-world.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ❌ |'
- en: '| YOLOv8l-worldv2 | [yolov8l-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-worldv2.pt)
    | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8l-worldv2 | [yolov8l-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-worldv2.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ✅ |'
- en: '| YOLOv8x-world | [yolov8x-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-world.pt)
    | Object Detection | ✅ | ✅ | ✅ | ❌ |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8x-world | [yolov8x-world.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-world.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ❌ |'
- en: '| YOLOv8x-worldv2 | [yolov8x-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-worldv2.pt)
    | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| YOLOv8x-worldv2 | [yolov8x-worldv2.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-worldv2.pt)
    | 目标检测 | ✅ | ✅ | ✅ | ✅ |'
- en: How do I reproduce the official results of YOLO-World from scratch?
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我如何从头开始复现 YOLO-World 的官方结果？
- en: 'To reproduce the official results from scratch, you need to prepare the datasets
    and launch the training using the provided code. The training procedure involves
    creating a data dictionary and running the `train` method with a custom trainer:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 要从头开始复现官方结果，您需要准备数据集并使用提供的代码启动训练。训练过程涉及创建数据字典，并使用自定义训练器运行`train`方法：
- en: '[PRE16]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
