["```py\n>>> import numpy as np\n>>> x = np.array([1, 2, 5.0, 8])\n>>> x.__array_interface__\n{'data': (94708397920832, False), 'strides': None, 'descr': [('', '<f8')], 'typestr': '<f8', 'shape': (4,), 'version': 3} \n```", "```py\n>>> class wrapper():\n...     pass\n...\n>>> arr = np.array([1, 2, 3, 4])\n>>> buf = arr.__array_interface__\n>>> buf\n{'data': (140497590272032, False), 'strides': None, 'descr': [('', '<i8')], 'typestr': '<i8', 'shape': (4,), 'version': 3}\n>>> buf['shape'] = (2, 2)\n>>> w = wrapper()\n>>> w.__array_interface__ = buf\n>>> new_arr = np.array(w, copy=False)\n>>> new_arr\narray([[1, 2],\n [3, 4]]) \n```", "```py\n>>> new_arr[0, 0] = 1000\n>>> new_arr\narray([[1000,    2],\n [   3,    4]])\n>>> arr\narray([1000, 2, 3, 4]) \n```", "```py\n>>> import numpy as np\n>>> def f(x):\n...     return np.mean(np.exp(x)) \n```", "```py\n>>> x = np.array([1, 2, 3, 4])\n>>> f(x)\n21.1977562209304 \n```", "```py\n>>> import pandas as pd\n>>> ser = pd.Series([1, 2, 3, 4])\n>>> type(ser)\npandas.core.series.Series \n```", "```py\n>>> np.exp(ser)\n 0     2.718282\n 1     7.389056\n 2    20.085537\n 3    54.598150\n dtype: float64\n>>> np.sin(ser)\n 0    0.841471\n 1    0.909297\n 2    0.141120\n 3   -0.756802\n dtype: float64 \n```", "```py\n>>> np.add(ser, np.array([5, 6, 7, 8]))\n 0     6\n 1     8\n 2    10\n 3    12\n dtype: int64\n>>> f(ser)\n21.1977562209304\n>>> result = ser.__array__()\n>>> type(result)\nnumpy.ndarray \n```", "```py\n>>> import torch\n>>> data = [[1, 2],[3, 4]]\n>>> x_np = np.array(data)\n>>> x_tensor = torch.tensor(data) \n```", "```py\n>>> x_np\narray([[1, 2],\n [3, 4]])\n>>> x_tensor\ntensor([[1, 2],\n [3, 4]]) \n```", "```py\n>>> np.exp(x_tensor)\ntensor([[ 2.7183,  7.3891],\n [20.0855, 54.5982]], dtype=torch.float64) \n```", "```py\n>>> import torch\n>>> t = torch.arange(4)\n>>> np.abs(t)\ntensor([0, 1, 2, 3]) \n```", "```py\n>>> import cupy as cp\n>>> x_gpu = cp.array([1, 2, 3, 4]) \n```", "```py\n>>> np.mean(np.exp(x_gpu))\narray(21.19775622) \n```", "```py\n>>> arr = cp.random.randn(1, 2, 3, 4).astype(cp.float32)\n>>> result = np.sum(arr)\n>>> print(type(result))\n<class 'cupy._core.core.ndarray'> \n```", "```py\n>>> a = np.random.randn(100, 100)\n>>> a_gpu = cp.asarray(a)\n>>> qr_gpu = np.linalg.qr(a_gpu) \n```", "```py\n>>> import dask.array as da\n>>> x = da.random.normal(1, 0.1, size=(20, 20), chunks=(10, 10))\n>>> np.mean(np.exp(x))\ndask.array<mean_agg-aggregate, shape=(), dtype=float64, chunksize=(), chunktype=numpy.ndarray>\n>>> np.mean(np.exp(x)).compute()\n5.090097550553843 \n```", "```py\n>>> import torch\n>>> x_torch = torch.arange(5)\n>>> x_torch\ntensor([0, 1, 2, 3, 4])\n>>> x_np = np.from_dlpack(x_torch)\n>>> x_np\narray([0, 1, 2, 3, 4])\n>>> # note that x_np is a view of x_torch\n>>> x_torch[1] = 100\n>>> x_torch\ntensor([  0, 100,   2,   3,   4])\n>>> x_np\narray([  0, 100,   2,   3,   4]) \n```", "```py\n>>> x.flags.writeable\nFalse\n>>> x_np[1] = 1\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: assignment destination is read-only \n```", "```py\n>>> x_np_copy = x_np.copy()\n>>> x_np_copy.sort()  # works \n```", "```py\n>>> x_torch = torch.arange(5, device='cuda')\n>>> np.from_dlpack(x_torch)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nRuntimeError: Unsupported device in DLTensor. \n```", "```py\n>>> x_torch = torch.arange(5, device='cuda')\n>>> x_cupy = cupy.from_dlpack(x_torch) \n```", "```py\n>>> x_np = np.arange(5)\n>>> x_torch = torch.from_dlpack(x_np) \n```", "```py\n>>> x_np = np.arange(5)\n>>> x_np.flags.writeable = False\n>>> torch.from_dlpack(x_np)  \nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \".../site-packages/torch/utils/dlpack.py\", line 63, in from_dlpack\n  dlpack = ext_tensor.__dlpack__()\nTypeError: NumPy currently only supports dlpack for writeable arrays \n```", "```py\n>>> import numpy as np\n>>> x = np.array([1, 2, 5.0, 8])\n>>> x.__array_interface__\n{'data': (94708397920832, False), 'strides': None, 'descr': [('', '<f8')], 'typestr': '<f8', 'shape': (4,), 'version': 3} \n```", "```py\n>>> class wrapper():\n...     pass\n...\n>>> arr = np.array([1, 2, 3, 4])\n>>> buf = arr.__array_interface__\n>>> buf\n{'data': (140497590272032, False), 'strides': None, 'descr': [('', '<i8')], 'typestr': '<i8', 'shape': (4,), 'version': 3}\n>>> buf['shape'] = (2, 2)\n>>> w = wrapper()\n>>> w.__array_interface__ = buf\n>>> new_arr = np.array(w, copy=False)\n>>> new_arr\narray([[1, 2],\n [3, 4]]) \n```", "```py\n>>> new_arr[0, 0] = 1000\n>>> new_arr\narray([[1000,    2],\n [   3,    4]])\n>>> arr\narray([1000, 2, 3, 4]) \n```", "```py\n>>> import numpy as np\n>>> x = np.array([1, 2, 5.0, 8])\n>>> x.__array_interface__\n{'data': (94708397920832, False), 'strides': None, 'descr': [('', '<f8')], 'typestr': '<f8', 'shape': (4,), 'version': 3} \n```", "```py\n>>> class wrapper():\n...     pass\n...\n>>> arr = np.array([1, 2, 3, 4])\n>>> buf = arr.__array_interface__\n>>> buf\n{'data': (140497590272032, False), 'strides': None, 'descr': [('', '<i8')], 'typestr': '<i8', 'shape': (4,), 'version': 3}\n>>> buf['shape'] = (2, 2)\n>>> w = wrapper()\n>>> w.__array_interface__ = buf\n>>> new_arr = np.array(w, copy=False)\n>>> new_arr\narray([[1, 2],\n [3, 4]]) \n```", "```py\n>>> new_arr[0, 0] = 1000\n>>> new_arr\narray([[1000,    2],\n [   3,    4]])\n>>> arr\narray([1000, 2, 3, 4]) \n```", "```py\n>>> import numpy as np\n>>> def f(x):\n...     return np.mean(np.exp(x)) \n```", "```py\n>>> x = np.array([1, 2, 3, 4])\n>>> f(x)\n21.1977562209304 \n```", "```py\n>>> import pandas as pd\n>>> ser = pd.Series([1, 2, 3, 4])\n>>> type(ser)\npandas.core.series.Series \n```", "```py\n>>> np.exp(ser)\n 0     2.718282\n 1     7.389056\n 2    20.085537\n 3    54.598150\n dtype: float64\n>>> np.sin(ser)\n 0    0.841471\n 1    0.909297\n 2    0.141120\n 3   -0.756802\n dtype: float64 \n```", "```py\n>>> np.add(ser, np.array([5, 6, 7, 8]))\n 0     6\n 1     8\n 2    10\n 3    12\n dtype: int64\n>>> f(ser)\n21.1977562209304\n>>> result = ser.__array__()\n>>> type(result)\nnumpy.ndarray \n```", "```py\n>>> import torch\n>>> data = [[1, 2],[3, 4]]\n>>> x_np = np.array(data)\n>>> x_tensor = torch.tensor(data) \n```", "```py\n>>> x_np\narray([[1, 2],\n [3, 4]])\n>>> x_tensor\ntensor([[1, 2],\n [3, 4]]) \n```", "```py\n>>> np.exp(x_tensor)\ntensor([[ 2.7183,  7.3891],\n [20.0855, 54.5982]], dtype=torch.float64) \n```", "```py\n>>> import torch\n>>> t = torch.arange(4)\n>>> np.abs(t)\ntensor([0, 1, 2, 3]) \n```", "```py\n>>> import cupy as cp\n>>> x_gpu = cp.array([1, 2, 3, 4]) \n```", "```py\n>>> np.mean(np.exp(x_gpu))\narray(21.19775622) \n```", "```py\n>>> arr = cp.random.randn(1, 2, 3, 4).astype(cp.float32)\n>>> result = np.sum(arr)\n>>> print(type(result))\n<class 'cupy._core.core.ndarray'> \n```", "```py\n>>> a = np.random.randn(100, 100)\n>>> a_gpu = cp.asarray(a)\n>>> qr_gpu = np.linalg.qr(a_gpu) \n```", "```py\n>>> import dask.array as da\n>>> x = da.random.normal(1, 0.1, size=(20, 20), chunks=(10, 10))\n>>> np.mean(np.exp(x))\ndask.array<mean_agg-aggregate, shape=(), dtype=float64, chunksize=(), chunktype=numpy.ndarray>\n>>> np.mean(np.exp(x)).compute()\n5.090097550553843 \n```", "```py\n>>> import torch\n>>> x_torch = torch.arange(5)\n>>> x_torch\ntensor([0, 1, 2, 3, 4])\n>>> x_np = np.from_dlpack(x_torch)\n>>> x_np\narray([0, 1, 2, 3, 4])\n>>> # note that x_np is a view of x_torch\n>>> x_torch[1] = 100\n>>> x_torch\ntensor([  0, 100,   2,   3,   4])\n>>> x_np\narray([  0, 100,   2,   3,   4]) \n```", "```py\n>>> x.flags.writeable\nFalse\n>>> x_np[1] = 1\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: assignment destination is read-only \n```", "```py\n>>> x_np_copy = x_np.copy()\n>>> x_np_copy.sort()  # works \n```", "```py\n>>> x_torch = torch.arange(5, device='cuda')\n>>> np.from_dlpack(x_torch)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nRuntimeError: Unsupported device in DLTensor. \n```", "```py\n>>> x_torch = torch.arange(5, device='cuda')\n>>> x_cupy = cupy.from_dlpack(x_torch) \n```", "```py\n>>> x_np = np.arange(5)\n>>> x_torch = torch.from_dlpack(x_np) \n```", "```py\n>>> x_np = np.arange(5)\n>>> x_np.flags.writeable = False\n>>> torch.from_dlpack(x_np)  \nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \".../site-packages/torch/utils/dlpack.py\", line 63, in from_dlpack\n  dlpack = ext_tensor.__dlpack__()\nTypeError: NumPy currently only supports dlpack for writeable arrays \n```", "```py\n>>> import pandas as pd\n>>> ser = pd.Series([1, 2, 3, 4])\n>>> type(ser)\npandas.core.series.Series \n```", "```py\n>>> np.exp(ser)\n 0     2.718282\n 1     7.389056\n 2    20.085537\n 3    54.598150\n dtype: float64\n>>> np.sin(ser)\n 0    0.841471\n 1    0.909297\n 2    0.141120\n 3   -0.756802\n dtype: float64 \n```", "```py\n>>> np.add(ser, np.array([5, 6, 7, 8]))\n 0     6\n 1     8\n 2    10\n 3    12\n dtype: int64\n>>> f(ser)\n21.1977562209304\n>>> result = ser.__array__()\n>>> type(result)\nnumpy.ndarray \n```", "```py\n>>> import torch\n>>> data = [[1, 2],[3, 4]]\n>>> x_np = np.array(data)\n>>> x_tensor = torch.tensor(data) \n```", "```py\n>>> x_np\narray([[1, 2],\n [3, 4]])\n>>> x_tensor\ntensor([[1, 2],\n [3, 4]]) \n```", "```py\n>>> np.exp(x_tensor)\ntensor([[ 2.7183,  7.3891],\n [20.0855, 54.5982]], dtype=torch.float64) \n```", "```py\n>>> import torch\n>>> t = torch.arange(4)\n>>> np.abs(t)\ntensor([0, 1, 2, 3]) \n```", "```py\n>>> import cupy as cp\n>>> x_gpu = cp.array([1, 2, 3, 4]) \n```", "```py\n>>> np.mean(np.exp(x_gpu))\narray(21.19775622) \n```", "```py\n>>> arr = cp.random.randn(1, 2, 3, 4).astype(cp.float32)\n>>> result = np.sum(arr)\n>>> print(type(result))\n<class 'cupy._core.core.ndarray'> \n```", "```py\n>>> a = np.random.randn(100, 100)\n>>> a_gpu = cp.asarray(a)\n>>> qr_gpu = np.linalg.qr(a_gpu) \n```", "```py\n>>> import dask.array as da\n>>> x = da.random.normal(1, 0.1, size=(20, 20), chunks=(10, 10))\n>>> np.mean(np.exp(x))\ndask.array<mean_agg-aggregate, shape=(), dtype=float64, chunksize=(), chunktype=numpy.ndarray>\n>>> np.mean(np.exp(x)).compute()\n5.090097550553843 \n```", "```py\n>>> import torch\n>>> x_torch = torch.arange(5)\n>>> x_torch\ntensor([0, 1, 2, 3, 4])\n>>> x_np = np.from_dlpack(x_torch)\n>>> x_np\narray([0, 1, 2, 3, 4])\n>>> # note that x_np is a view of x_torch\n>>> x_torch[1] = 100\n>>> x_torch\ntensor([  0, 100,   2,   3,   4])\n>>> x_np\narray([  0, 100,   2,   3,   4]) \n```", "```py\n>>> x.flags.writeable\nFalse\n>>> x_np[1] = 1\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: assignment destination is read-only \n```", "```py\n>>> x_np_copy = x_np.copy()\n>>> x_np_copy.sort()  # works \n```", "```py\n>>> x_torch = torch.arange(5, device='cuda')\n>>> np.from_dlpack(x_torch)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nRuntimeError: Unsupported device in DLTensor. \n```", "```py\n>>> x_torch = torch.arange(5, device='cuda')\n>>> x_cupy = cupy.from_dlpack(x_torch) \n```", "```py\n>>> x_np = np.arange(5)\n>>> x_torch = torch.from_dlpack(x_np) \n```", "```py\n>>> x_np = np.arange(5)\n>>> x_np.flags.writeable = False\n>>> torch.from_dlpack(x_np)  \nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \".../site-packages/torch/utils/dlpack.py\", line 63, in from_dlpack\n  dlpack = ext_tensor.__dlpack__()\nTypeError: NumPy currently only supports dlpack for writeable arrays \n```"]