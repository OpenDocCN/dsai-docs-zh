# pandas.read_table

> 原文：[`pandas.pydata.org/docs/reference/api/pandas.read_table.html`](https://pandas.pydata.org/docs/reference/api/pandas.read_table.html)

```py
pandas.read_table(filepath_or_buffer, *, sep=_NoDefault.no_default, delimiter=None, header='infer', names=_NoDefault.no_default, index_col=None, usecols=None, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=_NoDefault.no_default, skip_blank_lines=True, parse_dates=False, infer_datetime_format=_NoDefault.no_default, keep_date_col=_NoDefault.no_default, date_parser=_NoDefault.no_default, date_format=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors='strict', dialect=None, on_bad_lines='error', delim_whitespace=_NoDefault.no_default, low_memory=True, memory_map=False, float_precision=None, storage_options=None, dtype_backend=_NoDefault.no_default)
```

将通用分隔文件读入 DataFrame。

还支持可选地迭代或将文件分成块。

额外的帮助可以在[IO 工具](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)的在线文档中找到。

参数：

**filepath_or_buffer**str，路径对象或类文件对象

任何有效的字符串路径都可以接受。字符串可以是 URL。有效的 URL 方案包括 http、ftp、s3、gs 和 file。对于文件 URL，期望有一个主机。本地文件可以是：file://localhost/path/to/table.csv。

如果要传递路径对象，pandas 接受任何`os.PathLike`。

通过类文件对象，我们指的是具有`read()`方法的对象，例如文件句柄（例如通过内置的`open`函数）或`StringIO`。

**sep**str，默认为‘\t’（制表符）

要视为分隔符的字符或正则表达式模式。如果`sep=None`，则 C 引擎无法自动检测分隔符，但 Python 解析引擎可以，这意味着将使用后者，并且 Python 的内置嗅探工具`csv.Sniffer`将仅从文件的第一行自动检测分隔符。此外，长度大于 1 个字符且不同于`'\s+'`的分隔符将被解释为正则表达式，并且还将强制使用 Python 解析引擎。请注意，正则表达式分隔符容易忽略带引号的数据。正则表达式示例：`'\r\t'`。

**delimiter**str，可选

`sep`的别名。

**header**int，int 序列，‘infer’或 None，默认为‘infer’

包含列标签并标记数据起始位置的行号（从零开始索引）。默认行为是推断列名：如果没有传递`names`，则行为与`header=0`相同，并且列名从文件的第一行推断出来；如果列名明确传递给`names`，则行为与`header=None`相同。显式传递`header=0`以替换现有名称。标题可以是指定列的`MultiIndex`的行位置的整数列表，例如`[0, 1, 3]`。未指定的中间行将被跳过（例如，在此示例中跳过了 2）。请注意，如果`skip_blank_lines=True`，此参数将忽略注释行和空行，因此`header=0`表示数据的第一行而不是文件的第一行。

**names**Hashable 序列，可选

要应用的列标签序列。如果文件包含标题行，则应明确传递`header=0`以覆盖列名。此列表中不允许重复项。

**index_col**Hashable，Hashable 序列或 False，可选

作为行标签使用的列，标记为列标签或列索引。如果给出一系列标签或索引，将为行标签形成 `MultiIndex`。

注意：`index_col=False` 可以用来强制 pandas *不* 将第一列用作索引，例如，当您有一个每行末尾都有分隔符的格式错误文件时。

**usecols**可哈希序列或可调用对象，可选

要选择的列的子集，标记为列标签或列索引。如果类似列表，所有元素必须是位置的（即整数索引到文档列）或字符串，这些字符串对应于用户在 `names` 中提供的列名，或者从文档头行（s）中推断出的列名。如果给出了 `names`，则不考虑文档头行（s）。例如，一个有效的类似列表的 `usecols` 参数将是 `[0, 1, 2]` 或 `['foo', 'bar', 'baz']`。元素顺序被忽略，所以 `usecols=[0, 1]` 和 `[1, 0]` 是相同的。要保留元素顺序的 `DataFrame` 实例化，请使用 `pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]` 来按照 `['foo', 'bar']` 顺序的列或 `pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]` 为 `['bar', 'foo']` 顺序。 

如果可调用，将根据列名评估可调用函数，返回可调用函数评估为 `True` 的名称。一个有效的可调用参数示例是 `lambda x: x.upper() in ['AAA', 'BBB', 'DDD']`。使用此参数会导致更快的解析时间和更低的内存使用。

**dtype**dtype 或 {可哈希 dtype} 字典，可选

要应用于整个数据集或单个列的数据类型。例如，`{'a': np.float64, 'b': np.int32, 'c': 'Int64'}` 使用 `str` 或 `object` 与合适的 `na_values` 设置一起来保留并不解释 `dtype`。如果指定了 `converters`，它们将被应用于 INSTEAD 的 `dtype` 转换。

自版本 1.5.0 新增：添加了对 `defaultdict` 的支持。指定一个 `defaultdict` 作为输入，其中默认值确定了未显式列出的列的 `dtype`。

**engine**{‘c’, ‘python’, ‘pyarrow’}，可选

要使用的解析引擎。C 和 pyarrow 引擎更快，而 python 引擎目前更完整。多线程目前只由 pyarrow 引擎支持。

自版本 1.4.0 新增：将‘pyarrow’引擎添加为 *实验性* 引擎，并且某些功能不受支持，或者可能不正确地使用此引擎。

**converters**{可哈希可调用对象} 字典，可选

用于转换指定列中值的函数。键可以是列标签或列索引。

**true_values**列表，可选

除了大小写变体的`True`之外，还考虑为 `True` 的值。

**false_values**列表，可选

除了大小写变体的`False`之外，还考虑为 `False` 的值。

**skipinitialspace**bool，默认为 False

在分隔符后跳过空格。

**skiprows**int，int 列表或可调用，可选

要跳过的行号（从 0 开始）或文件开头要跳过的行数（`int`）。

如果是可调用的，可调用函数将根据行索引进行评估，如果应跳过该行则返回`True`，否则返回`False`。一个有效的可调用参数示例是`lambda x: x in [0, 2]`。

**skipfooter**int，默认为 0

要跳过的文件底部行数（使用`engine='c'`时不支持）。

**nrows**int，可选

要读取的文件行数。用于读取大文件的片段。

**na_values**可哈希，可迭代的可哈希或{可哈希迭代}的字典，可选

附加的字符串以识别为`NA`/`NaN`。如果传递了`dict`，则特定于每列的`NA`值。默认情况下，以下值被解释为`NaN`：“ “, “#N/A”, “#N/A N/A”, “#NA”, “-1.#IND”, “-1.#QNAN”, “-NaN”, “-nan”, “1.#IND”, “1.#QNAN”, “<NA>”, “N/A”, `NA`, “NULL”, `NaN`, “None”, “n/a”, “nan”, “null”。

**keep_default_na**bool，默认为 True

是否在解析数据时包括默认的`NaN`值。根据是否传入`na_values`，行为如下：

+   如果`keep_default_na`为`True`，并且指定了`na_values`，则将`na_values`附加到用于解析的默认`NaN`值。

+   如果`keep_default_na`为`True`，并且未指定`na_values`，则仅使用默认的`NaN`值进行解析。

+   如果`keep_default_na`为`False`，并且指定了`na_values`，则仅使用指定的`na_values`值进行解析。

+   如果`keep_default_na`为`False`，并且未指定`na_values`，则不会将任何字符串解析为`NaN`。

请注意，如果将`na_filter`传递为`False`，则将忽略`keep_default_na`和`na_values`参数。

**na_filter**bool，默认为 True

检测缺失值标记（空字符串和`na_values`的值）。在没有任何`NA`值的数据中，传递`na_filter=False`可以提高读取大文件的性能。

**verbose**bool，默认为 False

指示放置在非数字列中的`NA`值的数量。

自版本 2.2.0 起已弃用。

**skip_blank_lines**bool，默认为 True

如果为`True`，则跳过空行而不解释为`NaN`值。

**parse_dates**bool，可哈希列表，列表的列表或{哈希列表}的字典，默认为 False

行为如下：

+   `bool`。如果为`True` -> 尝试解析索引。注意：如果传递了`date_format`或`date_parser`参数，则会自动设置为`True`。

+   `int`或名称的`list`。例如，如果`[1, 2, 3]` -> 尝试将列 1、2、3 分别解析为单独的日期列。

+   `list`的`list`。例如，如果`[[1, 3]]` -> 将列 1 和 3 合并并解析为单个日期列。在解析之前，值用空格连接。

+   `dict`，例如`{'foo' : [1, 3]}` -> 将列 1、3 解析为日期并称为‘foo’。在解析之前，值用空格连接。

如果某列或索引无法表示为`datetime`数组，比如因为存在无法解析的值或时区混合，该列或索引将以`object`数据类型不变返回。对于非标准的`datetime`解析，请在`read_csv()`之后使用`to_datetime()`。

注意：存在用于 iso8601 格式日期的快速路径。

**infer_datetime_format**bool，默认为 False

如果`True`并且启用了`parse_dates`，pandas 将尝试推断列中`datetime`字符串的格式，如果可以推断出来，将切换到更快的解析方法。在某些情况下，这可以将解析速度提高 5-10 倍。

自版本 2.0.0 起弃用：严格版本的此参数现在是默认的，传递它没有任何效果。

**keep_date_col**bool，默认为 False

如果`True`并且`parse_dates`指定了合并多个列，则保留原始列。

**date_parser**可调用对象，可选

用于将一系列字符串列转换为`datetime`实例数组的函数。默认使用`dateutil.parser.parser`进行转换。pandas 将尝试以三种不同的方式调用`date_parser`，如果发生异常，则继续下一个：1) 将一个或多个数组（由`parse_dates`定义）作为参数传递；2) 将由`parse_dates`定义的列中的字符串值（按行连接）合并为单个数组并传递；3) 对每一行使用一个或多个字符串（对应于由`parse_dates`定义的列）调用`date_parser`。

自版本 2.0.0 起弃用：改用`date_format`，或者读取为`object`，然后根据需要应用`to_datetime()`。

**date_format**str 或列->格式的字典，可选

与`parse_dates`结合使用时用于解析日期的格式。解析时间的 strftime，例如`"%d/%m/%Y"`。有关更多选择的信息，请参阅[strftime 文档](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior)，尽管请注意`"%f"`将解析直到纳秒。你也可以传递：

+   “ISO8601”，解析任何[ISO8601](https://en.wikipedia.org/wiki/ISO_8601)

    时间字符串（不一定完全相同的格式）；

+   “mixed”，为了单独推断每个元素的格式。这是有风险的，

    你可能应该与 dayfirst 一起使用它。

版本 2.0.0 中的新功能。

**dayfirst**bool，默认为 False

DD/MM 格式日期，国际和欧洲格式。

**cache_dates**bool，默认为 True

如果`True`，使用唯一的转换日期缓存来应用`datetime`转换。在解析重复日期字符串时可能会产生显著的加速，特别是带有时区偏移的日期字符串。

**iterator**bool，默认为 False

返回用于迭代或使用`get_chunk()`获取块的`TextFileReader`对象。

**chunksize**int，可选

从文件中每块读取的行数。传递一个值会导致函数返回一个 `TextFileReader` 对象以进行迭代。有关 `iterator` 和 `chunksize` 的更多信息，请参阅 [IO 工具文档](https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking)。

**compression**str 或 dict，默认为 ‘infer’

用于在磁盘上的数据的即时解压缩。如果‘infer’并且‘filepath_or_buffer’是类似路径的，则从以下扩展名检测压缩：‘.gz’、‘.bz2’、‘.zip’、‘.xz’、‘.zst’、‘.tar’、‘.tar.gz’、‘.tar.xz’或‘.tar.bz2’（否则不压缩）。如果使用`'zip'`或`'tar'`，ZIP 文件必须只包含一个要读取的数据文件。设置为 `None` 不进行解压缩。也可以是一个字典，其中键 `'method'` 设置为其中一个 {`'zip'`、`'gzip'`、`'bz2'`、`'zstd'`、`'xz'`、`'tar'`}，其他键值对被转发到 `zipfile.ZipFile`、`gzip.GzipFile`、`bz2.BZ2File`、`zstandard.ZstdDecompressor`、`lzma.LZMAFile` 或 `tarfile.TarFile`。例如，可以通过以下方式传递用于 Zstandard 解压缩的自定义压缩字典：`compression={'method': 'zstd', 'dict_data': my_compression_dict}`。

1.5.0 版本中的新功能：增加了对.tar 文件的支持。

在 1.4.0 版本中更改：增加了对 Zstandard 的支持。

**thousands**str（长度为 1），可选

数值中的千位分隔符。

**decimal**str（长度为 1），默认为 ‘.’

将作为十进制点识别的字符（例如，使用‘，’表示欧洲数据）。

**lineterminator**str（长度为 1），可选

用于表示换行的字符。只有与 C 解析器一起使用时才有效。

**quotechar**str（长度为 1），可选

用于表示引用项目的开始和结束的字符。引用项目可以包括 `delimiter`，并且将被忽略。

**quoting**{0 或 csv.QUOTE_MINIMAL, 1 或 csv.QUOTE_ALL, 2 或 csv.QUOTE_NONNUMERIC, 3 或 csv.QUOTE_NONE}，默认为 csv.QUOTE_MINIMAL

控制字段引号行为的 `csv.QUOTE_*` 常量。默认为 `csv.QUOTE_MINIMAL`（即，0），表示仅引用包含特殊字符的字段（例如，在 `quotechar`、`delimiter` 或 `lineterminator` 中定义的字符）。

**doublequote**bool，默认为 True

当指定了 `quotechar` 且 `quoting` 不是 `QUOTE_NONE` 时，指示是否将字段内连续的两个 `quotechar` 元素解释为单个 `quotechar` 元素。

**escapechar**str（长度为 1），可选

用于转义其他字符的字符。

**comment**str（长度为 1），可选

表示应不解析行剩余部分的字符。如果在行的开头找到，将完全忽略该行。此参数必须是单个字符。与空行一样（只要 `skip_blank_lines=True`），完全被注释的行由参数 `header` 忽略，但不由 `skiprows` 忽略。例如，如果 `comment='#'`，使用 `header=0` 解析 `#empty\na,b,c\n1,2,3` 将导致 `'a,b,c'` 被视为标题。

**encoding**str，可选，默认为 ‘utf-8’

读取/写入 UTF 时要使用的编码（例如。`'utf-8'`）。[Python 标准编码列表](https://docs.python.org/3/library/codecs.html#standard-encodings)。

**encoding_errors**str，可选，默认为‘strict’

如何处理编码错误。[可能值列表](https://docs.python.org/3/library/codecs.html#error-handlers)。

从版本 1.3.0 开始的新功能。

**dialect**str 或 csv.Dialect，可选

如果提供，此参数将覆盖以下参数的值（默认或非默认）：`delimiter`，`doublequote`，`escapechar`，`skipinitialspace`，`quotechar` 和 `quoting`。如果需要覆盖值，则将发出`ParserWarning`。有关更多详细信息，请参阅 `csv.Dialect` 文档。

**on_bad_lines**{‘error’，‘warn’，‘skip’} 或 Callable，默认为‘error’

指定在遇到错误行（字段过多的行）时要执行的操作。允许的值有：

+   `'error'`，当遇到错误行时引发异常。

+   `'warn'`，在遇到错误行时引发警告并跳过该行。

+   `'skip'`，在遇到错误行时跳过，而不引发或警告。

从版本 1.3.0 开始的新功能。

从版本 1.4.0 开始的新功能：

+   可调用函数，具有签名 `(bad_line: list[str]) -> list[str] | None`，将处理单个错误行。`bad_line`是由`sep`分割的字符串列表。如果函数返回`None`，则会忽略错误行。如果函数返回具有比预期更多元素的新的字符串`list`，则会发出`ParserWarning`，同时删除额外的元素。仅在`engine='python'`时受支持。

从版本 2.2.0 开始更改：

+   当`engine='pyarrow'`时，具有如[pyarrow 文档](https://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html#pyarrow.csv.ParseOptions.invalid_row_handler)中描述的签名的可调用函数。

**delim_whitespace**bool，默认为 False

指定是否使用空白字符（例如。`' '`或`'\t'`）作为`sep`分隔符。等效于设置`sep='\s+'`。如果将此选项设置为`True`，则不应传递任何内容给`delimiter`参数。

自版本 2.2.0 起弃用：请改用`sep="\s+"`。

**low_memory**bool，默认为 True

将文件分块内部处理，以降低解析时的内存使用，但可能导致混合类型推断。为了确保没有混合类型，要么设置为`False`，要么使用`dtype`参数指定类型。请注意，无论如何整个文件都会被读入单个`DataFrame`中，可以使用`chunksize`或`iterator`参数以块返回数据。（仅在 C 解析器中有效）。

**memory_map**bool，默认为 False

如果为`filepath_or_buffer`提供了文件路径，则将文件对象直接映射到内存中，并直接从中访问数据。使用此选项可以提高性能，因为不再有任何 I/O 开销。

**float_precision**{‘high’，‘legacy’，‘round_trip’}，可选

指定 C 引擎应使用哪个转换器处理浮点值。选项为`None`或`'high'`表示普通转换器，`'legacy'`表示原始较低精度的 pandas 转换器，`'round_trip'`表示往返转换器。

**storage_options**字典，可选

针对特定存储连接有额外选项，例如主机、端口、用户名、密码等。对于 HTTP(S) URL，键值对将作为头部选项转发给`urllib.request.Request`。对于其他 URL（例如以“s3://”和“gcs://”开头的 URL），键值对将转发给`fsspec.open`。更多详情请参阅`fsspec`和`urllib`，有关存储选项的更多示例请参考[此处](https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files)。

**dtype_backend**{‘numpy_nullable’, ‘pyarrow’}，默认为‘numpy_nullable’

应用于结果`DataFrame`的后端数据类型（仍处于实验阶段）。行为如下：

+   `"numpy_nullable"`：返回支持可空 dtype 的`DataFrame`（默认值）。

+   `"pyarrow"`：返回由 pyarrow 支持的可空`ArrowDtype` DataFrame。

新功能在 2.0 版本中新增。

返回：

DataFrame 或 TextFileReader

逗号分隔值（csv）文件被返回为带有标记轴的二维数据结构。

另请参见

`DataFrame.to_csv`

将 DataFrame 写入逗号分隔值（csv）文件。

`read_csv`

将逗号分隔值（csv）文件读入 DataFrame。

`read_fwf`

将一张固定宽度格式的表格行读入 DataFrame。

示例

```py
>>> pd.read_table('data.csv') 
```
