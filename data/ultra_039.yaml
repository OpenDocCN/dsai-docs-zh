- en: LVIS Dataset
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LVIS 数据集
- en: 原文：[`docs.ultralytics.com/datasets/detect/lvis/`](https://docs.ultralytics.com/datasets/detect/lvis/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/datasets/detect/lvis/`](https://docs.ultralytics.com/datasets/detect/lvis/)
- en: The [LVIS dataset](https://www.lvisdataset.org/) is a large-scale, fine-grained
    vocabulary-level annotation dataset developed and released by Facebook AI Research
    (FAIR). It is primarily used as a research benchmark for object detection and
    instance segmentation with a large vocabulary of categories, aiming to drive further
    advancements in computer vision field.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[LVIS 数据集](https://www.lvisdataset.org/) 是由 Facebook AI Research（FAIR）开发和发布的大规模、细粒度词汇级别注释数据集，主要用作物体检测和实例分割的研究基准，具有大量类别的词汇，旨在推动计算机视觉领域的进一步发展。'
- en: '[`www.youtube.com/embed/cfTKj96TjSE`](https://www.youtube.com/embed/cfTKj96TjSE)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[`www.youtube.com/embed/cfTKj96TjSE`](https://www.youtube.com/embed/cfTKj96TjSE)'
- en: '**Watch:** YOLO World training workflow with LVIS dataset'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**Watch:** YOLO World 使用 LVIS 数据集的训练工作流程'
- en: '![LVIS Dataset example images](img/684a611bba29bcc799f8d375ae56ea86.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![LVIS 数据集示例图像](img/684a611bba29bcc799f8d375ae56ea86.png)'
- en: Key Features
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主要特点
- en: LVIS contains 160k images and 2M instance annotations for object detection,
    segmentation, and captioning tasks.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LVIS 包含 160k 张图像和 2M 个实例标注，用于物体检测、分割和字幕任务。
- en: The dataset comprises 1203 object categories, including common objects like
    cars, bicycles, and animals, as well as more specific categories such as umbrellas,
    handbags, and sports equipment.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该数据集包括 1203 个对象类别，包括常见对象如汽车、自行车和动物，以及更具体的类别如雨伞、手提包和体育设备。
- en: Annotations include object bounding boxes, segmentation masks, and captions
    for each image.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标注包括每张图像的对象边界框、分割蒙版和说明。
- en: LVIS provides standardized evaluation metrics like mean Average Precision (mAP)
    for object detection, and mean Average Recall (mAR) for segmentation tasks, making
    it suitable for comparing model performance.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LVIS 提供标准化的评估指标，如物体检测的平均精确度（mAP）和分割任务的平均召回率（mAR），适合比较模型性能。
- en: LVIS uses exactly the same images as COCO dataset, but with different splits
    and different annotations.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LVIS 使用与 COCO 数据集完全相同的图像，但具有不同的拆分和不同的注释。
- en: Dataset Structure
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集结构
- en: 'The LVIS dataset is split into three subsets:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: LVIS 数据集分为三个子集：
- en: '**Train**: This subset contains 100k images for training object detection,
    segmentation, and captioning models.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Train**: 这个子集包含 100k 张图像，用于训练物体检测、分割和字幕模型。'
- en: '**Val**: This subset has 20k images used for validation purposes during model
    training.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Val**: 这个子集有 20k 张图像，用于模型训练的验证目的。'
- en: '**Minival**: This subset is exactly the same as COCO val2017 set which has
    5k images used for validation purposes during model training.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Minival**: 这个子集与 COCO val2017 集合完全相同，有 5k 张图像，用于模型训练的验证目的。'
- en: '**Test**: This subset consists of 20k images used for testing and benchmarking
    the trained models. Ground truth annotations for this subset are not publicly
    available, and the results are submitted to the [LVIS evaluation server](https://eval.ai/web/challenges/challenge-page/675/overview)
    for performance evaluation.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Test**: 这个子集包含 20k 张图像，用于测试和基准测试经过训练的模型。此子集的地面真实标注不公开，结果提交到 [LVIS 评估服务器](https://eval.ai/web/challenges/challenge-page/675/overview)
    进行性能评估。'
- en: Applications
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用
- en: The LVIS dataset is widely used for training and evaluating deep learning models
    in object detection (such as YOLO, Faster R-CNN, and SSD), instance segmentation
    (such as Mask R-CNN). The dataset's diverse set of object categories, large number
    of annotated images, and standardized evaluation metrics make it an essential
    resource for computer vision researchers and practitioners.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: LVIS 数据集被广泛用于训练和评估物体检测（如 YOLO、Faster R-CNN 和 SSD）、实例分割（如 Mask R-CNN）的深度学习模型。数据集的多样的对象类别集合、大量注释图像和标准化评估指标使其成为计算机视觉研究人员和从业者的重要资源。
- en: Dataset YAML
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集 YAML
- en: A YAML (Yet Another Markup Language) file is used to define the dataset configuration.
    It contains information about the dataset's paths, classes, and other relevant
    information. In the case of the LVIS dataset, the `lvis.yaml` file is maintained
    at [`github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/lvis.yaml`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/lvis.yaml).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 YAML（另一种标记语言）文件定义数据集配置。它包含关于数据集路径、类别和其他相关信息的信息。在 LVIS 数据集的情况下，`lvis.yaml`
    文件保存在 [`github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/lvis.yaml`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/lvis.yaml)。
- en: ultralytics/cfg/datasets/lvis.yaml
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ultralytics/cfg/datasets/lvis.yaml
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Usage
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用方法
- en: To train a YOLOv8n model on the LVIS dataset for 100 epochs with an image size
    of 640, you can use the following code snippets. For a comprehensive list of available
    arguments, refer to the model Training page.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要在LVIS数据集上使用640像素大小的图像训练100个epochs的YOLOv8n模型，您可以使用以下代码片段。有关可用参数的详细列表，请参阅模型训练页面。
- en: Train Example
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 训练示例
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Sample Images and Annotations
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 样本图像和注释
- en: 'The LVIS dataset contains a diverse set of images with various object categories
    and complex scenes. Here are some examples of images from the dataset, along with
    their corresponding annotations:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: LVIS数据集包含各种对象类别和复杂场景的多样化图像。以下是数据集中一些图像及其相应的注释示例：
- en: '![LVIS Dataset sample image](img/5509e501459eedb1ecd24c2fdfef1f51.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![LVIS数据集示例图像](img/5509e501459eedb1ecd24c2fdfef1f51.png)'
- en: '**Mosaiced Image**: This image demonstrates a training batch composed of mosaiced
    dataset images. Mosaicing is a technique used during training that combines multiple
    images into a single image to increase the variety of objects and scenes within
    each training batch. This helps improve the model''s ability to generalize to
    different object sizes, aspect ratios, and contexts.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**马赛克图像**：这幅图展示了由马赛克数据集图像组成的训练批次。马赛克是一种在训练过程中使用的技术，将多个图像合并成一张图像，以增加每个训练批次中对象和场景的多样性。这有助于改善模型对不同对象大小、长宽比和上下文的泛化能力。'
- en: The example showcases the variety and complexity of the images in the LVIS dataset
    and the benefits of using mosaicing during the training process.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例展示了LVIS数据集中图像的多样性和复杂性，以及在训练过程中使用马赛克的好处。
- en: Citations and Acknowledgments
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引用和致谢
- en: 'If you use the LVIS dataset in your research or development work, please cite
    the following paper:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在研究或开发工作中使用LVIS数据集，请引用以下论文：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We would like to acknowledge the LVIS Consortium for creating and maintaining
    this valuable resource for the computer vision community. For more information
    about the LVIS dataset and its creators, visit the [LVIS dataset website](https://www.lvisdataset.org/).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢LVIS联盟为计算机视觉社区创建和维护这一宝贵资源。有关LVIS数据集及其创建者的更多信息，请访问[LVIS数据集网站](https://www.lvisdataset.org/)。
- en: FAQ
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题
- en: What is the LVIS dataset, and how is it used in computer vision?
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LVIS数据集是什么，如何在计算机视觉中使用？
- en: The [LVIS dataset](https://www.lvisdataset.org/) is a large-scale dataset with
    fine-grained vocabulary-level annotations developed by Facebook AI Research (FAIR).
    It is primarily used for object detection and instance segmentation, featuring
    over 1203 object categories and 2 million instance annotations. Researchers and
    practitioners use it to train and benchmark models like Ultralytics YOLO for advanced
    computer vision tasks. The dataset's extensive size and diversity make it an essential
    resource for pushing the boundaries of model performance in detection and segmentation.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[LVIS数据集](https://www.lvisdataset.org/)是由Facebook AI Research (FAIR)开发的带有细粒度词汇级注释的大规模数据集。它主要用于对象检测和实例分割，涵盖了超过1203个对象类别和200万个实例注释。研究人员和实践者使用它来训练和评估像Ultralytics
    YOLO这样的模型，用于高级计算机视觉任务。数据集的广泛大小和多样性使其成为推动检测和分割模型性能边界的重要资源。'
- en: How can I train a YOLOv8n model using the LVIS dataset?
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何使用LVIS数据集训练YOLOv8n模型？
- en: To train a YOLOv8n model on the LVIS dataset for 100 epochs with an image size
    of 640, follow the example below. This process utilizes Ultralytics' framework,
    which offers comprehensive training features.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 要在LVIS数据集上使用640像素大小的图像训练100个epochs的YOLOv8n模型，请参考以下示例。此过程利用了Ultralytics的框架，提供了全面的训练功能。
- en: Train Example
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 训练示例
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: For detailed training configurations, refer to the Training documentation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如需详细的训练配置，请参阅训练文档。
- en: How does the LVIS dataset differ from the COCO dataset?
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LVIS数据集与COCO数据集有何不同？
- en: The images in the LVIS dataset are the same as those in the COCO dataset, but
    the two differ in terms of splitting and annotations. LVIS provides a larger and
    more detailed vocabulary with 1203 object categories compared to COCO's 80 categories.
    Additionally, LVIS focuses on annotation completeness and diversity, aiming to
    push the limits of object detection and instance segmentation models by offering
    more nuanced and comprehensive data.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: LVIS数据集中的图像与COCO数据集中的图像相同，但两者在分割和注释方面有所不同。LVIS提供了1203个对象类别的更大和更详细的词汇表，而COCO只有80个类别。此外，LVIS侧重于注释的完整性和多样性，旨在通过提供更细致和全面的数据来推动对象检测和实例分割模型的极限。
- en: Why should I use Ultralytics YOLO for training on the LVIS dataset?
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么要在LVIS数据集上使用Ultralytics YOLO进行训练？
- en: Ultralytics YOLO models, including the latest YOLOv8, are optimized for real-time
    object detection with state-of-the-art accuracy and speed. They support a wide
    range of annotations, such as the fine-grained ones provided by the LVIS dataset,
    making them ideal for advanced computer vision applications. Moreover, Ultralytics
    offers seamless integration with various training, validation, and prediction
    modes, ensuring efficient model development and deployment.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics YOLO模型，包括最新的YOLOv8，针对实时目标检测进行了优化，具有领先的准确性和速度。它们支持广泛的注释，例如LVIS数据集提供的精细注释，使其成为高级计算机视觉应用的理想选择。此外，Ultralytics提供与各种训练、验证和预测模式的无缝集成，确保高效的模型开发和部署。
- en: Can I see some sample annotations from the LVIS dataset?
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我可以看一些来自LVIS数据集的示例注释吗？
- en: 'Yes, the LVIS dataset includes a variety of images with diverse object categories
    and complex scenes. Here is an example of a sample image along with its annotations:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，LVIS数据集包含多种具有不同对象类别和复杂场景的图像。这里是一张示例图像及其注释：
- en: '![LVIS Dataset sample image](img/5509e501459eedb1ecd24c2fdfef1f51.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![LVIS 数据集示例图像](img/5509e501459eedb1ecd24c2fdfef1f51.png)'
- en: This mosaiced image demonstrates a training batch composed of multiple dataset
    images combined into one. Mosaicing increases the variety of objects and scenes
    within each training batch, enhancing the model's ability to generalize across
    different contexts. For more details on the LVIS dataset, explore the LVIS dataset
    documentation.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这幅马赛克图像展示了一个训练批次，由多个数据集图像组合而成。马赛克增加了每个训练批次中对象和场景的多样性，增强了模型在不同环境下的泛化能力。有关LVIS数据集的更多详细信息，请查阅LVIS数据集文档。
