- en: scipy.stats.entropy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: scipy.stats.entropy
- en: Original text：[https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.stats.entropy.html#scipy.stats.entropy](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.stats.entropy.html#scipy.stats.entropy)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.stats.entropy.html#scipy.stats.entropy](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.stats.entropy.html#scipy.stats.entropy)
- en: '[PRE0]'
  id: totrans-2
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Calculate the Shannon entropy/relative entropy of given distribution(s).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 计算给定分布的Shannon熵/相对熵。
- en: If only probabilities *pk* are given, the Shannon entropy is calculated as `H
    = -sum(pk * log(pk))`.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仅提供了概率*pk*，则香农熵计算为`H = -sum(pk * log(pk))`。
- en: If *qk* is not None, then compute the relative entropy `D = sum(pk * log(pk
    / qk))`. This quantity is also known as the Kullback-Leibler divergence.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如果*qk*不为None，则计算相对熵`D = sum(pk * log(pk / qk))`。这个量也被称为Kullback-Leibler散度。
- en: This routine will normalize *pk* and *qk* if they don’t sum to 1.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果*pk*和*qk*的和不为1，则此例程将对它们进行标准化。
- en: 'Parameters:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**pk**array_like'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**pk**array_like'
- en: Defines the (discrete) distribution. Along each axis-slice of `pk`, element
    `i` is the (possibly unnormalized) probability of event `i`.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 定义（离散）分布。对于`pk`的每个轴切片，元素`i`是事件`i`的（可能未标准化的）概率。
- en: '**qk**array_like, optional'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**qk**array_like，可选'
- en: Sequence against which the relative entropy is computed. Should be in the same
    format as *pk*.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 用于计算相对熵的序列。应与*pk*具有相同的格式。
- en: '**base**float, optional'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**base**float，可选'
- en: The logarithmic base to use, defaults to `e` (natural logarithm).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用的对数基数，默认为`e`（自然对数）。
- en: '**axis**int or None, default: 0'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**axis**int或None，默认值：0'
- en: If an int, the axis of the input along which to compute the statistic. The statistic
    of each axis-slice (e.g. row) of the input will appear in a corresponding element
    of the output. If `None`, the input will be raveled before computing the statistic.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是整数，则是计算统计量的输入轴。输入的每个轴切片（例如行）的统计量将出现在输出的相应元素中。如果为`None`，则在计算统计量之前将对输入进行展平。
- en: '**nan_policy**{‘propagate’, ‘omit’, ‘raise’}'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**nan_policy**{‘propagate’, ‘omit’, ‘raise’}'
- en: Defines how to handle input NaNs.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 定义如何处理输入的NaN值。
- en: '`propagate`: if a NaN is present in the axis slice (e.g. row) along which the
    statistic is computed, the corresponding entry of the output will be NaN.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`propagate`：如果在计算统计量的轴切片（例如行）中存在NaN值，则输出的相应条目将为NaN。'
- en: '`omit`: NaNs will be omitted when performing the calculation. If insufficient
    data remains in the axis slice along which the statistic is computed, the corresponding
    entry of the output will be NaN.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`omit`：在执行计算时将忽略NaN值。如果沿着计算统计量的轴切片中剩余的数据不足，输出的相应条目将为NaN。'
- en: '`raise`: if a NaN is present, a `ValueError` will be raised.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`raise`：如果存在NaN值，则会引发`ValueError`。'
- en: '**keepdims**bool, default: False'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**keepdims**bool，默认值：False'
- en: If this is set to True, the axes which are reduced are left in the result as
    dimensions with size one. With this option, the result will broadcast correctly
    against the input array.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果设置为True，则减少的轴将作为大小为1的维度保留在结果中。选择此选项后，结果将正确地与输入数组进行广播。
- en: 'Returns:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值：
- en: '**S**{float, array_like}'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**S**{float, array_like}'
- en: The calculated entropy.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 计算得到的熵。
- en: Notes
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意事项
- en: Informally, the Shannon entropy quantifies the expected uncertainty inherent
    in the possible outcomes of a discrete random variable. For example, if messages
    consisting of sequences of symbols from a set are to be encoded and transmitted
    over a noiseless channel, then the Shannon entropy `H(pk)` gives a tight lower
    bound for the average number of units of information needed per symbol if the
    symbols occur with frequencies governed by the discrete distribution *pk* [[1]](#r7a63479d8f91-1).
    The choice of base determines the choice of units; e.g., `e` for nats, `2` for
    bits, etc.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通俗地讲，香农熵量化了离散随机变量可能结果的预期不确定性。例如，如果要对由一组符号序列组成的消息进行编码并通过无噪声信道传输，则香农熵`H(pk)`给出了每个符号所需的信息单位数的平均下界，如果符号的发生频率由离散分布*pk*控制[[1]](#r7a63479d8f91-1)。基数的选择确定了单位的选择；例如，自然对数`e`用于nats，`2`用于bits，等等。
- en: The relative entropy, `D(pk|qk)`, quantifies the increase in the average number
    of units of information needed per symbol if the encoding is optimized for the
    probability distribution *qk* instead of the true distribution *pk*. Informally,
    the relative entropy quantifies the expected excess in surprise experienced if
    one believes the true distribution is *qk* when it is actually *pk*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 相对熵 `D(pk|qk)` 量化了如果编码针对概率分布 *qk* 而不是真实分布 *pk* 进行了优化，则每个符号所需的平均信息单位数的增加量。非正式地，相对熵量化了在真实分布实际为
    *pk* 时，但人们认为其为 *qk* 时所经历的预期惊讶的过量。
- en: A related quantity, the cross entropy `CE(pk, qk)`, satisfies the equation `CE(pk,
    qk) = H(pk) + D(pk|qk)` and can also be calculated with the formula `CE = -sum(pk
    * log(qk))`. It gives the average number of units of information needed per symbol
    if an encoding is optimized for the probability distribution *qk* when the true
    distribution is *pk*. It is not computed directly by [`entropy`](#scipy.stats.entropy
    "scipy.stats.entropy"), but it can be computed using two calls to the function
    (see Examples).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 相关量，交叉熵 `CE(pk, qk)`，满足方程 `CE(pk, qk) = H(pk) + D(pk|qk)`，也可以用公式 `CE = -sum(pk
    * log(qk))` 计算。如果编码针对概率分布 *qk* 进行了优化，当真实分布为 *pk* 时，它给出每个符号所需的平均信息单位数。它不是直接由 [`entropy`](#scipy.stats.entropy
    "scipy.stats.entropy") 计算的，但可以通过两次调用函数来计算（见示例）。
- en: See [[2]](#r7a63479d8f91-2) for more information.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息请参见 [[2]](#r7a63479d8f91-2)。
- en: Beginning in SciPy 1.9, `np.matrix` inputs (not recommended for new code) are
    converted to `np.ndarray` before the calculation is performed. In this case, the
    output will be a scalar or `np.ndarray` of appropriate shape rather than a 2D
    `np.matrix`. Similarly, while masked elements of masked arrays are ignored, the
    output will be a scalar or `np.ndarray` rather than a masked array with `mask=False`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从 SciPy 1.9 开始，`np.matrix` 输入（不建议在新代码中使用）在进行计算之前会转换为 `np.ndarray`。在这种情况下，输出将是一个标量或适当形状的
    `np.ndarray`，而不是二维的 `np.matrix`。类似地，虽然忽略了掩码数组的掩码元素，但输出将是一个标量或 `np.ndarray`，而不是带有
    `mask=False` 的掩码数组。
- en: References
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[[1](#id1)]'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1](#id1)]'
- en: 'Shannon, C.E. (1948), A Mathematical Theory of Communication. Bell System Technical
    Journal, 27: 379-423. [https://doi.org/10.1002/j.1538-7305.1948.tb01338.x](https://doi.org/10.1002/j.1538-7305.1948.tb01338.x)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 'Shannon, C.E. (1948)，A Mathematical Theory of Communication. Bell System Technical
    Journal, 27: 379-423. [https://doi.org/10.1002/j.1538-7305.1948.tb01338.x](https://doi.org/10.1002/j.1538-7305.1948.tb01338.x)'
- en: '[[2](#id2)]'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[[2](#id2)]'
- en: Thomas M. Cover and Joy A. Thomas. 2006\. Elements of Information Theory (Wiley
    Series in Telecommunications and Signal Processing). Wiley-Interscience, USA.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Thomas M. Cover 和 Joy A. Thomas. 2006\. Elements of Information Theory (Wiley
    Series in Telecommunications and Signal Processing). Wiley-Interscience, USA.
- en: Examples
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: 'The outcome of a fair coin is the most uncertain:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 公平硬币的结果是最不确定的：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The outcome of a biased coin is less uncertain:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有偏硬币的结果不那么不确定：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The relative entropy between the fair coin and biased coin is calculated as:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 公平硬币和有偏硬币之间的相对熵计算如下：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The cross entropy can be calculated as the sum of the entropy and relative
    entropy`:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉熵可以计算为熵和相对熵的总和`：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
