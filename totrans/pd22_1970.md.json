["```py\n    # previously, you would have set levels or labels directly\n    >>> pd.index.levels = [[1, 2, 3, 4], [1, 2, 4, 4]]\n\n    # now, you use the set_levels or set_labels methods\n    >>> index = pd.index.set_levels([[1, 2, 3, 4], [1, 2, 4, 4]])\n\n    # similarly, for names, you can rename the object\n    # but setting names is not deprecated\n    >>> index = pd.index.set_names([\"bob\", \"cranberry\"])\n\n    # and all methods take an inplace kwarg - but return None\n    >>> pd.index.set_names([\"bob\", \"cranberry\"], inplace=True) \n    ```", "```py\n    In [3]: arr = np.array([1, 2, 3, 4])\n\n    In [4]: arr2 = np.array([5, 3, 2, 1])\n\n    In [5]: arr / arr2\n    Out[5]: array([0, 0, 1, 4])\n\n    In [6]: pd.Series(arr) // pd.Series(arr2)\n    Out[6]:\n    0    0\n    1    0\n    2    1\n    3    4\n    dtype: int64 \n    ```", "```py\n    In [7]: pd.Series(arr) / pd.Series(arr2)  # no future import required\n    Out[7]:\n    0    0.200000\n    1    0.666667\n    2    1.500000\n    3    4.000000\n    dtype: float64 \n    ```", "```py\n    >>> df = pd.DataFrame({'A': np.random.randn(10),\n    ...                    'B': np.random.randn(10),\n    ...                    'C': pd.date_range('20130101', periods=10)\n    ...                    })\n    ...\n    >>> if df:\n    ...     pass\n    ...\n    Traceback (most recent call last):\n      ...\n    ValueError: The truth value of a DataFrame is ambiguous.  Use a.empty,\n    a.bool(), a.item(), a.any() or a.all().\n\n    >>> df1 = df\n    >>> df2 = df\n    >>> df1 and df2\n    Traceback (most recent call last):\n      ...\n    ValueError: The truth value of a DataFrame is ambiguous.  Use a.empty,\n    a.bool(), a.item(), a.any() or a.all().\n\n    >>> d = [1, 2, 3]\n    >>> s1 = pd.Series(d)\n    >>> s2 = pd.Series(d)\n    >>> s1 and s2\n    Traceback (most recent call last):\n      ...\n    ValueError: The truth value of a DataFrame is ambiguous.  Use a.empty,\n    a.bool(), a.item(), a.any() or a.all(). \n    ```", "```py\n    >>> pd.Series([True]).bool()\n     True\n    >>> pd.Series([False]).bool()\n     False\n    >>> pd.DataFrame([[True]]).bool()\n     True\n    >>> pd.DataFrame([[False]]).bool()\n     False \n    ```", "```py\n    In [1]: dfc = pd.DataFrame({'A': ['aaa', 'bbb', 'ccc'], 'B': [1, 2, 3]})\n\n    In [2]: pd.set_option('chained_assignment', 'warn') \n    ```", "```py\n    In [3]: dfc.loc[0]['A'] = 1111 \n    ```", "```py\n    Traceback (most recent call last)\n       ...\n    SettingWithCopyWarning:\n       A value is trying to be set on a copy of a slice from a DataFrame.\n       Try using .loc[row_index,col_indexer] = value instead \n    ```", "```py\n    In [4]: dfc.loc[0, 'A'] = 11\n\n    In [5]: dfc\n    Out[5]: \n     A  B\n    0   11  1\n    1  bbb  2\n    2  ccc  3 \n    ```", "```py\nIn [6]: s = pd.Series([1, 2, 3])\n\nIn [7]: s\nOut[7]: \n0    1\n1    2\n2    3\ndtype: int64\n\nIn [8]: s[5] = 5.\n\nIn [9]: s\nOut[9]: \n0    1.0\n1    2.0\n2    3.0\n5    5.0\ndtype: float64 \n```", "```py\nIn [10]: dfi = pd.DataFrame(np.arange(6).reshape(3, 2),\n ....:                   columns=['A', 'B'])\n ....: \n\nIn [11]: dfi\nOut[11]: \n A  B\n0  0  1\n1  2  3\n2  4  5 \n```", "```py\nIn [12]: dfi.loc[:, 'C'] = dfi.loc[:, 'A']\n\nIn [13]: dfi\nOut[13]: \n A  B  C\n0  0  1  0\n1  2  3  2\n2  4  5  4 \n```", "```py\nIn [14]: dfi.loc[3] = 5\n\nIn [15]: dfi\nOut[15]: \n A  B  C\n0  0  1  0\n1  2  3  2\n2  4  5  4\n3  5  5  5 \n```", "```py\nIn [20]: p = pd.Panel(np.arange(16).reshape(2, 4, 2),\n ....:             items=['Item1', 'Item2'],\n ....:             major_axis=pd.date_range('2001/1/12', periods=4),\n ....:             minor_axis=['A', 'B'], dtype='float64')\n ....:\n\nIn [21]: p\nOut[21]:\n<class 'pandas.core.panel.Panel'>\nDimensions: 2 (items) x 4 (major_axis) x 2 (minor_axis)\nItems axis: Item1 to Item2\nMajor_axis axis: 2001-01-12 00:00:00 to 2001-01-15 00:00:00\nMinor_axis axis: A to B\n\nIn [22]: p.loc[:, :, 'C'] = pd.Series([30, 32], index=p.items)\n\nIn [23]: p\nOut[23]:\n<class 'pandas.core.panel.Panel'>\nDimensions: 2 (items) x 4 (major_axis) x 3 (minor_axis)\nItems axis: Item1 to Item2\nMajor_axis axis: 2001-01-12 00:00:00 to 2001-01-15 00:00:00\nMinor_axis axis: A to C\n\nIn [24]: p.loc[:, :, 'C']\nOut[24]:\n Item1  Item2\n2001-01-12   30.0   32.0\n2001-01-13   30.0   32.0\n2001-01-14   30.0   32.0\n2001-01-15   30.0   32.0 \n```", "```py\n    In [16]: index = pd.Index([1.5, 2, 3, 4.5, 5])\n\n    In [17]: index\n    Out[17]: Index([1.5, 2.0, 3.0, 4.5, 5.0], dtype='float64')\n\n    In [18]: s = pd.Series(range(5), index=index)\n\n    In [19]: s\n    Out[19]: \n    1.5    0\n    2.0    1\n    3.0    2\n    4.5    3\n    5.0    4\n    dtype: int64 \n    ```", "```py\n    In [20]: s[3]\n    Out[20]: 2\n\n    In [21]: s.loc[3]\n    Out[21]: 2 \n    ```", "```py\n    In [22]: s.iloc[3]\n    Out[22]: 3 \n    ```", "```py\n    In [23]: s[2:4]\n    Out[23]: \n    2.0    1\n    3.0    2\n    dtype: int64\n\n    In [24]: s.loc[2:4]\n    Out[24]: \n    2.0    1\n    3.0    2\n    dtype: int64\n\n    In [25]: s.iloc[2:4]\n    Out[25]: \n    3.0    2\n    4.5    3\n    dtype: int64 \n    ```", "```py\n    In [26]: s[2.1:4.6]\n    Out[26]: \n    3.0    2\n    4.5    3\n    dtype: int64\n\n    In [27]: s.loc[2.1:4.6]\n    Out[27]: \n    3.0    2\n    4.5    3\n    dtype: int64 \n    ```", "```py\n    In [1]: pd.Series(range(5))[3.5]\n    TypeError: the label [3.5] is not a proper indexer for this index type (Int64Index)\n\n    In [1]: pd.Series(range(5))[3.5:4.5]\n    TypeError: the slice start [3.5] is not a proper indexer for this index type (Int64Index) \n    ```", "```py\n    In [3]: pd.Series(range(5))[3.0]\n    Out[3]: 3 \n    ```", "```py\n    In [28]: path = 'test.h5'\n\n    In [29]: dfq = pd.DataFrame(np.random.randn(10, 4),\n     ....:                   columns=list('ABCD'),\n     ....:                   index=pd.date_range('20130101', periods=10))\n     ....: \n\n    In [30]: dfq.to_hdf(path, key='dfq', format='table', data_columns=True) \n    ```", "```py\n    In [31]: pd.read_hdf(path, 'dfq',\n     ....:            where=\"index>Timestamp('20130104') & columns=['A', 'B']\")\n     ....: \n    Out[31]: \n     A         B\n    2013-01-05 -0.424972  0.567020\n    2013-01-06 -0.673690  0.113648\n    2013-01-07  0.404705  0.577046\n    2013-01-08 -0.370647 -1.157892\n    2013-01-09  1.075770 -0.109050\n    2013-01-10  0.357021 -0.674600 \n    ```", "```py\n    In [32]: pd.read_hdf(path, 'dfq',\n     ....:            where=\"A>0 or C>0\")\n     ....: \n    Out[32]: \n     A         B         C         D\n    2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\n    2013-01-02  1.212112 -0.173215  0.119209 -1.044236\n    2013-01-04  0.721555 -0.706771 -1.039575  0.271860\n    2013-01-05 -0.424972  0.567020  0.276232 -1.087401\n    2013-01-07  0.404705  0.577046 -1.715002 -1.039268\n    2013-01-09  1.075770 -0.109050  1.643563 -1.469388\n    2013-01-10  0.357021 -0.674600 -1.776904 -0.968914 \n    ```", "```py\n    In [33]: path = 'test.h5'\n\n    In [34]: df = pd.DataFrame(np.random.randn(10, 2))\n\n    In [35]: df.to_hdf(path, key='df_table', format='table')\n\n    In [36]: df.to_hdf(path, key='df_table2', append=True)\n\n    In [37]: df.to_hdf(path, key='df_fixed')\n\n    In [38]: with pd.HDFStore(path) as store:\n     ....:    print(store)\n     ....: \n    <class 'pandas.io.pytables.HDFStore'>\n    File path: test.h5 \n    ```", "```py\n    In [39]: path = 'test.h5'\n\n    In [40]: df = pd.DataFrame(np.random.randn(10, 2))\n\n    In [41]: store1 = pd.HDFStore(path)\n\n    In [42]: store2 = pd.HDFStore(path)\n\n    In [43]: store1.append('df', df)\n\n    In [44]: store2.append('df2', df)\n\n    In [45]: store1\n    Out[45]: \n    <class 'pandas.io.pytables.HDFStore'>\n    File path: test.h5\n\n    In [46]: store2\n    Out[46]: \n    <class 'pandas.io.pytables.HDFStore'>\n    File path: test.h5\n\n    In [47]: store1.close()\n\n    In [48]: store2\n    Out[48]: \n    <class 'pandas.io.pytables.HDFStore'>\n    File path: test.h5\n\n    In [49]: store2.close()\n\n    In [50]: store2\n    Out[50]: \n    <class 'pandas.io.pytables.HDFStore'>\n    File path: test.h5 \n    ```", "```py\n    # previously, nan was erroneously counted as 2 here\n    # now it is not counted at all\n    In [51]: pd.get_dummies([1, 2, np.nan])\n    Out[51]: \n     1.0    2.0\n    0   True  False\n    1  False   True\n    2  False  False\n\n    # unless requested\n    In [52]: pd.get_dummies([1, 2, np.nan], dummy_na=True)\n    Out[52]: \n     1.0    2.0    NaN\n    0   True  False  False\n    1  False   True  False\n    2  False  False   True \n    ```", "```py\n    In [53]: pd.to_timedelta('1 days 06:05:01.00003')\n    Out[53]: Timedelta('1 days 06:05:01.000030')\n\n    In [54]: pd.to_timedelta('15.5us')\n    Out[54]: Timedelta('0 days 00:00:00.000015500')\n\n    In [55]: pd.to_timedelta(['1 days 06:05:01.00003', '15.5us', 'nan'])\n    Out[55]: TimedeltaIndex(['1 days 06:05:01.000030', '0 days 00:00:00.000015500', NaT], dtype='timedelta64[ns]', freq=None)\n\n    In [56]: pd.to_timedelta(np.arange(5), unit='s')\n    Out[56]: \n    TimedeltaIndex(['0 days 00:00:00', '0 days 00:00:01', '0 days 00:00:02',\n     '0 days 00:00:03', '0 days 00:00:04'],\n     dtype='timedelta64[ns]', freq=None)\n\n    In [57]: pd.to_timedelta(np.arange(5), unit='d')\n    Out[57]: TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'], dtype='timedelta64[ns]', freq=None) \n    ```", "```py\n    In [58]: import datetime\n\n    In [59]: td = pd.Series(pd.date_range('20130101', periods=4)) - pd.Series(\n     ....:    pd.date_range('20121201', periods=4))\n     ....: \n\n    In [60]: td[2] += np.timedelta64(datetime.timedelta(minutes=5, seconds=3))\n\n    In [61]: td[3] = np.nan\n\n    In [62]: td\n    Out[62]: \n    0   31 days 00:00:00\n    1   31 days 00:00:00\n    2   31 days 00:05:03\n    3                NaT\n    dtype: timedelta64[ns] \n    ```", "```py\n    # to days\n    In [63]: td / np.timedelta64(1, 'D')\n    Out[63]:\n    0    31.000000\n    1    31.000000\n    2    31.003507\n    3          NaN\n    dtype: float64\n\n    In [64]: td.astype('timedelta64[D]')\n    Out[64]:\n    0    31.0\n    1    31.0\n    2    31.0\n    3     NaN\n    dtype: float64\n\n    # to seconds\n    In [65]: td / np.timedelta64(1, 's')\n    Out[65]:\n    0    2678400.0\n    1    2678400.0\n    2    2678703.0\n    3          NaN\n    dtype: float64\n\n    In [66]: td.astype('timedelta64[s]')\n    Out[66]:\n    0    2678400.0\n    1    2678400.0\n    2    2678703.0\n    3          NaN\n    dtype: float64 \n    ```", "```py\n    In [63]: td * -1\n    Out[63]: \n    0   -31 days +00:00:00\n    1   -31 days +00:00:00\n    2   -32 days +23:54:57\n    3                  NaT\n    dtype: timedelta64[ns]\n\n    In [64]: td * pd.Series([1, 2, 3, 4])\n    Out[64]: \n    0   31 days 00:00:00\n    1   62 days 00:00:00\n    2   93 days 00:15:09\n    3                NaT\n    dtype: timedelta64[ns] \n    ```", "```py\n    In [65]: from pandas import offsets\n\n    In [66]: td + offsets.Minute(5) + offsets.Milli(5)\n    Out[66]: \n    0   31 days 00:05:00.005000\n    1   31 days 00:05:00.005000\n    2   31 days 00:10:03.005000\n    3                       NaT\n    dtype: timedelta64[ns] \n    ```", "```py\n    In [67]: td.fillna(pd.Timedelta(0))\n    Out[67]: \n    0   31 days 00:00:00\n    1   31 days 00:00:00\n    2   31 days 00:05:03\n    3    0 days 00:00:00\n    dtype: timedelta64[ns]\n\n    In [68]: td.fillna(datetime.timedelta(days=1, seconds=5))\n    Out[68]: \n    0   31 days 00:00:00\n    1   31 days 00:00:00\n    2   31 days 00:05:03\n    3    1 days 00:00:05\n    dtype: timedelta64[ns] \n    ```", "```py\n    In [69]: td.mean()\n    Out[69]: Timedelta('31 days 00:01:41')\n\n    In [70]: td.quantile(.1)\n    Out[70]: Timedelta('31 days 00:00:00') \n    ```", "```py\n    In [71]: pd.Series(['a1', 'b2', 'c3']).str.extract('[ab](\\\\d)')\n    Out[71]: \n     0\n    0    1\n    1    2\n    2  NaN \n    ```", "```py\n    In [72]: pd.Series(['a1', 'b2', 'c3']).str.extract('([ab])(\\\\d)')\n    Out[72]: \n     0    1\n    0    a    1\n    1    b    2\n    2  NaN  NaN \n    ```", "```py\n    In [73]: pd.Series(['a1', 'b2', 'c3']).str.extract(\n     ....:    '(?P<letter>[ab])(?P<digit>\\\\d)')\n     ....: \n    Out[73]: \n     letter digit\n    0      a     1\n    1      b     2\n    2    NaN   NaN \n    ```", "```py\n    In [74]: pd.Series(['a1', 'b2', '3']).str.extract(\n     ....:     '(?P<letter>[ab])?(?P<digit>\\\\d)')\n     ....: \n    Out[74]: \n     letter digit\n    0      a     1\n    1      b     2\n    2    NaN     3 \n    ```", "```py\n    In [79]: pd.date_range('2013-01-01', periods=5, freq='5N')\n    Out[79]:\n    DatetimeIndex([          '2013-01-01 00:00:00',\n                   '2013-01-01 00:00:00.000000005',\n                   '2013-01-01 00:00:00.000000010',\n                   '2013-01-01 00:00:00.000000015',\n                   '2013-01-01 00:00:00.000000020'],\n                  dtype='datetime64[ns]', freq='5N') \n    ```", "```py\n    In [75]: pd.date_range('2013-01-01', periods=5, freq=pd.offsets.Nano(5))\n    Out[75]: \n    DatetimeIndex([          '2013-01-01 00:00:00',\n     '2013-01-01 00:00:00.000000005',\n     '2013-01-01 00:00:00.000000010',\n     '2013-01-01 00:00:00.000000015',\n     '2013-01-01 00:00:00.000000020'],\n     dtype='datetime64[ns]', freq='5ns') \n    ```", "```py\n    In [76]: t = pd.Timestamp('20130101 09:01:02')\n\n    In [77]: t + pd.tseries.offsets.Nano(123)\n    Out[77]: Timestamp('2013-01-01 09:01:02.000000123') \n    ```", "```py\n    In [78]: dfi = pd.DataFrame({'A': [1, 2, 3, 4], 'B': ['a', 'b', 'f', 'n']})\n\n    In [79]: dfi\n    Out[79]: \n     A  B\n    0  1  a\n    1  2  b\n    2  3  f\n    3  4  n\n\n    In [80]: other = pd.DataFrame({'A': [1, 3, 3, 7], 'B': ['e', 'f', 'f', 'e']})\n\n    In [81]: mask = dfi.isin(other)\n\n    In [82]: mask\n    Out[82]: \n     A      B\n    0   True  False\n    1  False  False\n    2   True   True\n    3  False  False\n\n    In [83]: dfi[mask.any(axis=1)]\n    Out[83]: \n     A  B\n    0  1  a\n    2  3  f \n    ```", "```py\n    # note that pandas.rpy was deprecated in v0.16.0\n    import pandas.rpy.common as com\n    com.load_data('Titanic') \n    ```", "```py\n    In [84]: df = pd.DataFrame({'A': [1, 2.1, np.nan, 4.7, 5.6, 6.8],\n     ....:                  'B': [.25, np.nan, np.nan, 4, 12.2, 14.4]})\n     ....: \n\n    In [85]: df.interpolate()\n    Out[85]: \n     A      B\n    0  1.0   0.25\n    1  2.1   1.50\n    2  3.4   2.75\n    3  4.7   4.00\n    4  5.6  12.20\n    5  6.8  14.40 \n    ```", "```py\n    In [86]: ser = pd.Series([1, 3, np.nan, np.nan, np.nan, 11])\n\n    In [87]: ser.interpolate(limit=2)\n    Out[87]: \n    0     1.0\n    1     3.0\n    2     5.0\n    3     7.0\n    4     NaN\n    5    11.0\n    dtype: float64 \n    ```", "```py\n    In [88]: np.random.seed(123)\n\n    In [89]: df = pd.DataFrame({\"A1970\" : {0 : \"a\", 1 : \"b\", 2 : \"c\"},\n     ....:                   \"A1980\" : {0 : \"d\", 1 : \"e\", 2 : \"f\"},\n     ....:                   \"B1970\" : {0 : 2.5, 1 : 1.2, 2 : .7},\n     ....:                   \"B1980\" : {0 : 3.2, 1 : 1.3, 2 : .1},\n     ....:                   \"X\"     : dict(zip(range(3), np.random.randn(3)))\n     ....:                  })\n     ....: \n\n    In [90]: df[\"id\"] = df.index\n\n    In [91]: df\n    Out[91]: \n     A1970 A1980  B1970  B1980         X  id\n    0     a     d    2.5    3.2 -1.085631   0\n    1     b     e    1.2    1.3  0.997345   1\n    2     c     f    0.7    0.1  0.282978   2\n\n    In [92]: pd.wide_to_long(df, [\"A\", \"B\"], i=\"id\", j=\"year\")\n    Out[92]: \n     X  A    B\n    id year \n    0  1970 -1.085631  a  2.5\n    1  1970  0.997345  b  1.2\n    2  1970  0.282978  c  0.7\n    0  1980 -1.085631  d  3.2\n    1  1980  0.997345  e  1.3\n    2  1980  0.282978  f  0.1 \n    ```", "```py\n    In [93]: nrows, ncols = 20000, 100\n\n    In [94]: df1, df2, df3, df4 = [pd.DataFrame(np.random.randn(nrows, ncols))\n     ....:                      for _ in range(4)]\n     ....: \n    ```", "```py\n    # eval with NumExpr backend\n    In [95]: %timeit pd.eval('df1 + df2 + df3 + df4')\n    2.82 ms +- 67.4 us per loop (mean +- std. dev. of 7 runs, 100 loops each) \n    ```", "```py\n    # pure Python evaluation\n    In [96]: %timeit df1 + df2 + df3 + df4\n    2.89 ms +- 56.9 us per loop (mean +- std. dev. of 7 runs, 100 loops each) \n    ```", "```py\n    In [97]: df = pd.DataFrame(np.random.randn(10, 2), columns=['a', 'b'])\n\n    In [98]: df.eval('a + b')\n    Out[98]: \n    0   -0.685204\n    1    1.589745\n    2    0.325441\n    3   -1.784153\n    4   -0.432893\n    5    0.171850\n    6    1.895919\n    7    3.065587\n    8   -0.092759\n    9    1.391365\n    dtype: float64 \n    ```", "```py\n    In [99]: n = 20\n\n    In [100]: df = pd.DataFrame(np.random.randint(n, size=(n, 3)), columns=['a', 'b', 'c'])\n\n    In [101]: df.query('a < b < c')\n    Out[101]: \n     a   b   c\n    11  1   5   8\n    15  8  16  19 \n    ```", "```py\n    df = pd.DataFrame(np.random.rand(5, 2), columns=list('AB'))\n    df.to_msgpack('foo.msg')\n    pd.read_msgpack('foo.msg')\n\n    s = pd.Series(np.random.rand(5), index=pd.date_range('20130101', periods=5))\n    pd.to_msgpack('foo.msg', df, s)\n    pd.read_msgpack('foo.msg') \n    ```", "```py\n    for o in pd.read_msgpack('foo.msg', iterator=True):\n        print(o) \n    ```", "```py\n    from pandas.io import gbq\n\n    # A query to select the average monthly temperatures in the\n    # in the year 2000 across the USA. The dataset,\n    # publicata:samples.gsod, is available on all BigQuery accounts,\n    # and is based on NOAA gsod data.\n\n    query = \"\"\"SELECT station_number as STATION,\n    month as MONTH, AVG(mean_temp) as MEAN_TEMP\n    FROM publicdata:samples.gsod\n    WHERE YEAR = 2000\n    GROUP BY STATION, MONTH\n    ORDER BY STATION, MONTH ASC\"\"\"\n\n    # Fetch the result set for this query\n\n    # Your Google BigQuery Project ID\n    # To find this, see your dashboard:\n    # https://console.developers.google.com/iam-admin/projects?authuser=0\n    projectid = 'xxxxxxxxx'\n    df = gbq.read_gbq(query, project_id=projectid)\n\n    # Use pandas to process and reshape the dataset\n\n    df2 = df.pivot(index='STATION', columns='MONTH', values='MEAN_TEMP')\n    df3 = pd.concat([df2.min(), df2.mean(), df2.max()],\n                    axis=1, keys=[\"Min Tem\", \"Mean Temp\", \"Max Temp\"]) \n    ```", "```py\n    > df3\n                Min Tem  Mean Temp    Max Temp\n     MONTH\n     1     -53.336667  39.827892   89.770968\n     2     -49.837500  43.685219   93.437932\n     3     -77.926087  48.708355   96.099998\n     4     -82.892858  55.070087   97.317240\n     5     -92.378261  61.428117  102.042856\n     6     -77.703334  65.858888  102.900000\n     7     -87.821428  68.169663  106.510714\n     8     -89.431999  68.614215  105.500000\n     9     -86.611112  63.436935  107.142856\n     10    -78.209677  56.880838   92.103333\n     11    -50.125000  48.861228   94.996428\n     12    -50.332258  42.286879   94.396774 \n    ```", "```py\n    In [102]: s = pd.Series([1, 2, 3, 4]) \n    ```", "```py\n    In [103]: np.ones_like(s)\n    Out[103]: array([1, 1, 1, 1])\n\n    In [104]: np.diff(s)\n    Out[104]: array([1, 1, 1])\n\n    In [105]: np.where(s > 1, s, np.nan)\n    Out[105]: array([nan,  2.,  3.,  4.]) \n    ```", "```py\n    In [106]: pd.Series(1, index=s.index)\n    Out[106]: \n    0    1\n    1    1\n    2    1\n    3    1\n    dtype: int64\n\n    In [107]: s.diff()\n    Out[107]: \n    0    NaN\n    1    1.0\n    2    1.0\n    3    1.0\n    dtype: float64\n\n    In [108]: s.where(s > 1)\n    Out[108]: \n    0    NaN\n    1    2.0\n    2    3.0\n    3    4.0\n    dtype: float64 \n    ```", "```py\n    In [109]: s = pd.Series([1, 2, 3], index=list('abc'))\n\n    In [110]: s.b\n    Out[110]: 2\n\n    In [111]: s.a = 5\n\n    In [112]: s\n    Out[112]: \n    a    5\n    b    2\n    c    3\n    dtype: int64 \n    ```", "```py\n    # previously, you would have set levels or labels directly\n    >>> pd.index.levels = [[1, 2, 3, 4], [1, 2, 4, 4]]\n\n    # now, you use the set_levels or set_labels methods\n    >>> index = pd.index.set_levels([[1, 2, 3, 4], [1, 2, 4, 4]])\n\n    # similarly, for names, you can rename the object\n    # but setting names is not deprecated\n    >>> index = pd.index.set_names([\"bob\", \"cranberry\"])\n\n    # and all methods take an inplace kwarg - but return None\n    >>> pd.index.set_names([\"bob\", \"cranberry\"], inplace=True) \n    ```", "```py\n    In [3]: arr = np.array([1, 2, 3, 4])\n\n    In [4]: arr2 = np.array([5, 3, 2, 1])\n\n    In [5]: arr / arr2\n    Out[5]: array([0, 0, 1, 4])\n\n    In [6]: pd.Series(arr) // pd.Series(arr2)\n    Out[6]:\n    0    0\n    1    0\n    2    1\n    3    4\n    dtype: int64 \n    ```", "```py\n    In [7]: pd.Series(arr) / pd.Series(arr2)  # no future import required\n    Out[7]:\n    0    0.200000\n    1    0.666667\n    2    1.500000\n    3    4.000000\n    dtype: float64 \n    ```", "```py\n    >>> df = pd.DataFrame({'A': np.random.randn(10),\n    ...                    'B': np.random.randn(10),\n    ...                    'C': pd.date_range('20130101', periods=10)\n    ...                    })\n    ...\n    >>> if df:\n    ...     pass\n    ...\n    Traceback (most recent call last):\n      ...\n    ValueError: The truth value of a DataFrame is ambiguous.  Use a.empty,\n    a.bool(), a.item(), a.any() or a.all().\n\n    >>> df1 = df\n    >>> df2 = df\n    >>> df1 and df2\n    Traceback (most recent call last):\n      ...\n    ValueError: The truth value of a DataFrame is ambiguous.  Use a.empty,\n    a.bool(), a.item(), a.any() or a.all().\n\n    >>> d = [1, 2, 3]\n    >>> s1 = pd.Series(d)\n    >>> s2 = pd.Series(d)\n    >>> s1 and s2\n    Traceback (most recent call last):\n      ...\n    ValueError: The truth value of a DataFrame is ambiguous.  Use a.empty,\n    a.bool(), a.item(), a.any() or a.all(). \n    ```", "```py\n    >>> pd.Series([True]).bool()\n     True\n    >>> pd.Series([False]).bool()\n     False\n    >>> pd.DataFrame([[True]]).bool()\n     True\n    >>> pd.DataFrame([[False]]).bool()\n     False \n    ```", "```py\n    In [1]: dfc = pd.DataFrame({'A': ['aaa', 'bbb', 'ccc'], 'B': [1, 2, 3]})\n\n    In [2]: pd.set_option('chained_assignment', 'warn') \n    ```", "```py\n    In [3]: dfc.loc[0]['A'] = 1111 \n    ```", "```py\n    Traceback (most recent call last)\n       ...\n    SettingWithCopyWarning:\n       A value is trying to be set on a copy of a slice from a DataFrame.\n       Try using .loc[row_index,col_indexer] = value instead \n    ```", "```py\n    In [4]: dfc.loc[0, 'A'] = 11\n\n    In [5]: dfc\n    Out[5]: \n     A  B\n    0   11  1\n    1  bbb  2\n    2  ccc  3 \n    ```", "```py\nIn [6]: s = pd.Series([1, 2, 3])\n\nIn [7]: s\nOut[7]: \n0    1\n1    2\n2    3\ndtype: int64\n\nIn [8]: s[5] = 5.\n\nIn [9]: s\nOut[9]: \n0    1.0\n1    2.0\n2    3.0\n5    5.0\ndtype: float64 \n```", "```py\nIn [10]: dfi = pd.DataFrame(np.arange(6).reshape(3, 2),\n ....:                   columns=['A', 'B'])\n ....: \n\nIn [11]: dfi\nOut[11]: \n A  B\n0  0  1\n1  2  3\n2  4  5 \n```", "```py\nIn [12]: dfi.loc[:, 'C'] = dfi.loc[:, 'A']\n\nIn [13]: dfi\nOut[13]: \n A  B  C\n0  0  1  0\n1  2  3  2\n2  4  5  4 \n```", "```py\nIn [14]: dfi.loc[3] = 5\n\nIn [15]: dfi\nOut[15]: \n A  B  C\n0  0  1  0\n1  2  3  2\n2  4  5  4\n3  5  5  5 \n```", "```py\nIn [20]: p = pd.Panel(np.arange(16).reshape(2, 4, 2),\n ....:             items=['Item1', 'Item2'],\n ....:             major_axis=pd.date_range('2001/1/12', periods=4),\n ....:             minor_axis=['A', 'B'], dtype='float64')\n ....:\n\nIn [21]: p\nOut[21]:\n<class 'pandas.core.panel.Panel'>\nDimensions: 2 (items) x 4 (major_axis) x 2 (minor_axis)\nItems axis: Item1 to Item2\nMajor_axis axis: 2001-01-12 00:00:00 to 2001-01-15 00:00:00\nMinor_axis axis: A to B\n\nIn [22]: p.loc[:, :, 'C'] = pd.Series([30, 32], index=p.items)\n\nIn [23]: p\nOut[23]:\n<class 'pandas.core.panel.Panel'>\nDimensions: 2 (items) x 4 (major_axis) x 3 (minor_axis)\nItems axis: Item1 to Item2\nMajor_axis axis: 2001-01-12 00:00:00 to 2001-01-15 00:00:00\nMinor_axis axis: A to C\n\nIn [24]: p.loc[:, :, 'C']\nOut[24]:\n Item1  Item2\n2001-01-12   30.0   32.0\n2001-01-13   30.0   32.0\n2001-01-14   30.0   32.0\n2001-01-15   30.0   32.0 \n```", "```py\n    In [16]: index = pd.Index([1.5, 2, 3, 4.5, 5])\n\n    In [17]: index\n    Out[17]: Index([1.5, 2.0, 3.0, 4.5, 5.0], dtype='float64')\n\n    In [18]: s = pd.Series(range(5), index=index)\n\n    In [19]: s\n    Out[19]: \n    1.5    0\n    2.0    1\n    3.0    2\n    4.5    3\n    5.0    4\n    dtype: int64 \n    ```", "```py\n    In [20]: s[3]\n    Out[20]: 2\n\n    In [21]: s.loc[3]\n    Out[21]: 2 \n    ```", "```py\n    In [22]: s.iloc[3]\n    Out[22]: 3 \n    ```", "```py\n    In [23]: s[2:4]\n    Out[23]: \n    2.0    1\n    3.0    2\n    dtype: int64\n\n    In [24]: s.loc[2:4]\n    Out[24]: \n    2.0    1\n    3.0    2\n    dtype: int64\n\n    In [25]: s.iloc[2:4]\n    Out[25]: \n    3.0    2\n    4.5    3\n    dtype: int64 \n    ```", "```py\n    In [26]: s[2.1:4.6]\n    Out[26]: \n    3.0    2\n    4.5    3\n    dtype: int64\n\n    In [27]: s.loc[2.1:4.6]\n    Out[27]: \n    3.0    2\n    4.5    3\n    dtype: int64 \n    ```", "```py\n    In [1]: pd.Series(range(5))[3.5]\n    TypeError: the label [3.5] is not a proper indexer for this index type (Int64Index)\n\n    In [1]: pd.Series(range(5))[3.5:4.5]\n    TypeError: the slice start [3.5] is not a proper indexer for this index type (Int64Index) \n    ```", "```py\n    In [3]: pd.Series(range(5))[3.0]\n    Out[3]: 3 \n    ```", "```py\n    In [28]: path = 'test.h5'\n\n    In [29]: dfq = pd.DataFrame(np.random.randn(10, 4),\n     ....:                   columns=list('ABCD'),\n     ....:                   index=pd.date_range('20130101', periods=10))\n     ....: \n\n    In [30]: dfq.to_hdf(path, key='dfq', format='table', data_columns=True) \n    ```", "```py\n    In [31]: pd.read_hdf(path, 'dfq',\n     ....:            where=\"index>Timestamp('20130104') & columns=['A', 'B']\")\n     ....: \n    Out[31]: \n     A         B\n    2013-01-05 -0.424972  0.567020\n    2013-01-06 -0.673690  0.113648\n    2013-01-07  0.404705  0.577046\n    2013-01-08 -0.370647 -1.157892\n    2013-01-09  1.075770 -0.109050\n    2013-01-10  0.357021 -0.674600 \n    ```", "```py\n    In [32]: pd.read_hdf(path, 'dfq',\n     ....:            where=\"A>0 or C>0\")\n     ....: \n    Out[32]: \n     A         B         C         D\n    2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\n    2013-01-02  1.212112 -0.173215  0.119209 -1.044236\n    2013-01-04  0.721555 -0.706771 -1.039575  0.271860\n    2013-01-05 -0.424972  0.567020  0.276232 -1.087401\n    2013-01-07  0.404705  0.577046 -1.715002 -1.039268\n    2013-01-09  1.075770 -0.109050  1.643563 -1.469388\n    2013-01-10  0.357021 -0.674600 -1.776904 -0.968914 \n    ```", "```py\n    In [33]: path = 'test.h5'\n\n    In [34]: df = pd.DataFrame(np.random.randn(10, 2))\n\n    In [35]: df.to_hdf(path, key='df_table', format='table')\n\n    In [36]: df.to_hdf(path, key='df_table2', append=True)\n\n    In [37]: df.to_hdf(path, key='df_fixed')\n\n    In [38]: with pd.HDFStore(path) as store:\n     ....:    print(store)\n     ....: \n    <class 'pandas.io.pytables.HDFStore'>\n    File path: test.h5 \n    ```", "```py\n    In [39]: path = 'test.h5'\n\n    In [40]: df = pd.DataFrame(np.random.randn(10, 2))\n\n    In [41]: store1 = pd.HDFStore(path)\n\n    In [42]: store2 = pd.HDFStore(path)\n\n    In [43]: store1.append('df', df)\n\n    In [44]: store2.append('df2', df)\n\n    In [45]: store1\n    Out[45]: \n    <class 'pandas.io.pytables.HDFStore'>\n    File path: test.h5\n\n    In [46]: store2\n    Out[46]: \n    <class 'pandas.io.pytables.HDFStore'>\n    File path: test.h5\n\n    In [47]: store1.close()\n\n    In [48]: store2\n    Out[48]: \n    <class 'pandas.io.pytables.HDFStore'>\n    File path: test.h5\n\n    In [49]: store2.close()\n\n    In [50]: store2\n    Out[50]: \n    <class 'pandas.io.pytables.HDFStore'>\n    File path: test.h5 \n    ```", "```py\n    # previously, nan was erroneously counted as 2 here\n    # now it is not counted at all\n    In [51]: pd.get_dummies([1, 2, np.nan])\n    Out[51]: \n     1.0    2.0\n    0   True  False\n    1  False   True\n    2  False  False\n\n    # unless requested\n    In [52]: pd.get_dummies([1, 2, np.nan], dummy_na=True)\n    Out[52]: \n     1.0    2.0    NaN\n    0   True  False  False\n    1  False   True  False\n    2  False  False   True \n    ```", "```py\n    In [53]: pd.to_timedelta('1 days 06:05:01.00003')\n    Out[53]: Timedelta('1 days 06:05:01.000030')\n\n    In [54]: pd.to_timedelta('15.5us')\n    Out[54]: Timedelta('0 days 00:00:00.000015500')\n\n    In [55]: pd.to_timedelta(['1 days 06:05:01.00003', '15.5us', 'nan'])\n    Out[55]: TimedeltaIndex(['1 days 06:05:01.000030', '0 days 00:00:00.000015500', NaT], dtype='timedelta64[ns]', freq=None)\n\n    In [56]: pd.to_timedelta(np.arange(5), unit='s')\n    Out[56]: \n    TimedeltaIndex(['0 days 00:00:00', '0 days 00:00:01', '0 days 00:00:02',\n     '0 days 00:00:03', '0 days 00:00:04'],\n     dtype='timedelta64[ns]', freq=None)\n\n    In [57]: pd.to_timedelta(np.arange(5), unit='d')\n    Out[57]: TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'], dtype='timedelta64[ns]', freq=None) \n    ```", "```py\n    In [58]: import datetime\n\n    In [59]: td = pd.Series(pd.date_range('20130101', periods=4)) - pd.Series(\n     ....:    pd.date_range('20121201', periods=4))\n     ....: \n\n    In [60]: td[2] += np.timedelta64(datetime.timedelta(minutes=5, seconds=3))\n\n    In [61]: td[3] = np.nan\n\n    In [62]: td\n    Out[62]: \n    0   31 days 00:00:00\n    1   31 days 00:00:00\n    2   31 days 00:05:03\n    3                NaT\n    dtype: timedelta64[ns] \n    ```", "```py\n    # to days\n    In [63]: td / np.timedelta64(1, 'D')\n    Out[63]:\n    0    31.000000\n    1    31.000000\n    2    31.003507\n    3          NaN\n    dtype: float64\n\n    In [64]: td.astype('timedelta64[D]')\n    Out[64]:\n    0    31.0\n    1    31.0\n    2    31.0\n    3     NaN\n    dtype: float64\n\n    # to seconds\n    In [65]: td / np.timedelta64(1, 's')\n    Out[65]:\n    0    2678400.0\n    1    2678400.0\n    2    2678703.0\n    3          NaN\n    dtype: float64\n\n    In [66]: td.astype('timedelta64[s]')\n    Out[66]:\n    0    2678400.0\n    1    2678400.0\n    2    2678703.0\n    3          NaN\n    dtype: float64 \n    ```", "```py\n    In [63]: td * -1\n    Out[63]: \n    0   -31 days +00:00:00\n    1   -31 days +00:00:00\n    2   -32 days +23:54:57\n    3                  NaT\n    dtype: timedelta64[ns]\n\n    In [64]: td * pd.Series([1, 2, 3, 4])\n    Out[64]: \n    0   31 days 00:00:00\n    1   62 days 00:00:00\n    2   93 days 00:15:09\n    3                NaT\n    dtype: timedelta64[ns] \n    ```", "```py\n    In [65]: from pandas import offsets\n\n    In [66]: td + offsets.Minute(5) + offsets.Milli(5)\n    Out[66]: \n    0   31 days 00:05:00.005000\n    1   31 days 00:05:00.005000\n    2   31 days 00:10:03.005000\n    3                       NaT\n    dtype: timedelta64[ns] \n    ```", "```py\n    In [67]: td.fillna(pd.Timedelta(0))\n    Out[67]: \n    0   31 days 00:00:00\n    1   31 days 00:00:00\n    2   31 days 00:05:03\n    3    0 days 00:00:00\n    dtype: timedelta64[ns]\n\n    In [68]: td.fillna(datetime.timedelta(days=1, seconds=5))\n    Out[68]: \n    0   31 days 00:00:00\n    1   31 days 00:00:00\n    2   31 days 00:05:03\n    3    1 days 00:00:05\n    dtype: timedelta64[ns] \n    ```", "```py\n    In [69]: td.mean()\n    Out[69]: Timedelta('31 days 00:01:41')\n\n    In [70]: td.quantile(.1)\n    Out[70]: Timedelta('31 days 00:00:00') \n    ```", "```py\n    In [71]: pd.Series(['a1', 'b2', 'c3']).str.extract('[ab](\\\\d)')\n    Out[71]: \n     0\n    0    1\n    1    2\n    2  NaN \n    ```", "```py\n    In [72]: pd.Series(['a1', 'b2', 'c3']).str.extract('([ab])(\\\\d)')\n    Out[72]: \n     0    1\n    0    a    1\n    1    b    2\n    2  NaN  NaN \n    ```", "```py\n    In [73]: pd.Series(['a1', 'b2', 'c3']).str.extract(\n     ....:    '(?P<letter>[ab])(?P<digit>\\\\d)')\n     ....: \n    Out[73]: \n     letter digit\n    0      a     1\n    1      b     2\n    2    NaN   NaN \n    ```", "```py\n    In [74]: pd.Series(['a1', 'b2', '3']).str.extract(\n     ....:     '(?P<letter>[ab])?(?P<digit>\\\\d)')\n     ....: \n    Out[74]: \n     letter digit\n    0      a     1\n    1      b     2\n    2    NaN     3 \n    ```", "```py\n    In [79]: pd.date_range('2013-01-01', periods=5, freq='5N')\n    Out[79]:\n    DatetimeIndex([          '2013-01-01 00:00:00',\n                   '2013-01-01 00:00:00.000000005',\n                   '2013-01-01 00:00:00.000000010',\n                   '2013-01-01 00:00:00.000000015',\n                   '2013-01-01 00:00:00.000000020'],\n                  dtype='datetime64[ns]', freq='5N') \n    ```", "```py\n    In [75]: pd.date_range('2013-01-01', periods=5, freq=pd.offsets.Nano(5))\n    Out[75]: \n    DatetimeIndex([          '2013-01-01 00:00:00',\n     '2013-01-01 00:00:00.000000005',\n     '2013-01-01 00:00:00.000000010',\n     '2013-01-01 00:00:00.000000015',\n     '2013-01-01 00:00:00.000000020'],\n     dtype='datetime64[ns]', freq='5ns') \n    ```", "```py\n    In [76]: t = pd.Timestamp('20130101 09:01:02')\n\n    In [77]: t + pd.tseries.offsets.Nano(123)\n    Out[77]: Timestamp('2013-01-01 09:01:02.000000123') \n    ```", "```py\n    In [78]: dfi = pd.DataFrame({'A': [1, 2, 3, 4], 'B': ['a', 'b', 'f', 'n']})\n\n    In [79]: dfi\n    Out[79]: \n     A  B\n    0  1  a\n    1  2  b\n    2  3  f\n    3  4  n\n\n    In [80]: other = pd.DataFrame({'A': [1, 3, 3, 7], 'B': ['e', 'f', 'f', 'e']})\n\n    In [81]: mask = dfi.isin(other)\n\n    In [82]: mask\n    Out[82]: \n     A      B\n    0   True  False\n    1  False  False\n    2   True   True\n    3  False  False\n\n    In [83]: dfi[mask.any(axis=1)]\n    Out[83]: \n     A  B\n    0  1  a\n    2  3  f \n    ```", "```py\n    # note that pandas.rpy was deprecated in v0.16.0\n    import pandas.rpy.common as com\n    com.load_data('Titanic') \n    ```", "```py\n    In [84]: df = pd.DataFrame({'A': [1, 2.1, np.nan, 4.7, 5.6, 6.8],\n     ....:                  'B': [.25, np.nan, np.nan, 4, 12.2, 14.4]})\n     ....: \n\n    In [85]: df.interpolate()\n    Out[85]: \n     A      B\n    0  1.0   0.25\n    1  2.1   1.50\n    2  3.4   2.75\n    3  4.7   4.00\n    4  5.6  12.20\n    5  6.8  14.40 \n    ```", "```py\n    In [86]: ser = pd.Series([1, 3, np.nan, np.nan, np.nan, 11])\n\n    In [87]: ser.interpolate(limit=2)\n    Out[87]: \n    0     1.0\n    1     3.0\n    2     5.0\n    3     7.0\n    4     NaN\n    5    11.0\n    dtype: float64 \n    ```", "```py\n    In [88]: np.random.seed(123)\n\n    In [89]: df = pd.DataFrame({\"A1970\" : {0 : \"a\", 1 : \"b\", 2 : \"c\"},\n     ....:                   \"A1980\" : {0 : \"d\", 1 : \"e\", 2 : \"f\"},\n     ....:                   \"B1970\" : {0 : 2.5, 1 : 1.2, 2 : .7},\n     ....:                   \"B1980\" : {0 : 3.2, 1 : 1.3, 2 : .1},\n     ....:                   \"X\"     : dict(zip(range(3), np.random.randn(3)))\n     ....:                  })\n     ....: \n\n    In [90]: df[\"id\"] = df.index\n\n    In [91]: df\n    Out[91]: \n     A1970 A1980  B1970  B1980         X  id\n    0     a     d    2.5    3.2 -1.085631   0\n    1     b     e    1.2    1.3  0.997345   1\n    2     c     f    0.7    0.1  0.282978   2\n\n    In [92]: pd.wide_to_long(df, [\"A\", \"B\"], i=\"id\", j=\"year\")\n    Out[92]: \n     X  A    B\n    id year \n    0  1970 -1.085631  a  2.5\n    1  1970  0.997345  b  1.2\n    2  1970  0.282978  c  0.7\n    0  1980 -1.085631  d  3.2\n    1  1980  0.997345  e  1.3\n    2  1980  0.282978  f  0.1 \n    ```", "```py\n    In [93]: nrows, ncols = 20000, 100\n\n    In [94]: df1, df2, df3, df4 = [pd.DataFrame(np.random.randn(nrows, ncols))\n     ....:                      for _ in range(4)]\n     ....: \n    ```", "```py\n    # eval with NumExpr backend\n    In [95]: %timeit pd.eval('df1 + df2 + df3 + df4')\n    2.82 ms +- 67.4 us per loop (mean +- std. dev. of 7 runs, 100 loops each) \n    ```", "```py\n    # pure Python evaluation\n    In [96]: %timeit df1 + df2 + df3 + df4\n    2.89 ms +- 56.9 us per loop (mean +- std. dev. of 7 runs, 100 loops each) \n    ```", "```py\n    In [97]: df = pd.DataFrame(np.random.randn(10, 2), columns=['a', 'b'])\n\n    In [98]: df.eval('a + b')\n    Out[98]: \n    0   -0.685204\n    1    1.589745\n    2    0.325441\n    3   -1.784153\n    4   -0.432893\n    5    0.171850\n    6    1.895919\n    7    3.065587\n    8   -0.092759\n    9    1.391365\n    dtype: float64 \n    ```", "```py\n    In [99]: n = 20\n\n    In [100]: df = pd.DataFrame(np.random.randint(n, size=(n, 3)), columns=['a', 'b', 'c'])\n\n    In [101]: df.query('a < b < c')\n    Out[101]: \n     a   b   c\n    11  1   5   8\n    15  8  16  19 \n    ```", "```py\n    df = pd.DataFrame(np.random.rand(5, 2), columns=list('AB'))\n    df.to_msgpack('foo.msg')\n    pd.read_msgpack('foo.msg')\n\n    s = pd.Series(np.random.rand(5), index=pd.date_range('20130101', periods=5))\n    pd.to_msgpack('foo.msg', df, s)\n    pd.read_msgpack('foo.msg') \n    ```", "```py\n    for o in pd.read_msgpack('foo.msg', iterator=True):\n        print(o) \n    ```", "```py\n    from pandas.io import gbq\n\n    # A query to select the average monthly temperatures in the\n    # in the year 2000 across the USA. The dataset,\n    # publicata:samples.gsod, is available on all BigQuery accounts,\n    # and is based on NOAA gsod data.\n\n    query = \"\"\"SELECT station_number as STATION,\n    month as MONTH, AVG(mean_temp) as MEAN_TEMP\n    FROM publicdata:samples.gsod\n    WHERE YEAR = 2000\n    GROUP BY STATION, MONTH\n    ORDER BY STATION, MONTH ASC\"\"\"\n\n    # Fetch the result set for this query\n\n    # Your Google BigQuery Project ID\n    # To find this, see your dashboard:\n    # https://console.developers.google.com/iam-admin/projects?authuser=0\n    projectid = 'xxxxxxxxx'\n    df = gbq.read_gbq(query, project_id=projectid)\n\n    # Use pandas to process and reshape the dataset\n\n    df2 = df.pivot(index='STATION', columns='MONTH', values='MEAN_TEMP')\n    df3 = pd.concat([df2.min(), df2.mean(), df2.max()],\n                    axis=1, keys=[\"Min Tem\", \"Mean Temp\", \"Max Temp\"]) \n    ```", "```py\n    > df3\n                Min Tem  Mean Temp    Max Temp\n     MONTH\n     1     -53.336667  39.827892   89.770968\n     2     -49.837500  43.685219   93.437932\n     3     -77.926087  48.708355   96.099998\n     4     -82.892858  55.070087   97.317240\n     5     -92.378261  61.428117  102.042856\n     6     -77.703334  65.858888  102.900000\n     7     -87.821428  68.169663  106.510714\n     8     -89.431999  68.614215  105.500000\n     9     -86.611112  63.436935  107.142856\n     10    -78.209677  56.880838   92.103333\n     11    -50.125000  48.861228   94.996428\n     12    -50.332258  42.286879   94.396774 \n    ```", "```py\n    In [102]: s = pd.Series([1, 2, 3, 4]) \n    ```", "```py\n    In [103]: np.ones_like(s)\n    Out[103]: array([1, 1, 1, 1])\n\n    In [104]: np.diff(s)\n    Out[104]: array([1, 1, 1])\n\n    In [105]: np.where(s > 1, s, np.nan)\n    Out[105]: array([nan,  2.,  3.,  4.]) \n    ```", "```py\n    In [106]: pd.Series(1, index=s.index)\n    Out[106]: \n    0    1\n    1    1\n    2    1\n    3    1\n    dtype: int64\n\n    In [107]: s.diff()\n    Out[107]: \n    0    NaN\n    1    1.0\n    2    1.0\n    3    1.0\n    dtype: float64\n\n    In [108]: s.where(s > 1)\n    Out[108]: \n    0    NaN\n    1    2.0\n    2    3.0\n    3    4.0\n    dtype: float64 \n    ```", "```py\n    In [109]: s = pd.Series([1, 2, 3], index=list('abc'))\n\n    In [110]: s.b\n    Out[110]: 2\n\n    In [111]: s.a = 5\n\n    In [112]: s\n    Out[112]: \n    a    5\n    b    2\n    c    3\n    dtype: int64 \n    ```"]