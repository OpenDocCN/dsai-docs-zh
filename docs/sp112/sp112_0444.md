# `scipy.optimize.differential_evolution`

> 原文链接：[`docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.differential_evolution.html#scipy.optimize.differential_evolution`](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.differential_evolution.html#scipy.optimize.differential_evolution)

```py
scipy.optimize.differential_evolution(func, bounds, args=(), strategy='best1bin', maxiter=1000, popsize=15, tol=0.01, mutation=(0.5, 1), recombination=0.7, seed=None, callback=None, disp=False, polish=True, init='latinhypercube', atol=0, updating='immediate', workers=1, constraints=(), x0=None, *, integrality=None, vectorized=False)
```

找到多元函数的全局最小值。

差分进化方法[[1]](#r108fc14fa019-1)具有随机性质。它不使用梯度方法来找到最小值，可以搜索候选空间的大面积，但通常需要比传统的基于梯度的技术更多的函数评估次数。

算法是由斯托恩和普赖斯[[2]](#r108fc14fa019-2)提出的。

参数：

**func**可调用

要最小化的目标函数。必须以 `f(x, *args)` 的形式存在，其中 *x* 是形式为 1-D 数组的参数，*args* 是任何额外的固定参数元组，用于完全指定函数。参数数量 *N* 等于 `len(x)`。

**bounds**序列或`Bounds`

变量的边界。有两种指定边界的方式：

> 1.  `Bounds` 类的实例。
> 1.  
> 1.  `(min, max)`对，用于定义 *func* 优化参数 *x* 的有限下限和上限。

使用总边界数来确定参数数量 *N*。如果有参数的边界相等，则自由参数的总数为 `N - N_equal`。

**args**元组，可选

用于完全指定目标函数的任何额外固定参数。

**strategy**{str, 可调用}，可选

使用的差分进化策略。应为以下之一：

> +   ‘best1bin’
> +   
> +   ‘best1exp’
> +   
> +   ‘rand1bin’
> +   
> +   ‘rand1exp’
> +   
> +   ‘rand2bin’
> +   
> +   ‘rand2exp’
> +   
> +   ‘randtobest1bin’
> +   
> +   ‘randtobest1exp’
> +   
> +   ‘currenttobest1bin’
> +   
> +   ‘currenttobest1exp’
> +   
> +   ‘best2exp’
> +   
> +   ‘best2bin’

默认为‘best1bin’。可以实施的策略在‘Notes’中有概述。另外，差分进化策略可以通过提供一个构建试验向量的可调用对象来进行定制化。该可调用对象必须具有形式`strategy(candidate: int, population: np.ndarray, rng=None)`，其中`candidate`是一个整数，指定要进化的种群条目，`population`是形状为`(S, N)`的数组，包含所有种群成员（其中 S 是总种群大小），`rng`是求解器内使用的随机数生成器。`candidate`的范围为`[0, S)`。`strategy`必须返回一个形状为*(N,)*的试验向量。将此试验向量的适应度与`population[candidate]`的适应度进行比较。

自版本 1.12.0 起更改：通过可调用对象定制进化策略。

**maxiter**int，可选

演化整个种群的最大代数。没有优化的最大函数评估次数为：`(maxiter + 1) * popsize * (N - N_equal)`。

**popsize**int, optional

用于设置总种群大小的乘数。种群包含`popsize * (N - N_equal)`个个体。如果通过*init*关键字提供了初始种群，则此关键字将被覆盖。使用`init='sobol'`时，种群大小计算为`popsize * (N - N_equal)`后的下一个 2 的幂。

**tol**float, optional

收敛的相对容差，当`np.std(pop) <= atol + tol * np.abs(np.mean(population_energies))`时停止求解，其中*atol*和*tol*分别为绝对容差和相对容差。

**mutation**float or tuple(float, float), optional

变异常数。在文献中，这也被称为差分权重，用 F 表示。如果指定为浮点数，则应在[0, 2]范围内。如果指定为元组`(min, max)`，则采用抖动。抖动会随机地在每代基础上改变变异常数。该代的变异常数取自`U[min, max)`。抖动可以显著加快收敛速度。增加变异常数会增加搜索半径，但会减慢收敛速度。

**recombination**float, optional

重组常数，应在[0, 1]范围内。在文献中，这也被称为交叉概率，用 CR 表示。增加此值允许更多的突变体进入下一代，但会有种群稳定性的风险。

**seed**{None, int, [`numpy.random.Generator`](https://numpy.org/devdocs/reference/random/generator.html#numpy.random.Generator "(在 NumPy v2.0.dev0 中)"), [`numpy.random.RandomState`](https://numpy.org/devdocs/reference/random/legacy.html#numpy.random.RandomState "(在 NumPy v2.0.dev0 中)")}, optional

如果*seed*为 None（或*np.random*），则使用[`numpy.random.RandomState`](https://numpy.org/devdocs/reference/random/legacy.html#numpy.random.RandomState "(在 NumPy v2.0.dev0 中)")单例。如果*seed*为整数，则使用一个新的`RandomState`实例，并用*seed*进行种子化。如果*seed*已经是`Generator`或`RandomState`实例，则使用该实例。为了重复最小化操作，请指定*seed*。

**disp**bool, optional

每次迭代时打印评估的*func*。

**callback**callable, optional

每次迭代后调用的可调用对象，具有以下签名：

> `callback(intermediate_result: OptimizeResult)`。

其中`intermediate_result`是一个包含`OptimizeResult`属性`x`和`fun`的关键字参数，表示到目前为止找到的最佳解和目标函数值。请注意，回调函数必须传递一个名为`intermediate_result`的`OptimizeResult`。

回调还支持类似的签名：

> `callback(x, convergence: float=val)`

`val`表示种群收敛的分数值。当`val`大于`1.0`时，函数停止。

使用内省来确定调用的签名之一。

全局最小化将在回调引发`StopIteration`或返回`True`时终止；仍会执行任何调整。

在版本 1.12.0 中更改：回调接受`intermediate_result`关键字。

**polish**bool，可选

如果为 True（默认），则最后使用*L-BFGS-B*方法的`scipy.optimize.minimize`来优化最佳种群成员，这可能会略微改善最小化。如果正在研究受约束问题，则改为使用*trust-constr*方法。对于具有许多约束的大问题，由于雅可比计算，优化可能需要很长时间。

**init**str 或类数组，可选

指定执行的种群初始化类型。应为以下之一：

> +   ‘latinhypercube’
> +   
> +   ‘sobol’
> +   
> +   ‘halton’
> +   
> +   ‘random’
> +   
> +   数组指定初始种群。数组应具有形状`(S, N)`，其中 S 为总种群大小，N 为参数数量。在使用之前，*init*将被剪辑到*bounds*内。

默认为‘latinhypercube’。拉丁超立方体采样试图最大化可用参数空间的覆盖。

‘sobol’和‘halton’是更优的选择，甚至更大程度地最大化参数空间。‘sobol’将强制初始种群大小计算为`popsize * (N - N_equal)`后的下一个 2 的幂。‘halton’没有要求，但效率稍低。有关更多详情，请参见`scipy.stats.qmc`。

‘random’随机初始化种群 - 这样做的缺点是可能会发生聚类，从而阻止参数空间的整体覆盖。例如，可以使用数组来指定种群，以在已知解存在的位置创建一组紧密的初始猜测，从而减少收敛时间。

**atol**float，可选

收敛的绝对容差，当`np.std(pop) <= atol + tol * np.abs(np.mean(population_energies))`时，求解停止，其中*atol*和*tol*分别是绝对容差和相对容差。

**updating**{‘immediate’, ‘deferred’}, optional

如果是`'immediate'`，则最佳解向量在单一生成过程中持续更新[[4]](#r108fc14fa019-4)。这可以加快收敛速度，因为试验向量可以利用最佳解的持续改进。如果是`'deferred'`，则最佳解向量每代更新一次。只有`'deferred'`与并行化或向量化兼容，且*workers*和*vectorized*关键字可以覆盖此选项。

自 1.2.0 版新增。

**工作者**int 或类似映射的可调用对象，可选

如果*workers*是整数，则将种群细分为*workers*部分，并并行评估（使用[`multiprocessing.Pool`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing "(在 Python v3.12 中)")）。提供-1 以使用所有可用 CPU 核心。或者提供类似映射的可调用对象，例如*multiprocessing.Pool.map*以并行评估种群。此评估以`workers(func, iterable)`进行。如果`workers != 1`，此选项将覆盖*updating*关键字为`updating='deferred'`。如果`workers != 1`，此选项将覆盖*vectorized*关键字。要求*func*可 pickle 化。

自 1.2.0 版新增。

**约束条件**{非线性约束，线性约束，边界}

解算器的约束条件，除了*bounds* kwd 应用的约束外。使用 Lampinen 的方法[[5]](#r108fc14fa019-5)。

自 1.4.0 版新增。

**x0**None 或类似数组，可选

提供最小化的初始猜测。一旦种群被初始化，此向量替换第一个（最佳）成员。即使*init*给出了初始种群，也会进行此替换。`x0.shape == (N,)`。

自 1.7.0 版新增。

**整数性**1-D 数组，可选

对于每个决策变量，一个布尔值，指示决策变量是否约束为整数值。该数组广播到`(N,)`。如果有任何决策变量被约束为整数，则在精炼过程中它们不会改变。只使用介于下限和上限之间的整数值。如果在边界之间没有整数值，则会引发*ValueError*。

自 1.9.0 版新增。

**向量化**bool，可选

如果`vectorized`为 True，则将使用形状为`(N, S)`的*x*数组发送给*func*，并期望返回一个形状为`(S,)`的数组，其中*S*是要计算的解向量数量。如果应用了约束条件，则用于构建*Constraint*对象的每个函数应接受形状为`(N, S)`的*x*数组，并返回形状为`(M, S)`的数组，其中*M*是约束组件的数量。这个选项是*workers*提供的并行化的替代方案，并且可以通过减少从多个函数调用中的解释器开销来提高优化速度。如果`workers != 1`，则将忽略此关键字。此选项将覆盖*updating*关键字为`updating='deferred'`。有关何时使用`'vectorized'`和何时使用`'workers'`的进一步讨论，请参见备注部分。

新版本 1.9.0 中的更新。

返回：

**res**OptimizeResult

优化结果表示为[`OptimizeResult`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.OptimizeResult.html#scipy.optimize.OptimizeResult "scipy.optimize.OptimizeResult")对象。重要属性包括：`x`解向量数组，`success`布尔标志，指示优化器是否成功退出，`message`描述终止原因，`population`种群中的解向量以及`population_energies`每个`population`条目的目标函数值。有关其他属性的描述，请参见[`OptimizeResult`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.OptimizeResult.html#scipy.optimize.OptimizeResult "scipy.optimize.OptimizeResult")。如果使用了*polish*，并且通过打磨获得了更低的最小值，则 OptimizeResult 还包含`jac`属性。如果最终解决方案不满足应用的约束条件，则`success`将为*False*。

备注

差分进化是一种基于随机种群的方法，适用于全局优化问题。在每次种群遍历过程中，算法通过与其他候选解混合来生成一个试验候选解，对每个候选解进行突变。有几种策略[[3]](#r108fc14fa019-3)用于创建试验候选解，适用于不同的问题。"best1bin"策略对许多系统而言是一个良好的起点。在这种策略中，随机选择种群中的两个成员。他们的差异用于突变迄今为止最佳成员（"best"在"best1bin"中的意思），\(x_0\)：

\[b' = x_0 + mutation * (x_{r_0} - x_{r_1})\]

然后构造一个试验向量。从随机选择的第 i 个参数开始，依次用来自`b'`或原始候选者的参数填充（取模）。使用`b'`或原始候选者的选择是通过二项分布（'best1bin'中的'bin'）进行的 - 生成一个介于[0, 1)的随机数。如果此数小于*recombination*常数，则参数从`b'`加载，否则从原始候选者加载。最后一个参数始终从`b'`加载。构建完试验候选者后，评估其适应度。如果试验结果比原始候选者好，则替换它。如果它还优于整体最佳候选者，则也替换该候选者。

其他可用的策略见 Qiang 和 Mitchell（2014）[[3]](https://r108fc14fa019-3)。

\[ \begin{align}\begin{aligned}rand1* : b' = x_{r_0} + mutation*(x_{r_1} - x_{r_2})\\rand2* : b' = x_{r_0} + mutation*(x_{r_1} + x_{r_2} - x_{r_3} - x_{r_4})\\best1* : b' = x_0 + mutation*(x_{r_0} - x_{r_1})\\best2* : b' = x_0 + mutation*(x_{r_0} + x_{r_1} - x_{r_2} - x_{r_3})\\currenttobest1* : b' = x_i + mutation*(x_0 - x_i + x_{r_0} - x_{r_1})\\randtobest1* : b' = x_{r_0} + mutation*(x_0 - x_{r_0} + x_{r_1} - x_{r_2})\end{aligned}\end{align} \]

其中整数\(r_0, r_1, r_2, r_3, r_4\)从区间[0, NP)随机选择，其中*NP*是总体大小，原始候选者索引为*i*。用户可以通过向`strategy`提供可调用对象来完全自定义试验候选者的生成方式。

要提高找到全局最小值的机会，可以使用更高的*popsize*值，更高的*mutation*值和（抖动），但更低的*recombination*值。这样做会扩大搜索半径，但会减慢收敛速度。

默认情况下，最佳解向量在单次迭代中持续更新（`updating='immediate'`）。这是对原始差分进化算法的修改[[4]](#r108fc14fa019-4)，可以使试验向量立即从改进的解决方案中获益。要使用斯托恩和普莱斯的原始行为，即每次迭代更新一次最佳解，设置`updating='deferred'`。`'deferred'`方法既兼容并行化和矢量化（`'workers'`和`'vectorized'`关键字）。这些方法可能通过更有效地利用计算资源来提高最小化速度。`'workers'`将计算分布到多个处理器上。默认情况下，Python 的[`multiprocessing`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing "(在 Python v3.12 中)")模块用于此，但也可以使用其他方法，例如在集群上使用消息传递接口（MPI）[[6]](#r108fc14fa019-6) [[7]](#r108fc14fa019-7)。这些方法（创建新进程等）可能会带来一定的开销，这意味着计算速度并不一定随使用处理器数量的增加而线性扩展。并行化最适合计算密集型目标函数。如果目标函数较为简单，则`'vectorized'`可能会有所帮助，因为它每次迭代仅调用一次目标函数，而不是为所有种群成员多次调用；解释器开销减少。

0.15.0 版新增内容。

参考文献

[1]

差分进化，维基百科，[`en.wikipedia.org/wiki/Differential_evolution`](http://en.wikipedia.org/wiki/Differential_evolution)

[2]

斯托恩（Storn, R）和普莱斯（Price, K），差分进化 - 一种简单高效的连续空间全局优化启发式算法，全球优化期刊，1997 年，11，341 - 359。

[3] (1,2)

强（Qiang, J.），米切尔（Mitchell, C.），统一差分进化算法用于全局优化，2014 年，[`www.osti.gov/servlets/purl/1163659`](https://www.osti.gov/servlets/purl/1163659)

[4] (1,2)

沃明顿（Wormington, M.），帕纳乔内（Panaccione, C.），马特尼（Matney, K. M.），鲍文（Bowen, D. K.），利用遗传算法从 X 射线散射数据中表征结构，伦敦皇家学会 A 类学报，1999 年，357，2827-2848

[5]

兰皮宁（Lampinen, J.），差分进化算法的约束处理方法。2002 年进化计算大会论文集。CEC’02（Cat. No. 02TH8600）。第 2 卷。IEEE，2002 年。

[6]

[`mpi4py.readthedocs.io/en/stable/`](https://mpi4py.readthedocs.io/en/stable/)

[7]

[`schwimmbad.readthedocs.io/en/latest/`](https://schwimmbad.readthedocs.io/en/latest/)

例子

让我们考虑最小化 Rosenbrock 函数的问题。这个函数在 `rosen` 中实现于 `scipy.optimize`。

```py
>>> import numpy as np
>>> from scipy.optimize import rosen, differential_evolution
>>> bounds = [(0,2), (0, 2), (0, 2), (0, 2), (0, 2)]
>>> result = differential_evolution(rosen, bounds)
>>> result.x, result.fun
(array([1., 1., 1., 1., 1.]), 1.9216496320061384e-19) 
```

现在重复，但使用并行化。

```py
>>> result = differential_evolution(rosen, bounds, updating='deferred',
...                                 workers=2)
>>> result.x, result.fun
(array([1., 1., 1., 1., 1.]), 1.9216496320061384e-19) 
```

让我们进行有约束的最小化。

```py
>>> from scipy.optimize import LinearConstraint, Bounds 
```

我们增加约束条件，即 `x[0]` 和 `x[1]` 的和必须小于或等于 1.9。这是一个线性约束，可以写成 `A @ x <= 1.9`，其中 `A = array([[1, 1]])`。这可以编码为 `LinearConstraint` 实例：

```py
>>> lc = LinearConstraint([[1, 1]], -np.inf, 1.9) 
```

使用 `Bounds` 对象指定限制。

```py
>>> bounds = Bounds([0., 0.], [2., 2.])
>>> result = differential_evolution(rosen, bounds, constraints=lc,
...                                 seed=1)
>>> result.x, result.fun
(array([0.96632622, 0.93367155]), 0.0011352416852625719) 
```

寻找 Ackley 函数的最小值（[`en.wikipedia.org/wiki/Test_functions_for_optimization`](https://en.wikipedia.org/wiki/Test_functions_for_optimization)）。

```py
>>> def ackley(x):
...     arg1 = -0.2 * np.sqrt(0.5 * (x[0] ** 2 + x[1] ** 2))
...     arg2 = 0.5 * (np.cos(2. * np.pi * x[0]) + np.cos(2. * np.pi * x[1]))
...     return -20. * np.exp(arg1) - np.exp(arg2) + 20. + np.e
>>> bounds = [(-5, 5), (-5, 5)]
>>> result = differential_evolution(ackley, bounds, seed=1)
>>> result.x, result.fun
(array([0., 0.]), 4.440892098500626e-16) 
```

Ackley 函数以矢量化方式编写，因此可以使用 `'vectorized'` 关键字。请注意减少的函数评估次数。

```py
>>> result = differential_evolution(
...     ackley, bounds, vectorized=True, updating='deferred', seed=1
... )
>>> result.x, result.fun
(array([0., 0.]), 4.440892098500626e-16) 
```

以下自定义策略函数模仿 'best1bin'：

```py
>>> def custom_strategy_fn(candidate, population, rng=None):
...     parameter_count = population.shape(-1)
...     mutation, recombination = 0.7, 0.9
...     trial = np.copy(population[candidate])
...     fill_point = rng.choice(parameter_count)
...
...     pool = np.arange(len(population))
...     rng.shuffle(pool)
...
...     # two unique random numbers that aren't the same, and
...     # aren't equal to candidate.
...     idxs = []
...     while len(idxs) < 2 and len(pool) > 0:
...         idx = pool[0]
...         pool = pool[1:]
...         if idx != candidate:
...             idxs.append(idx)
...
...     r0, r1 = idxs[:2]
...
...     bprime = (population[0] + mutation *
...               (population[r0] - population[r1]))
...
...     crossovers = rng.uniform(size=parameter_count)
...     crossovers = crossovers < recombination
...     crossovers[fill_point] = True
...     trial = np.where(crossovers, bprime, trial)
...     return trial 
```
