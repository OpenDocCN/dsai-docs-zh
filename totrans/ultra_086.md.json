["```py\n`import cv2  from ultralytics import YOLO from ultralytics.utils.plotting import Annotator, colors  model = YOLO(\"yolov8n-seg.pt\")  # segmentation model names = model.model.names cap = cv2.VideoCapture(\"path/to/video/file.mp4\") w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))  out = cv2.VideoWriter(\"instance-segmentation.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), fps, (w, h))  while True:     ret, im0 = cap.read()     if not ret:         print(\"Video frame is empty or video processing has been successfully completed.\")         break      results = model.predict(im0)     annotator = Annotator(im0, line_width=2)      if results[0].masks is not None:         clss = results[0].boxes.cls.cpu().tolist()         masks = results[0].masks.xy         for mask, cls in zip(masks, clss):             color = colors(int(cls), True)             txt_color = annotator.get_txt_color(color)             annotator.seg_bbox(mask=mask, mask_color=color, label=names[int(cls)], txt_color=txt_color)      out.write(im0)     cv2.imshow(\"instance-segmentation\", im0)      if cv2.waitKey(1) & 0xFF == ord(\"q\"):         break  out.release() cap.release() cv2.destroyAllWindows()` \n```", "```py\n`from collections import defaultdict  import cv2  from ultralytics import YOLO from ultralytics.utils.plotting import Annotator, colors  track_history = defaultdict(lambda: [])  model = YOLO(\"yolov8n-seg.pt\")  # segmentation model cap = cv2.VideoCapture(\"path/to/video/file.mp4\") w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))  out = cv2.VideoWriter(\"instance-segmentation-object-tracking.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), fps, (w, h))  while True:     ret, im0 = cap.read()     if not ret:         print(\"Video frame is empty or video processing has been successfully completed.\")         break      annotator = Annotator(im0, line_width=2)      results = model.track(im0, persist=True)      if results[0].boxes.id is not None and results[0].masks is not None:         masks = results[0].masks.xy         track_ids = results[0].boxes.id.int().cpu().tolist()          for mask, track_id in zip(masks, track_ids):             color = colors(int(track_id), True)             txt_color = annotator.get_txt_color(color)             annotator.seg_bbox(mask=mask, mask_color=color, label=str(track_id), txt_color=txt_color)      out.write(im0)     cv2.imshow(\"instance-segmentation-object-tracking\", im0)      if cv2.waitKey(1) & 0xFF == ord(\"q\"):         break  out.release() cap.release() cv2.destroyAllWindows()` \n```", "```py\n`import cv2  from ultralytics import YOLO from ultralytics.utils.plotting import Annotator, colors  model = YOLO(\"yolov8n-seg.pt\")  # segmentation model cap = cv2.VideoCapture(\"path/to/video/file.mp4\") w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))  out = cv2.VideoWriter(\"instance-segmentation.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), fps, (w, h))  while True:     ret, im0 = cap.read()     if not ret:         break      results = model.predict(im0)     annotator = Annotator(im0, line_width=2)      if results[0].masks is not None:         clss = results[0].boxes.cls.cpu().tolist()         masks = results[0].masks.xy         for mask, cls in zip(masks, clss):             annotator.seg_bbox(mask=mask, mask_color=colors(int(cls), True), det_label=model.model.names[int(cls)])      out.write(im0)     cv2.imshow(\"instance-segmentation\", im0)     if cv2.waitKey(1) & 0xFF == ord(\"q\"):         break  out.release() cap.release() cv2.destroyAllWindows()` \n```", "```py\n`from collections import defaultdict  import cv2  from ultralytics import YOLO from ultralytics.utils.plotting import Annotator, colors  track_history = defaultdict(lambda: [])  model = YOLO(\"yolov8n-seg.pt\")  # segmentation model cap = cv2.VideoCapture(\"path/to/video/file.mp4\") w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))  out = cv2.VideoWriter(\"instance-segmentation-object-tracking.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), fps, (w, h))  while True:     ret, im0 = cap.read()     if not ret:         break      annotator = Annotator(im0, line_width=2)     results = model.track(im0, persist=True)      if results[0].boxes.id is not None and results[0].masks is not None:         masks = results[0].masks.xy         track_ids = results[0].boxes.id.int().cpu().tolist()          for mask, track_id in zip(masks, track_ids):             annotator.seg_bbox(mask=mask, mask_color=colors(track_id, True), track_label=str(track_id))      out.write(im0)     cv2.imshow(\"instance-segmentation-object-tracking\", im0)     if cv2.waitKey(1) & 0xFF == ord(\"q\"):         break  out.release() cap.release() cv2.destroyAllWindows()` \n```"]