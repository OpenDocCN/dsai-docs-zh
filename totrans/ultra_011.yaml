- en: Object Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/tasks/detect/`](https://docs.ultralytics.com/tasks/detect/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Object detection examples](img/50b6b378e346803a6cbcccf9fc297381.png)'
  prefs: []
  type: TYPE_IMG
- en: Object detection is a task that involves identifying the location and class
    of objects in an image or video stream.
  prefs: []
  type: TYPE_NORMAL
- en: The output of an object detector is a set of bounding boxes that enclose the
    objects in the image, along with class labels and confidence scores for each box.
    Object detection is a good choice when you need to identify objects of interest
    in a scene, but don't need to know exactly where the object is or its exact shape.
  prefs: []
  type: TYPE_NORMAL
- en: '[`www.youtube.com/embed/5ku7npMrW40?si=6HQO1dDXunV8gekh`](https://www.youtube.com/embed/5ku7npMrW40?si=6HQO1dDXunV8gekh)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch:** Object Detection with Pre-trained Ultralytics YOLOv8 Model.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: YOLOv8 Detect models are the default YOLOv8 models, i.e. `yolov8n.pt` and are
    pretrained on [COCO](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml).
  prefs: []
  type: TYPE_NORMAL
- en: '[Models](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v8)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: YOLOv8 pretrained Detect models are shown here. Detect, Segment and Pose models
    are pretrained on the [COCO](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml)
    dataset, while Classify models are pretrained on the [ImageNet](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/ImageNet.yaml)
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[Models](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models)
    download automatically from the latest Ultralytics [release](https://github.com/ultralytics/assets/releases)
    on first use.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)
    | 640 | 37.3 | 80.4 | 0.99 | 3.2 | 8.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)
    | 640 | 44.9 | 128.4 | 1.20 | 11.2 | 28.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)
    | 640 | 50.2 | 234.7 | 1.83 | 25.9 | 78.9 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt)
    | 640 | 52.9 | 375.2 | 2.39 | 43.7 | 165.2 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt)
    | 640 | 53.9 | 479.1 | 3.53 | 68.2 | 257.8 |'
  prefs: []
  type: TYPE_TB
- en: '**mAP^(val)** values are for single-model single-scale on [COCO val2017](https://cocodataset.org)
    dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reproduce by `yolo val detect data=coco.yaml device=0`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Speed** averaged over COCO val images using an [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/)
    instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reproduce by `yolo val detect data=coco8.yaml batch=1 device=0|cpu`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Train
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Train YOLOv8n on the COCO8 dataset for 100 epochs at image size 640\. For a
    full list of available arguments see the Configuration page.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Dataset format
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLO detection dataset format can be found in detail in the Dataset Guide. To
    convert your existing dataset from other formats (like COCO etc.) to YOLO format,
    please use [JSON2YOLO](https://github.com/ultralytics/JSON2YOLO) tool by Ultralytics.
  prefs: []
  type: TYPE_NORMAL
- en: Val
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Validate trained YOLOv8n model accuracy on the COCO8 dataset. No argument need
    to passed as the `model` retains its training `data` and arguments as model attributes.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Predict
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use a trained YOLOv8n model to run predictions on images.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: See full `predict` mode details in the Predict page.
  prefs: []
  type: TYPE_NORMAL
- en: Export
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Export a YOLOv8n model to a different format like ONNX, CoreML, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Available YOLOv8 export formats are in the table below. You can export to any
    format using the `format` argument, i.e. `format='onnx'` or `format='engine'`.
    You can predict or validate directly on exported models, i.e. `yolo predict model=yolov8n.onnx`.
    Usage examples are shown for your model after export completes.
  prefs: []
  type: TYPE_NORMAL
- en: '| Format | `format` Argument | Model | Metadata | Arguments |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [PyTorch](https://pytorch.org/) | - | `yolov8n.pt` | ✅ | - |'
  prefs: []
  type: TYPE_TB
- en: '| TorchScript | `torchscript` | `yolov8n.torchscript` | ✅ | `imgsz`, `optimize`,
    `batch` |'
  prefs: []
  type: TYPE_TB
- en: '| ONNX | `onnx` | `yolov8n.onnx` | ✅ | `imgsz`, `half`, `dynamic`, `simplify`,
    `opset`, `batch` |'
  prefs: []
  type: TYPE_TB
- en: '| OpenVINO | `openvino` | `yolov8n_openvino_model/` | ✅ | `imgsz`, `half`,
    `int8`, `batch`, `dynamic` |'
  prefs: []
  type: TYPE_TB
- en: '| TensorRT | `engine` | `yolov8n.engine` | ✅ | `imgsz`, `half`, `dynamic`,
    `simplify`, `workspace`, `int8`, `batch` |'
  prefs: []
  type: TYPE_TB
- en: '| CoreML | `coreml` | `yolov8n.mlpackage` | ✅ | `imgsz`, `half`, `int8`, `nms`,
    `batch` |'
  prefs: []
  type: TYPE_TB
- en: '| TF SavedModel | `saved_model` | `yolov8n_saved_model/` | ✅ | `imgsz`, `keras`,
    `int8`, `batch` |'
  prefs: []
  type: TYPE_TB
- en: '| TF GraphDef | `pb` | `yolov8n.pb` | ❌ | `imgsz`, `batch` |'
  prefs: []
  type: TYPE_TB
- en: '| TF Lite | `tflite` | `yolov8n.tflite` | ✅ | `imgsz`, `half`, `int8`, `batch`
    |'
  prefs: []
  type: TYPE_TB
- en: '| TF Edge TPU | `edgetpu` | `yolov8n_edgetpu.tflite` | ✅ | `imgsz` |'
  prefs: []
  type: TYPE_TB
- en: '| TF.js | `tfjs` | `yolov8n_web_model/` | ✅ | `imgsz`, `half`, `int8`, `batch`
    |'
  prefs: []
  type: TYPE_TB
- en: '| PaddlePaddle | `paddle` | `yolov8n_paddle_model/` | ✅ | `imgsz`, `batch`
    |'
  prefs: []
  type: TYPE_TB
- en: '| NCNN | `ncnn` | `yolov8n_ncnn_model/` | ✅ | `imgsz`, `half`, `batch` |'
  prefs: []
  type: TYPE_TB
- en: See full `export` details in the Export page.
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How do I train a YOLOv8 model on my custom dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Training a YOLOv8 model on a custom dataset involves a few steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prepare the Dataset**: Ensure your dataset is in the YOLO format. For guidance,
    refer to our Dataset Guide.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Load the Model**: Use the Ultralytics YOLO library to load a pre-trained
    model or create a new model from a YAML file.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Train the Model**: Execute the `train` method in Python or the `yolo detect
    train` command in CLI.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: For detailed configuration options, visit the Configuration page.
  prefs: []
  type: TYPE_NORMAL
- en: What pretrained models are available in YOLOv8?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Ultralytics YOLOv8 offers various pretrained models for object detection, segmentation,
    and pose estimation. These models are pretrained on the COCO dataset or ImageNet
    for classification tasks. Here are some of the available models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a detailed list and performance metrics, refer to the [Models](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v8)
    section.
  prefs: []
  type: TYPE_NORMAL
- en: How can I validate the accuracy of my trained YOLOv8 model?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To validate the accuracy of your trained YOLOv8 model, you can use the `.val()`
    method in Python or the `yolo detect val` command in CLI. This will provide metrics
    like mAP50-95, mAP50, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: For more validation details, visit the Val page.
  prefs: []
  type: TYPE_NORMAL
- en: What formats can I export a YOLOv8 model to?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ultralytics YOLOv8 allows exporting models to various formats such as ONNX,
    TensorRT, CoreML, and more to ensure compatibility across different platforms
    and devices.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Check the full list of supported formats and instructions on the Export page.
  prefs: []
  type: TYPE_NORMAL
- en: Why should I use Ultralytics YOLOv8 for object detection?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Ultralytics YOLOv8 is designed to offer state-of-the-art performance for object
    detection, segmentation, and pose estimation. Here are some key advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pretrained Models**: Utilize models pretrained on popular datasets like COCO
    and ImageNet for faster development.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**High Accuracy**: Achieves impressive mAP scores, ensuring reliable object
    detection.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Speed**: Optimized for real-time inference, making it ideal for applications
    requiring swift processing.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Flexibility**: Export models to various formats like ONNX and TensorRT for
    deployment across multiple platforms.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explore our [Blog](https://www.ultralytics.com/blog) for use cases and success
    stories showcasing YOLOv8 in action.
  prefs: []
  type: TYPE_NORMAL
