- en: Home
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[`docs.ultralytics.com/`](https://docs.ultralytics.com/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Ultralytics YOLO banner](https://github.com/ultralytics/assets/releases/tag/v8.2.0)
    [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/)
    | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/)
    | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/)
    | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/)
    | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/)
    | [‡§π‡§ø‡§®‡•ç‡§¶‡•Ä](https://docs.ultralytics.com/hi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)'
  prefs: []
  type: TYPE_IMG
- en: '![Ultralytics CI](https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml)
    ![YOLOv8 Citation](https://zenodo.org/badge/latestdoi/264818686) ![Docker Pulls](https://hub.docker.com/r/ultralytics/ultralytics)
    ![Discord](https://ultralytics.com/discord) ![Ultralytics Forums](https://community.ultralytics.com)'
  prefs: []
  type: TYPE_IMG
- en: '![Run on Gradient](https://console.paperspace.com/github/ultralytics/ultralytics)
    ![Open In Colab](https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb)
    ![Open In Kaggle](https://www.kaggle.com/ultralytics/yolov8)'
  prefs: []
  type: TYPE_IMG
- en: Introducing [Ultralytics](https://ultralytics.com) [YOLOv8](https://github.com/ultralytics/ultralytics),
    the latest version of the acclaimed real-time object detection and image segmentation
    model. YOLOv8 is built on cutting-edge advancements in deep learning and computer
    vision, offering unparalleled performance in terms of speed and accuracy. Its
    streamlined design makes it suitable for various applications and easily adaptable
    to different hardware platforms, from edge devices to cloud APIs.
  prefs: []
  type: TYPE_NORMAL
- en: Explore the YOLOv8 Docs, a comprehensive resource designed to help you understand
    and utilize its features and capabilities. Whether you are a seasoned machine
    learning practitioner or new to the field, this hub aims to maximize YOLOv8's
    potential in your projects
  prefs: []
  type: TYPE_NORMAL
- en: '![Ultralytics GitHub](https://github.com/ultralytics) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics LinkedIn](https://www.linkedin.com/company/ultralytics/) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics Twitter](https://twitter.com/ultralytics) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics YouTube](https://youtube.com/ultralytics?sub_confirmation=1) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics TikTok](https://www.tiktok.com/@ultralytics) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics BiliBili](https://ultralytics.com/bilibili) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics Discord](https://ultralytics.com/discord)'
  prefs: []
  type: TYPE_IMG
- en: Where to Start
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Install** `ultralytics` with pip and get up and running in minutes ¬† Get
    Started'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predict** new images and videos with YOLOv8 ¬† Predict on Images'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Train** a new YOLOv8 model on your own custom dataset ¬† Train a Model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tasks** YOLOv8 tasks like segment, classify, pose and track ¬† Explore Tasks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NEW üöÄ Explore** datasets with advanced semantic and SQL search ¬† Explore
    a Dataset'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`www.youtube.com/embed/LNwODJXcvt4?si=7n1UvGRLSd9p5wKs`](https://www.youtube.com/embed/LNwODJXcvt4?si=7n1UvGRLSd9p5wKs)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch:** How to Train a YOLOv8 model on Your Custom Dataset in [Google Colab](https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb).'
  prefs: []
  type: TYPE_NORMAL
- en: 'YOLO: A Brief History'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[YOLO](https://arxiv.org/abs/1506.02640) (You Only Look Once), a popular object
    detection and image segmentation model, was developed by Joseph Redmon and Ali
    Farhadi at the University of Washington. Launched in 2015, YOLO quickly gained
    popularity for its high speed and accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: '[YOLOv2](https://arxiv.org/abs/1612.08242), released in 2016, improved the
    original model by incorporating batch normalization, anchor boxes, and dimension
    clusters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv3](https://pjreddie.com/media/files/papers/YOLOv3.pdf), launched in 2018,
    further enhanced the model''s performance using a more efficient backbone network,
    multiple anchors and spatial pyramid pooling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv4](https://arxiv.org/abs/2004.10934) was released in 2020, introducing
    innovations like Mosaic data augmentation, a new anchor-free detection head, and
    a new loss function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv5](https://github.com/ultralytics/yolov5) further improved the model''s
    performance and added new features such as hyperparameter optimization, integrated
    experiment tracking and automatic export to popular export formats.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv6](https://github.com/meituan/YOLOv6) was open-sourced by [Meituan](https://about.meituan.com/)
    in 2022 and is in use in many of the company''s autonomous delivery robots.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv7](https://github.com/WongKinYiu/yolov7) added additional tasks such
    as pose estimation on the COCO keypoints dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv8](https://github.com/ultralytics/ultralytics) is the latest version
    of YOLO by Ultralytics. As a cutting-edge, state-of-the-art (SOTA) model, YOLOv8
    builds on the success of previous versions, introducing new features and improvements
    for enhanced performance, flexibility, and efficiency. YOLOv8 supports a full
    range of vision AI tasks, including detection, segmentation, pose estimation,
    tracking, and classification. This versatility allows users to leverage YOLOv8''s
    capabilities across diverse applications and domains.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: YOLOv9 introduces innovative methods like Programmable Gradient Information
    (PGI) and the Generalized Efficient Layer Aggregation Network (GELAN).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: YOLOv10 is created by researchers from [Tsinghua University](https://www.tsinghua.edu.cn/en/)
    using the [Ultralytics](https://ultralytics.com/) [Python package](https://pypi.org/project/ultralytics/).
    This version provides real-time object detection advancements by introducing an
    End-to-End head that eliminates Non-Maximum Suppression (NMS) requirements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'YOLO Licenses: How is Ultralytics YOLO licensed?'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Ultralytics offers two licensing options to accommodate diverse use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**AGPL-3.0 License**: This [OSI-approved](https://opensource.org/licenses/)
    open-source license is ideal for students and enthusiasts, promoting open collaboration
    and knowledge sharing. See the [LICENSE](https://github.com/ultralytics/ultralytics/blob/main/LICENSE)
    file for more details.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enterprise License**: Designed for commercial use, this license permits seamless
    integration of Ultralytics software and AI models into commercial goods and services,
    bypassing the open-source requirements of AGPL-3.0\. If your scenario involves
    embedding our solutions into a commercial offering, reach out through [Ultralytics
    Licensing](https://ultralytics.com/license).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our licensing strategy is designed to ensure that any improvements to our open-source
    projects are returned to the community. We hold the principles of open source
    close to our hearts ‚ù§Ô∏è, and our mission is to guarantee that our contributions
    can be utilized and expanded upon in ways that are beneficial to all.
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is Ultralytics YOLO and how does it improve object detection?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ultralytics YOLO is the latest advancement in the acclaimed YOLO (You Only Look
    Once) series for real-time object detection and image segmentation. It builds
    on previous versions by introducing new features and improvements for enhanced
    performance, flexibility, and efficiency. YOLOv8 supports various vision AI tasks
    such as detection, segmentation, pose estimation, tracking, and classification.
    Its state-of-the-art architecture ensures superior speed and accuracy, making
    it suitable for diverse applications, including edge devices and cloud APIs.
  prefs: []
  type: TYPE_NORMAL
- en: How can I get started with YOLO installation and setup?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Getting started with YOLO is quick and straightforward. You can install the
    Ultralytics package using pip and get up and running in minutes. Here''s a basic
    installation command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For a comprehensive step-by-step guide, visit our quickstart guide. This resource
    will help you with installation instructions, initial setup, and running your
    first model.
  prefs: []
  type: TYPE_NORMAL
- en: How can I train a custom YOLO model on my dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Training a custom YOLO model on your dataset involves a few detailed steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Prepare your annotated dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure the training parameters in a YAML file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the `yolo train` command to start training.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here''s an example command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: For a detailed walkthrough, check out our Train a Model guide, which includes
    examples and tips for optimizing your training process.
  prefs: []
  type: TYPE_NORMAL
- en: What are the licensing options available for Ultralytics YOLO?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Ultralytics offers two licensing options for YOLO:'
  prefs: []
  type: TYPE_NORMAL
- en: '**AGPL-3.0 License**: This open-source license is ideal for educational and
    non-commercial use, promoting open collaboration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enterprise License**: This is designed for commercial applications, allowing
    seamless integration of Ultralytics software into commercial products without
    the restrictions of the AGPL-3.0 license.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more details, visit our [Licensing](https://ultralytics.com/license) page.
  prefs: []
  type: TYPE_NORMAL
- en: How can Ultralytics YOLO be used for real-time object tracking?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Ultralytics YOLO supports efficient and customizable multi-object tracking.
    To utilize tracking capabilities, you can use the `yolo track` command as shown
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: For a detailed guide on setting up and running object tracking, check our tracking
    mode documentation, which explains the configuration and practical applications
    in real-time scenarios.
  prefs: []
  type: TYPE_NORMAL
