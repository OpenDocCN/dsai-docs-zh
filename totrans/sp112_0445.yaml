- en: scipy.optimize.shgo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.shgo.html#scipy.optimize.shgo](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.shgo.html#scipy.optimize.shgo)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Finds the global minimum of a function using SHG optimization.
  prefs: []
  type: TYPE_NORMAL
- en: SHGO stands for “simplicial homology global optimization”.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**func**callable'
  prefs: []
  type: TYPE_NORMAL
- en: The objective function to be minimized. Must be in the form `f(x, *args)`, where
    `x` is the argument in the form of a 1-D array and `args` is a tuple of any additional
    fixed parameters needed to completely specify the function.
  prefs: []
  type: TYPE_NORMAL
- en: '**bounds**sequence or [`Bounds`](scipy.optimize.Bounds.html#scipy.optimize.Bounds
    "scipy.optimize.Bounds")'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bounds for variables. There are two ways to specify the bounds:'
  prefs: []
  type: TYPE_NORMAL
- en: Instance of [`Bounds`](scipy.optimize.Bounds.html#scipy.optimize.Bounds "scipy.optimize.Bounds")
    class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sequence of `(min, max)` pairs for each element in *x*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**args**tuple, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Any additional fixed parameters needed to completely specify the objective function.
  prefs: []
  type: TYPE_NORMAL
- en: '**constraints**{Constraint, dict} or List of {Constraint, dict}, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Constraints definition. Only for COBYLA, SLSQP and trust-constr. See the tutorial
    [[5]](#rb2e152d227b3-5) for further details on specifying constraints.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Only COBYLA, SLSQP, and trust-constr local minimize methods currently support
    constraint arguments. If the `constraints` sequence used in the local optimization
    problem is not defined in `minimizer_kwargs` and a constrained method is used
    then the global `constraints` will be used. (Defining a `constraints` sequence
    in `minimizer_kwargs` means that `constraints` will not be added so if equality
    constraints and so forth need to be added then the inequality functions in `constraints`
    need to be added to `minimizer_kwargs` too). COBYLA only supports inequality constraints.
  prefs: []
  type: TYPE_NORMAL
- en: 'Changed in version 1.11.0: `constraints` accepts [`NonlinearConstraint`](scipy.optimize.NonlinearConstraint.html#scipy.optimize.NonlinearConstraint
    "scipy.optimize.NonlinearConstraint"), [`LinearConstraint`](scipy.optimize.LinearConstraint.html#scipy.optimize.LinearConstraint
    "scipy.optimize.LinearConstraint").'
  prefs: []
  type: TYPE_NORMAL
- en: '**n**int, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Number of sampling points used in the construction of the simplicial complex.
    For the default `simplicial` sampling method 2**dim + 1 sampling points are generated
    instead of the default *n=100*. For all other specified values *n* sampling points
    are generated. For `sobol`, `halton` and other arbitrary *sampling_methods* *n=100*
    or another specified number of sampling points are generated.
  prefs: []
  type: TYPE_NORMAL
- en: '**iters**int, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Number of iterations used in the construction of the simplicial complex. Default
    is 1.
  prefs: []
  type: TYPE_NORMAL
- en: '**callback**callable, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Called after each iteration, as `callback(xk)`, where `xk` is the current parameter
    vector.
  prefs: []
  type: TYPE_NORMAL
- en: '**minimizer_kwargs**dict, optional'
  prefs: []
  type: TYPE_NORMAL
- en: 'Extra keyword arguments to be passed to the minimizer `scipy.optimize.minimize`
    Some important options could be:'
  prefs: []
  type: TYPE_NORMAL
- en: methodstr
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The minimization method. If not given, chosen to be one of BFGS, L-BFGS-B, SLSQP,
    depending on whether or not the problem has constraints or bounds.
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: argstuple
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Extra arguments passed to the objective function (`func`) and its derivatives
    (Jacobian, Hessian).
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: optionsdict, optional
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Note that by default the tolerance is specified as `{ftol: 1e-12}`'
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: '**options**dict, optional'
  prefs: []
  type: TYPE_NORMAL
- en: A dictionary of solver options. Many of the options specified for the global
    routine are also passed to the scipy.optimize.minimize routine. The options that
    are also passed to the local routine are marked with “(L)”.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stopping criteria, the algorithm will terminate if any of the specified criteria
    are met. However, the default algorithm does not require any to be specified:'
  prefs: []
  type: TYPE_NORMAL
- en: maxfevint (L)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximum number of function evaluations in the feasible domain. (Note only methods
    that support this option will terminate the routine at precisely exact specified
    value. Otherwise the criterion will only terminate during a global iteration)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: f_min
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specify the minimum objective function value, if it is known.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: f_tolfloat
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Precision goal for the value of f in the stopping criterion. Note that the global
    routine will also terminate if a sampling point in the global routine is within
    this tolerance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: maxiterint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximum number of iterations to perform.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: maxevint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximum number of sampling evaluations to perform (includes searching in infeasible
    points).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: maxtimefloat
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximum processing runtime allowed
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: minhgrdint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimum homology group rank differential. The homology group of the objective
    function is calculated (approximately) during every iteration. The rank of this
    group has a one-to-one correspondence with the number of locally convex subdomains
    in the objective function (after adequate sampling points each of these subdomains
    contain a unique global minimum). If the difference in the hgr is 0 between iterations
    for `maxhgrd` specified iterations the algorithm will terminate.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Objective function knowledge:'
  prefs: []
  type: TYPE_NORMAL
- en: symmetrylist or bool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specify if the objective function contains symmetric variables. The search space
    (and therefore performance) is decreased by up to O(n!) times in the fully symmetric
    case. If *True* is specified then all variables will be set symmetric to the first
    variable. Default is set to False.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: E.g. f(x) = (x_1 + x_2 + x_3) + (x_4)**2 + (x_5)**2 + (x_6)**2
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In this equation x_2 and x_3 are symmetric to x_1, while x_5 and x_6 are symmetric
    to x_4, this can be specified to the solver as:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'symmetry = [0, # Variable 1'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '0, # symmetric to variable 1 0, # symmetric to variable 1 3, # Variable 4 3,
    # symmetric to variable 4 3, # symmetric to variable 4 ]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: jacbool or callable, optional
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jacobian (gradient) of objective function. Only for CG, BFGS, Newton-CG, L-BFGS-B,
    TNC, SLSQP, dogleg, trust-ncg. If `jac` is a boolean and is True, `fun` is assumed
    to return the gradient along with the objective function. If False, the gradient
    will be estimated numerically. `jac` can also be a callable returning the gradient
    of the objective. In this case, it must accept the same arguments as `fun`. (Passed
    to [`scipy.optimize.minimize`](scipy.optimize.minimize.html#scipy.optimize.minimize
    "scipy.optimize.minimize") automatically)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: hess, hesspcallable, optional
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hessian (matrix of second-order derivatives) of objective function or Hessian
    of objective function times an arbitrary vector p. Only for Newton-CG, dogleg,
    trust-ncg. Only one of `hessp` or `hess` needs to be given. If `hess` is provided,
    then `hessp` will be ignored. If neither `hess` nor `hessp` is provided, then
    the Hessian product will be approximated using finite differences on `jac`. `hessp`
    must compute the Hessian times an arbitrary vector. (Passed to [`scipy.optimize.minimize`](scipy.optimize.minimize.html#scipy.optimize.minimize
    "scipy.optimize.minimize") automatically)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Algorithm settings:'
  prefs: []
  type: TYPE_NORMAL
- en: minimize_every_iterbool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If True then promising global sampling points will be passed to a local minimization
    routine every iteration. If True then only the final minimizer pool will be run.
    Defaults to True.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: local_iterint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Only evaluate a few of the best minimizer pool candidates every iteration. If
    False all potential points are passed to the local minimization routine.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: infty_constraintsbool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If True then any sampling points generated which are outside will the feasible
    domain will be saved and given an objective function value of `inf`. If False
    then these points will be discarded. Using this functionality could lead to higher
    performance with respect to function evaluations before the global minimum is
    found, specifying False will use less memory at the cost of a slight decrease
    in performance. Defaults to True.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Feedback:'
  prefs: []
  type: TYPE_NORMAL
- en: dispbool (L)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set to True to print convergence messages.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**sampling_method**str or function, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Current built in sampling method options are `halton`, `sobol` and `simplicial`.
    The default `simplicial` provides the theoretical guarantee of convergence to
    the global minimum in finite time. `halton` and `sobol` method are faster in terms
    of sampling point generation at the cost of the loss of guaranteed convergence.
    It is more appropriate for most “easier” problems where the convergence is relatively
    fast. User defined sampling functions must accept two arguments of `n` sampling
    points of dimension `dim` per call and output an array of sampling points with
    shape *n x dim*.
  prefs: []
  type: TYPE_NORMAL
- en: '**workers**int or map-like callable, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Sample and run the local serial minimizations in parallel. Supply -1 to use
    all available CPU cores, or an int to use that many Processes (uses [`multiprocessing.Pool`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing
    "(in Python v3.12)")).
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively supply a map-like callable, such as *multiprocessing.Pool.map*
    for parallel evaluation. This evaluation is carried out as `workers(func, iterable)`.
    Requires that *func* be pickleable.
  prefs: []
  type: TYPE_NORMAL
- en: New in version 1.11.0.
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: '**res**OptimizeResult'
  prefs: []
  type: TYPE_NORMAL
- en: 'The optimization result represented as a [`OptimizeResult`](scipy.optimize.OptimizeResult.html#scipy.optimize.OptimizeResult
    "scipy.optimize.OptimizeResult") object. Important attributes are: `x` the solution
    array corresponding to the global minimum, `fun` the function output at the global
    solution, `xl` an ordered list of local minima solutions, `funl` the function
    output at the corresponding local solutions, `success` a Boolean flag indicating
    if the optimizer exited successfully, `message` which describes the cause of the
    termination, `nfev` the total number of objective function evaluations including
    the sampling calls, `nlfev` the total number of objective function evaluations
    culminating from all local search optimizations, `nit` number of iterations performed
    by the global routine.'
  prefs: []
  type: TYPE_NORMAL
- en: Notes
  prefs: []
  type: TYPE_NORMAL
- en: Global optimization using simplicial homology global optimization [[1]](#rb2e152d227b3-1).
    Appropriate for solving general purpose NLP and blackbox optimization problems
    to global optimality (low-dimensional problems).
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, the optimization problems are of the form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: where x is a vector of one or more variables. `f(x)` is the objective function
    `R^n -> R`, `g_i(x)` are the inequality constraints, and `h_j(x)` are the equality
    constraints.
  prefs: []
  type: TYPE_NORMAL
- en: Optionally, the lower and upper bounds for each element in x can also be specified
    using the *bounds* argument.
  prefs: []
  type: TYPE_NORMAL
- en: While most of the theoretical advantages of SHGO are only proven for when `f(x)`
    is a Lipschitz smooth function, the algorithm is also proven to converge to the
    global optimum for the more general case where `f(x)` is non-continuous, non-convex
    and non-smooth, if the default sampling method is used [[1]](#rb2e152d227b3-1).
  prefs: []
  type: TYPE_NORMAL
- en: The local search method may be specified using the `minimizer_kwargs` parameter
    which is passed on to `scipy.optimize.minimize`. By default, the `SLSQP` method
    is used. In general, it is recommended to use the `SLSQP` or `COBYLA` local minimization
    if inequality constraints are defined for the problem since the other methods
    do not use constraints.
  prefs: []
  type: TYPE_NORMAL
- en: The `halton` and `sobol` method points are generated using [`scipy.stats.qmc`](../stats.qmc.html#module-scipy.stats.qmc
    "scipy.stats.qmc"). Any other QMC method could be used.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs: []
  type: TYPE_NORMAL
- en: '[1] ([1](#id2),[2](#id3))'
  prefs: []
  type: TYPE_NORMAL
- en: Endres, SC, Sandrock, C, Focke, WW (2018) “A simplicial homology algorithm for
    lipschitz optimisation”, Journal of Global Optimization.
  prefs: []
  type: TYPE_NORMAL
- en: '[2]'
  prefs: []
  type: TYPE_NORMAL
- en: Joe, SW and Kuo, FY (2008) “Constructing Sobol’ sequences with better two-dimensional
    projections”, SIAM J. Sci. Comput. 30, 2635-2654.
  prefs: []
  type: TYPE_NORMAL
- en: '[3] ([1](#id10),[2](#id11))'
  prefs: []
  type: TYPE_NORMAL
- en: Hock, W and Schittkowski, K (1981) “Test examples for nonlinear programming
    codes”, Lecture Notes in Economics and Mathematical Systems, 187\. Springer-Verlag,
    New York. [http://www.ai7.uni-bayreuth.de/test_problem_coll.pdf](http://www.ai7.uni-bayreuth.de/test_problem_coll.pdf)
  prefs: []
  type: TYPE_NORMAL
- en: '[[4](#id9)]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Wales, DJ (2015) “Perspective: Insight into reaction coordinates and dynamics
    from the potential energy landscape”, Journal of Chemical Physics, 142(13), 2015.'
  prefs: []
  type: TYPE_NORMAL
- en: '[[5](#id1)]'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.scipy.org/doc/scipy/tutorial/optimize.html#constrained-minimization-of-multivariate-scalar-functions-minimize](https://docs.scipy.org/doc/scipy/tutorial/optimize.html#constrained-minimization-of-multivariate-scalar-functions-minimize)'
  prefs: []
  type: TYPE_NORMAL
- en: Examples
  prefs: []
  type: TYPE_NORMAL
- en: 'First consider the problem of minimizing the Rosenbrock function, [`rosen`](scipy.optimize.rosen.html#scipy.optimize.rosen
    "scipy.optimize.rosen"):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note that bounds determine the dimensionality of the objective function and
    is therefore a required input, however you can specify empty bounds using `None`
    or objects like `np.inf` which will be converted to large float numbers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Next, we consider the Eggholder function, a problem with several local minima
    and one global minimum. We will demonstrate the use of arguments and the capabilities
    of [`shgo`](#scipy.optimize.shgo "scipy.optimize.shgo"). ([https://en.wikipedia.org/wiki/Test_functions_for_optimization](https://en.wikipedia.org/wiki/Test_functions_for_optimization))
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[`shgo`](#scipy.optimize.shgo "scipy.optimize.shgo") has built-in low discrepancy
    sampling sequences. First, we will input 64 initial sampling points of the *Sobol’*
    sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[`shgo`](#scipy.optimize.shgo "scipy.optimize.shgo") also has a return for
    any other local minima that was found, these can be called using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: These results are useful in applications where there are many global minima
    and the values of other global minima are desired or where the local minima can
    provide insight into the system (for example morphologies in physical chemistry
    [[4]](#rb2e152d227b3-4)).
  prefs: []
  type: TYPE_NORMAL
- en: If we want to find a larger number of local minima, we can increase the number
    of sampling points or the number of iterations. We’ll increase the number of sampling
    points to 64 and the number of iterations from the default of 1 to 3\. Using `simplicial`
    this would have given us 64 x 3 = 192 initial sampling points.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Note the difference between, e.g., `n=192, iters=1` and `n=64, iters=3`. In
    the first case the promising points contained in the minimiser pool are processed
    only once. In the latter case it is processed every 64 sampling points for a total
    of 3 times.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate solving problems with non-linear constraints consider the following
    example from Hock and Schittkowski problem 73 (cattle-feed) [[3]](#rb2e152d227b3-3):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The approximate answer given in [[3]](#rb2e152d227b3-3) is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
