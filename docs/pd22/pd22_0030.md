# 写时复制（CoW）

> 原文：[`pandas.pydata.org/docs/user_guide/copy_on_write.html`](https://pandas.pydata.org/docs/user_guide/copy_on_write.html)

注意

写时复制将成为 pandas 3.0 的默认设置。我们建议现在就启用它以从所有改进中受益。

写时复制首次引入于版本 1.5.0。从版本 2.0 开始，大部分通过 CoW 可能实现和支持的优化已经实现。从 pandas 2.1 开始，所有可能的优化都得到支持。

写时复制将在版本 3.0 中默认启用。

CoW 将导致更可预测的行为，因为不可能用一个语句更新多个对象，例如索引操作或方法不会产生副作用。此外，通过尽可能延迟复制，平均性能和内存使用将得到改善。

## 先前的行为

pandas 的索引行为很难理解。一些操作返回视图，而其他操作返回副本。根据操作的结果，改变一个对象可能会意外地改变另一个对象：

```py
In [1]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [2]: subset = df["foo"]

In [3]: subset.iloc[0] = 100

In [4]: df
Out[4]: 
 foo  bar
0  100    4
1    2    5
2    3    6 
```

改变`subset`，例如更新其值，也会更新`df`。确切的行为很难预测。写时复制解决了意外修改多个对象的问题，它明确禁止这种情况。启用写时复制后，`df`保持不变：

```py
In [5]: pd.options.mode.copy_on_write = True

In [6]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [7]: subset = df["foo"]

In [8]: subset.iloc[0] = 100

In [9]: df
Out[9]: 
 foo  bar
0    1    4
1    2    5
2    3    6 
```

接下来的部分将解释这意味着什么，以及它如何影响现有应用程序。

## 迁移到写时复制

写时复制将成为 pandas 3.0 的默认和唯一模式。这意味着用户需要迁移他们的代码以符合 CoW 规则。

pandas 的默认模式将对某些情况发出警告，这些情况将积极改变行为，从而改变用户预期的行为。

我们添加了另一种模式，例如

```py
pd.options.mode.copy_on_write = "warn" 
```

将会对每个会改变 CoW 行为的操作发出警告。我们预计这种模式会非常嘈杂，因为许多我们不认为会影响用户的情况也会发出警告。我们建议检查这种模式并分析警告，但不需要解决所有这些警告。以下列表的前两项是需要解决的唯一情况，以使现有代码与 CoW 兼容。

接下来的几个项目描述了用户可见的变化：

**链接赋值永远不会起作用**

应该使用`loc`作为替代。查看链接赋值部分获取更多细节。

**访问 pandas 对象的底层数组将返回一个只读视图**

```py
In [10]: ser = pd.Series([1, 2, 3])

In [11]: ser.to_numpy()
Out[11]: array([1, 2, 3]) 
```

这个示例返回一个 NumPy 数组，它是 Series 对象的一个视图。这个视图可以被修改，从而也会修改 pandas 对象。这不符合 CoW 规则。返回的数组被设置为不可写，以防止这种行为。创建这个数组的副本允许修改。如果你不再关心 pandas 对象，你也可以再次使数组可写。

有关只读 NumPy 数组的更多详细信息，请参阅相关部分。

**一次只更新一个 pandas 对象**

以下代码片段在没有 CoW 的情况下同时更新`df`和`subset`：

```py
In [12]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [13]: subset = df["foo"]

In [14]: subset.iloc[0] = 100

In [15]: df
Out[15]: 
 foo  bar
0    1    4
1    2    5
2    3    6 
```

这在 CoW 中将不再可能，因为 CoW 规则明确禁止这样做。这包括将单个列更新为`Series`并依赖于更改传播回父`DataFrame`。如果需要此行为，可以使用`loc`或`iloc`将此语句重写为单个语句。`DataFrame.where()`是此情况的另一个合适的替代方案。

使用就地方法从`DataFrame`中选择的列更新也将不再起作用。

```py
In [16]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [17]: df["foo"].replace(1, 5, inplace=True)

In [18]: df
Out[18]: 
 foo  bar
0    1    4
1    2    5
2    3    6 
```

这是另一种链式赋值的形式。通常可以以 2 种不同形式重写：

```py
In [19]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [20]: df.replace({"foo": {1: 5}}, inplace=True)

In [21]: df
Out[21]: 
 foo  bar
0    5    4
1    2    5
2    3    6 
```

另一种选择是不使用`inplace`：

```py
In [22]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [23]: df["foo"] = df["foo"].replace(1, 5)

In [24]: df
Out[24]: 
 foo  bar
0    5    4
1    2    5
2    3    6 
```

**构造函数现在默认复制 NumPy 数组**

Series 和 DataFrame 构造函数现在默认情况下将复制 NumPy 数组。这一变化是为了避免在 pandas 之外就地更改 NumPy 数组时改变 pandas 对象。您可以设置`copy=False`以避免此复制。

## 描述

CoW 意味着以任何方式从另一个 DataFrame 或 Series 派生的任何 DataFrame 或 Series 始终表现为副本。因此，我们只能通过修改对象本身来更改对象的值。CoW 不允许就地更新与另一个 DataFrame 或 Series 对象共享数据的 DataFrame 或 Series。

这样可以避免在修改值时产生副作用，因此大多数方法可以避免实际复制数据，只在必要时触发复制。

以下示例将在 CoW 下就地操作：

```py
In [25]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [26]: df.iloc[0, 0] = 100

In [27]: df
Out[27]: 
 foo  bar
0  100    4
1    2    5
2    3    6 
```

对象`df`不与任何其他对象共享数据，因此在更新值时不会触发复制。相比之下，以下操作在 CoW 下触发数据的复制：

```py
In [28]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [29]: df2 = df.reset_index(drop=True)

In [30]: df2.iloc[0, 0] = 100

In [31]: df
Out[31]: 
 foo  bar
0    1    4
1    2    5
2    3    6

In [32]: df2
Out[32]: 
 foo  bar
0  100    4
1    2    5
2    3    6 
```

`reset_index`返回一个带有 CoW 的延迟复制，而不带 CoW 的复制数据。由于`df`和`df2`两个对象共享相同的数据，当修改`df2`时会触发复制。对象`df`仍然具有最初的值，而`df2`已被修改。

如果在执行`reset_index`操作后不再需要对象`df`，您可以通过将`reset_index`的输出分配给同一变量来模拟类似就地操作：

```py
In [33]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [34]: df = df.reset_index(drop=True)

In [35]: df.iloc[0, 0] = 100

In [36]: df
Out[36]: 
 foo  bar
0  100    4
1    2    5
2    3    6 
```

当`reset_index`的结果被重新分配时，初始对象立即超出范围，因此`df`不与任何其他对象共享数据。在修改对象时不需要复制。这通常适用于写时复制优化中列出的所有方法。

以前，在操作视图时，会修改视图和父对象：

```py
In [37]: with pd.option_context("mode.copy_on_write", False):
 ....:    df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
 ....:    view = df[:]
 ....:    df.iloc[0, 0] = 100
 ....: 

In [38]: df
Out[38]: 
 foo  bar
0  100    4
1    2    5
2    3    6

In [39]: view
Out[39]: 
 foo  bar
0  100    4
1    2    5
2    3    6 
```

当`df`更改时触发拷贝，以避免突变`view`：

```py
In [40]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [41]: view = df[:]

In [42]: df.iloc[0, 0] = 100

In [43]: df
Out[43]: 
 foo  bar
0  100    4
1    2    5
2    3    6

In [44]: view
Out[44]: 
 foo  bar
0    1    4
1    2    5
2    3    6 
```

## 链式赋值

链式赋值引用一种技术，通过两个连续的索引操作来更新对象，例如。

```py
In [45]: with pd.option_context("mode.copy_on_write", False):
 ....:    df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
 ....:    df["foo"][df["bar"] > 5] = 100
 ....:    df
 ....: 
```

当列`bar`大于 5 时，更新列`foo`。尽管如此，这违反了写时拷贝的原则，因为它必须在一步中修改视图`df["foo"]`和`df`。因此，链式赋值将始终无法工作，并在启用写时拷贝时引发`ChainedAssignmentError`警告：

```py
In [46]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [47]: df["foo"][df["bar"] > 5] = 100 
```

通过使用`loc`可以实现写时拷贝。

```py
In [48]: df.loc[df["bar"] > 5, "foo"] = 100 
```  ## 只读 NumPy 数组

如果数组与初始 DataFrame 共享数据，则访问 DataFrame 的底层 NumPy 数组将返回只读数组：

如果初始 DataFrame 由多个数组组成，则该数组是一个拷贝：

```py
In [49]: df = pd.DataFrame({"a": [1, 2], "b": [1.5, 2.5]})

In [50]: df.to_numpy()
Out[50]: 
array([[1\. , 1.5],
 [2\. , 2.5]]) 
```

如果 DataFrame 仅由一个 NumPy 数组组成，则该数组与 DataFrame 共享数据：

```py
In [51]: df = pd.DataFrame({"a": [1, 2], "b": [3, 4]})

In [52]: df.to_numpy()
Out[52]: 
array([[1, 3],
 [2, 4]]) 
```

此数组是只读的，这意味着它不能就地修改：

```py
In [53]: arr = df.to_numpy()

In [54]: arr[0, 0] = 100
---------------------------------------------------------------------------
ValueError  Traceback (most recent call last)
Cell In[54], line 1
----> 1 arr[0, 0] = 100

ValueError: assignment destination is read-only 
```

对于 Series 也是如此，因为 Series 始终由单个数组组成。

这有两种潜在的解决方案：

+   如果想避免更新与数组共享内存的 DataFrame，则手动触发拷贝。

+   使数组可写。这是一种性能更好的解决方案，但是绕过了写时拷贝规则，因此应谨慎使用。

```py
In [55]: arr = df.to_numpy()

In [56]: arr.flags.writeable = True

In [57]: arr[0, 0] = 100

In [58]: arr
Out[58]: 
array([[100,   3],
 [  2,   4]]) 
```

## 避免模式

如果两个对象共享相同的数据，而您正在就地修改一个对象，则不会执行防御性拷贝。

```py
In [59]: df = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})

In [60]: df2 = df.reset_index(drop=True)

In [61]: df2.iloc[0, 0] = 100 
```

这将创建两个共享数据的对象，因此 setitem 操作将触发一个拷贝。如果不再需要初始对象`df`，则不需要这样做。简单地重新分配给相同的变量将使对象持有的引用无效。

```py
In [62]: df = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})

In [63]: df = df.reset_index(drop=True)

In [64]: df.iloc[0, 0] = 100 
```

在这个例子中不需要拷贝。创建多个引用会保持不必要的引用存在，因此会影响性能，因为写时拷贝。

## 写时拷贝优化

新的惰性拷贝机制，直到修改问题对象并且仅当该对象与另一个对象共享数据时才进行拷贝。此机制已添加到不需要底层数据拷贝的方法中。流行的例子有`DataFrame.drop()`用于`axis=1`和`DataFrame.rename()`。

当启用写时拷贝时，这些方法返回视图，与常规执行相比提供了显著的性能改进。  ## 如何启用写时拷贝

写时拷贝可以通过配置选项`copy_on_write`启用。该选项可以通过以下任一方式 __ 全局 __ 启用：

```py
In [65]: pd.set_option("mode.copy_on_write", True)

In [66]: pd.options.mode.copy_on_write = True 
```

## 先前的行为

pandas 的索引行为很难理解。一些操作返回视图，而另一些操作返回副本。根据操作的结果，改变一个对象可能会意外地改变另一个对象：

```py
In [1]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [2]: subset = df["foo"]

In [3]: subset.iloc[0] = 100

In [4]: df
Out[4]: 
 foo  bar
0  100    4
1    2    5
2    3    6 
```

改变`subset`，例如更新其值，也会更新`df`。确切的行为很难预测。Copy-on-Write 解决了意外修改多个对象的问题，它明确禁止这种情况发生。启用 CoW 后，`df`保持不变：

```py
In [5]: pd.options.mode.copy_on_write = True

In [6]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [7]: subset = df["foo"]

In [8]: subset.iloc[0] = 100

In [9]: df
Out[9]: 
 foo  bar
0    1    4
1    2    5
2    3    6 
```

接下来的部分将解释这意味着什么以及它如何影响现有应用程序。

## 迁移至 Copy-on-Write

在 pandas 3.0 中，Copy-on-Write 将成为默认且唯一模式。这意味着用户需要迁移其代码以符合 CoW 规则。

pandas 的默认模式将对某些情况发出警告，这些情况将积极改变行为，从而改变用户预期的行为。

我们添加了另一种模式，例如。

```py
pd.options.mode.copy_on_write = "warn" 
```

对于每个会改变行为的操作都会发出 CoW 警告。我们预计这种模式会非常嘈杂，因为许多我们不希望影响用户的情况也会发出警告。我们建议检查此模式并分析警告，但不需要解决所有这些警告。以下列表的前两项是需要解决的唯一情况，以使现有代码与 CoW 一起正常工作。

接下来的几个项目描述了用户可见的更改：

**链式赋值永远不会起作用**

应该使用`loc`作为替代方法。查看链式赋值部分以获取更多详细信息。

**访问 pandas 对象的底层数组将返回一个只读视图**

```py
In [10]: ser = pd.Series([1, 2, 3])

In [11]: ser.to_numpy()
Out[11]: array([1, 2, 3]) 
```

此示例返回一个 Series 对象的视图的 NumPy 数组。此视图可以被修改，从而也修改 pandas 对象。这不符合 CoW 规则。返回的数组设置为不可写，以防止这种行为。创建此数组的副本允许修改。如果不再关心 pandas 对象，也可以再次使数组可写。

查看关于只读 NumPy 数组的部分以获取更多详细信息。

**一次只更新一个 pandas 对象**

以下代码片段在没有 CoW 的情况下同时更新`df`和`subset`：

```py
In [12]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [13]: subset = df["foo"]

In [14]: subset.iloc[0] = 100

In [15]: df
Out[15]: 
 foo  bar
0    1    4
1    2    5
2    3    6 
```

这在 CoW 下将不再可能，因为 CoW 规则明确禁止这样做。这包括更新单个列作为`Series`并依赖于更改传播回父`DataFrame`。如果需要此行为，可以将此语句重写为使用`loc`或`iloc`的单个语句。`DataFrame.where()`是此情况的另一个合适的替代方法。

使用就地方法从`DataFrame`中选择的列更新列也将不再起作用。

```py
In [16]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [17]: df["foo"].replace(1, 5, inplace=True)

In [18]: df
Out[18]: 
 foo  bar
0    1    4
1    2    5
2    3    6 
```

这是另一种链式赋值的形式。这通常可以以 2 种不同的形式重写：

```py
In [19]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [20]: df.replace({"foo": {1: 5}}, inplace=True)

In [21]: df
Out[21]: 
 foo  bar
0    5    4
1    2    5
2    3    6 
```

另一种选择是不使用`inplace`：

```py
In [22]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [23]: df["foo"] = df["foo"].replace(1, 5)

In [24]: df
Out[24]: 
 foo  bar
0    5    4
1    2    5
2    3    6 
```

**构造函数现在默认复制 NumPy 数组**

当没有另行指定时，Series 和 DataFrame 构造函数现在默认复制 NumPy 数组。这一变更是为了避免在 pandas 之外原位更改 NumPy 数组时突变 pandas 对象。您可以设置`copy=False`来避免此复制。

## 描述

CoW 意味着以任何方式从另一个 DataFrame 或 Series 派生的任何 DataFrame 或 Series 都始终表现为副本。因此，我们只能通过修改对象本身来更改对象的值。CoW 不允许直接更新共享数据与另一个 DataFrame 或 Series 对象的 DataFrame 或 Series。

在修改值时避免副作用，因此，大多数方法可以避免实际复制数据，并且只在必要时触发复制。

以下示例将在 CoW 下进行就地操作：

```py
In [25]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [26]: df.iloc[0, 0] = 100

In [27]: df
Out[27]: 
 foo  bar
0  100    4
1    2    5
2    3    6 
```

对象`df`不与任何其他对象共享数据，因此在更新值时不触发复制。相比之下，下面的操作在 CoW 下触发数据的复制：

```py
In [28]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [29]: df2 = df.reset_index(drop=True)

In [30]: df2.iloc[0, 0] = 100

In [31]: df
Out[31]: 
 foo  bar
0    1    4
1    2    5
2    3    6

In [32]: df2
Out[32]: 
 foo  bar
0  100    4
1    2    5
2    3    6 
```

`reset_index`返回一个带有 CoW 的延迟副本，而在没有 CoW 的情况下复制数据。由于`df`和`df2`这两个对象共享相同的数据，所以当修改`df2`时会触发复制。对象`df`仍然具有最初的相同值，而`df2`已经被修改。

如果在执行`reset_index`操作后不再需要对象`df`，则可以通过将`reset_index`的输出分配给同一变量来模拟类似于 inplace 的操作：

```py
In [33]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [34]: df = df.reset_index(drop=True)

In [35]: df.iloc[0, 0] = 100

In [36]: df
Out[36]: 
 foo  bar
0  100    4
1    2    5
2    3    6 
```

当`reset_index`的结果重新分配时，初始对象就会超出范围，因此`df`与任何其他对象都不共享数据。在修改对象时，不需要复制。这通常对于列表中列出的所有方法都成立写时复制优化。

以前，在操作视图时，视图和父对象都会被修改：

```py
In [37]: with pd.option_context("mode.copy_on_write", False):
 ....:    df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
 ....:    view = df[:]
 ....:    df.iloc[0, 0] = 100
 ....: 

In [38]: df
Out[38]: 
 foo  bar
0  100    4
1    2    5
2    3    6

In [39]: view
Out[39]: 
 foo  bar
0  100    4
1    2    5
2    3    6 
```

当修改`df`时，CoW 会触发复制以避免同时更改`view`：

```py
In [40]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [41]: view = df[:]

In [42]: df.iloc[0, 0] = 100

In [43]: df
Out[43]: 
 foo  bar
0  100    4
1    2    5
2    3    6

In [44]: view
Out[44]: 
 foo  bar
0    1    4
1    2    5
2    3    6 
```

## 链式赋值

链式赋值引用一种通过两个后续索引操作更新对象的技术，例如

```py
In [45]: with pd.option_context("mode.copy_on_write", False):
 ....:    df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
 ....:    df["foo"][df["bar"] > 5] = 100
 ....:    df
 ....: 
```

当列`bar`大于 5 时，更新列`foo`。尽管如此，这违反了 CoW 原则，因为它需要一次性修改视图`df["foo"]`和`df`。因此，链式赋值始终不起作用，并在启用 CoW 时引发`ChainedAssignmentError`警告：

```py
In [46]: df = pd.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})

In [47]: df["foo"][df["bar"] > 5] = 100 
```

使用`loc`可以使用写时复制来完成这个过程。

```py
In [48]: df.loc[df["bar"] > 5, "foo"] = 100 
```

## 只读 NumPy 数组

访问 DataFrame 的底层 NumPy 数组将返回一个只读数组，如果数组与初始 DataFrame 共享数据：

如果初始 DataFrame 包含多个数组，则数组是副本：

```py
In [49]: df = pd.DataFrame({"a": [1, 2], "b": [1.5, 2.5]})

In [50]: df.to_numpy()
Out[50]: 
array([[1\. , 1.5],
 [2\. , 2.5]]) 
```

如果 DataFrame 只包含一个 NumPy 数组，则该数组与 DataFrame 共享数据：

```py
In [51]: df = pd.DataFrame({"a": [1, 2], "b": [3, 4]})

In [52]: df.to_numpy()
Out[52]: 
array([[1, 3],
 [2, 4]]) 
```

此数组是只读的，这意味着它不能就地修改：

```py
In [53]: arr = df.to_numpy()

In [54]: arr[0, 0] = 100
---------------------------------------------------------------------------
ValueError  Traceback (most recent call last)
Cell In[54], line 1
----> 1 arr[0, 0] = 100

ValueError: assignment destination is read-only 
```

对于 Series 也是如此，因为 Series 总是由单个数组组成。

有两种潜在的解决方案：

+   如果您想要避免更新与数组共享内存的 DataFrame，则手动触发复制。

+   使数组可写。这是一种更高效的解决方案，但是它绕过了写时复制规则，因此应谨慎使用。

```py
In [55]: arr = df.to_numpy()

In [56]: arr.flags.writeable = True

In [57]: arr[0, 0] = 100

In [58]: arr
Out[58]: 
array([[100,   3],
 [  2,   4]]) 
```

## 避免的模式

如果两个对象在您就地修改一个对象时共享相同的数据，则不会执行防御性复制。

```py
In [59]: df = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})

In [60]: df2 = df.reset_index(drop=True)

In [61]: df2.iloc[0, 0] = 100 
```

这会创建两个共享数据的对象，因此 setitem 操作将触发复制。如果初始对象 `df` 不再需要，则不需要这样做。简单地重新分配给同一个变量将使对象持有的引用失效。

```py
In [62]: df = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})

In [63]: df = df.reset_index(drop=True)

In [64]: df.iloc[0, 0] = 100 
```

在这个例子中不需要复制。创建多个引用会保持不必要的引用活动，因此会通过写时复制对性能造成损害。

## 写时复制优化

新的惰性复制机制推迟了直到修改了问题对象并且仅在此对象与另一个对象共享数据时才复制该对象。此机制已添加到不需要复制底层数据的方法中。常见示例是`DataFrame.drop()`对于`axis=1`和`DataFrame.rename()`。

当启用写时复制（Copy-on-Write）时，这些方法返回视图，与常规执行相比，这提供了显著的性能改进。

## 如何启用写时复制

可以通过配置选项 `copy_on_write` 启用写时复制。该选项可以通过以下任一全局方式进行打开：

```py
In [65]: pd.set_option("mode.copy_on_write", True)

In [66]: pd.options.mode.copy_on_write = True 
```
