- en: Home
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 首页
- en: 原文：[`docs.ultralytics.com/`](https://docs.ultralytics.com/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/`](https://docs.ultralytics.com/)
- en: '![Ultralytics YOLO banner](https://github.com/ultralytics/assets/releases/tag/v8.2.0)
    [中文](https://docs.ultralytics.com/zh/) | [한국어](https://docs.ultralytics.com/ko/)
    | [日本語](https://docs.ultralytics.com/ja/) | [Русский](https://docs.ultralytics.com/ru/)
    | [Deutsch](https://docs.ultralytics.com/de/) | [Français](https://docs.ultralytics.com/fr/)
    | [Español](https://docs.ultralytics.com/es/) | [Português](https://docs.ultralytics.com/pt/)
    | [Türkçe](https://docs.ultralytics.com/tr/) | [Tiếng Việt](https://docs.ultralytics.com/vi/)
    | [हिन्दी](https://docs.ultralytics.com/hi/) | [العربية](https://docs.ultralytics.com/ar/)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Ultralytics YOLO 横幅](https://github.com/ultralytics/assets/releases/tag/v8.2.0)
    [中文](https://docs.ultralytics.com/zh/) | [한국어](https://docs.ultralytics.com/ko/)
    | [日本語](https://docs.ultralytics.com/ja/) | [Русский](https://docs.ultralytics.com/ru/)
    | [Deutsch](https://docs.ultralytics.com/de/) | [Français](https://docs.ultralytics.com/fr/)
    | [Español](https://docs.ultralytics.com/es/) | [Português](https://docs.ultralytics.com/pt/)
    | [Türkçe](https://docs.ultralytics.com/tr/) | [Tiếng Việt](https://docs.ultralytics.com/vi/)
    | [हिन्दी](https://docs.ultralytics.com/hi/) | [العربية](https://docs.ultralytics.com/ar/)'
- en: '![Ultralytics CI](https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml)
    ![YOLOv8 Citation](https://zenodo.org/badge/latestdoi/264818686) ![Docker Pulls](https://hub.docker.com/r/ultralytics/ultralytics)
    ![Discord](https://ultralytics.com/discord) ![Ultralytics Forums](https://community.ultralytics.com)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![Ultralytics CI](https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml)
    ![YOLOv8 引用](https://zenodo.org/badge/latestdoi/264818686) ![Docker 拉取](https://hub.docker.com/r/ultralytics/ultralytics)
    ![Discord](https://ultralytics.com/discord) ![Ultralytics 论坛](https://community.ultralytics.com)'
- en: '![Run on Gradient](https://console.paperspace.com/github/ultralytics/ultralytics)
    ![Open In Colab](https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb)
    ![Open In Kaggle](https://www.kaggle.com/ultralytics/yolov8)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![在 Gradient 上运行](https://console.paperspace.com/github/ultralytics/ultralytics)
    ![在 Colab 中打开](https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb)
    ![在 Kaggle 中打开](https://www.kaggle.com/ultralytics/yolov8)'
- en: Introducing [Ultralytics](https://ultralytics.com) [YOLOv8](https://github.com/ultralytics/ultralytics),
    the latest version of the acclaimed real-time object detection and image segmentation
    model. YOLOv8 is built on cutting-edge advancements in deep learning and computer
    vision, offering unparalleled performance in terms of speed and accuracy. Its
    streamlined design makes it suitable for various applications and easily adaptable
    to different hardware platforms, from edge devices to cloud APIs.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍 [Ultralytics](https://ultralytics.com) [YOLOv8](https://github.com/ultralytics/ultralytics)，这是备受赞誉的实时目标检测和图像分割模型的最新版本。YOLOv8
    基于深度学习和计算机视觉的前沿进展，提供无与伦比的速度和准确性。其简化的设计使其适用于各种应用，并且可以轻松适应不同的硬件平台，从边缘设备到云 API。
- en: Explore the YOLOv8 Docs, a comprehensive resource designed to help you understand
    and utilize its features and capabilities. Whether you are a seasoned machine
    learning practitioner or new to the field, this hub aims to maximize YOLOv8's
    potential in your projects
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 探索 YOLOv8 文档，这是一个全面的资源，旨在帮助您理解和利用其功能和能力。无论您是经验丰富的机器学习从业者还是新手，本中心旨在最大化 YOLOv8
    在您项目中的潜力。
- en: '![Ultralytics GitHub](https://github.com/ultralytics) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics LinkedIn](https://www.linkedin.com/company/ultralytics/) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics Twitter](https://twitter.com/ultralytics) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics YouTube](https://youtube.com/ultralytics?sub_confirmation=1) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics TikTok](https://www.tiktok.com/@ultralytics) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics BiliBili](https://ultralytics.com/bilibili) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics Discord](https://ultralytics.com/discord)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![Ultralytics GitHub](https://github.com/ultralytics) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics LinkedIn](https://www.linkedin.com/company/ultralytics/) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics Twitter](https://twitter.com/ultralytics) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics YouTube](https://youtube.com/ultralytics?sub_confirmation=1) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics TikTok](https://www.tiktok.com/@ultralytics) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics BiliBili](https://ultralytics.com/bilibili) ![space](img/bea28c9c7f1a0c4c2108b8795e6e2889.png)
    ![Ultralytics Discord](https://ultralytics.com/discord)'
- en: Where to Start
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从哪里开始
- en: '**Install** `ultralytics` with pip and get up and running in minutes   Get
    Started'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 pip **安装** `ultralytics`，几分钟内即可开始使用   开始使用
- en: '**Predict** new images and videos with YOLOv8   Predict on Images'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 YOLOv8 **预测** 新的图像和视频   在图像上预测
- en: '**Train** a new YOLOv8 model on your own custom dataset   Train a Model'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Train** 在您自己的定制数据集上训练新的 YOLOv8 模型   训练一个模型'
- en: '**Tasks** YOLOv8 tasks like segment, classify, pose and track   Explore Tasks'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tasks** YOLOv8 任务如分段、分类、姿势和跟踪   探索任务'
- en: '**NEW 🚀 Explore** datasets with advanced semantic and SQL search   Explore
    a Dataset'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NEW 🚀 探索** 带有高级语义和 SQL 搜索功能的数据集   探索数据集'
- en: '[`www.youtube.com/embed/LNwODJXcvt4?si=7n1UvGRLSd9p5wKs`](https://www.youtube.com/embed/LNwODJXcvt4?si=7n1UvGRLSd9p5wKs)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[`www.youtube.com/embed/LNwODJXcvt4?si=7n1UvGRLSd9p5wKs`](https://www.youtube.com/embed/LNwODJXcvt4?si=7n1UvGRLSd9p5wKs)'
- en: '**Watch:** How to Train a YOLOv8 model on Your Custom Dataset in [Google Colab](https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**Watch:** 如何在 [Google Colab](https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb)
    上训练 YOLOv8 模型的视频。'
- en: 'YOLO: A Brief History'
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: YOLO：简史
- en: '[YOLO](https://arxiv.org/abs/1506.02640) (You Only Look Once), a popular object
    detection and image segmentation model, was developed by Joseph Redmon and Ali
    Farhadi at the University of Washington. Launched in 2015, YOLO quickly gained
    popularity for its high speed and accuracy.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[YOLO](https://arxiv.org/abs/1506.02640)（You Only Look Once）是一种流行的目标检测和图像分割模型，由华盛顿大学的
    Joseph Redmon 和 Ali Farhadi 开发。YOLO 由于其高速和高准确性，在2015年发布后迅速受到欢迎。'
- en: '[YOLOv2](https://arxiv.org/abs/1612.08242), released in 2016, improved the
    original model by incorporating batch normalization, anchor boxes, and dimension
    clusters.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv2](https://arxiv.org/abs/1612.08242)，发布于2016年，通过引入批量归一化、锚框和维度聚类，改进了原始模型。'
- en: '[YOLOv3](https://pjreddie.com/media/files/papers/YOLOv3.pdf), launched in 2018,
    further enhanced the model''s performance using a more efficient backbone network,
    multiple anchors and spatial pyramid pooling.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv3](https://pjreddie.com/media/files/papers/YOLOv3.pdf)，于2018年发布，通过更高效的骨干网络、多个锚点和空间金字塔池化进一步提升了模型的性能。'
- en: '[YOLOv4](https://arxiv.org/abs/2004.10934) was released in 2020, introducing
    innovations like Mosaic data augmentation, a new anchor-free detection head, and
    a new loss function.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv4](https://arxiv.org/abs/2004.10934) 于2020年发布，引入了 Mosaic 数据增强、新的无锚检测头部和新的损失函数等创新。'
- en: '[YOLOv5](https://github.com/ultralytics/yolov5) further improved the model''s
    performance and added new features such as hyperparameter optimization, integrated
    experiment tracking and automatic export to popular export formats.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv5](https://github.com/ultralytics/yolov5) 进一步提升了模型的性能，并增加了超参数优化、集成实验追踪和自动导出到流行的导出格式等新功能。'
- en: '[YOLOv6](https://github.com/meituan/YOLOv6) was open-sourced by [Meituan](https://about.meituan.com/)
    in 2022 and is in use in many of the company''s autonomous delivery robots.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv6](https://github.com/meituan/YOLOv6) 由 [美团](https://about.meituan.com/)
    在2022年开源，并在该公司的许多自动配送机器人中使用。'
- en: '[YOLOv7](https://github.com/WongKinYiu/yolov7) added additional tasks such
    as pose estimation on the COCO keypoints dataset.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv7](https://github.com/WongKinYiu/yolov7) 在 COCO 关键点数据集上增加了姿势估计等附加任务。'
- en: '[YOLOv8](https://github.com/ultralytics/ultralytics) is the latest version
    of YOLO by Ultralytics. As a cutting-edge, state-of-the-art (SOTA) model, YOLOv8
    builds on the success of previous versions, introducing new features and improvements
    for enhanced performance, flexibility, and efficiency. YOLOv8 supports a full
    range of vision AI tasks, including detection, segmentation, pose estimation,
    tracking, and classification. This versatility allows users to leverage YOLOv8''s
    capabilities across diverse applications and domains.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv8](https://github.com/ultralytics/ultralytics) 是由 Ultralytics 推出的最新版本
    YOLO。作为先进的模型，YOLOv8 在之前版本的成功基础上引入了新功能和改进，提升了性能、灵活性和效率。YOLOv8 支持包括检测、分割、姿势估计、跟踪和分类在内的全方位视觉
    AI 任务。这种多功能性使用户可以在各种应用和领域中充分利用 YOLOv8 的能力。'
- en: YOLOv9 introduces innovative methods like Programmable Gradient Information
    (PGI) and the Generalized Efficient Layer Aggregation Network (GELAN).
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YOLOv9 引入了像可编程梯度信息（PGI）和广义高效层聚合网络（GELAN）等创新方法。
- en: YOLOv10 is created by researchers from [Tsinghua University](https://www.tsinghua.edu.cn/en/)
    using the [Ultralytics](https://ultralytics.com/) [Python package](https://pypi.org/project/ultralytics/).
    This version provides real-time object detection advancements by introducing an
    End-to-End head that eliminates Non-Maximum Suppression (NMS) requirements.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YOLOv10 是由 [清华大学](https://www.tsinghua.edu.cn/en/) 的研究人员使用 [Ultralytics](https://ultralytics.com/)
    的 [Python package](https://pypi.org/project/ultralytics/) 创建的。这个版本通过引入端到端头部消除了非最大抑制（NMS）要求，提供了实时目标检测的进展。
- en: 'YOLO Licenses: How is Ultralytics YOLO licensed?'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: YOLO许可证：Ultralytics YOLO如何许可？
- en: 'Ultralytics offers two licensing options to accommodate diverse use cases:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics提供两种许可选项以适应不同的使用场景：
- en: '**AGPL-3.0 License**: This [OSI-approved](https://opensource.org/licenses/)
    open-source license is ideal for students and enthusiasts, promoting open collaboration
    and knowledge sharing. See the [LICENSE](https://github.com/ultralytics/ultralytics/blob/main/LICENSE)
    file for more details.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AGPL-3.0 许可证**：这个[OSI批准的](https://opensource.org/licenses/)开源许可证非常适合学生和爱好者，促进开放协作和知识共享。详见[LICENSE](https://github.com/ultralytics/ultralytics/blob/main/LICENSE)文件获取更多详情。'
- en: '**Enterprise License**: Designed for commercial use, this license permits seamless
    integration of Ultralytics software and AI models into commercial goods and services,
    bypassing the open-source requirements of AGPL-3.0\. If your scenario involves
    embedding our solutions into a commercial offering, reach out through [Ultralytics
    Licensing](https://ultralytics.com/license).'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**企业许可证**：设计用于商业使用，此许可证允许无缝集成Ultralytics软件和AI模型到商业产品和服务中，绕过AGPL-3.0许可证的开源要求。如果您的情况涉及将我们的解决方案嵌入到商业产品中，请通过[Ultralytics
    Licensing](https://ultralytics.com/license)联系。'
- en: Our licensing strategy is designed to ensure that any improvements to our open-source
    projects are returned to the community. We hold the principles of open source
    close to our hearts ❤️, and our mission is to guarantee that our contributions
    can be utilized and expanded upon in ways that are beneficial to all.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的许可策略旨在确保对我们开源项目的任何改进都能回馈给社区。我们深知开源原则的重要性 ❤️，我们的使命是确保我们的贡献可以以有益于所有人的方式被利用和扩展。
- en: FAQ
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题解答
- en: What is Ultralytics YOLO and how does it improve object detection?
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是Ultralytics YOLO以及它如何改善目标检测？
- en: Ultralytics YOLO is the latest advancement in the acclaimed YOLO (You Only Look
    Once) series for real-time object detection and image segmentation. It builds
    on previous versions by introducing new features and improvements for enhanced
    performance, flexibility, and efficiency. YOLOv8 supports various vision AI tasks
    such as detection, segmentation, pose estimation, tracking, and classification.
    Its state-of-the-art architecture ensures superior speed and accuracy, making
    it suitable for diverse applications, including edge devices and cloud APIs.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics YOLO是备受赞誉的YOLO（You Only Look Once）系列的最新进展，用于实时目标检测和图像分割。它通过引入新功能和改进来建立在之前版本的基础上，提升了性能、灵活性和效率。YOLOv8支持多种视觉AI任务，如检测、分割、姿态估计、跟踪和分类。其先进的架构确保了超高的速度和精度，适用于各种应用场景，包括边缘设备和云API。
- en: How can I get started with YOLO installation and setup?
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何开始使用YOLO进行安装和设置？
- en: 'Getting started with YOLO is quick and straightforward. You can install the
    Ultralytics package using pip and get up and running in minutes. Here''s a basic
    installation command:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 快速开始YOLO非常简单直接。您可以使用pip安装Ultralytics包，并在几分钟内运行起来。以下是一个基本的安装命令：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For a comprehensive step-by-step guide, visit our quickstart guide. This resource
    will help you with installation instructions, initial setup, and running your
    first model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对于全面的逐步指南，请访问我们的快速入门指南。这个资源将帮助您完成安装指导、初始设置和运行您的第一个模型。
- en: How can I train a custom YOLO model on my dataset?
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何在我的数据集上训练自定义YOLO模型？
- en: 'Training a custom YOLO model on your dataset involves a few detailed steps:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的数据集上训练自定义YOLO模型涉及几个详细步骤：
- en: Prepare your annotated dataset.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备您的标注数据集。
- en: Configure the training parameters in a YAML file.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个YAML文件中配置训练参数。
- en: Use the `yolo train` command to start training.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`yolo train`命令开始训练。
- en: 'Here''s an example command:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个示例命令：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For a detailed walkthrough, check out our Train a Model guide, which includes
    examples and tips for optimizing your training process.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解详细步骤，请查看我们的模型训练指南，其中包括示例和优化训练过程的技巧。
- en: What are the licensing options available for Ultralytics YOLO?
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Ultralytics YOLO有哪些许可选项？
- en: 'Ultralytics offers two licensing options for YOLO:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics为YOLO提供了两种许可选项：
- en: '**AGPL-3.0 License**: This open-source license is ideal for educational and
    non-commercial use, promoting open collaboration.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AGPL-3.0 许可证**：这个开源许可证非常适合教育和非商业用途，促进开放协作。'
- en: '**Enterprise License**: This is designed for commercial applications, allowing
    seamless integration of Ultralytics software into commercial products without
    the restrictions of the AGPL-3.0 license.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**企业许可证**：这个许可证专为商业应用设计，允许无缝集成Ultralytics软件到商业产品中，无需遵守AGPL-3.0许可证的限制。'
- en: For more details, visit our [Licensing](https://ultralytics.com/license) page.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多详情，请访问我们的[许可](https://ultralytics.com/license)页面。
- en: How can Ultralytics YOLO be used for real-time object tracking?
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Ultralytics YOLO如何用于实时目标跟踪？
- en: 'Ultralytics YOLO supports efficient and customizable multi-object tracking.
    To utilize tracking capabilities, you can use the `yolo track` command as shown
    below:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics YOLO支持高效且可定制的多目标跟踪。要利用跟踪功能，可以使用`yolo track`命令，如下所示：
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For a detailed guide on setting up and running object tracking, check our tracking
    mode documentation, which explains the configuration and practical applications
    in real-time scenarios.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 有关设置和运行目标跟踪的详细指南，请查看我们的跟踪模式文档，其中解释了配置和在实时场景中的实际应用。
