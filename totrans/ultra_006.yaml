- en: Model Prediction with Ultralytics YOLO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/modes/predict/`](https://docs.ultralytics.com/modes/predict/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Ultralytics YOLO ecosystem and integrations](img/1933b0eeaf180eaa6d0c37f29931fb7d.png)'
  prefs: []
  type: TYPE_IMG
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the world of machine learning and computer vision, the process of making
    sense out of visual data is called 'inference' or 'prediction'. Ultralytics YOLOv8
    offers a powerful feature known as **predict mode** that is tailored for high-performance,
    real-time inference on a wide range of data sources.
  prefs: []
  type: TYPE_NORMAL
- en: '[`www.youtube.com/embed/QtsI0TnwDZs?si=ljesw75cMO2Eas14`](https://www.youtube.com/embed/QtsI0TnwDZs?si=ljesw75cMO2Eas14)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch:** How to Extract the Outputs from Ultralytics YOLOv8 Model for Custom
    Projects.'
  prefs: []
  type: TYPE_NORMAL
- en: Real-world Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Manufacturing | Sports | Safety |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ![Vehicle Spare Parts Detection](img/ec2480c75b750dbc15e22cd0ae7db1d3.png)
    | ![Football Player Detection](img/129da9e4720fda945dbb94f3a4c38fc7.png) | ![People
    Fall Detection](img/e1e052c2cdac6a3c10f8a36f47bb2417.png) |'
  prefs: []
  type: TYPE_TB
- en: '| Vehicle Spare Parts Detection | Football Player Detection | People Fall Detection
    |'
  prefs: []
  type: TYPE_TB
- en: Why Use Ultralytics YOLO for Inference?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here''s why you should consider YOLOv8''s predict mode for your various inference
    needs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Versatility:** Capable of making inferences on images, videos, and even live
    streams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance:** Engineered for real-time, high-speed processing without sacrificing
    accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ease of Use:** Intuitive Python and CLI interfaces for rapid deployment and
    testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Highly Customizable:** Various settings and parameters to tune the model''s
    inference behavior according to your specific requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Key Features of Predict Mode
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'YOLOv8''s predict mode is designed to be robust and versatile, featuring:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiple Data Source Compatibility:** Whether your data is in the form of
    individual images, a collection of images, video files, or real-time video streams,
    predict mode has you covered.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Streaming Mode:** Use the streaming feature to generate a memory-efficient
    generator of `Results` objects. Enable this by setting `stream=True` in the predictor''s
    call method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Batch Processing:** The ability to process multiple images or video frames
    in a single batch, further speeding up inference time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration Friendly:** Easily integrate with existing data pipelines and
    other software components, thanks to its flexible API.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ultralytics YOLO models return either a Python list of `Results` objects, or
    a memory-efficient Python generator of `Results` objects when `stream=True` is
    passed to the model during inference:'
  prefs: []
  type: TYPE_NORMAL
- en: Predict
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Inference Sources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: YOLOv8 can process different types of input sources for inference, as shown
    in the table below. The sources include static images, video streams, and various
    data formats. The table also indicates whether each source can be used in streaming
    mode with the argument `stream=True` ✅. Streaming mode is beneficial for processing
    videos or live streams as it creates a generator of results instead of loading
    all frames into memory.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Use `stream=True` for processing long videos or large datasets to efficiently
    manage memory. When `stream=False`, the results for all frames or data points
    are stored in memory, which can quickly add up and cause out-of-memory errors
    for large inputs. In contrast, `stream=True` utilizes a generator, which only
    keeps the results of the current frame or data point in memory, significantly
    reducing memory consumption and preventing out-of-memory issues.
  prefs: []
  type: TYPE_NORMAL
- en: '| Source | Example | Type | Notes |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| image | `''image.jpg''` | `str` or `Path` | Single image file. |'
  prefs: []
  type: TYPE_TB
- en: '| URL | `''https://ultralytics.com/images/bus.jpg''` | `str` | URL to an image.
    |'
  prefs: []
  type: TYPE_TB
- en: '| screenshot | `''screen''` | `str` | Capture a screenshot. |'
  prefs: []
  type: TYPE_TB
- en: '| PIL | `Image.open(''im.jpg'')` | `PIL.Image` | HWC format with RGB channels.
    |'
  prefs: []
  type: TYPE_TB
- en: '| OpenCV | `cv2.imread(''im.jpg'')` | `np.ndarray` | HWC format with BGR channels
    `uint8 (0-255)`. |'
  prefs: []
  type: TYPE_TB
- en: '| numpy | `np.zeros((640,1280,3))` | `np.ndarray` | HWC format with BGR channels
    `uint8 (0-255)`. |'
  prefs: []
  type: TYPE_TB
- en: '| torch | `torch.zeros(16,3,320,640)` | `torch.Tensor` | BCHW format with RGB
    channels `float32 (0.0-1.0)`. |'
  prefs: []
  type: TYPE_TB
- en: '| CSV | `''sources.csv''` | `str` or `Path` | CSV file containing paths to
    images, videos, or directories. |'
  prefs: []
  type: TYPE_TB
- en: '| video ✅ | `''video.mp4''` | `str` or `Path` | Video file in formats like
    MP4, AVI, etc. |'
  prefs: []
  type: TYPE_TB
- en: '| directory ✅ | `''path/''` | `str` or `Path` | Path to a directory containing
    images or videos. |'
  prefs: []
  type: TYPE_TB
- en: '| glob ✅ | `''path/*.jpg''` | `str` | Glob pattern to match multiple files.
    Use the `*` character as a wildcard. |'
  prefs: []
  type: TYPE_TB
- en: '| YouTube ✅ | `''https://youtu.be/LNwODJXcvt4''` | `str` | URL to a YouTube
    video. |'
  prefs: []
  type: TYPE_TB
- en: '| stream ✅ | `''rtsp://example.com/media.mp4''` | `str` | URL for streaming
    protocols such as RTSP, RTMP, TCP, or an IP address. |'
  prefs: []
  type: TYPE_TB
- en: '| multi-stream ✅ | `''list.streams''` | `str` or `Path` | `*.streams` text
    file with one stream URL per row, i.e. 8 streams will run at batch-size 8. |'
  prefs: []
  type: TYPE_TB
- en: 'Below are code examples for using each source type:'
  prefs: []
  type: TYPE_NORMAL
- en: Prediction sources
  prefs: []
  type: TYPE_NORMAL
- en: Run inference on an image file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Run inference on the current screen content as a screenshot.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Run inference on an image or video hosted remotely via URL.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Run inference on an image opened with Python Imaging Library (PIL).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Run inference on an image read with OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Run inference on an image represented as a numpy array.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Run inference on an image represented as a PyTorch tensor.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Run inference on a collection of images, URLs, videos and directories listed
    in a CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Run inference on a video file. By using `stream=True`, you can create a generator
    of Results objects to reduce memory usage.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Run inference on all images and videos in a directory. To also capture images
    and videos in subdirectories use a glob pattern, i.e. `path/to/dir/**/*`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Run inference on all images and videos that match a glob expression with `*`
    characters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Run inference on a YouTube video. By using `stream=True`, you can create a generator
    of Results objects to reduce memory usage for long videos.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Run inference on remote streaming sources using RTSP, RTMP, TCP and IP address
    protocols. If multiple streams are provided in a `*.streams` text file then batched
    inference will run, i.e. 8 streams will run at batch-size 8, otherwise single
    streams will run at batch-size 1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Inference Arguments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`model.predict()` accepts multiple arguments that can be passed at inference
    time to override defaults:'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Inference arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Argument | Type | Default | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `source` | `str` | `''ultralytics/assets''` | Specifies the data source for
    inference. Can be an image path, video file, directory, URL, or device ID for
    live feeds. Supports a wide range of formats and sources, enabling flexible application
    across different types of input. |'
  prefs: []
  type: TYPE_TB
- en: '| `conf` | `float` | `0.25` | Sets the minimum confidence threshold for detections.
    Objects detected with confidence below this threshold will be disregarded. Adjusting
    this value can help reduce false positives. |'
  prefs: []
  type: TYPE_TB
- en: '| `iou` | `float` | `0.7` | Intersection Over Union (IoU) threshold for Non-Maximum
    Suppression (NMS). Lower values result in fewer detections by eliminating overlapping
    boxes, useful for reducing duplicates. |'
  prefs: []
  type: TYPE_TB
- en: '| `imgsz` | `int or tuple` | `640` | Defines the image size for inference.
    Can be a single integer `640` for square resizing or a (height, width) tuple.
    Proper sizing can improve detection accuracy and processing speed. |'
  prefs: []
  type: TYPE_TB
- en: '| `half` | `bool` | `False` | Enables half-precision (FP16) inference, which
    can speed up model inference on supported GPUs with minimal impact on accuracy.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `device` | `str` | `None` | Specifies the device for inference (e.g., `cpu`,
    `cuda:0` or `0`). Allows users to select between CPU, a specific GPU, or other
    compute devices for model execution. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_det` | `int` | `300` | Maximum number of detections allowed per image.
    Limits the total number of objects the model can detect in a single inference,
    preventing excessive outputs in dense scenes. |'
  prefs: []
  type: TYPE_TB
- en: '| `vid_stride` | `int` | `1` | Frame stride for video inputs. Allows skipping
    frames in videos to speed up processing at the cost of temporal resolution. A
    value of 1 processes every frame, higher values skip frames. |'
  prefs: []
  type: TYPE_TB
- en: '| `stream_buffer` | `bool` | `False` | Determines if all frames should be buffered
    when processing video streams (`True`), or if the model should return the most
    recent frame (`False`). Useful for real-time applications. |'
  prefs: []
  type: TYPE_TB
- en: '| `visualize` | `bool` | `False` | Activates visualization of model features
    during inference, providing insights into what the model is "seeing". Useful for
    debugging and model interpretation. |'
  prefs: []
  type: TYPE_TB
- en: '| `augment` | `bool` | `False` | Enables test-time augmentation (TTA) for predictions,
    potentially improving detection robustness at the cost of inference speed. |'
  prefs: []
  type: TYPE_TB
- en: '| `agnostic_nms` | `bool` | `False` | Enables class-agnostic Non-Maximum Suppression
    (NMS), which merges overlapping boxes of different classes. Useful in multi-class
    detection scenarios where class overlap is common. |'
  prefs: []
  type: TYPE_TB
- en: '| `classes` | `list[int]` | `None` | Filters predictions to a set of class
    IDs. Only detections belonging to the specified classes will be returned. Useful
    for focusing on relevant objects in multi-class detection tasks. |'
  prefs: []
  type: TYPE_TB
- en: '| `retina_masks` | `bool` | `False` | Uses high-resolution segmentation masks
    if available in the model. This can enhance mask quality for segmentation tasks,
    providing finer detail. |'
  prefs: []
  type: TYPE_TB
- en: '| `embed` | `list[int]` | `None` | Specifies the layers from which to extract
    feature vectors or embeddings. Useful for downstream tasks like clustering or
    similarity search. |'
  prefs: []
  type: TYPE_TB
- en: 'Visualization arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Argument | Type | Default | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `show` | `bool` | `False` | If `True`, displays the annotated images or videos
    in a window. Useful for immediate visual feedback during development or testing.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `save` | `bool` | `False` | Enables saving of the annotated images or videos
    to file. Useful for documentation, further analysis, or sharing results. |'
  prefs: []
  type: TYPE_TB
- en: '| `save_frames` | `bool` | `False` | When processing videos, saves individual
    frames as images. Useful for extracting specific frames or for detailed frame-by-frame
    analysis. |'
  prefs: []
  type: TYPE_TB
- en: '| `save_txt` | `bool` | `False` | Saves detection results in a text file, following
    the format `[class] [x_center] [y_center] [width] [height] [confidence]`. Useful
    for integration with other analysis tools. |'
  prefs: []
  type: TYPE_TB
- en: '| `save_conf` | `bool` | `False` | Includes confidence scores in the saved
    text files. Enhances the detail available for post-processing and analysis. |'
  prefs: []
  type: TYPE_TB
- en: '| `save_crop` | `bool` | `False` | Saves cropped images of detections. Useful
    for dataset augmentation, analysis, or creating focused datasets for specific
    objects. |'
  prefs: []
  type: TYPE_TB
- en: '| `show_labels` | `bool` | `True` | Displays labels for each detection in the
    visual output. Provides immediate understanding of detected objects. |'
  prefs: []
  type: TYPE_TB
- en: '| `show_conf` | `bool` | `True` | Displays the confidence score for each detection
    alongside the label. Gives insight into the model''s certainty for each detection.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `show_boxes` | `bool` | `True` | Draws bounding boxes around detected objects.
    Essential for visual identification and location of objects in images or video
    frames. |'
  prefs: []
  type: TYPE_TB
- en: '| `line_width` | `None or int` | `None` | Specifies the line width of bounding
    boxes. If `None`, the line width is automatically adjusted based on the image
    size. Provides visual customization for clarity. |'
  prefs: []
  type: TYPE_TB
- en: Image and Video Formats
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: YOLOv8 supports various image and video formats, as specified in [ultralytics/data/utils.py](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/data/utils.py).
    See the tables below for the valid suffixes and example predict commands.
  prefs: []
  type: TYPE_NORMAL
- en: Images
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The below table contains valid Ultralytics image formats.
  prefs: []
  type: TYPE_NORMAL
- en: '| Image Suffixes | Example Predict Command | Reference |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `.bmp` | `yolo predict source=image.bmp` | [Microsoft BMP File Format](https://en.wikipedia.org/wiki/BMP_file_format)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.dng` | `yolo predict source=image.dng` | [Adobe DNG](https://en.wikipedia.org/wiki/Digital_Negative)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.jpeg` | `yolo predict source=image.jpeg` | [JPEG](https://en.wikipedia.org/wiki/JPEG)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.jpg` | `yolo predict source=image.jpg` | [JPEG](https://en.wikipedia.org/wiki/JPEG)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.mpo` | `yolo predict source=image.mpo` | [Multi Picture Object](https://fileinfo.com/extension/mpo)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.png` | `yolo predict source=image.png` | [Portable Network Graphics](https://en.wikipedia.org/wiki/PNG)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.tif` | `yolo predict source=image.tif` | [Tag Image File Format](https://en.wikipedia.org/wiki/TIFF)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.tiff` | `yolo predict source=image.tiff` | [Tag Image File Format](https://en.wikipedia.org/wiki/TIFF)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.webp` | `yolo predict source=image.webp` | [WebP](https://en.wikipedia.org/wiki/WebP)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.pfm` | `yolo predict source=image.pfm` | [Portable FloatMap](https://en.wikipedia.org/wiki/Netpbm#File_formats)
    |'
  prefs: []
  type: TYPE_TB
- en: Videos
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The below table contains valid Ultralytics video formats.
  prefs: []
  type: TYPE_NORMAL
- en: '| Video Suffixes | Example Predict Command | Reference |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `.asf` | `yolo predict source=video.asf` | [Advanced Systems Format](https://en.wikipedia.org/wiki/Advanced_Systems_Format)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.avi` | `yolo predict source=video.avi` | [Audio Video Interleave](https://en.wikipedia.org/wiki/Audio_Video_Interleave)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.gif` | `yolo predict source=video.gif` | [Graphics Interchange Format](https://en.wikipedia.org/wiki/GIF)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.m4v` | `yolo predict source=video.m4v` | [MPEG-4 Part 14](https://en.wikipedia.org/wiki/M4V)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.mkv` | `yolo predict source=video.mkv` | [Matroska](https://en.wikipedia.org/wiki/Matroska)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.mov` | `yolo predict source=video.mov` | [QuickTime File Format](https://en.wikipedia.org/wiki/QuickTime_File_Format)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.mp4` | `yolo predict source=video.mp4` | [MPEG-4 Part 14 - Wikipedia](https://en.wikipedia.org/wiki/MPEG-4_Part_14)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.mpeg` | `yolo predict source=video.mpeg` | [MPEG-1 Part 2](https://en.wikipedia.org/wiki/MPEG-1)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.mpg` | `yolo predict source=video.mpg` | [MPEG-1 Part 2](https://en.wikipedia.org/wiki/MPEG-1)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.ts` | `yolo predict source=video.ts` | [MPEG Transport Stream](https://en.wikipedia.org/wiki/MPEG_transport_stream)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.wmv` | `yolo predict source=video.wmv` | [Windows Media Video](https://en.wikipedia.org/wiki/Windows_Media_Video)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `.webm` | `yolo predict source=video.webm` | [WebM Project](https://en.wikipedia.org/wiki/WebM)
    |'
  prefs: []
  type: TYPE_TB
- en: Working with Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All Ultralytics `predict()` calls will return a list of `Results` objects:'
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '`Results` objects have the following attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Attribute | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `orig_img` | `numpy.ndarray` | The original image as a numpy array. |'
  prefs: []
  type: TYPE_TB
- en: '| `orig_shape` | `tuple` | The original image shape in (height, width) format.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `boxes` | `Boxes, optional` | A Boxes object containing the detection bounding
    boxes. |'
  prefs: []
  type: TYPE_TB
- en: '| `masks` | `Masks, optional` | A Masks object containing the detection masks.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `probs` | `Probs, optional` | A Probs object containing probabilities of
    each class for classification task. |'
  prefs: []
  type: TYPE_TB
- en: '| `keypoints` | `Keypoints, optional` | A Keypoints object containing detected
    keypoints for each object. |'
  prefs: []
  type: TYPE_TB
- en: '| `obb` | `OBB, optional` | An OBB object containing oriented bounding boxes.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `speed` | `dict` | A dictionary of preprocess, inference, and postprocess
    speeds in milliseconds per image. |'
  prefs: []
  type: TYPE_TB
- en: '| `names` | `dict` | A dictionary of class names. |'
  prefs: []
  type: TYPE_TB
- en: '| `path` | `str` | The path to the image file. |'
  prefs: []
  type: TYPE_TB
- en: '`Results` objects have the following methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Return Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `update()` | `None` | Update the boxes, masks, and probs attributes of the
    Results object. |'
  prefs: []
  type: TYPE_TB
- en: '| `cpu()` | `Results` | Return a copy of the Results object with all tensors
    on CPU memory. |'
  prefs: []
  type: TYPE_TB
- en: '| `numpy()` | `Results` | Return a copy of the Results object with all tensors
    as numpy arrays. |'
  prefs: []
  type: TYPE_TB
- en: '| `cuda()` | `Results` | Return a copy of the Results object with all tensors
    on GPU memory. |'
  prefs: []
  type: TYPE_TB
- en: '| `to()` | `Results` | Return a copy of the Results object with tensors on
    the specified device and dtype. |'
  prefs: []
  type: TYPE_TB
- en: '| `new()` | `Results` | Return a new Results object with the same image, path,
    and names. |'
  prefs: []
  type: TYPE_TB
- en: '| `plot()` | `numpy.ndarray` | Plots the detection results. Returns a numpy
    array of the annotated image. |'
  prefs: []
  type: TYPE_TB
- en: '| `show()` | `None` | Show annotated results to screen. |'
  prefs: []
  type: TYPE_TB
- en: '| `save()` | `None` | Save annotated results to file. |'
  prefs: []
  type: TYPE_TB
- en: '| `verbose()` | `str` | Return log string for each task. |'
  prefs: []
  type: TYPE_TB
- en: '| `save_txt()` | `None` | Save predictions into a txt file. |'
  prefs: []
  type: TYPE_TB
- en: '| `save_crop()` | `None` | Save cropped predictions to `save_dir/cls/file_name.jpg`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `tojson()` | `str` | Convert the object to JSON format. |'
  prefs: []
  type: TYPE_TB
- en: For more details see the `Results` class documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Boxes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`Boxes` object can be used to index, manipulate, and convert bounding boxes
    to different formats.'
  prefs: []
  type: TYPE_NORMAL
- en: Boxes
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a table for the `Boxes` class methods and properties, including their
    name, type, and description:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `cpu()` | Method | Move the object to CPU memory. |'
  prefs: []
  type: TYPE_TB
- en: '| `numpy()` | Method | Convert the object to a numpy array. |'
  prefs: []
  type: TYPE_TB
- en: '| `cuda()` | Method | Move the object to CUDA memory. |'
  prefs: []
  type: TYPE_TB
- en: '| `to()` | Method | Move the object to the specified device. |'
  prefs: []
  type: TYPE_TB
- en: '| `xyxy` | Property (`torch.Tensor`) | Return the boxes in xyxy format. |'
  prefs: []
  type: TYPE_TB
- en: '| `conf` | Property (`torch.Tensor`) | Return the confidence values of the
    boxes. |'
  prefs: []
  type: TYPE_TB
- en: '| `cls` | Property (`torch.Tensor`) | Return the class values of the boxes.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `id` | Property (`torch.Tensor`) | Return the track IDs of the boxes (if
    available). |'
  prefs: []
  type: TYPE_TB
- en: '| `xywh` | Property (`torch.Tensor`) | Return the boxes in xywh format. |'
  prefs: []
  type: TYPE_TB
- en: '| `xyxyn` | Property (`torch.Tensor`) | Return the boxes in xyxy format normalized
    by original image size. |'
  prefs: []
  type: TYPE_TB
- en: '| `xywhn` | Property (`torch.Tensor`) | Return the boxes in xywh format normalized
    by original image size. |'
  prefs: []
  type: TYPE_TB
- en: For more details see the `Boxes` class documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Masks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`Masks` object can be used index, manipulate and convert masks to segments.'
  prefs: []
  type: TYPE_NORMAL
- en: Masks
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a table for the `Masks` class methods and properties, including their
    name, type, and description:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `cpu()` | Method | Returns the masks tensor on CPU memory. |'
  prefs: []
  type: TYPE_TB
- en: '| `numpy()` | Method | Returns the masks tensor as a numpy array. |'
  prefs: []
  type: TYPE_TB
- en: '| `cuda()` | Method | Returns the masks tensor on GPU memory. |'
  prefs: []
  type: TYPE_TB
- en: '| `to()` | Method | Returns the masks tensor with the specified device and
    dtype. |'
  prefs: []
  type: TYPE_TB
- en: '| `xyn` | Property (`torch.Tensor`) | A list of normalized segments represented
    as tensors. |'
  prefs: []
  type: TYPE_TB
- en: '| `xy` | Property (`torch.Tensor`) | A list of segments in pixel coordinates
    represented as tensors. |'
  prefs: []
  type: TYPE_TB
- en: For more details see the `Masks` class documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Keypoints
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`Keypoints` object can be used index, manipulate and normalize coordinates.'
  prefs: []
  type: TYPE_NORMAL
- en: Keypoints
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a table for the `Keypoints` class methods and properties, including
    their name, type, and description:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `cpu()` | Method | Returns the keypoints tensor on CPU memory. |'
  prefs: []
  type: TYPE_TB
- en: '| `numpy()` | Method | Returns the keypoints tensor as a numpy array. |'
  prefs: []
  type: TYPE_TB
- en: '| `cuda()` | Method | Returns the keypoints tensor on GPU memory. |'
  prefs: []
  type: TYPE_TB
- en: '| `to()` | Method | Returns the keypoints tensor with the specified device
    and dtype. |'
  prefs: []
  type: TYPE_TB
- en: '| `xyn` | Property (`torch.Tensor`) | A list of normalized keypoints represented
    as tensors. |'
  prefs: []
  type: TYPE_TB
- en: '| `xy` | Property (`torch.Tensor`) | A list of keypoints in pixel coordinates
    represented as tensors. |'
  prefs: []
  type: TYPE_TB
- en: '| `conf` | Property (`torch.Tensor`) | Returns confidence values of keypoints
    if available, else None. |'
  prefs: []
  type: TYPE_TB
- en: For more details see the `Keypoints` class documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Probs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`Probs` object can be used index, get `top1` and `top5` indices and scores
    of classification.'
  prefs: []
  type: TYPE_NORMAL
- en: Probs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s a table summarizing the methods and properties for the `Probs` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `cpu()` | Method | Returns a copy of the probs tensor on CPU memory. |'
  prefs: []
  type: TYPE_TB
- en: '| `numpy()` | Method | Returns a copy of the probs tensor as a numpy array.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `cuda()` | Method | Returns a copy of the probs tensor on GPU memory. |'
  prefs: []
  type: TYPE_TB
- en: '| `to()` | Method | Returns a copy of the probs tensor with the specified device
    and dtype. |'
  prefs: []
  type: TYPE_TB
- en: '| `top1` | Property (`int`) | Index of the top 1 class. |'
  prefs: []
  type: TYPE_TB
- en: '| `top5` | Property (`list[int]`) | Indices of the top 5 classes. |'
  prefs: []
  type: TYPE_TB
- en: '| `top1conf` | Property (`torch.Tensor`) | Confidence of the top 1 class. |'
  prefs: []
  type: TYPE_TB
- en: '| `top5conf` | Property (`torch.Tensor`) | Confidences of the top 5 classes.
    |'
  prefs: []
  type: TYPE_TB
- en: For more details see the `Probs` class documentation.
  prefs: []
  type: TYPE_NORMAL
- en: OBB
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`OBB` object can be used to index, manipulate, and convert oriented bounding
    boxes to different formats.'
  prefs: []
  type: TYPE_NORMAL
- en: OBB
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a table for the `OBB` class methods and properties, including their
    name, type, and description:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `cpu()` | Method | Move the object to CPU memory. |'
  prefs: []
  type: TYPE_TB
- en: '| `numpy()` | Method | Convert the object to a numpy array. |'
  prefs: []
  type: TYPE_TB
- en: '| `cuda()` | Method | Move the object to CUDA memory. |'
  prefs: []
  type: TYPE_TB
- en: '| `to()` | Method | Move the object to the specified device. |'
  prefs: []
  type: TYPE_TB
- en: '| `conf` | Property (`torch.Tensor`) | Return the confidence values of the
    boxes. |'
  prefs: []
  type: TYPE_TB
- en: '| `cls` | Property (`torch.Tensor`) | Return the class values of the boxes.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `id` | Property (`torch.Tensor`) | Return the track IDs of the boxes (if
    available). |'
  prefs: []
  type: TYPE_TB
- en: '| `xyxy` | Property (`torch.Tensor`) | Return the horizontal boxes in xyxy
    format. |'
  prefs: []
  type: TYPE_TB
- en: '| `xywhr` | Property (`torch.Tensor`) | Return the rotated boxes in xywhr format.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `xyxyxyxy` | Property (`torch.Tensor`) | Return the rotated boxes in xyxyxyxy
    format. |'
  prefs: []
  type: TYPE_TB
- en: '| `xyxyxyxyn` | Property (`torch.Tensor`) | Return the rotated boxes in xyxyxyxy
    format normalized by image size. |'
  prefs: []
  type: TYPE_TB
- en: For more details see the `OBB` class documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Plotting Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `plot()` method in `Results` objects facilitates visualization of predictions
    by overlaying detected objects (such as bounding boxes, masks, keypoints, and
    probabilities) onto the original image. This method returns the annotated image
    as a NumPy array, allowing for easy display or saving.
  prefs: []
  type: TYPE_NORMAL
- en: Plotting
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '`plot()` Method Parameters'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `plot()` method supports various arguments to customize the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Argument | Type | Description | Default |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `conf` | `bool` | Include detection confidence scores. | `True` |'
  prefs: []
  type: TYPE_TB
- en: '| `line_width` | `float` | Line width of bounding boxes. Scales with image
    size if `None`. | `None` |'
  prefs: []
  type: TYPE_TB
- en: '| `font_size` | `float` | Text font size. Scales with image size if `None`.
    | `None` |'
  prefs: []
  type: TYPE_TB
- en: '| `font` | `str` | Font name for text annotations. | `''Arial.ttf''` |'
  prefs: []
  type: TYPE_TB
- en: '| `pil` | `bool` | Return image as a PIL Image object. | `False` |'
  prefs: []
  type: TYPE_TB
- en: '| `img` | `numpy.ndarray` | Alternative image for plotting. Uses the original
    image if `None`. | `None` |'
  prefs: []
  type: TYPE_TB
- en: '| `im_gpu` | `torch.Tensor` | GPU-accelerated image for faster mask plotting.
    Shape: (1, 3, 640, 640). | `None` |'
  prefs: []
  type: TYPE_TB
- en: '| `kpt_radius` | `int` | Radius for drawn keypoints. | `5` |'
  prefs: []
  type: TYPE_TB
- en: '| `kpt_line` | `bool` | Connect keypoints with lines. | `True` |'
  prefs: []
  type: TYPE_TB
- en: '| `labels` | `bool` | Include class labels in annotations. | `True` |'
  prefs: []
  type: TYPE_TB
- en: '| `boxes` | `bool` | Overlay bounding boxes on the image. | `True` |'
  prefs: []
  type: TYPE_TB
- en: '| `masks` | `bool` | Overlay masks on the image. | `True` |'
  prefs: []
  type: TYPE_TB
- en: '| `probs` | `bool` | Include classification probabilities. | `True` |'
  prefs: []
  type: TYPE_TB
- en: '| `show` | `bool` | Display the annotated image directly using the default
    image viewer. | `False` |'
  prefs: []
  type: TYPE_TB
- en: '| `save` | `bool` | Save the annotated image to a file specified by `filename`.
    | `False` |'
  prefs: []
  type: TYPE_TB
- en: '| `filename` | `str` | Path and name of the file to save the annotated image
    if `save` is `True`. | `None` |'
  prefs: []
  type: TYPE_TB
- en: Thread-Safe Inference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensuring thread safety during inference is crucial when you are running multiple
    YOLO models in parallel across different threads. Thread-safe inference guarantees
    that each thread's predictions are isolated and do not interfere with one another,
    avoiding race conditions and ensuring consistent and reliable outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using YOLO models in a multi-threaded application, it''s important to
    instantiate separate model objects for each thread or employ thread-local storage
    to prevent conflicts:'
  prefs: []
  type: TYPE_NORMAL
- en: Thread-Safe Inference
  prefs: []
  type: TYPE_NORMAL
- en: 'Instantiate a single model inside each thread for thread-safe inference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: For an in-depth look at thread-safe inference with YOLO models and step-by-step
    instructions, please refer to our YOLO Thread-Safe Inference Guide. This guide
    will provide you with all the necessary information to avoid common pitfalls and
    ensure that your multi-threaded inference runs smoothly.
  prefs: []
  type: TYPE_NORMAL
- en: Streaming Source `for`-loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here's a Python script using OpenCV (`cv2`) and YOLOv8 to run inference on video
    frames. This script assumes you have already installed the necessary packages
    (`opencv-python` and `ultralytics`).
  prefs: []
  type: TYPE_NORMAL
- en: Streaming for-loop
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This script will run predictions on each frame of the video, visualize the results,
    and display them in a window. The loop can be exited by pressing 'q'.
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is Ultralytics YOLOv8 and its predict mode for real-time inference?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ultralytics YOLOv8 is a state-of-the-art model for real-time object detection,
    segmentation, and classification. Its **predict mode** allows users to perform
    high-speed inference on various data sources such as images, videos, and live
    streams. Designed for performance and versatility, it also offers batch processing
    and streaming modes. For more details on its features, check out the Ultralytics
    YOLOv8 predict mode.
  prefs: []
  type: TYPE_NORMAL
- en: How can I run inference using Ultralytics YOLOv8 on different data sources?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ultralytics YOLOv8 can process a wide range of data sources, including individual
    images, videos, directories, URLs, and streams. You can specify the data source
    in the `model.predict()` call. For example, use `'image.jpg'` for a local image
    or `'https://ultralytics.com/images/bus.jpg'` for a URL. Check out the detailed
    examples for various inference sources in the documentation.
  prefs: []
  type: TYPE_NORMAL
- en: How do I optimize YOLOv8 inference speed and memory usage?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To optimize inference speed and manage memory efficiently, you can use the streaming
    mode by setting `stream=True` in the predictor's call method. The streaming mode
    generates a memory-efficient generator of `Results` objects instead of loading
    all frames into memory. For processing long videos or large datasets, streaming
    mode is particularly useful. Learn more about streaming mode.
  prefs: []
  type: TYPE_NORMAL
- en: What inference arguments does Ultralytics YOLOv8 support?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `model.predict()` method in YOLOv8 supports various arguments such as `conf`,
    `iou`, `imgsz`, `device`, and more. These arguments allow you to customize the
    inference process, setting parameters like confidence thresholds, image size,
    and the device used for computation. Detailed descriptions of these arguments
    can be found in the inference arguments section.
  prefs: []
  type: TYPE_NORMAL
- en: How can I visualize and save the results of YOLOv8 predictions?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After running inference with YOLOv8, the `Results` objects contain methods for
    displaying and saving annotated images. You can use methods like `result.show()`
    and `result.save(filename="result.jpg")` to visualize and save the results. For
    a comprehensive list of these methods, refer to the working with results section.
  prefs: []
  type: TYPE_NORMAL
