- en: YOLOv8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/models/yolov8/`](https://docs.ultralytics.com/models/yolov8/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Overview
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: YOLOv8 is the latest iteration in the YOLO series of real-time object detectors,
    offering cutting-edge performance in terms of accuracy and speed. Building upon
    the advancements of previous YOLO versions, YOLOv8 introduces new features and
    optimizations that make it an ideal choice for various object detection tasks
    in a wide range of applications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: '![Ultralytics YOLOv8](img/ceeef27fc01c2eb25ee99a7364e044f5.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
- en: '[`www.youtube.com/embed/Na0HvJ4hkk0`](https://www.youtube.com/embed/Na0HvJ4hkk0)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch:** Ultralytics YOLOv8 Model Overview'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Key Features
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Advanced Backbone and Neck Architectures:** YOLOv8 employs state-of-the-art
    backbone and neck architectures, resulting in improved feature extraction and
    object detection performance.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anchor-free Split Ultralytics Head:** YOLOv8 adopts an anchor-free split
    Ultralytics head, which contributes to better accuracy and a more efficient detection
    process compared to anchor-based approaches.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimized Accuracy-Speed Tradeoff:** With a focus on maintaining an optimal
    balance between accuracy and speed, YOLOv8 is suitable for real-time object detection
    tasks in diverse application areas.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variety of Pre-trained Models:** YOLOv8 offers a range of pre-trained models
    to cater to various tasks and performance requirements, making it easier to find
    the right model for your specific use case.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supported Tasks and Modes
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The YOLOv8 series offers a diverse range of models, each specialized for specific
    tasks in computer vision. These models are designed to cater to various requirements,
    from object detection to more complex tasks like instance segmentation, pose/keypoints
    detection, oriented object detection, and classification.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Each variant of the YOLOv8 series is optimized for its respective task, ensuring
    high performance and accuracy. Additionally, these models are compatible with
    various operational modes including Inference, Validation, Training, and Export,
    facilitating their use in different stages of deployment and development.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Filenames | Task | Inference | Validation | Training | Export |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8 | `yolov8n.pt` `yolov8s.pt` `yolov8m.pt` `yolov8l.pt` `yolov8x.pt`
    | Detection | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-seg | `yolov8n-seg.pt` `yolov8s-seg.pt` `yolov8m-seg.pt` `yolov8l-seg.pt`
    `yolov8x-seg.pt` | Instance Segmentation | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-pose | `yolov8n-pose.pt` `yolov8s-pose.pt` `yolov8m-pose.pt` `yolov8l-pose.pt`
    `yolov8x-pose.pt` `yolov8x-pose-p6.pt` | Pose/Keypoints | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-obb | `yolov8n-obb.pt` `yolov8s-obb.pt` `yolov8m-obb.pt` `yolov8l-obb.pt`
    `yolov8x-obb.pt` | Oriented Detection | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-cls | `yolov8n-cls.pt` `yolov8s-cls.pt` `yolov8m-cls.pt` `yolov8l-cls.pt`
    `yolov8x-cls.pt` | Classification | ✅ | ✅ | ✅ | ✅ |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
- en: This table provides an overview of the YOLOv8 model variants, highlighting their
    applicability in specific tasks and their compatibility with various operational
    modes such as Inference, Validation, Training, and Export. It showcases the versatility
    and robustness of the YOLOv8 series, making them suitable for a variety of applications
    in computer vision.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Performance Metrics
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Performance
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: See Detection Docs for usage examples with these models trained on COCO, which
    include 80 pre-trained classes.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)
    | 640 | 37.3 | 80.4 | 0.99 | 3.2 | 8.7 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)
    | 640 | 44.9 | 128.4 | 1.20 | 11.2 | 28.6 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)
    | 640 | 50.2 | 234.7 | 1.83 | 25.9 | 78.9 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt)
    | 640 | 52.9 | 375.2 | 2.39 | 43.7 | 165.2 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt)
    | 640 | 53.9 | 479.1 | 3.53 | 68.2 | 257.8 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
- en: See Detection Docs for usage examples with these models trained on Open Image
    V7, which include 600 pre-trained classes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-oiv7.pt)
    | 640 | 18.4 | 142.4 | 1.21 | 3.5 | 10.5 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-oiv7.pt)
    | 640 | 27.7 | 183.1 | 1.40 | 11.4 | 29.7 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-oiv7.pt)
    | 640 | 33.6 | 408.5 | 2.26 | 26.2 | 80.6 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-oiv7.pt)
    | 640 | 34.9 | 596.9 | 2.43 | 44.1 | 167.4 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-oiv7.pt)
    | 640 | 36.3 | 860.6 | 3.56 | 68.7 | 260.6 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
- en: See Segmentation Docs for usage examples with these models trained on COCO,
    which include 80 pre-trained classes.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(box 50-95) | mAP^(mask 50-95) | Speed ^(CPU
    ONNX'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-seg.pt)
    | 640 | 36.7 | 30.5 | 96.1 | 1.21 | 3.4 | 12.6 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-seg.pt)
    | 640 | 44.6 | 36.8 | 155.7 | 1.47 | 11.8 | 42.6 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-seg.pt)
    | 640 | 49.9 | 40.8 | 317.0 | 2.18 | 27.3 | 110.2 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-seg.pt)
    | 640 | 52.3 | 42.6 | 572.4 | 2.79 | 46.0 | 220.5 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-seg.pt)
    | 640 | 53.4 | 43.4 | 712.1 | 4.02 | 71.8 | 344.1 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
- en: See Classification Docs for usage examples with these models trained on ImageNet,
    which include 1000 pre-trained classes.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | acc ^(top1) | acc ^(top5) | Speed ^(CPU ONNX'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B) at 640) |
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-cls.pt)
    | 224 | 69.0 | 88.3 | 12.9 | 0.31 | 2.7 | 4.3 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-cls.pt)
    | 224 | 73.8 | 91.7 | 23.4 | 0.35 | 6.4 | 13.5 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-cls.pt)
    | 224 | 76.8 | 93.5 | 85.4 | 0.62 | 17.0 | 42.7 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-cls.pt)
    | 224 | 76.8 | 93.5 | 163.0 | 0.87 | 37.5 | 99.7 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-cls.pt)
    | 224 | 79.0 | 94.6 | 232.0 | 1.01 | 57.4 | 154.8 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: See Pose Estimation Docs for usage examples with these models trained on COCO,
    which include 1 pre-trained class, 'person'.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(pose 50-95) | mAP^(pose 50) | Speed ^(CPU
    ONNX'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-pose.pt)
    | 640 | 50.4 | 80.1 | 131.8 | 1.18 | 3.3 | 9.2 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-pose.pt)
    | 640 | 60.0 | 86.2 | 233.2 | 1.42 | 11.6 | 30.2 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-pose.pt)
    | 640 | 65.0 | 88.8 | 456.3 | 2.00 | 26.4 | 81.0 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-pose.pt)
    | 640 | 67.6 | 90.0 | 784.5 | 2.59 | 44.4 | 168.6 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-pose.pt)
    | 640 | 69.2 | 90.2 | 1607.1 | 3.73 | 69.4 | 263.2 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-pose-p6](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-pose-p6.pt)
    | 1280 | 71.6 | 91.2 | 4088.7 | 10.04 | 99.1 | 1066.4 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
- en: See Oriented Detection Docs for usage examples with these models trained on
    DOTAv1, which include 15 pre-trained classes.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(test 50) | Speed ^(CPU ONNX'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n-obb](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-obb.pt)
    | 1024 | 78.0 | 204.77 | 3.57 | 3.1 | 23.3 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s-obb](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-obb.pt)
    | 1024 | 79.5 | 424.88 | 4.07 | 11.4 | 76.3 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m-obb](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-obb.pt)
    | 1024 | 80.5 | 763.48 | 7.61 | 26.4 | 208.6 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l-obb](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-obb.pt)
    | 1024 | 80.7 | 1278.42 | 11.83 | 44.5 | 433.8 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-obb](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-obb.pt)
    | 1024 | 81.36 | 1759.10 | 13.23 | 69.5 | 676.7 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
- en: Usage Examples
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This example provides simple YOLOv8 training and inference examples. For full
    documentation on these and other modes see the Predict, Train, Val and Export
    docs pages.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Note the below example is for YOLOv8 Detect models for object detection. For
    additional supported tasks see the Segment, Classify, OBB docs and Pose docs.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Example
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'PyTorch pretrained `*.pt` models as well as configuration `*.yaml` files can
    be passed to the `YOLO()` class to create a model instance in python:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'CLI commands are available to directly run the models:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Citations and Acknowledgements
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you use the YOLOv8 model or any other software from this repository in your
    work, please cite it using the following format:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Please note that the DOI is pending and will be added to the citation once it
    is available. YOLOv8 models are provided under [AGPL-3.0](https://github.com/ultralytics/ultralytics/blob/main/LICENSE)
    and [Enterprise](https://ultralytics.com/license) licenses.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is YOLOv8 and how does it differ from previous YOLO versions?
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv8 is the latest iteration in the Ultralytics YOLO series, designed to improve
    real-time object detection performance with advanced features. Unlike earlier
    versions, YOLOv8 incorporates an **anchor-free split Ultralytics head**, state-of-the-art
    backbone and neck architectures, and offers optimized accuracy-speed tradeoff,
    making it ideal for diverse applications. For more details, check the Overview
    and Key Features sections.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: How can I use YOLOv8 for different computer vision tasks?
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv8 supports a wide range of computer vision tasks, including object detection,
    instance segmentation, pose/keypoints detection, oriented object detection, and
    classification. Each model variant is optimized for its specific task and compatible
    with various operational modes like Inference, Validation, Training, and Export.
    Refer to the Supported Tasks and Modes section for more information.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: What are the performance metrics for YOLOv8 models?
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv8 models achieve state-of-the-art performance across various benchmarking
    datasets. For instance, the YOLOv8n model achieves a mAP (mean Average Precision)
    of 37.3 on the COCO dataset and a speed of 0.99 ms on A100 TensorRT. Detailed
    performance metrics for each model variant across different tasks and datasets
    can be found in the Performance Metrics section.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv8模型在各种基准数据集上实现了最先进的性能。例如，YOLOv8n模型在COCO数据集上达到了37.3的mAP（平均精度），在A100 TensorRT上的速度为0.99毫秒。您可以在性能指标部分找到每个模型变体在不同任务和数据集上的详细性能指标。
- en: How do I train a YOLOv8 model?
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何训练YOLOv8模型？
- en: 'Training a YOLOv8 model can be done using either Python or CLI. Below are examples
    for training a model using a COCO-pretrained YOLOv8 model on the COCO8 dataset
    for 100 epochs:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python或CLI可以训练YOLOv8模型。以下是使用COCO预训练的YOLOv8模型在COCO8数据集上进行100个epoch训练的示例：
- en: Example
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE3]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: For further details, visit the Training documentation.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多详细信息，请访问培训文档。
- en: Can I benchmark YOLOv8 models for performance?
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我可以对YOLOv8模型进行性能基准测试吗？
- en: 'Yes, YOLOv8 models can be benchmarked for performance in terms of speed and
    accuracy across various export formats. You can use PyTorch, ONNX, TensorRT, and
    more for benchmarking. Below are example commands for benchmarking using Python
    and CLI:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，YOLOv8模型可以根据速度和准确性在各种导出格式中进行性能基准测试。您可以使用PyTorch、ONNX、TensorRT等进行基准测试。以下是使用Python和CLI进行基准测试的示例命令：
- en: Example
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE5]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: For additional information, check the Performance Metrics section.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如需更多信息，请查看性能指标部分。
