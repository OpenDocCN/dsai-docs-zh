- en: COCO8 Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/datasets/detect/coco8/`](https://docs.ultralytics.com/datasets/detect/coco8/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Ultralytics](https://ultralytics.com) COCO8 is a small, but versatile object
    detection dataset composed of the first 8 images of the COCO train 2017 set, 4
    for training and 4 for validation. This dataset is ideal for testing and debugging
    object detection models, or for experimenting with new detection approaches. With
    8 images, it is small enough to be easily manageable, yet diverse enough to test
    training pipelines for errors and act as a sanity check before training larger
    datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '[`www.youtube.com/embed/uDrn9QZJ2lk`](https://www.youtube.com/embed/uDrn9QZJ2lk)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch:** Ultralytics COCO Dataset Overview'
  prefs: []
  type: TYPE_NORMAL
- en: This dataset is intended for use with Ultralytics [HUB](https://hub.ultralytics.com)
    and [YOLOv8](https://github.com/ultralytics/ultralytics).
  prefs: []
  type: TYPE_NORMAL
- en: Dataset YAML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A YAML (Yet Another Markup Language) file is used to define the dataset configuration.
    It contains information about the dataset's paths, classes, and other relevant
    information. In the case of the COCO8 dataset, the `coco8.yaml` file is maintained
    at [`github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco8.yaml`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco8.yaml).
  prefs: []
  type: TYPE_NORMAL
- en: ultralytics/cfg/datasets/coco8.yaml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To train a YOLOv8n model on the COCO8 dataset for 100 epochs with an image size
    of 640, you can use the following code snippets. For a comprehensive list of available
    arguments, refer to the model Training page.
  prefs: []
  type: TYPE_NORMAL
- en: Train Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Sample Images and Annotations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are some examples of images from the COCO8 dataset, along with their corresponding
    annotations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dataset sample image](img/79acdef0dc35e95245c0ac9dc1854e7e.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Mosaiced Image**: This image demonstrates a training batch composed of mosaiced
    dataset images. Mosaicing is a technique used during training that combines multiple
    images into a single image to increase the variety of objects and scenes within
    each training batch. This helps improve the model''s ability to generalize to
    different object sizes, aspect ratios, and contexts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The example showcases the variety and complexity of the images in the COCO8
    dataset and the benefits of using mosaicing during the training process.
  prefs: []
  type: TYPE_NORMAL
- en: Citations and Acknowledgments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you use the COCO dataset in your research or development work, please cite
    the following paper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We would like to acknowledge the COCO Consortium for creating and maintaining
    this valuable resource for the computer vision community. For more information
    about the COCO dataset and its creators, visit the [COCO dataset website](https://cocodataset.org/#home).
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is the Ultralytics COCO8 dataset used for?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Ultralytics COCO8 dataset is a compact yet versatile object detection dataset
    consisting of the first 8 images from the COCO train 2017 set, with 4 images for
    training and 4 for validation. It is designed for testing and debugging object
    detection models and experimentation with new detection approaches. Despite its
    small size, COCO8 offers enough diversity to act as a sanity check for your training
    pipelines before deploying larger datasets. For more details, view the [COCO8
    dataset](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco8.yaml).
  prefs: []
  type: TYPE_NORMAL
- en: How do I train a YOLOv8 model using the COCO8 dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To train a YOLOv8 model using the COCO8 dataset, you can employ either Python
    or CLI commands. Here''s how you can start:'
  prefs: []
  type: TYPE_NORMAL
- en: Train Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: For a comprehensive list of available arguments, refer to the model Training
    page.
  prefs: []
  type: TYPE_NORMAL
- en: Why should I use Ultralytics HUB for managing my COCO8 training?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ultralytics HUB is an all-in-one web tool designed to simplify the training
    and deployment of YOLO models, including the Ultralytics YOLOv8 models on the
    COCO8 dataset. It offers cloud training, real-time tracking, and seamless dataset
    management. HUB allows you to start training with a single click and avoids the
    complexities of manual setups. Discover more about [Ultralytics HUB](https://hub.ultralytics.com)
    and its benefits.
  prefs: []
  type: TYPE_NORMAL
- en: What are the benefits of using mosaic augmentation in training with the COCO8
    dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Mosaic augmentation, demonstrated in the COCO8 dataset, combines multiple images
    into a single image during training. This technique increases the variety of objects
    and scenes in each training batch, improving the model's ability to generalize
    across different object sizes, aspect ratios, and contexts. This results in a
    more robust object detection model. For more details, refer to the training guide.
  prefs: []
  type: TYPE_NORMAL
- en: How can I validate my YOLOv8 model trained on the COCO8 dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Validation of your YOLOv8 model trained on the COCO8 dataset can be performed
    using the model's validation commands. You can invoke the validation mode via
    CLI or Python script to evaluate the model's performance using precise metrics.
    For detailed instructions, visit the Validation page.
  prefs: []
  type: TYPE_NORMAL
