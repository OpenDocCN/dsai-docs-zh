- en: Open Images V7 Dataset
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Open Images V7 数据集
- en: 原文：[`docs.ultralytics.com/datasets/detect/open-images-v7/`](https://docs.ultralytics.com/datasets/detect/open-images-v7/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/datasets/detect/open-images-v7/`](https://docs.ultralytics.com/datasets/detect/open-images-v7/)
- en: '[Open Images V7](https://storage.googleapis.com/openimages/web/index.html)
    is a versatile and expansive dataset championed by Google. Aimed at propelling
    research in the realm of computer vision, it boasts a vast collection of images
    annotated with a plethora of data, including image-level labels, object bounding
    boxes, object segmentation masks, visual relationships, and localized narratives.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[Open Images V7](https://storage.googleapis.com/openimages/web/index.html)
    是由 Google 领导的多功能且广阔的数据集。旨在推动计算机视觉领域的研究，它拥有大量图像，并用多种数据进行了注释，包括图像级标签、物体边界框、物体分割蒙版、视觉关系和本地化叙述。'
- en: '[`www.youtube.com/embed/u3pLlgzUeV8`](https://www.youtube.com/embed/u3pLlgzUeV8)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[`www.youtube.com/embed/u3pLlgzUeV8`](https://www.youtube.com/embed/u3pLlgzUeV8)'
- en: '**Watch:** Object Detection using OpenImagesV7 Pretrained Model'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**观看：** 使用 OpenImagesV7 预训练模型进行物体检测'
- en: Open Images V7 Pretrained Models
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Open Images V7 预训练模型
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '| 模型 | 大小 ^((像素)) | mAP ^(val 50-95) | 速度 ^(CPU ONNX'
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: (毫秒)) | 速度 ^(A100 TensorRT
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: (毫秒)) | 参数 ^((M)) | FLOPs ^((B)) |
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-oiv7.pt)
    | 640 | 18.4 | 142.4 | 1.21 | 3.5 | 10.5 |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-oiv7.pt)
    | 640 | 18.4 | 142.4 | 1.21 | 3.5 | 10.5 |'
- en: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-oiv7.pt)
    | 640 | 27.7 | 183.1 | 1.40 | 11.4 | 29.7 |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-oiv7.pt)
    | 640 | 27.7 | 183.1 | 1.40 | 11.4 | 29.7 |'
- en: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-oiv7.pt)
    | 640 | 33.6 | 408.5 | 2.26 | 26.2 | 80.6 |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-oiv7.pt)
    | 640 | 33.6 | 408.5 | 2.26 | 26.2 | 80.6 |'
- en: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-oiv7.pt)
    | 640 | 34.9 | 596.9 | 2.43 | 44.1 | 167.4 |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-oiv7.pt)
    | 640 | 34.9 | 596.9 | 2.43 | 44.1 | 167.4 |'
- en: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-oiv7.pt)
    | 640 | 36.3 | 860.6 | 3.56 | 68.7 | 260.6 |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-oiv7.pt)
    | 640 | 36.3 | 860.6 | 3.56 | 68.7 | 260.6 |'
- en: '![Open Images V7 classes visual](img/7c2d0288343fcb2bd8111441fe64b145.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![Open Images V7 类别可视化](img/7c2d0288343fcb2bd8111441fe64b145.png)'
- en: Key Features
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主要特征
- en: Encompasses ~9M images annotated in various ways to suit multiple computer vision
    tasks.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 涵盖了以多种方式注释的约900万张图像，以适应多种计算机视觉任务。
- en: Houses a staggering 16M bounding boxes across 600 object classes in 1.9M images.
    These boxes are primarily hand-drawn by experts ensuring high precision.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在190万张图像中，共有1600万个边界框跨越600个物体类别。这些框主要由专家手绘，确保高精度。
- en: Visual relationship annotations totaling 3.3M are available, detailing 1,466
    unique relationship triplets, object properties, and human activities.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了330万个可视关系注释，详细说明了1466个独特的关系三元组、物体属性和人类活动。
- en: V5 introduced segmentation masks for 2.8M objects across 350 classes.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: V5 引入了对350个类别中2.8M个物体的分割蒙版。
- en: V6 introduced 675k localized narratives that amalgamate voice, text, and mouse
    traces highlighting described objects.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: V6 引入了67.5万个本地化叙述，融合了语音、文本和鼠标轨迹，突出描述的物体。
- en: V7 introduced 66.4M point-level labels on 1.4M images, spanning 5,827 classes.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: V7 引入了在140万张图像上的6640万个点级标签，涵盖了5827个类别。
- en: Encompasses 61.4M image-level labels across a diverse set of 20,638 classes.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 涵盖了20638个类别中共6140万个图像级标签。
- en: Provides a unified platform for image classification, object detection, relationship
    detection, instance segmentation, and multimodal image descriptions.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了一个统一的平台，用于图像分类、物体检测、关系检测、实例分割和多模态图像描述。
- en: Dataset Structure
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集结构
- en: 'Open Images V7 is structured in multiple components catering to varied computer
    vision challenges:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Open Images V7 是一个由多个组件组成的结构，旨在满足多样化的计算机视觉挑战：
- en: '**Images**: About 9 million images, often showcasing intricate scenes with
    an average of 8.3 objects per image.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像**：约900万张图像，通常展示复杂场景，平均每张图像有8.3个物体。'
- en: '**Bounding Boxes**: Over 16 million boxes that demarcate objects across 600
    categories.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**边界框**：超过1600万个框，标示了跨越600个类别的物体。'
- en: '**Segmentation Masks**: These detail the exact boundary of 2.8M objects across
    350 classes.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分割蒙版**：详细描述了350个类别中2.8M个物体的确切边界。'
- en: '**Visual Relationships**: 3.3M annotations indicating object relationships,
    properties, and actions.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视觉关系**：3.3M 注释，指示对象关系、属性和动作。'
- en: '**Localized Narratives**: 675k descriptions combining voice, text, and mouse
    traces.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地化叙述**：675k 描述，结合语音、文本和鼠标轨迹。'
- en: '**Point-Level Labels**: 66.4M labels across 1.4M images, suitable for zero/few-shot
    semantic segmentation.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**点级标签**：66.4M 标签跨越 1.4M 图像，适用于零/少次语义分割。'
- en: Applications
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用
- en: Open Images V7 is a cornerstone for training and evaluating state-of-the-art
    models in various computer vision tasks. The dataset's broad scope and high-quality
    annotations make it indispensable for researchers and developers specializing
    in computer vision.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Open Images V7 是在各种计算机视觉任务中训练和评估最先进模型的基石。数据集的广泛范围和高质量的标注使其对专注于计算机视觉的研究人员和开发者不可或缺。
- en: Dataset YAML
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集 YAML
- en: Typically, datasets come with a YAML (Yet Another Markup Language) file that
    delineates the dataset's configuration. For the case of Open Images V7, a hypothetical
    `OpenImagesV7.yaml` might exist. For accurate paths and configurations, one should
    refer to the dataset's official repository or documentation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，数据集配备一个 YAML（Yet Another Markup Language）文件，该文件详细说明了数据集的配置。对于 Open Images
    V7 来说，可能存在一个假设的 `OpenImagesV7.yaml`。为了准确的路径和配置，应参考数据集的官方存储库或文档。
- en: OpenImagesV7.yaml
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: OpenImagesV7.yaml
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Usage
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用
- en: To train a YOLOv8n model on the Open Images V7 dataset for 100 epochs with an
    image size of 640, you can use the following code snippets. For a comprehensive
    list of available arguments, refer to the model Training page.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Open Images V7 数据集上用 YOLOv8n 模型进行 100 个 epoch 的训练，并且图像大小为 640，您可以使用以下代码片段。有关可用参数的详细列表，请参考模型训练页面。
- en: Warning
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: The complete Open Images V7 dataset comprises 1,743,042 training images and
    41,620 validation images, requiring approximately **561 GB of storage space**
    upon download.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的 Open Images V7 数据集包括 1,743,042 张训练图像和 41,620 张验证图像，下载后需要约 **561 GB 的存储空间**。
- en: 'Executing the commands provided below will trigger an automatic download of
    the full dataset if it''s not already present locally. Before running the below
    example it''s crucial to:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下提供的命令将自动下载完整数据集（如果本地尚未存在）。在运行以下示例之前，关键是：
- en: Verify that your device has enough storage capacity.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保您的设备有足够的存储空间。
- en: Ensure a robust and speedy internet connection.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保稳定且高速的互联网连接。
- en: Train Example
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 训练示例
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Sample Data and Annotations
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 样本数据和注释
- en: 'Illustrations of the dataset help provide insights into its richness:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的示例图可以帮助深入了解其丰富性：
- en: '![Dataset sample image](img/38cf6c99add645a565b3f5ed41237ab9.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![数据集示例图](img/38cf6c99add645a565b3f5ed41237ab9.png)'
- en: '**Open Images V7**: This image exemplifies the depth and detail of annotations
    available, including bounding boxes, relationships, and segmentation masks.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Open Images V7**：这幅图展示了可用的注释深度和细节，包括边界框、关系和分割掩模。'
- en: Researchers can gain invaluable insights into the array of computer vision challenges
    that the dataset addresses, from basic object detection to intricate relationship
    identification.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员可以从数据集解决的一系列计算机视觉挑战中获得宝贵的见解，从基本的物体检测到复杂的关系识别。
- en: Citations and Acknowledgments
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引用和致谢
- en: 'For those employing Open Images V7 in their work, it''s prudent to cite the
    relevant papers and acknowledge the creators:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些在工作中使用 Open Images V7 的人，引用相关论文并承认创建者是明智之举：
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: A heartfelt acknowledgment goes out to the Google AI team for creating and maintaining
    the Open Images V7 dataset. For a deep dive into the dataset and its offerings,
    navigate to the [official Open Images V7 website](https://storage.googleapis.com/openimages/web/index.html).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 由衷感谢谷歌 AI 团队创建和维护 Open Images V7 数据集。要深入了解数据集及其提供的内容，请访问[官方 Open Images V7 网站](https://storage.googleapis.com/openimages/web/index.html)。
- en: FAQ
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题
- en: What is the Open Images V7 dataset?
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Open Images V7 数据集是什么？
- en: Open Images V7 is an extensive and versatile dataset created by Google, designed
    to advance research in computer vision. It includes image-level labels, object
    bounding boxes, object segmentation masks, visual relationships, and localized
    narratives, making it ideal for various computer vision tasks such as object detection,
    segmentation, and relationship detection.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Open Images V7 是由谷歌创建的广泛而多功能的数据集，旨在推动计算机视觉研究。它包括图像级标签、物体边界框、物体分割掩模、视觉关系和本地化叙述，非常适合各种计算机视觉任务，如物体检测、分割和关系检测。
- en: How do I train a YOLOv8 model on the Open Images V7 dataset?
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我如何在 Open Images V7 数据集上训练 YOLOv8 模型？
- en: 'To train a YOLOv8 model on the Open Images V7 dataset, you can use both Python
    and CLI commands. Here''s an example of training the YOLOv8n model for 100 epochs
    with an image size of 640:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Open Images V7 数据集上训练 YOLOv8 模型，您可以使用 Python 和 CLI 命令。以下是使用图像尺寸为 640 训练 YOLOv8n
    模型 100 个 epochs 的示例：
- en: Train Example
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 训练示例
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: For more details on arguments and settings, refer to the Training page.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 关于参数和设置的更多详细信息，请参阅训练页面。
- en: What are some key features of the Open Images V7 dataset?
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Open Images V7 数据集的一些关键特性是什么？
- en: 'The Open Images V7 dataset includes approximately 9 million images with various
    annotations: - **Bounding Boxes**: 16 million bounding boxes across 600 object
    classes. - **Segmentation Masks**: Masks for 2.8 million objects across 350 classes.
    - **Visual Relationships**: 3.3 million annotations indicating relationships,
    properties, and actions. - **Localized Narratives**: 675,000 descriptions combining
    voice, text, and mouse traces. - **Point-Level Labels**: 66.4 million labels across
    1.4 million images. - **Image-Level Labels**: 61.4 million labels across 20,638
    classes.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Open Images V7 数据集包括大约 900 万张图像，具有各种注释：- **边界框**：跨越 600 个对象类别的 1600 万个边界框。-
    **分割蒙版**：涵盖 350 个类别的 280 万个对象的蒙版。- **视觉关系**：表示关系、属性和动作的 330 万个注释。- **本地化叙述**：结合语音、文本和鼠标轨迹的
    67.5 万个描述。- **点级标签**：跨 140 万个图像的 6640 万个标签。- **图像级标签**：跨 20,638 个类别的 6140 万个标签。
- en: What pretrained models are available for the Open Images V7 dataset?
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Open Images V7 数据集有哪些预训练模型可用？
- en: 'Ultralytics provides several YOLOv8 pretrained models for the Open Images V7
    dataset, each with different sizes and performance metrics:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics 为 Open Images V7 数据集提供了几个预训练的 YOLOv8 模型，每个模型具有不同的尺寸和性能指标：
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '| 模型 | 尺寸 ^((像素)) | mAP^(val 50-95) | 速度 ^(CPU ONNX'
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: (ms)) | 速度 ^(A100 TensorRT
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: (ms)) | 参数 ^((M)) | FLOPs ^((B)) |
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-oiv7.pt)
    | 640 | 18.4 | 142.4 | 1.21 | 3.5 | 10.5 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-oiv7.pt)
    | 640 | 18.4 | 142.4 | 1.21 | 3.5 | 10.5 |'
- en: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-oiv7.pt)
    | 640 | 27.7 | 183.1 | 1.40 | 11.4 | 29.7 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-oiv7.pt)
    | 640 | 27.7 | 183.1 | 1.40 | 11.4 | 29.7 |'
- en: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-oiv7.pt)
    | 640 | 33.6 | 408.5 | 2.26 | 26.2 | 80.6 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-oiv7.pt)
    | 640 | 33.6 | 408.5 | 2.26 | 26.2 | 80.6 |'
- en: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-oiv7.pt)
    | 640 | 34.9 | 596.9 | 2.43 | 44.1 | 167.4 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-oiv7.pt)
    | 640 | 34.9 | 596.9 | 2.43 | 44.1 | 167.4 |'
- en: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-oiv7.pt)
    | 640 | 36.3 | 860.6 | 3.56 | 68.7 | 260.6 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-oiv7.pt)
    | 640 | 36.3 | 860.6 | 3.56 | 68.7 | 260.6 |'
- en: What applications can the Open Images V7 dataset be used for?
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Open Images V7 数据集可以用于哪些应用？
- en: 'The Open Images V7 dataset supports a variety of computer vision tasks including:
    - **Image Classification** - **Object Detection** - **Instance Segmentation**
    - **Visual Relationship Detection** - **Multimodal Image Descriptions**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Open Images V7 数据集支持多种计算机视觉任务，包括：- **图像分类** - **目标检测** - **实例分割** - **视觉关系检测**
    - **多模态图像描述**
- en: Its comprehensive annotations and broad scope make it suitable for training
    and evaluating advanced machine learning models, as highlighted in practical use
    cases detailed in our applications section.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 其详尽的标注和广泛的范围使其适用于训练和评估先进的机器学习模型，如在我们的应用程序部分详细说明的实际用例中所强调的。
