["```py\nIn [1]: headers = {\"User-Agent\": \"pandas\"}\nIn [2]: df = pd.read_csv(\n ...:    \"https://download.bls.gov/pub/time.series/cu/cu.item\",\n ...:    sep=\"\\t\",\n ...:    storage_options=headers\n ...: ) \n```", "```py\nIn [1]: xml = \"\"\"<?xml version='1.0' encoding='utf-8'?>\n ...: <data>\n ...: <row>\n ...:    <shape>square</shape>\n ...:    <degrees>360</degrees>\n ...:    <sides>4.0</sides>\n ...: </row>\n ...: <row>\n ...:    <shape>circle</shape>\n ...:    <degrees>360</degrees>\n ...:    <sides/>\n ...: </row>\n ...: <row>\n ...:    <shape>triangle</shape>\n ...:    <degrees>180</degrees>\n ...:    <sides>3.0</sides>\n ...: </row>\n ...: </data>\"\"\"\n\nIn [2]: df = pd.read_xml(xml)\nIn [3]: df\nOut[3]:\n shape  degrees  sides\n0    square      360    4.0\n1    circle      360    NaN\n2  triangle      180    3.0\n\nIn [4]: df.to_xml()\nOut[4]:\n<?xml version='1.0' encoding='utf-8'?>\n<data>\n <row>\n <index>0</index>\n <shape>square</shape>\n <degrees>360</degrees>\n <sides>4.0</sides>\n </row>\n <row>\n <index>1</index>\n <shape>circle</shape>\n <degrees>360</degrees>\n <sides/>\n </row>\n <row>\n <index>2</index>\n <shape>triangle</shape>\n <degrees>180</degrees>\n <sides>3.0</sides>\n </row>\n</data> \n```", "```py\nIn [1]: arr = np.array([1, 2, 3])\n\nIn [2]: df = pd.DataFrame({\"A\": arr, \"B\": arr.copy()}, copy=False)\n\nIn [3]: df\nOut[3]: \n A  B\n0  1  1\n1  2  2\n2  3  3 \n```", "```py\nIn [4]: arr[0] = 0\n\nIn [5]: assert df.iloc[0, 0] == 0 \n```", "```py\nIn [6]: pd.Series(['abc', None, 'def'], dtype=pd.StringDtype(storage=\"pyarrow\"))\nOut[6]: \n0     abc\n1    <NA>\n2     def\ndtype: string \n```", "```py\nIn [7]: s = pd.Series(['abc', None, 'def'], dtype=\"string[pyarrow]\")\n\nIn [8]: s\nOut[8]: \n0     abc\n1    <NA>\n2     def\ndtype: string \n```", "```py\nIn [9]: with pd.option_context(\"string_storage\", \"pyarrow\"):\n ...:    s = pd.Series(['abc', None, 'def'], dtype=\"string\")\n ...: \n\nIn [10]: s\nOut[10]: \n0     abc\n1    <NA>\n2     def\ndtype: string \n```", "```py\nIn [11]: s.str.upper()\nOut[11]: \n0     ABC\n1    <NA>\n2     DEF\ndtype: string\n\nIn [12]: s.str.split('b', expand=True).dtypes\nOut[12]: \n0    string[pyarrow]\n1    string[pyarrow]\ndtype: object \n```", "```py\nIn [13]: s.str.count(\"a\")\nOut[13]: \n0       1\n1    <NA>\n2       0\ndtype: Int64 \n```", "```py\nIn [14]: df = pd.DataFrame(\n ....:    {\"A\": [0, 1, 2, 3, 4]}, index=pd.date_range(\"2020\", periods=5, freq=\"1D\")\n ....: )\n ....: \n\nIn [15]: df\nOut[15]: \n A\n2020-01-01  0\n2020-01-02  1\n2020-01-03  2\n2020-01-04  3\n2020-01-05  4\n\nIn [16]: df.rolling(\"2D\", center=True).mean()\nOut[16]: \n A\n2020-01-01  0.5\n2020-01-02  1.5\n2020-01-03  2.5\n2020-01-04  3.5\n2020-01-05  4.0 \n```", "```py\nIn [17]: dtype = pd.CategoricalDtype(['bad', 'neutral', 'good'], ordered=True)\n\nIn [18]: cat = pd.Categorical(['good', 'good', 'bad', 'bad'], dtype=dtype)\n\nIn [19]: original = pd.Series(cat)\n\nIn [20]: unique = original.unique() \n```", "```py\nIn [1]: unique\n['good', 'bad']\nCategories (2, object): ['bad' < 'good']\nIn [2]: original.dtype == unique.dtype\nFalse \n```", "```py\nIn [21]: unique\nOut[21]: \n['good', 'bad']\nCategories (3, object): ['bad' < 'neutral' < 'good']\n\nIn [22]: original.dtype == unique.dtype\nOut[22]: True \n```", "```py\nIn [23]: df1 = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [1, 2, 3]}, index=[0, 1, 2])\n\nIn [24]: df1\nOut[24]: \n A  B\n0  1  1\n1  2  2\n2  3  3\n\nIn [25]: df2 = pd.DataFrame({\"B\": [4, 5, 6], \"C\": [1, 2, 3]}, index=[2, 3, 4])\n\nIn [26]: df2\nOut[26]: \n B  C\n2  4  1\n3  5  2\n4  6  3\n\nIn [27]: combined = df1.combine_first(df2) \n```", "```py\nIn [1]: combined.dtypes\nOut[2]:\nA    float64\nB    float64\nC    float64\ndtype: object \n```", "```py\nIn [28]: combined.dtypes\nOut[28]: \nA    float64\nB      int64\nC    float64\ndtype: object \n```", "```py\nIn [29]: df = pd.DataFrame({'key': [1, 1], 'a': [True, False], 'b': [True, True]})\n\nIn [30]: df\nOut[30]: \n key      a     b\n0    1   True  True\n1    1  False  True \n```", "```py\nIn [5]: df.groupby('key').agg(lambda x: x.sum())\nOut[5]:\n a  b\nkey\n1    True  2 \n```", "```py\nIn [31]: df.groupby('key').agg(lambda x: x.sum())\nOut[31]: \n a  b\nkey \n1    1  2 \n```", "```py\nIn [32]: df = pd.DataFrame({'a': [True], 'b': [1], 'c': [1.0]}) \n```", "```py\nIn [5]: df.groupby(df.index).mean()\nOut[5]:\n a  b    c\n0    True  1  1.0 \n```", "```py\nIn [33]: df.groupby(df.index).mean()\nOut[33]: \n a    b    c\n0  1.0  1.0  1.0 \n```", "```py\nIn [34]: df = pd.DataFrame(range(3), columns=[\"A\"], dtype=\"float64\")\n\nIn [35]: values = df.values\n\nIn [36]: new = np.array([5, 6, 7], dtype=\"int64\")\n\nIn [37]: df.loc[[0, 1, 2], \"A\"] = new \n```", "```py\nIn [1]: df.dtypes\nOut[1]:\nA    int64\ndtype: object\nIn [2]: np.shares_memory(df[\"A\"].values, new)\nOut[2]: False\nIn [3]: np.shares_memory(df[\"A\"].values, values)\nOut[3]: False \n```", "```py\nIn [38]: df.dtypes\nOut[38]: \nA    float64\ndtype: object\n\nIn [39]: np.shares_memory(df[\"A\"], new)\nOut[39]: False\n\nIn [40]: np.shares_memory(df[\"A\"], values)\nOut[40]: True \n```", "```py\nIn [41]: df = pd.DataFrame(range(3), columns=[\"A\"], dtype=\"float64\")\n\nIn [42]: df[[\"A\"]] = 5 \n```", "```py\nIn [1]: df.dtypes\nOut[1]:\nA    float64 \n```", "```py\nIn [43]: df.dtypes\nOut[43]: \nA    int64\ndtype: object \n```", "```py\nIn [1]: orig = pd.Series([True, False])\n\nIn [2]: ser = orig.copy()\n\nIn [3]: ser.iloc[1] = np.nan\n\nIn [4]: ser2 = orig.copy()\n\nIn [5]: ser2.iloc[1] = 2.0 \n```", "```py\nIn [1]: ser\nOut [1]:\n0    1.0\n1    NaN\ndtype: float64\n\nIn [2]:ser2\nOut [2]:\n0    True\n1     2.0\ndtype: object \n```", "```py\nIn [1]: ser\nOut [1]:\n0    True\n1     NaN\ndtype: object\n\nIn [2]:ser2\nOut [2]:\n0    True\n1     2.0\ndtype: object \n```", "```py\nIn [44]: df = pd.DataFrame({\"A\": [1, 1, 2, 3], \"B\": [0, 1, 2, 3]})\n\nIn [45]: df\nOut[45]: \n A  B\n0  1  0\n1  1  1\n2  2  2\n3  3  3 \n```", "```py\nIn [1]: df.groupby(\"A\").rolling(2).sum()\nOut[1]:\n A    B\nA\n1 0  NaN  NaN\n1    2.0  1.0\n2 2  NaN  NaN\n3 3  NaN  NaN \n```", "```py\nIn [46]: df.groupby(\"A\").rolling(2).sum()\nOut[46]: \n B\nA \n1 0  NaN\n 1  1.0\n2 2  NaN\n3 3  NaN \n```", "```py\nIn [47]: s = pd.Series([7, 5, 5, 5])\n\nIn [48]: s.rolling(3).var()\nOut[48]: \n0         NaN\n1         NaN\n2    1.333333\n3    0.000000\ndtype: float64 \n```", "```py\nIn [49]: index = pd.MultiIndex.from_tuples([('idx1', 'idx2')], names=['label1', 'label2'])\n\nIn [50]: df = pd.DataFrame({'a': [1], 'b': [2]}, index=index)\n\nIn [51]: df\nOut[51]: \n a  b\nlabel1 label2 \nidx1   idx2    1  2 \n```", "```py\nIn [1]: df.groupby('label1').rolling(1).sum()\nOut[1]:\n a    b\nlabel1\nidx1    1.0  2.0 \n```", "```py\nIn [52]: df.groupby('label1').rolling(1).sum()\nOut[52]: \n a    b\nlabel1 label1 label2 \nidx1   idx1   idx2    1.0  2.0 \n```", "```py\nIn [53]: df = pd.DataFrame({\"A\": [1, 2, 3, 4], \"B\": pd.date_range(\"2016-01-01\", periods=4)})\n\nIn [54]: df\nOut[54]: \n A          B\n0  1 2016-01-01\n1  2 2016-01-02\n2  3 2016-01-03\n3  4 2016-01-04 \n```", "```py\nIn [3]: df.prod()\nOut[3]:\nOut[3]:\nA    24\ndtype: int64 \n```", "```py\nIn [4]: df.prod()\n...\nTypeError: 'DatetimeArray' does not implement reduction 'prod'\n\nIn [5]: df[[\"A\"]].prod()\nOut[5]:\nA    24\ndtype: int64 \n```", "```py\nIn [55]: df = pd.DataFrame({\"A\": [1, 2, 3, 4], \"B\": pd.date_range(\"2016-01-01\", periods=4)})\n\nIn [56]: gb = df.groupby([1, 1, 2, 2]) \n```", "```py\nIn [4]: gb.prod(numeric_only=False)\nOut[4]:\nA\n1   2\n2  12 \n```", "```py\nIn [5]: gb.prod(numeric_only=False)\n...\nTypeError: datetime64 type does not support prod operations\n\nIn [6]: gb[[\"A\"]].prod(numeric_only=False)\nOut[6]:\n A\n1   2\n2  12 \n```", "```py\nIn [1]: headers = {\"User-Agent\": \"pandas\"}\nIn [2]: df = pd.read_csv(\n ...:    \"https://download.bls.gov/pub/time.series/cu/cu.item\",\n ...:    sep=\"\\t\",\n ...:    storage_options=headers\n ...: ) \n```", "```py\nIn [1]: xml = \"\"\"<?xml version='1.0' encoding='utf-8'?>\n ...: <data>\n ...: <row>\n ...:    <shape>square</shape>\n ...:    <degrees>360</degrees>\n ...:    <sides>4.0</sides>\n ...: </row>\n ...: <row>\n ...:    <shape>circle</shape>\n ...:    <degrees>360</degrees>\n ...:    <sides/>\n ...: </row>\n ...: <row>\n ...:    <shape>triangle</shape>\n ...:    <degrees>180</degrees>\n ...:    <sides>3.0</sides>\n ...: </row>\n ...: </data>\"\"\"\n\nIn [2]: df = pd.read_xml(xml)\nIn [3]: df\nOut[3]:\n shape  degrees  sides\n0    square      360    4.0\n1    circle      360    NaN\n2  triangle      180    3.0\n\nIn [4]: df.to_xml()\nOut[4]:\n<?xml version='1.0' encoding='utf-8'?>\n<data>\n <row>\n <index>0</index>\n <shape>square</shape>\n <degrees>360</degrees>\n <sides>4.0</sides>\n </row>\n <row>\n <index>1</index>\n <shape>circle</shape>\n <degrees>360</degrees>\n <sides/>\n </row>\n <row>\n <index>2</index>\n <shape>triangle</shape>\n <degrees>180</degrees>\n <sides>3.0</sides>\n </row>\n</data> \n```", "```py\nIn [1]: arr = np.array([1, 2, 3])\n\nIn [2]: df = pd.DataFrame({\"A\": arr, \"B\": arr.copy()}, copy=False)\n\nIn [3]: df\nOut[3]: \n A  B\n0  1  1\n1  2  2\n2  3  3 \n```", "```py\nIn [4]: arr[0] = 0\n\nIn [5]: assert df.iloc[0, 0] == 0 \n```", "```py\nIn [6]: pd.Series(['abc', None, 'def'], dtype=pd.StringDtype(storage=\"pyarrow\"))\nOut[6]: \n0     abc\n1    <NA>\n2     def\ndtype: string \n```", "```py\nIn [7]: s = pd.Series(['abc', None, 'def'], dtype=\"string[pyarrow]\")\n\nIn [8]: s\nOut[8]: \n0     abc\n1    <NA>\n2     def\ndtype: string \n```", "```py\nIn [9]: with pd.option_context(\"string_storage\", \"pyarrow\"):\n ...:    s = pd.Series(['abc', None, 'def'], dtype=\"string\")\n ...: \n\nIn [10]: s\nOut[10]: \n0     abc\n1    <NA>\n2     def\ndtype: string \n```", "```py\nIn [11]: s.str.upper()\nOut[11]: \n0     ABC\n1    <NA>\n2     DEF\ndtype: string\n\nIn [12]: s.str.split('b', expand=True).dtypes\nOut[12]: \n0    string[pyarrow]\n1    string[pyarrow]\ndtype: object \n```", "```py\nIn [13]: s.str.count(\"a\")\nOut[13]: \n0       1\n1    <NA>\n2       0\ndtype: Int64 \n```", "```py\nIn [14]: df = pd.DataFrame(\n ....:    {\"A\": [0, 1, 2, 3, 4]}, index=pd.date_range(\"2020\", periods=5, freq=\"1D\")\n ....: )\n ....: \n\nIn [15]: df\nOut[15]: \n A\n2020-01-01  0\n2020-01-02  1\n2020-01-03  2\n2020-01-04  3\n2020-01-05  4\n\nIn [16]: df.rolling(\"2D\", center=True).mean()\nOut[16]: \n A\n2020-01-01  0.5\n2020-01-02  1.5\n2020-01-03  2.5\n2020-01-04  3.5\n2020-01-05  4.0 \n```", "```py\nIn [1]: headers = {\"User-Agent\": \"pandas\"}\nIn [2]: df = pd.read_csv(\n ...:    \"https://download.bls.gov/pub/time.series/cu/cu.item\",\n ...:    sep=\"\\t\",\n ...:    storage_options=headers\n ...: ) \n```", "```py\nIn [1]: xml = \"\"\"<?xml version='1.0' encoding='utf-8'?>\n ...: <data>\n ...: <row>\n ...:    <shape>square</shape>\n ...:    <degrees>360</degrees>\n ...:    <sides>4.0</sides>\n ...: </row>\n ...: <row>\n ...:    <shape>circle</shape>\n ...:    <degrees>360</degrees>\n ...:    <sides/>\n ...: </row>\n ...: <row>\n ...:    <shape>triangle</shape>\n ...:    <degrees>180</degrees>\n ...:    <sides>3.0</sides>\n ...: </row>\n ...: </data>\"\"\"\n\nIn [2]: df = pd.read_xml(xml)\nIn [3]: df\nOut[3]:\n shape  degrees  sides\n0    square      360    4.0\n1    circle      360    NaN\n2  triangle      180    3.0\n\nIn [4]: df.to_xml()\nOut[4]:\n<?xml version='1.0' encoding='utf-8'?>\n<data>\n <row>\n <index>0</index>\n <shape>square</shape>\n <degrees>360</degrees>\n <sides>4.0</sides>\n </row>\n <row>\n <index>1</index>\n <shape>circle</shape>\n <degrees>360</degrees>\n <sides/>\n </row>\n <row>\n <index>2</index>\n <shape>triangle</shape>\n <degrees>180</degrees>\n <sides>3.0</sides>\n </row>\n</data> \n```", "```py\nIn [1]: arr = np.array([1, 2, 3])\n\nIn [2]: df = pd.DataFrame({\"A\": arr, \"B\": arr.copy()}, copy=False)\n\nIn [3]: df\nOut[3]: \n A  B\n0  1  1\n1  2  2\n2  3  3 \n```", "```py\nIn [4]: arr[0] = 0\n\nIn [5]: assert df.iloc[0, 0] == 0 \n```", "```py\nIn [6]: pd.Series(['abc', None, 'def'], dtype=pd.StringDtype(storage=\"pyarrow\"))\nOut[6]: \n0     abc\n1    <NA>\n2     def\ndtype: string \n```", "```py\nIn [7]: s = pd.Series(['abc', None, 'def'], dtype=\"string[pyarrow]\")\n\nIn [8]: s\nOut[8]: \n0     abc\n1    <NA>\n2     def\ndtype: string \n```", "```py\nIn [9]: with pd.option_context(\"string_storage\", \"pyarrow\"):\n ...:    s = pd.Series(['abc', None, 'def'], dtype=\"string\")\n ...: \n\nIn [10]: s\nOut[10]: \n0     abc\n1    <NA>\n2     def\ndtype: string \n```", "```py\nIn [11]: s.str.upper()\nOut[11]: \n0     ABC\n1    <NA>\n2     DEF\ndtype: string\n\nIn [12]: s.str.split('b', expand=True).dtypes\nOut[12]: \n0    string[pyarrow]\n1    string[pyarrow]\ndtype: object \n```", "```py\nIn [13]: s.str.count(\"a\")\nOut[13]: \n0       1\n1    <NA>\n2       0\ndtype: Int64 \n```", "```py\nIn [14]: df = pd.DataFrame(\n ....:    {\"A\": [0, 1, 2, 3, 4]}, index=pd.date_range(\"2020\", periods=5, freq=\"1D\")\n ....: )\n ....: \n\nIn [15]: df\nOut[15]: \n A\n2020-01-01  0\n2020-01-02  1\n2020-01-03  2\n2020-01-04  3\n2020-01-05  4\n\nIn [16]: df.rolling(\"2D\", center=True).mean()\nOut[16]: \n A\n2020-01-01  0.5\n2020-01-02  1.5\n2020-01-03  2.5\n2020-01-04  3.5\n2020-01-05  4.0 \n```", "```py\nIn [17]: dtype = pd.CategoricalDtype(['bad', 'neutral', 'good'], ordered=True)\n\nIn [18]: cat = pd.Categorical(['good', 'good', 'bad', 'bad'], dtype=dtype)\n\nIn [19]: original = pd.Series(cat)\n\nIn [20]: unique = original.unique() \n```", "```py\nIn [1]: unique\n['good', 'bad']\nCategories (2, object): ['bad' < 'good']\nIn [2]: original.dtype == unique.dtype\nFalse \n```", "```py\nIn [21]: unique\nOut[21]: \n['good', 'bad']\nCategories (3, object): ['bad' < 'neutral' < 'good']\n\nIn [22]: original.dtype == unique.dtype\nOut[22]: True \n```", "```py\nIn [23]: df1 = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [1, 2, 3]}, index=[0, 1, 2])\n\nIn [24]: df1\nOut[24]: \n A  B\n0  1  1\n1  2  2\n2  3  3\n\nIn [25]: df2 = pd.DataFrame({\"B\": [4, 5, 6], \"C\": [1, 2, 3]}, index=[2, 3, 4])\n\nIn [26]: df2\nOut[26]: \n B  C\n2  4  1\n3  5  2\n4  6  3\n\nIn [27]: combined = df1.combine_first(df2) \n```", "```py\nIn [1]: combined.dtypes\nOut[2]:\nA    float64\nB    float64\nC    float64\ndtype: object \n```", "```py\nIn [28]: combined.dtypes\nOut[28]: \nA    float64\nB      int64\nC    float64\ndtype: object \n```", "```py\nIn [29]: df = pd.DataFrame({'key': [1, 1], 'a': [True, False], 'b': [True, True]})\n\nIn [30]: df\nOut[30]: \n key      a     b\n0    1   True  True\n1    1  False  True \n```", "```py\nIn [5]: df.groupby('key').agg(lambda x: x.sum())\nOut[5]:\n a  b\nkey\n1    True  2 \n```", "```py\nIn [31]: df.groupby('key').agg(lambda x: x.sum())\nOut[31]: \n a  b\nkey \n1    1  2 \n```", "```py\nIn [32]: df = pd.DataFrame({'a': [True], 'b': [1], 'c': [1.0]}) \n```", "```py\nIn [5]: df.groupby(df.index).mean()\nOut[5]:\n a  b    c\n0    True  1  1.0 \n```", "```py\nIn [33]: df.groupby(df.index).mean()\nOut[33]: \n a    b    c\n0  1.0  1.0  1.0 \n```", "```py\nIn [34]: df = pd.DataFrame(range(3), columns=[\"A\"], dtype=\"float64\")\n\nIn [35]: values = df.values\n\nIn [36]: new = np.array([5, 6, 7], dtype=\"int64\")\n\nIn [37]: df.loc[[0, 1, 2], \"A\"] = new \n```", "```py\nIn [1]: df.dtypes\nOut[1]:\nA    int64\ndtype: object\nIn [2]: np.shares_memory(df[\"A\"].values, new)\nOut[2]: False\nIn [3]: np.shares_memory(df[\"A\"].values, values)\nOut[3]: False \n```", "```py\nIn [38]: df.dtypes\nOut[38]: \nA    float64\ndtype: object\n\nIn [39]: np.shares_memory(df[\"A\"], new)\nOut[39]: False\n\nIn [40]: np.shares_memory(df[\"A\"], values)\nOut[40]: True \n```", "```py\nIn [41]: df = pd.DataFrame(range(3), columns=[\"A\"], dtype=\"float64\")\n\nIn [42]: df[[\"A\"]] = 5 \n```", "```py\nIn [1]: df.dtypes\nOut[1]:\nA    float64 \n```", "```py\nIn [43]: df.dtypes\nOut[43]: \nA    int64\ndtype: object \n```", "```py\nIn [1]: orig = pd.Series([True, False])\n\nIn [2]: ser = orig.copy()\n\nIn [3]: ser.iloc[1] = np.nan\n\nIn [4]: ser2 = orig.copy()\n\nIn [5]: ser2.iloc[1] = 2.0 \n```", "```py\nIn [1]: ser\nOut [1]:\n0    1.0\n1    NaN\ndtype: float64\n\nIn [2]:ser2\nOut [2]:\n0    True\n1     2.0\ndtype: object \n```", "```py\nIn [1]: ser\nOut [1]:\n0    True\n1     NaN\ndtype: object\n\nIn [2]:ser2\nOut [2]:\n0    True\n1     2.0\ndtype: object \n```", "```py\nIn [44]: df = pd.DataFrame({\"A\": [1, 1, 2, 3], \"B\": [0, 1, 2, 3]})\n\nIn [45]: df\nOut[45]: \n A  B\n0  1  0\n1  1  1\n2  2  2\n3  3  3 \n```", "```py\nIn [1]: df.groupby(\"A\").rolling(2).sum()\nOut[1]:\n A    B\nA\n1 0  NaN  NaN\n1    2.0  1.0\n2 2  NaN  NaN\n3 3  NaN  NaN \n```", "```py\nIn [46]: df.groupby(\"A\").rolling(2).sum()\nOut[46]: \n B\nA \n1 0  NaN\n 1  1.0\n2 2  NaN\n3 3  NaN \n```", "```py\nIn [47]: s = pd.Series([7, 5, 5, 5])\n\nIn [48]: s.rolling(3).var()\nOut[48]: \n0         NaN\n1         NaN\n2    1.333333\n3    0.000000\ndtype: float64 \n```", "```py\nIn [49]: index = pd.MultiIndex.from_tuples([('idx1', 'idx2')], names=['label1', 'label2'])\n\nIn [50]: df = pd.DataFrame({'a': [1], 'b': [2]}, index=index)\n\nIn [51]: df\nOut[51]: \n a  b\nlabel1 label2 \nidx1   idx2    1  2 \n```", "```py\nIn [1]: df.groupby('label1').rolling(1).sum()\nOut[1]:\n a    b\nlabel1\nidx1    1.0  2.0 \n```", "```py\nIn [52]: df.groupby('label1').rolling(1).sum()\nOut[52]: \n a    b\nlabel1 label1 label2 \nidx1   idx1   idx2    1.0  2.0 \n```", "```py\nIn [17]: dtype = pd.CategoricalDtype(['bad', 'neutral', 'good'], ordered=True)\n\nIn [18]: cat = pd.Categorical(['good', 'good', 'bad', 'bad'], dtype=dtype)\n\nIn [19]: original = pd.Series(cat)\n\nIn [20]: unique = original.unique() \n```", "```py\nIn [1]: unique\n['good', 'bad']\nCategories (2, object): ['bad' < 'good']\nIn [2]: original.dtype == unique.dtype\nFalse \n```", "```py\nIn [21]: unique\nOut[21]: \n['good', 'bad']\nCategories (3, object): ['bad' < 'neutral' < 'good']\n\nIn [22]: original.dtype == unique.dtype\nOut[22]: True \n```", "```py\nIn [23]: df1 = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [1, 2, 3]}, index=[0, 1, 2])\n\nIn [24]: df1\nOut[24]: \n A  B\n0  1  1\n1  2  2\n2  3  3\n\nIn [25]: df2 = pd.DataFrame({\"B\": [4, 5, 6], \"C\": [1, 2, 3]}, index=[2, 3, 4])\n\nIn [26]: df2\nOut[26]: \n B  C\n2  4  1\n3  5  2\n4  6  3\n\nIn [27]: combined = df1.combine_first(df2) \n```", "```py\nIn [1]: combined.dtypes\nOut[2]:\nA    float64\nB    float64\nC    float64\ndtype: object \n```", "```py\nIn [28]: combined.dtypes\nOut[28]: \nA    float64\nB      int64\nC    float64\ndtype: object \n```", "```py\nIn [29]: df = pd.DataFrame({'key': [1, 1], 'a': [True, False], 'b': [True, True]})\n\nIn [30]: df\nOut[30]: \n key      a     b\n0    1   True  True\n1    1  False  True \n```", "```py\nIn [5]: df.groupby('key').agg(lambda x: x.sum())\nOut[5]:\n a  b\nkey\n1    True  2 \n```", "```py\nIn [31]: df.groupby('key').agg(lambda x: x.sum())\nOut[31]: \n a  b\nkey \n1    1  2 \n```", "```py\nIn [32]: df = pd.DataFrame({'a': [True], 'b': [1], 'c': [1.0]}) \n```", "```py\nIn [5]: df.groupby(df.index).mean()\nOut[5]:\n a  b    c\n0    True  1  1.0 \n```", "```py\nIn [33]: df.groupby(df.index).mean()\nOut[33]: \n a    b    c\n0  1.0  1.0  1.0 \n```", "```py\nIn [34]: df = pd.DataFrame(range(3), columns=[\"A\"], dtype=\"float64\")\n\nIn [35]: values = df.values\n\nIn [36]: new = np.array([5, 6, 7], dtype=\"int64\")\n\nIn [37]: df.loc[[0, 1, 2], \"A\"] = new \n```", "```py\nIn [1]: df.dtypes\nOut[1]:\nA    int64\ndtype: object\nIn [2]: np.shares_memory(df[\"A\"].values, new)\nOut[2]: False\nIn [3]: np.shares_memory(df[\"A\"].values, values)\nOut[3]: False \n```", "```py\nIn [38]: df.dtypes\nOut[38]: \nA    float64\ndtype: object\n\nIn [39]: np.shares_memory(df[\"A\"], new)\nOut[39]: False\n\nIn [40]: np.shares_memory(df[\"A\"], values)\nOut[40]: True \n```", "```py\nIn [41]: df = pd.DataFrame(range(3), columns=[\"A\"], dtype=\"float64\")\n\nIn [42]: df[[\"A\"]] = 5 \n```", "```py\nIn [1]: df.dtypes\nOut[1]:\nA    float64 \n```", "```py\nIn [43]: df.dtypes\nOut[43]: \nA    int64\ndtype: object \n```", "```py\nIn [1]: orig = pd.Series([True, False])\n\nIn [2]: ser = orig.copy()\n\nIn [3]: ser.iloc[1] = np.nan\n\nIn [4]: ser2 = orig.copy()\n\nIn [5]: ser2.iloc[1] = 2.0 \n```", "```py\nIn [1]: ser\nOut [1]:\n0    1.0\n1    NaN\ndtype: float64\n\nIn [2]:ser2\nOut [2]:\n0    True\n1     2.0\ndtype: object \n```", "```py\nIn [1]: ser\nOut [1]:\n0    True\n1     NaN\ndtype: object\n\nIn [2]:ser2\nOut [2]:\n0    True\n1     2.0\ndtype: object \n```", "```py\nIn [44]: df = pd.DataFrame({\"A\": [1, 1, 2, 3], \"B\": [0, 1, 2, 3]})\n\nIn [45]: df\nOut[45]: \n A  B\n0  1  0\n1  1  1\n2  2  2\n3  3  3 \n```", "```py\nIn [1]: df.groupby(\"A\").rolling(2).sum()\nOut[1]:\n A    B\nA\n1 0  NaN  NaN\n1    2.0  1.0\n2 2  NaN  NaN\n3 3  NaN  NaN \n```", "```py\nIn [46]: df.groupby(\"A\").rolling(2).sum()\nOut[46]: \n B\nA \n1 0  NaN\n 1  1.0\n2 2  NaN\n3 3  NaN \n```", "```py\nIn [47]: s = pd.Series([7, 5, 5, 5])\n\nIn [48]: s.rolling(3).var()\nOut[48]: \n0         NaN\n1         NaN\n2    1.333333\n3    0.000000\ndtype: float64 \n```", "```py\nIn [49]: index = pd.MultiIndex.from_tuples([('idx1', 'idx2')], names=['label1', 'label2'])\n\nIn [50]: df = pd.DataFrame({'a': [1], 'b': [2]}, index=index)\n\nIn [51]: df\nOut[51]: \n a  b\nlabel1 label2 \nidx1   idx2    1  2 \n```", "```py\nIn [1]: df.groupby('label1').rolling(1).sum()\nOut[1]:\n a    b\nlabel1\nidx1    1.0  2.0 \n```", "```py\nIn [52]: df.groupby('label1').rolling(1).sum()\nOut[52]: \n a    b\nlabel1 label1 label2 \nidx1   idx1   idx2    1.0  2.0 \n```", "```py\nIn [53]: df = pd.DataFrame({\"A\": [1, 2, 3, 4], \"B\": pd.date_range(\"2016-01-01\", periods=4)})\n\nIn [54]: df\nOut[54]: \n A          B\n0  1 2016-01-01\n1  2 2016-01-02\n2  3 2016-01-03\n3  4 2016-01-04 \n```", "```py\nIn [3]: df.prod()\nOut[3]:\nOut[3]:\nA    24\ndtype: int64 \n```", "```py\nIn [4]: df.prod()\n...\nTypeError: 'DatetimeArray' does not implement reduction 'prod'\n\nIn [5]: df[[\"A\"]].prod()\nOut[5]:\nA    24\ndtype: int64 \n```", "```py\nIn [55]: df = pd.DataFrame({\"A\": [1, 2, 3, 4], \"B\": pd.date_range(\"2016-01-01\", periods=4)})\n\nIn [56]: gb = df.groupby([1, 1, 2, 2]) \n```", "```py\nIn [4]: gb.prod(numeric_only=False)\nOut[4]:\nA\n1   2\n2  12 \n```", "```py\nIn [5]: gb.prod(numeric_only=False)\n...\nTypeError: datetime64 type does not support prod operations\n\nIn [6]: gb[[\"A\"]].prod(numeric_only=False)\nOut[6]:\n A\n1   2\n2  12 \n```", "```py\nIn [53]: df = pd.DataFrame({\"A\": [1, 2, 3, 4], \"B\": pd.date_range(\"2016-01-01\", periods=4)})\n\nIn [54]: df\nOut[54]: \n A          B\n0  1 2016-01-01\n1  2 2016-01-02\n2  3 2016-01-03\n3  4 2016-01-04 \n```", "```py\nIn [3]: df.prod()\nOut[3]:\nOut[3]:\nA    24\ndtype: int64 \n```", "```py\nIn [4]: df.prod()\n...\nTypeError: 'DatetimeArray' does not implement reduction 'prod'\n\nIn [5]: df[[\"A\"]].prod()\nOut[5]:\nA    24\ndtype: int64 \n```", "```py\nIn [55]: df = pd.DataFrame({\"A\": [1, 2, 3, 4], \"B\": pd.date_range(\"2016-01-01\", periods=4)})\n\nIn [56]: gb = df.groupby([1, 1, 2, 2]) \n```", "```py\nIn [4]: gb.prod(numeric_only=False)\nOut[4]:\nA\n1   2\n2  12 \n```", "```py\nIn [5]: gb.prod(numeric_only=False)\n...\nTypeError: datetime64 type does not support prod operations\n\nIn [6]: gb[[\"A\"]].prod(numeric_only=False)\nOut[6]:\n A\n1   2\n2  12 \n```"]