- en: Understanding YOLOv8's Deployment Options
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 YOLOv8 的部署选项
- en: 原文：[`docs.ultralytics.com/guides/model-deployment-options/`](https://docs.ultralytics.com/guides/model-deployment-options/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/guides/model-deployment-options/`](https://docs.ultralytics.com/guides/model-deployment-options/)
- en: Introduction
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: 'You''ve come a long way on your journey with YOLOv8\. You''ve diligently collected
    data, meticulously annotated it, and put in the hours to train and rigorously
    evaluate your custom YOLOv8 model. Now, it''s time to put your model to work for
    your specific application, use case, or project. But there''s a critical decision
    that stands before you: how to export and deploy your model effectively.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的 YOLOv8 之旅中走过了很长的一段路。您勤奋地收集数据，细致地标注它，并花费时间训练和严格评估您的定制 YOLOv8 模型。现在，是时候将您的模型应用于您特定的应用、用例或项目了。但在您面前有一个关键决策：如何有效地导出和部署您的模型。
- en: This guide walks you through YOLOv8's deployment options and the essential factors
    to consider to choose the right option for your project.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将带您了解 YOLOv8 的部署选项以及选择适合您项目的正确选项所需考虑的关键因素。
- en: How to Select the Right Deployment Option for Your YOLOv8 Model
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何为您的 YOLOv8 模型选择合适的部署选项
- en: When it's time to deploy your YOLOv8 model, selecting a suitable export format
    is very important. As outlined in the Ultralytics YOLOv8 Modes documentation,
    the model.export() function allows for converting your trained model into a variety
    of formats tailored to diverse environments and performance requirements.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要部署您的 YOLOv8 模型时，选择合适的导出格式非常重要。如 Ultralytics YOLOv8 Modes 文档中所述，model.export()
    函数可将训练好的模型转换为多种格式，以满足不同环境和性能要求。
- en: The ideal format depends on your model's intended operational context, balancing
    speed, hardware constraints, and ease of integration. In the following section,
    we'll take a closer look at each export option, understanding when to choose each
    one.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 理想的格式取决于您模型的预期操作环境，平衡速度、硬件限制和集成的便利性。在接下来的部分中，我们将详细查看每个导出选项，了解何时选择每个选项。
- en: YOLOv8's Deployment Options
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: YOLOv8 的部署选项
- en: Let's walk through the different YOLOv8 deployment options. For a detailed walkthrough
    of the export process, visit the Ultralytics documentation page on exporting.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细了解不同的 YOLOv8 部署选项。有关导出过程的详细步骤，请访问 Ultralytics 的导出文档页面。
- en: PyTorch
  id: totrans-10
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: PyTorch
- en: PyTorch is an open-source machine learning library widely used for applications
    in deep learning and artificial intelligence. It provides a high level of flexibility
    and speed, which has made it a favorite among researchers and developers.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 是一个广泛用于深度学习和人工智能应用的开源机器学习库。它提供了高度的灵活性和速度，使其成为研究人员和开发人员喜爱的选择。
- en: '**Performance Benchmarks**: PyTorch is known for its ease of use and flexibility,
    which may result in a slight trade-off in raw performance when compared to other
    frameworks that are more specialized and optimized.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准**：PyTorch 因其易用性和灵活性而闻名，与其他更专业和优化的框架相比，可能会稍微牺牲一些原始性能。'
- en: '**Compatibility and Integration**: Offers excellent compatibility with various
    data science and machine learning libraries in Python.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：与 Python 中各种数据科学和机器学习库具有良好的兼容性。'
- en: '**Community Support and Ecosystem**: One of the most vibrant communities, with
    extensive resources for learning and troubleshooting.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：拥有最活跃的社区之一，提供丰富的学习和故障排除资源。'
- en: '**Case Studies**: Commonly used in research prototypes, many academic papers
    reference models deployed in PyTorch.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：在研究原型中常用，许多学术论文引用在 PyTorch 中部署的模型。'
- en: '**Maintenance and Updates**: Regular updates with active development and support
    for new features.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：定期更新，积极开发并支持新功能。'
- en: '**Security Considerations**: Regular patches for security issues, but security
    is largely dependent on the overall environment it''s deployed in.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性考虑**：定期修补安全问题，但安全性在很大程度上取决于部署环境的整体情况。'
- en: '**Hardware Acceleration**: Supports CUDA for GPU acceleration, essential for
    speeding up model training and inference.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：支持 CUDA 进行 GPU 加速，对于加速模型训练和推断至关重要。'
- en: TorchScript
  id: totrans-19
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: TorchScript
- en: TorchScript extends PyTorch's capabilities by allowing the exportation of models
    to be run in a C++ runtime environment. This makes it suitable for production
    environments where Python is unavailable.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: TorchScript 通过允许将模型导出到 C++ 运行时环境来扩展 PyTorch 的能力。这使其适用于 Python 不可用的生产环境。
- en: '**Performance Benchmarks**: Can offer improved performance over native PyTorch,
    especially in production environments.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准测试**：在生产环境中，可以比原生PyTorch提供更好的性能。'
- en: '**Compatibility and Integration**: Designed for seamless transition from PyTorch
    to C++ production environments, though some advanced features might not translate
    perfectly.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：设计用于从PyTorch无缝过渡到C++生产环境，尽管一些高级功能可能无法完美转换。'
- en: '**Community Support and Ecosystem**: Benefits from PyTorch''s large community
    but has a narrower scope of specialized developers.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：受益于PyTorch庞大的社区，但专业开发者范围较窄。'
- en: '**Case Studies**: Widely used in industry settings where Python''s performance
    overhead is a bottleneck.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：广泛用于产业设置中，Python的性能开销是一个瓶颈。'
- en: '**Maintenance and Updates**: Maintained alongside PyTorch with consistent updates.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：与PyTorch并行维护，并保持持续更新。'
- en: '**Security Considerations**: Offers improved security by enabling the running
    of models in environments without full Python installations.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：通过允许在没有完整Python安装的环境中运行模型，提供了改进的安全性。'
- en: '**Hardware Acceleration**: Inherits PyTorch''s CUDA support, ensuring efficient
    GPU utilization.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：继承了PyTorch的CUDA支持，确保了有效的GPU利用率。'
- en: ONNX
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ONNX
- en: The Open Neural Network Exchange (ONNX) is a format that allows for model interoperability
    across different frameworks, which can be critical when deploying to various platforms.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 开放神经网络交换（ONNX）是一种允许模型在不同框架之间互操作的格式，在部署到各种平台时尤为关键。
- en: '**Performance Benchmarks**: ONNX models may experience a variable performance
    depending on the specific runtime they are deployed on.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准测试**：ONNX模型在特定运行时上的性能可能有所不同。'
- en: '**Compatibility and Integration**: High interoperability across multiple platforms
    and hardware due to its framework-agnostic nature.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：由于其与框架无关的特性，高度支持多平台和硬件的互操作性。'
- en: '**Community Support and Ecosystem**: Supported by many organizations, leading
    to a broad ecosystem and a variety of tools for optimization.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：得到许多组织的支持，导致一个广泛的生态系统，并提供多种优化工具。'
- en: '**Case Studies**: Frequently used to move models between different machine
    learning frameworks, demonstrating its flexibility.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：经常用于在不同机器学习框架之间转移模型，展示了其灵活性。'
- en: '**Maintenance and Updates**: As an open standard, ONNX is regularly updated
    to support new operations and models.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：作为一个开放标准，ONNX定期更新以支持新的操作和模型。'
- en: '**Security Considerations**: As with any cross-platform tool, it''s essential
    to ensure secure practices in the conversion and deployment pipeline.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：与任何跨平台工具一样，确保在转换和部署流程中采用安全实践至关重要。'
- en: '**Hardware Acceleration**: With ONNX Runtime, models can leverage various hardware
    optimizations.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：使用ONNX Runtime，模型可以利用各种硬件优化。'
- en: OpenVINO
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: OpenVINO
- en: OpenVINO is an Intel toolkit designed to facilitate the deployment of deep learning
    models across Intel hardware, enhancing performance and speed.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: OpenVINO是Intel工具包，旨在促进在Intel硬件上部署深度学习模型，提升性能和速度。
- en: '**Performance Benchmarks**: Specifically optimized for Intel CPUs, GPUs, and
    VPUs, offering significant performance boosts on compatible hardware.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准测试**：专为Intel CPU、GPU和VPU优化，可在兼容硬件上显著提升性能。'
- en: '**Compatibility and Integration**: Works best within the Intel ecosystem but
    also supports a range of other platforms.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：在Intel生态系统内表现最佳，但也支持一系列其他平台。'
- en: '**Community Support and Ecosystem**: Backed by Intel, with a solid user base
    especially in the computer vision domain.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：由Intel支持，尤其在计算机视觉领域拥有坚实的用户群体。'
- en: '**Case Studies**: Often utilized in IoT and edge computing scenarios where
    Intel hardware is prevalent.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：通常在物联网和边缘计算场景中使用，其中Intel硬件占据主导地位。'
- en: '**Maintenance and Updates**: Intel regularly updates OpenVINO to support the
    latest deep learning models and Intel hardware.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：Intel定期更新OpenVINO，以支持最新的深度学习模型和Intel硬件。'
- en: '**Security Considerations**: Provides robust security features suitable for
    deployment in sensitive applications.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：提供强大的安全功能，适合在敏感应用中部署。'
- en: '**Hardware Acceleration**: Tailored for acceleration on Intel hardware, leveraging
    dedicated instruction sets and hardware features.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：专为在Intel硬件上加速而设计，利用专门的指令集和硬件功能。'
- en: 'For more details on deployment using OpenVINO, refer to the Ultralytics Integration
    documentation: Intel OpenVINO Export.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '若要了解更多关于使用OpenVINO进行部署的详细信息，请参阅Ultralytics Integration documentation: Intel
    OpenVINO Export。'
- en: TensorRT
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: TensorRT
- en: TensorRT is a high-performance deep learning inference optimizer and runtime
    from NVIDIA, ideal for applications needing speed and efficiency.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: TensorRT是NVIDIA提供的高性能深度学习推理优化器和运行时，非常适合需要速度和效率的应用。
- en: '**Performance Benchmarks**: Delivers top-tier performance on NVIDIA GPUs with
    support for high-speed inference.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准测试**：在NVIDIA GPU上提供顶级性能，支持高速推理。'
- en: '**Compatibility and Integration**: Best suited for NVIDIA hardware, with limited
    support outside this environment.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：最适合NVIDIA硬件，对于这个环境之外的支持有限。'
- en: '**Community Support and Ecosystem**: Strong support network through NVIDIA''s
    developer forums and documentation.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：通过NVIDIA的开发者论坛和文档提供强大的支持网络。'
- en: '**Case Studies**: Widely adopted in industries requiring real-time inference
    on video and image data.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：在需要对视频和图像数据进行实时推理的行业中广泛采用。'
- en: '**Maintenance and Updates**: NVIDIA maintains TensorRT with frequent updates
    to enhance performance and support new GPU architectures.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：NVIDIA定期维护TensorRT，以增强性能并支持新的GPU架构。'
- en: '**Security Considerations**: Like many NVIDIA products, it has a strong emphasis
    on security, but specifics depend on the deployment environment.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：像许多NVIDIA产品一样，它非常重视安全性，但具体情况取决于部署环境。'
- en: '**Hardware Acceleration**: Exclusively designed for NVIDIA GPUs, providing
    deep optimization and acceleration.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：专为NVIDIA GPU设计，提供深度优化和加速。'
- en: CoreML
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: CoreML
- en: CoreML is Apple's machine learning framework, optimized for on-device performance
    in the Apple ecosystem, including iOS, macOS, watchOS, and tvOS.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: CoreML是苹果的机器学习框架，专为iOS、macOS、watchOS和tvOS等Apple生态系统的设备性能优化。
- en: '**Performance Benchmarks**: Optimized for on-device performance on Apple hardware
    with minimal battery usage.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准测试**：在Apple硬件上优化设备性能，电池使用率最小化。'
- en: '**Compatibility and Integration**: Exclusively for Apple''s ecosystem, providing
    a streamlined workflow for iOS and macOS applications.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：专为Apple生态系统设计，为iOS和macOS应用提供流畅的工作流程。'
- en: '**Community Support and Ecosystem**: Strong support from Apple and a dedicated
    developer community, with extensive documentation and tools.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：得到Apple和专门开发者社区的大力支持，具备广泛的文档和工具。'
- en: '**Case Studies**: Commonly used in applications that require on-device machine
    learning capabilities on Apple products.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：在需要Apple产品上设备内机器学习能力的应用中广泛使用。'
- en: '**Maintenance and Updates**: Regularly updated by Apple to support the latest
    machine learning advancements and Apple hardware.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：由Apple定期更新，以支持最新的机器学习进展和Apple硬件。'
- en: '**Security Considerations**: Benefits from Apple''s focus on user privacy and
    data security.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：受益于Apple对用户隐私和数据安全的关注。'
- en: '**Hardware Acceleration**: Takes full advantage of Apple''s neural engine and
    GPU for accelerated machine learning tasks.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：充分利用Apple的神经引擎和GPU，加速机器学习任务。'
- en: TF SavedModel
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: TF SavedModel
- en: TF SavedModel is TensorFlow's format for saving and serving machine learning
    models, particularly suited for scalable server environments.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: TF SavedModel是TensorFlow用于保存和提供机器学习模型的格式，特别适用于可扩展的服务器环境。
- en: '**Performance Benchmarks**: Offers scalable performance in server environments,
    especially when used with TensorFlow Serving.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准测试**：在服务器环境中提供可扩展的性能，特别是与TensorFlow Serving一起使用时。'
- en: '**Compatibility and Integration**: Wide compatibility across TensorFlow''s
    ecosystem, including cloud and enterprise server deployments.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：在TensorFlow生态系统内具有广泛的兼容性，包括云和企业服务器部署。'
- en: '**Community Support and Ecosystem**: Large community support due to TensorFlow''s
    popularity, with a vast array of tools for deployment and optimization.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：由于TensorFlow的流行，拥有庞大的社区支持，提供大量用于部署和优化的工具。'
- en: '**Case Studies**: Extensively used in production environments for serving deep
    learning models at scale.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：在生产环境中广泛应用，用于大规模提供深度学习模型。'
- en: '**Maintenance and Updates**: Supported by Google and the TensorFlow community,
    ensuring regular updates and new features.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：由Google和TensorFlow社区支持，确保定期更新和新功能。'
- en: '**Security Considerations**: Deployment using TensorFlow Serving includes robust
    security features for enterprise-grade applications.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：使用TensorFlow Serving部署时，包含了面向企业级应用的强大安全功能。'
- en: '**Hardware Acceleration**: Supports various hardware accelerations through
    TensorFlow''s backends.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：通过TensorFlow后端支持各种硬件加速。'
- en: TF GraphDef
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: TF GraphDef
- en: TF GraphDef is a TensorFlow format that represents the model as a graph, which
    is beneficial for environments where a static computation graph is required.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: TF GraphDef是一种表示模型为图的TensorFlow格式，对于需要静态计算图的环境非常有益。
- en: '**Performance Benchmarks**: Provides stable performance for static computation
    graphs, with a focus on consistency and reliability.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准测试**：提供静态计算图的稳定性能，侧重于一致性和可靠性。'
- en: '**Compatibility and Integration**: Easily integrates within TensorFlow''s infrastructure
    but less flexible compared to SavedModel.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：在TensorFlow基础架构内易于集成，但与SavedModel相比不够灵活。'
- en: '**Community Support and Ecosystem**: Good support from TensorFlow''s ecosystem,
    with many resources available for optimizing static graphs.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：TensorFlow生态系统的良好支持，提供许多用于优化静态图的资源。'
- en: '**Case Studies**: Useful in scenarios where a static graph is necessary, such
    as in certain embedded systems.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：在需要静态图的场景中非常有用，例如某些嵌入式系统。'
- en: '**Maintenance and Updates**: Regular updates alongside TensorFlow''s core updates.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：与TensorFlow核心更新一起定期更新。'
- en: '**Security Considerations**: Ensures safe deployment with TensorFlow''s established
    security practices.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：确保使用TensorFlow已建立的安全实践进行安全部署。'
- en: '**Hardware Acceleration**: Can utilize TensorFlow''s hardware acceleration
    options, though not as flexible as SavedModel.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：可以利用TensorFlow的硬件加速选项，尽管不如SavedModel灵活。'
- en: TF Lite
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: TF Lite
- en: TF Lite is TensorFlow's solution for mobile and embedded device machine learning,
    providing a lightweight library for on-device inference.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: TF Lite是TensorFlow针对移动和嵌入式设备的解决方案，提供轻量级库进行设备端推理。
- en: '**Performance Benchmarks**: Designed for speed and efficiency on mobile and
    embedded devices.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准测试**：专为移动和嵌入式设备的速度和效率设计。'
- en: '**Compatibility and Integration**: Can be used on a wide range of devices due
    to its lightweight nature.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：由于其轻量化特性，可在广泛设备上使用。'
- en: '**Community Support and Ecosystem**: Backed by Google, it has a robust community
    and a growing number of resources for developers.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：由Google支持，拥有强大的社区和越来越多的开发者资源。'
- en: '**Case Studies**: Popular in mobile applications that require on-device inference
    with minimal footprint.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：在需要在设备上推理并保持最小占用空间的移动应用中流行。'
- en: '**Maintenance and Updates**: Regularly updated to include the latest features
    and optimizations for mobile devices.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：定期更新，包括最新功能和优化，适用于移动设备。'
- en: '**Security Considerations**: Provides a secure environment for running models
    on end-user devices.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：为在终端用户设备上运行模型提供安全环境。'
- en: '**Hardware Acceleration**: Supports a variety of hardware acceleration options,
    including GPU and DSP.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：支持包括GPU和DSP在内的多种硬件加速选项。'
- en: TF Edge TPU
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: TF Edge TPU
- en: TF Edge TPU is designed for high-speed, efficient computing on Google's Edge
    TPU hardware, perfect for IoT devices requiring real-time processing.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: TF Edge TPU专为在Google Edge TPU硬件上进行高速、高效计算设计，非常适合需要实时处理的物联网设备。
- en: '**Performance Benchmarks**: Specifically optimized for high-speed, efficient
    computing on Google''s Edge TPU hardware.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准测试**：专门针对Google Edge TPU硬件的高速、高效计算进行优化。'
- en: '**Compatibility and Integration**: Works exclusively with TensorFlow Lite models
    on Edge TPU devices.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：仅在Edge TPU设备上与TensorFlow Lite模型配合使用。'
- en: '**Community Support and Ecosystem**: Growing support with resources provided
    by Google and third-party developers.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：得到Google和第三方开发者提供的资源支持的增长。'
- en: '**Case Studies**: Used in IoT devices and applications that require real-time
    processing with low latency.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：用于物联网设备和需要低延迟实时处理的应用。'
- en: '**Maintenance and Updates**: Continually improved upon to leverage the capabilities
    of new Edge TPU hardware releases.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：持续改进以利用新的Edge TPU硬件发布的能力。'
- en: '**Security Considerations**: Integrates with Google''s robust security for
    IoT and edge devices.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：与Google为物联网和边缘设备提供的强大安全集成。'
- en: '**Hardware Acceleration**: Custom-designed to take full advantage of Google
    Coral devices.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：定制设计以充分利用 Google Coral 设备的性能。'
- en: TF.js
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: TF.js
- en: TensorFlow.js (TF.js) is a library that brings machine learning capabilities
    directly to the browser, offering a new realm of possibilities for web developers
    and users alike. It allows for the integration of machine learning models in web
    applications without the need for back-end infrastructure.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow.js（TF.js）是一个库，将机器学习能力直接带到浏览器中，为 web 开发者和用户提供了新的可能性。它允许在 web 应用中集成机器学习模型，无需后端基础设施支持。
- en: '**Performance Benchmarks**: Enables machine learning directly in the browser
    with reasonable performance, depending on the client device.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准**：可以依据客户端设备的性能，在浏览器中直接实现机器学习。'
- en: '**Compatibility and Integration**: High compatibility with web technologies,
    allowing for easy integration into web applications.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：与 web 技术高度兼容，易于集成到 web 应用中。'
- en: '**Community Support and Ecosystem**: Support from a community of web and Node.js
    developers, with a variety of tools for deploying ML models in browsers.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：得到 web 和 Node.js 开发者社区的支持，提供多种部署 ML 模型的工具。'
- en: '**Case Studies**: Ideal for interactive web applications that benefit from
    client-side machine learning without the need for server-side processing.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：适合需要客户端机器学习支持的交互式 web 应用，无需服务器端处理。'
- en: '**Maintenance and Updates**: Maintained by the TensorFlow team with contributions
    from the open-source community.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：由 TensorFlow 团队维护，并得到开源社区的贡献。'
- en: '**Security Considerations**: Runs within the browser''s secure context, utilizing
    the security model of the web platform.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：在浏览器的安全环境中运行，利用 web 平台的安全模型。'
- en: '**Hardware Acceleration**: Performance can be enhanced with web-based APIs
    that access hardware acceleration like WebGL.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：通过访问像 WebGL 这样的 web API，可增强性能。'
- en: PaddlePaddle
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: PaddlePaddle
- en: PaddlePaddle is an open-source deep learning framework developed by Baidu. It
    is designed to be both efficient for researchers and easy to use for developers.
    It's particularly popular in China and offers specialized support for Chinese
    language processing.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: PaddlePaddle 是百度开发的开源深度学习框架。它旨在为研究人员提供高效的同时，也为开发者提供易用性。在中国特别受欢迎，并且提供专门支持中文语言处理。
- en: '**Performance Benchmarks**: Offers competitive performance with a focus on
    ease of use and scalability.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准**：提供竞争性能，注重易用性和可扩展性。'
- en: '**Compatibility and Integration**: Well-integrated within Baidu''s ecosystem
    and supports a wide range of applications.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：在百度生态系统内良好集成，并支持广泛的应用场景。'
- en: '**Community Support and Ecosystem**: While the community is smaller globally,
    it''s rapidly growing, especially in China.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：虽然全球社区规模较小，但在中国特别是快速增长。'
- en: '**Case Studies**: Commonly used in Chinese markets and by developers looking
    for alternatives to other major frameworks.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：在中国市场普遍使用，并受开发者青睐，作为其他主要框架的替代选择。'
- en: '**Maintenance and Updates**: Regularly updated with a focus on serving Chinese
    language AI applications and services.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：定期更新，专注于服务于中文语言的 AI 应用和服务。'
- en: '**Security Considerations**: Emphasizes data privacy and security, catering
    to Chinese data governance standards.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：注重数据隐私和安全，符合中国的数据治理标准。'
- en: '**Hardware Acceleration**: Supports various hardware accelerations, including
    Baidu''s own Kunlun chips.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：支持包括百度鲲鹏芯片在内的各种硬件加速。'
- en: NCNN
  id: totrans-119
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: NCNN
- en: NCNN is a high-performance neural network inference framework optimized for
    the mobile platform. It stands out for its lightweight nature and efficiency,
    making it particularly well-suited for mobile and embedded devices where resources
    are limited.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: NCNN 是一个专为移动平台优化的高性能神经网络推断框架。它因其轻量和高效而脱颖而出，特别适用于资源有限的移动和嵌入式设备。
- en: '**Performance Benchmarks**: Highly optimized for mobile platforms, offering
    efficient inference on ARM-based devices.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能基准**：针对移动平台高度优化，能在基于 ARM 的设备上提供高效的推断。'
- en: '**Compatibility and Integration**: Suitable for applications on mobile phones
    and embedded systems with ARM architecture.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性和集成**：适用于基于 ARM 架构的手机和嵌入式系统应用。'
- en: '**Community Support and Ecosystem**: Supported by a niche but active community
    focused on mobile and embedded ML applications.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持和生态系统**：得到专注于移动和嵌入式 ML 应用的小众但活跃的社区支持。'
- en: '**Case Studies**: Favoured for mobile applications where efficiency and speed
    are critical on Android and other ARM-based systems.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例研究**：适用于移动应用，特别是在 Android 和其他基于 ARM 的系统上，效率和速度至关重要。'
- en: '**Maintenance and Updates**: Continuously improved to maintain high performance
    on a range of ARM devices.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护和更新**：持续改进，以保持在各种 ARM 设备上的高性能。'
- en: '**Security Considerations**: Focuses on running locally on the device, leveraging
    the inherent security of on-device processing.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：侧重于在设备上本地运行，利用设备处理的固有安全性。'
- en: '**Hardware Acceleration**: Tailored for ARM CPUs and GPUs, with specific optimizations
    for these architectures.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：专为 ARM CPU 和 GPU 定制，针对这些架构进行了特定的优化。'
- en: Comparative Analysis of YOLOv8 Deployment Options
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: YOLOv8 部署选项的比较分析
- en: The following table provides a snapshot of the various deployment options available
    for YOLOv8 models, helping you to assess which may best fit your project needs
    based on several critical criteria. For an in-depth look at each deployment option's
    format, please see the Ultralytics documentation page on export formats.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格展示了 YOLOv8 模型的各种部署选项，帮助您根据几个关键标准评估哪种最适合您的项目需求。要深入了解每种部署选项的格式，请查看 Ultralytics
    的文档页面上的导出格式。
- en: '| Deployment Option | Performance Benchmarks | Compatibility and Integration
    | Community Support and Ecosystem | Case Studies | Maintenance and Updates | Security
    Considerations | Hardware Acceleration |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 部署选项 | 性能基准 | 兼容性和集成 | 社区支持和生态系统 | 案例研究 | 维护和更新 | 安全考虑 | 硬件加速 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| PyTorch | Good flexibility; may trade off raw performance | Excellent with
    Python libraries | Extensive resources and community | Research and prototypes
    | Regular, active development | Dependent on deployment environment | CUDA support
    for GPU acceleration |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch | 灵活性强；可能会在原始性能上做出一些让步 | 与 Python 库兼容性优秀 | 广泛的资源和社区支持 | 研究和原型开发 |
    持续、活跃的开发 | 取决于部署环境 | 支持 CUDA 进行 GPU 加速 |'
- en: '| TorchScript | Better for production than PyTorch | Smooth transition from
    PyTorch to C++ | Specialized but narrower than PyTorch | Industry where Python
    is a bottleneck | Consistent updates with PyTorch | Improved security without
    full Python | Inherits CUDA support from PyTorch |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| TorchScript | 用于生产比 PyTorch 更好 | 从 PyTorch 迁移到 C++ 更加顺畅 | 比 PyTorch 更专业但范围较窄
    | 在 Python 是瓶颈的行业 | 与 PyTorch 一致的更新 | 在没有完整 Python 的情况下提高安全性 | 继承自 PyTorch 的 CUDA
    支持 |'
- en: '| ONNX | Variable depending on runtime | High across different frameworks |
    Broad ecosystem, supported by many orgs | Flexibility across ML frameworks | Regular
    updates for new operations | Ensure secure conversion and deployment practices
    | Various hardware optimizations |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| ONNX | 取决于运行时变量 | 在不同框架中表现良好 | 广泛的生态系统，得到许多组织的支持 | 在 ML 框架中具有灵活性 | 定期更新以支持新操作
    | 确保安全的转换和部署实践 | 各种硬件优化 |'
- en: '| OpenVINO | Optimized for Intel hardware | Best within Intel ecosystem | Solid
    in computer vision domain | IoT and edge with Intel hardware | Regular updates
    for Intel hardware | Robust features for sensitive applications | Tailored for
    Intel hardware |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| OpenVINO | 优化于 Intel 硬件 | 在 Intel 生态系统内表现最佳 | 在计算机视觉领域具有坚实基础 | IoT 和边缘计算中的
    Intel 硬件 | 针对 Intel 硬件的定期更新 | 针对敏感应用提供强大的功能 | 专为 Intel 硬件定制 |'
- en: '| TensorRT | Top-tier on NVIDIA GPUs | Best for NVIDIA hardware | Strong network
    through NVIDIA | Real-time video and image inference | Frequent updates for new
    GPUs | Emphasis on security | Designed for NVIDIA GPUs |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| TensorRT | 在 NVIDIA GPU 上处于顶尖水平 | 最适合 NVIDIA 硬件 | 通过 NVIDIA 形成强大的网络 | 实时视频和图像推理
    | 针对新 GPU 的频繁更新 | 重视安全性 | 设计用于 NVIDIA GPU |'
- en: '| CoreML | Optimized for on-device Apple hardware | Exclusive to Apple ecosystem
    | Strong Apple and developer support | On-device ML on Apple products | Regular
    Apple updates | Focus on privacy and security | Apple neural engine and GPU |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| CoreML | 优化用于设备上的 Apple 硬件 | 专属于 Apple 生态系统 | 强大的 Apple 和开发者支持 | 在 Apple
    产品上的设备 ML | Apple 定期更新 | 专注于隐私和安全 | Apple 神经引擎和 GPU |'
- en: '| TF SavedModel | Scalable in server environments | Wide compatibility in TensorFlow
    ecosystem | Large support due to TensorFlow popularity | Serving models at scale
    | Regular updates by Google and community | Robust features for enterprise | Various
    hardware accelerations |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| TF SavedModel | 在服务器环境中可扩展 | TensorFlow生态系统中广泛兼容 | 由于TensorFlow的流行性得到大量支持
    | 大规模服务模型 | 谷歌和社区的定期更新 | 企业级强大功能 | 各种硬件加速选项 |'
- en: '| TF GraphDef | Stable for static computation graphs | Integrates well with
    TensorFlow infrastructure | Resources for optimizing static graphs | Scenarios
    requiring static graphs | Updates alongside TensorFlow core | Established TensorFlow
    security practices | TensorFlow acceleration options |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| TF GraphDef | 适用于静态计算图的稳定性 | 与TensorFlow基础设施良好集成 | 用于优化静态图的资源 | 需要静态图的场景
    | 与TensorFlow核心同时更新 | 已建立的TensorFlow安全实践 | TensorFlow加速选项 |'
- en: '| TF Lite | Speed and efficiency on mobile/embedded | Wide range of device
    support | Robust community, Google backed | Mobile applications with minimal footprint
    | Latest features for mobile | Secure environment on end-user devices | GPU and
    DSP among others |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| TF Lite | 在移动/嵌入式设备上的速度和效率 | 广泛的设备支持 | 强大的社区，由Google支持 | 在端用户设备上的安全环境 | 移动应用程序的最新功能
    | GPU和DSP等多种硬件加速 |'
- en: '| TF Edge TPU | Optimized for Google''s Edge TPU hardware | Exclusive to Edge
    TPU devices | Growing with Google and third-party resources | IoT devices requiring
    real-time processing | Improvements for new Edge TPU hardware | Google''s robust
    IoT security | Custom-designed for Google Coral |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| TF Edge TPU | 针对谷歌Edge TPU硬件优化 | 专为Edge TPU设备独家设计 | 与谷歌及第三方资源一起增长 | 需要实时处理的IoT设备
    | 为新的Edge TPU硬件进行改进 | 谷歌强大的IoT安全性 | 专为谷歌Coral定制设计 |'
- en: '| TF.js | Reasonable in-browser performance | High with web technologies |
    Web and Node.js developers support | Interactive web applications | TensorFlow
    team and community contributions | Web platform security model | Enhanced with
    WebGL and other APIs |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| TF.js | 在浏览器中表现合理 | 与Web技术高度集成 | 支持Web和Node.js开发者 | 交互式Web应用程序 | TensorFlow团队和社区的贡献
    | Web平台安全模型 | 通过WebGL和其他API增强 |'
- en: '| PaddlePaddle | Competitive, easy to use and scalable | Baidu ecosystem, wide
    application support | Rapidly growing, especially in China | Chinese market and
    language processing | Focus on Chinese AI applications | Emphasizes data privacy
    and security | Including Baidu''s Kunlun chips |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| PaddlePaddle | 具有竞争力、易于使用和可扩展性 | 百度生态系统，广泛的应用支持 | 快速增长，特别是在中国 | 中文市场和语言处理
    | 专注于中国人工智能应用 | 强调数据隐私和安全性 | 包括百度的昆仑芯片 |'
- en: '| NCNN | Optimized for mobile ARM-based devices | Mobile and embedded ARM systems
    | Niche but active mobile/embedded ML community | Android and ARM systems efficiency
    | High performance maintenance on ARM | On-device security advantages | ARM CPUs
    and GPUs optimizations |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| NCNN | 针对移动基于ARM设备进行优化 | 移动和嵌入式ARM系统 | 小众但活跃的移动/嵌入式ML社区 | Android和ARM系统的效率
    | 在ARM上的高性能维护 | 设备上的安全优势 | ARM CPU和GPU的优化 |'
- en: This comparative analysis gives you a high-level overview. For deployment, it's
    essential to consider the specific requirements and constraints of your project,
    and consult the detailed documentation and resources available for each option.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这份比较分析为您提供了高层次的概述。在部署时，重要的是考虑您项目的具体要求和限制，并参考每个选项的详细文档和资源。
- en: Community and Support
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 社区与支持
- en: When you're getting started with YOLOv8, having a helpful community and support
    can make a significant impact. Here's how to connect with others who share your
    interests and get the assistance you need.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当您开始使用 YOLOv8 时，拥有一个乐于助人的社区和支持可以产生重要影响。以下是如何与分享您兴趣的其他人联系并获取所需帮助的方法。
- en: Engage with the Broader Community
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 与更广泛的社区互动
- en: '**GitHub Discussions:** The YOLOv8 repository on GitHub has a "Discussions"
    section where you can ask questions, report issues, and suggest improvements.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GitHub 讨论：** GitHub 上的 YOLOv8 仓库有一个 "讨论" 部分，您可以在此提问、报告问题和建议改进。'
- en: '**Ultralytics Discord Server:** Ultralytics has a [Discord server](https://ultralytics.com/discord/)
    where you can interact with other users and developers.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ultralytics Discord 服务器：** Ultralytics 拥有一个 [Discord 服务器](https://ultralytics.com/discord/)，您可以在此与其他用户和开发者交流。'
- en: Official Documentation and Resources
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 官方文档和资源
- en: '**Ultralytics YOLOv8 Docs:** The official documentation provides a comprehensive
    overview of YOLOv8, along with guides on installation, usage, and troubleshooting.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ultralytics YOLOv8 文档：** 官方文档提供了YOLOv8的全面概述，以及有关安装、使用和故障排除的指南。'
- en: These resources will help you tackle challenges and stay updated on the latest
    trends and best practices in the YOLOv8 community.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这些资源将帮助您解决挑战，并保持对YOLOv8社区最新趋势和最佳实践的更新。
- en: Conclusion
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this guide, we've explored the different deployment options for YOLOv8\.
    We've also discussed the important factors to consider when making your choice.
    These options allow you to customize your model for various environments and performance
    requirements, making it suitable for real-world applications.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在本指南中，我们探讨了YOLOv8的不同部署选项。我们还讨论了在做出选择时需要考虑的重要因素。这些选项允许您根据不同的环境和性能要求定制您的模型，使其适用于实际应用。
- en: Don't forget that the YOLOv8 and Ultralytics community is a valuable source
    of help. Connect with other developers and experts to learn unique tips and solutions
    you might not find in regular documentation. Keep seeking knowledge, exploring
    new ideas, and sharing your experiences.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记，YOLOv8和Ultralytics社区是帮助的宝贵来源。与其他开发人员和专家联系，学习您在常规文档中找不到的独特技巧和解决方案。继续追求知识，探索新思路，并分享您的经验。
- en: Happy deploying!
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 部署愉快！
- en: FAQ
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题解答
- en: What are the deployment options available for YOLOv8 on different hardware platforms?
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: YOLOv8在不同硬件平台上的部署选项有哪些？
- en: 'Ultralytics YOLOv8 supports various deployment formats, each designed for specific
    environments and hardware platforms. Key formats include:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics YOLOv8支持各种部署格式，每种都针对特定的环境和硬件平台设计。关键格式包括：
- en: '**PyTorch** for research and prototyping, with excellent Python integration.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PyTorch** 用于研究和原型设计，具有优秀的Python集成。'
- en: '**TorchScript** for production environments where Python is unavailable.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TorchScript** 用于在Python不可用的生产环境中。'
- en: '**ONNX** for cross-platform compatibility and hardware acceleration.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ONNX** 用于跨平台兼容性和硬件加速。'
- en: '**OpenVINO** for optimized performance on Intel hardware.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OpenVINO** 用于在Intel硬件上优化性能。'
- en: '**TensorRT** for high-speed inference on NVIDIA GPUs.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorRT** 用于在NVIDIA GPU上进行高速推断。'
- en: Each format has unique advantages. For a detailed walkthrough, see our export
    process documentation.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 每种格式都有独特的优势。详细步骤请参阅我们的导出过程文档。
- en: How do I improve the inference speed of my YOLOv8 model on an Intel CPU?
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何提高在Intel CPU上的YOLOv8模型推断速度？
- en: To enhance inference speed on Intel CPUs, you can deploy your YOLOv8 model using
    Intel's OpenVINO toolkit. OpenVINO offers significant performance boosts by optimizing
    models to leverage Intel hardware efficiently.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要提高在Intel CPU上的推断速度，可以使用Intel的OpenVINO工具包部署YOLOv8模型。OpenVINO通过优化模型以高效利用Intel硬件，显著提升性能。
- en: Convert your YOLOv8 model to the OpenVINO format using the `model.export()`
    function.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`model.export()`函数将您的YOLOv8模型转换为OpenVINO格式。
- en: Follow the detailed setup guide in the Intel OpenVINO Export documentation.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Intel OpenVINO导出文档中，按照详细的设置指南进行设置。
- en: For more insights, check out our [blog post](https://www.ultralytics.com/blog/achieve-faster-inference-speeds-ultralytics-yolov8-openvino).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 获得更多见解，请查看我们的[博客文章](https://www.ultralytics.com/blog/achieve-faster-inference-speeds-ultralytics-yolov8-openvino)。
- en: Can I deploy YOLOv8 models on mobile devices?
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我能在移动设备上部署YOLOv8模型吗？
- en: Yes, YOLOv8 models can be deployed on mobile devices using TensorFlow Lite (TF
    Lite) for both Android and iOS platforms. TF Lite is designed for mobile and embedded
    devices, providing efficient on-device inference.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，YOLOv8模型可以使用TensorFlow Lite（TF Lite）在Android和iOS平台上的移动设备上进行部署。TF Lite专为移动和嵌入式设备设计，提供高效的设备端推断能力。
- en: Example
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE0]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For more details on deploying models to mobile, refer to our TF Lite integration
    guide.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 有关在移动设备上部署模型的详细信息，请参阅我们的TF Lite集成指南。
- en: What factors should I consider when choosing a deployment format for my YOLOv8
    model?
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择YOLOv8模型部署格式时应考虑哪些因素？
- en: 'When choosing a deployment format for YOLOv8, consider the following factors:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择YOLOv8部署格式时，需要考虑以下因素：
- en: '**Performance**: Some formats like TensorRT provide exceptional speeds on NVIDIA
    GPUs, while OpenVINO is optimized for Intel hardware.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能**：像TensorRT这样的格式在NVIDIA GPU上提供卓越的速度，而OpenVINO则针对Intel硬件进行了优化。'
- en: '**Compatibility**: ONNX offers broad compatibility across different platforms.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性**：ONNX在不同平台上具有广泛的兼容性。'
- en: '**Ease of Integration**: Formats like CoreML or TF Lite are tailored for specific
    ecosystems like iOS and Android, respectively.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成便捷性**：像CoreML或TF Lite这样的格式专为iOS和Android等特定生态系统量身定制。'
- en: '**Community Support**: Formats like PyTorch and TensorFlow have extensive community
    resources and support.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区支持**：像PyTorch和TensorFlow这样的格式拥有丰富的社区资源和支持。'
- en: For a comparative analysis, refer to our export formats documentation.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行比较分析，请参阅我们的导出格式文档。
- en: How can I deploy YOLOv8 models in a web application?
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何在Web应用程序中部署YOLOv8模型？
- en: To deploy YOLOv8 models in a web application, you can use TensorFlow.js (TF.js),
    which allows for running machine learning models directly in the browser. This
    approach eliminates the need for backend infrastructure and provides real-time
    performance.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Web应用程序中部署YOLOv8模型，您可以使用TensorFlow.js（TF.js），它允许在浏览器中直接运行机器学习模型。这种方法消除了后端基础设施的需求，并提供实时性能。
- en: Export the YOLOv8 model to the TF.js format.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将YOLOv8模型导出到TF.js格式。
- en: Integrate the exported model into your web application.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将导出的模型集成到您的Web应用程序中。
- en: For step-by-step instructions, refer to our guide on TensorFlow.js integration.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 对于逐步说明，请参阅我们关于TensorFlow.js集成的指南。
