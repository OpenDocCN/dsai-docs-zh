- en: scipy.special.rel_entr
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.special.rel_entr.html#scipy.special.rel_entr](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.special.rel_entr.html#scipy.special.rel_entr)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Elementwise function for computing relative entropy.
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split}\mathrm{rel\_entr}(x, y) = \begin{cases} x \log(x / y) & x >
    0, y > 0 \\ 0 & x = 0, y \ge 0 \\ \infty & \text{otherwise} \end{cases}\end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**x, y**array_like'
  prefs: []
  type: TYPE_NORMAL
- en: Input arrays
  prefs: []
  type: TYPE_NORMAL
- en: '**out**ndarray, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Optional output array for the function results
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: scalar or ndarray
  prefs: []
  type: TYPE_NORMAL
- en: Relative entropy of the inputs
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs: []
  type: TYPE_NORMAL
- en: '[`entr`](scipy.special.entr.html#scipy.special.entr "scipy.special.entr"),
    [`kl_div`](scipy.special.kl_div.html#scipy.special.kl_div "scipy.special.kl_div"),
    [`scipy.stats.entropy`](scipy.stats.entropy.html#scipy.stats.entropy "scipy.stats.entropy")'
  prefs: []
  type: TYPE_NORMAL
- en: Notes
  prefs: []
  type: TYPE_NORMAL
- en: New in version 0.15.0.
  prefs: []
  type: TYPE_NORMAL
- en: This function is jointly convex in x and y.
  prefs: []
  type: TYPE_NORMAL
- en: The origin of this function is in convex programming; see [[1]](#r27be2019009a-1).
    Given two discrete probability distributions \(p_1, \ldots, p_n\) and \(q_1, \ldots,
    q_n\), the definition of relative entropy in the context of *information theory*
    is
  prefs: []
  type: TYPE_NORMAL
- en: \[\sum_{i = 1}^n \mathrm{rel\_entr}(p_i, q_i).\]
  prefs: []
  type: TYPE_NORMAL
- en: To compute the latter quantity, use [`scipy.stats.entropy`](scipy.stats.entropy.html#scipy.stats.entropy
    "scipy.stats.entropy").
  prefs: []
  type: TYPE_NORMAL
- en: See [[2]](#r27be2019009a-2) for details.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs: []
  type: TYPE_NORMAL
- en: '[[1](#id1)]'
  prefs: []
  type: TYPE_NORMAL
- en: Boyd, Stephen and Lieven Vandenberghe. *Convex optimization*. Cambridge University
    Press, 2004. [DOI:https://doi.org/10.1017/CBO9780511804441](https://doi.org/https://doi.org/10.1017/CBO9780511804441)
  prefs: []
  type: TYPE_NORMAL
- en: '[[2](#id2)]'
  prefs: []
  type: TYPE_NORMAL
- en: Kullback-Leibler divergence, [https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)
  prefs: []
  type: TYPE_NORMAL
