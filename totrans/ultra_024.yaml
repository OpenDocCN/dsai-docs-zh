- en: 'YOLOv10: Real-Time End-to-End Object Detection'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/models/yolov10/`](https://docs.ultralytics.com/models/yolov10/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: YOLOv10, built on the [Ultralytics](https://ultralytics.com) [Python package](https://pypi.org/project/ultralytics/)
    by researchers at [Tsinghua University](https://www.tsinghua.edu.cn/en/), introduces
    a new approach to real-time object detection, addressing both the post-processing
    and model architecture deficiencies found in previous YOLO versions. By eliminating
    non-maximum suppression (NMS) and optimizing various model components, YOLOv10
    achieves state-of-the-art performance with significantly reduced computational
    overhead. Extensive experiments demonstrate its superior accuracy-latency trade-offs
    across multiple model scales.
  prefs: []
  type: TYPE_NORMAL
- en: '![YOLOv10 consistent dual assignment for NMS-free training](img/f56ed2cd2a516bf95eb3eaa4b2572c8d.png)'
  prefs: []
  type: TYPE_IMG
- en: '[`www.youtube.com/embed/_gRqR-miFPE`](https://www.youtube.com/embed/_gRqR-miFPE)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch:** How to Train YOLOv10 on SKU-110k Dataset using Ultralytics | Retail
    Dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Real-time object detection aims to accurately predict object categories and
    positions in images with low latency. The YOLO series has been at the forefront
    of this research due to its balance between performance and efficiency. However,
    reliance on NMS and architectural inefficiencies have hindered optimal performance.
    YOLOv10 addresses these issues by introducing consistent dual assignments for
    NMS-free training and a holistic efficiency-accuracy driven model design strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The architecture of YOLOv10 builds upon the strengths of previous YOLO models
    while introducing several key innovations. The model architecture consists of
    the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Backbone**: Responsible for feature extraction, the backbone in YOLOv10 uses
    an enhanced version of CSPNet (Cross Stage Partial Network) to improve gradient
    flow and reduce computational redundancy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Neck**: The neck is designed to aggregate features from different scales
    and passes them to the head. It includes PAN (Path Aggregation Network) layers
    for effective multiscale feature fusion.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**One-to-Many Head**: Generates multiple predictions per object during training
    to provide rich supervisory signals and improve learning accuracy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**One-to-One Head**: Generates a single best prediction per object during inference
    to eliminate the need for NMS, thereby reducing latency and improving efficiency.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Key Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**NMS-Free Training**: Utilizes consistent dual assignments to eliminate the
    need for NMS, reducing inference latency.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Holistic Model Design**: Comprehensive optimization of various components
    from both efficiency and accuracy perspectives, including lightweight classification
    heads, spatial-channel decoupled down sampling, and rank-guided block design.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Enhanced Model Capabilities**: Incorporates large-kernel convolutions and
    partial self-attention modules to improve performance without significant computational
    cost.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model Variants
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'YOLOv10 comes in various model scales to cater to different application needs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**YOLOv10-N**: Nano version for extremely resource-constrained environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YOLOv10-S**: Small version balancing speed and accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YOLOv10-M**: Medium version for general-purpose use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YOLOv10-B**: Balanced version with increased width for higher accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YOLOv10-L**: Large version for higher accuracy at the cost of increased computational
    resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YOLOv10-X**: Extra-large version for maximum accuracy and performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: YOLOv10 outperforms previous YOLO versions and other state-of-the-art models
    in terms of accuracy and efficiency. For example, YOLOv10-S is 1.8x faster than
    RT-DETR-R18 with similar AP on the COCO dataset, and YOLOv10-B has 46% less latency
    and 25% fewer parameters than YOLOv9-C with the same performance.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Input Size | AP^(val) | FLOPs (G) | Latency (ms) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv10-N](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10n.pt)
    | 640 | 38.5 | **6.7** | **1.84** |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv10-S](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10s.pt)
    | 640 | 46.3 | 21.6 | 2.49 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv10-M](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10m.pt)
    | 640 | 51.1 | 59.1 | 4.74 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv10-B](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10b.pt)
    | 640 | 52.5 | 92.0 | 5.74 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv10-L](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10l.pt)
    | 640 | 53.2 | 120.3 | 7.28 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv10-X](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10x.pt)
    | 640 | **54.4** | 160.4 | 10.70 |'
  prefs: []
  type: TYPE_TB
- en: Latency measured with TensorRT FP16 on T4 GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consistent Dual Assignments for NMS-Free Training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv10 employs dual label assignments, combining one-to-many and one-to-one
    strategies during training to ensure rich supervision and efficient end-to-end
    deployment. The consistent matching metric aligns the supervision between both
    strategies, enhancing the quality of predictions during inference.
  prefs: []
  type: TYPE_NORMAL
- en: Holistic Efficiency-Accuracy Driven Model Design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Efficiency Enhancements
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**Lightweight Classification Head**: Reduces the computational overhead of
    the classification head by using depth-wise separable convolutions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Spatial-Channel Decoupled Down sampling**: Decouples spatial reduction and
    channel modulation to minimize information loss and computational cost.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Rank-Guided Block Design**: Adapts block design based on intrinsic stage
    redundancy, ensuring optimal parameter utilization.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Accuracy Enhancements
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**Large-Kernel Convolution**: Enlarges the receptive field to enhance feature
    extraction capability.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Partial Self-Attention (PSA)**: Incorporates self-attention modules to improve
    global representation learning with minimal overhead.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Experiments and Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: YOLOv10 has been extensively tested on standard benchmarks like COCO, demonstrating
    superior performance and efficiency. The model achieves state-of-the-art results
    across different variants, showcasing significant improvements in latency and
    accuracy compared to previous versions and other contemporary detectors.
  prefs: []
  type: TYPE_NORMAL
- en: Comparisons
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![YOLOv10 comparison with SOTA object detectors](img/cd970eef603f0cb066dbb5552573b8ea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Compared to other state-of-the-art detectors:'
  prefs: []
  type: TYPE_NORMAL
- en: YOLOv10-S / X are 1.8× / 1.3× faster than RT-DETR-R18 / R101 with similar accuracy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: YOLOv10-B has 25% fewer parameters and 46% lower latency than YOLOv9-C at same
    accuracy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: YOLOv10-L / X outperform YOLOv8-L / X by 0.3 AP / 0.5 AP with 1.8× / 2.3× fewer
    parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is a detailed comparison of YOLOv10 variants with other state-of-the-art
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Params ^((M)) | FLOPs ^((G)) | mAP^(val 50-95) | Latency ^((ms))
    | Latency-forward ^((ms)) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv6-3.0-N | 4.7 | 11.4 | 37.0 | 2.69 | **1.76** |'
  prefs: []
  type: TYPE_TB
- en: '| Gold-YOLO-N | 5.6 | 12.1 | **39.6** | 2.92 | 1.82 |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-N | 3.2 | 8.7 | 37.3 | 6.16 | 1.77 |'
  prefs: []
  type: TYPE_TB
- en: '| **[YOLOv10-N](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10n.pt)**
    | **2.3** | **6.7** | 39.5 | **1.84** | 1.79 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv6-3.0-S | 18.5 | 45.3 | 44.3 | 3.42 | 2.35 |'
  prefs: []
  type: TYPE_TB
- en: '| Gold-YOLO-S | 21.5 | 46.0 | 45.4 | 3.82 | 2.73 |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-S | 11.2 | 28.6 | 44.9 | 7.07 | **2.33** |'
  prefs: []
  type: TYPE_TB
- en: '| **[YOLOv10-S](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10s.pt)**
    | **7.2** | **21.6** | **46.8** | **2.49** | 2.39 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| RT-DETR-R18 | 20.0 | 60.0 | 46.5 | **4.58** | **4.49** |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv6-3.0-M | 34.9 | 85.8 | 49.1 | 5.63 | 4.56 |'
  prefs: []
  type: TYPE_TB
- en: '| Gold-YOLO-M | 41.3 | 87.5 | 49.8 | 6.38 | 5.45 |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-M | 25.9 | 78.9 | 50.6 | 9.50 | 5.09 |'
  prefs: []
  type: TYPE_TB
- en: '| **[YOLOv10-M](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10m.pt)**
    | **15.4** | **59.1** | **51.3** | 4.74 | 4.63 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv6-3.0-L | 59.6 | 150.7 | 51.8 | 9.02 | 7.90 |'
  prefs: []
  type: TYPE_TB
- en: '| Gold-YOLO-L | 75.1 | 151.7 | 51.8 | 10.65 | 9.78 |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-L | 43.7 | 165.2 | 52.9 | 12.39 | 8.06 |'
  prefs: []
  type: TYPE_TB
- en: '| RT-DETR-R50 | 42.0 | 136.0 | 53.1 | 9.20 | 9.07 |'
  prefs: []
  type: TYPE_TB
- en: '| **[YOLOv10-L](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10l.pt)**
    | **24.4** | **120.3** | **53.4** | **7.28** | **7.21** |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv8-X | 68.2 | 257.8 | 53.9 | 16.86 | 12.83 |'
  prefs: []
  type: TYPE_TB
- en: '| RT-DETR-R101 | 76.0 | 259.0 | 54.3 | 13.71 | 13.58 |'
  prefs: []
  type: TYPE_TB
- en: '| **[YOLOv10-X](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10x.pt)**
    | **29.5** | **160.4** | **54.4** | **10.70** | **10.60** |'
  prefs: []
  type: TYPE_TB
- en: Usage Examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For predicting new images with YOLOv10:'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'For training YOLOv10 on a custom dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Supported Tasks and Modes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The YOLOv10 models series offers a range of models, each optimized for high-performance
    Object Detection. These models cater to varying computational needs and accuracy
    requirements, making them versatile for a wide array of applications.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Filenames | Tasks | Inference | Validation | Training | Export |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv10 | `yolov10n.pt` `yolov10s.pt` `yolov10m.pt` `yolov10l.pt` `yolov10x.pt`
    | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: Exporting YOLOv10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Due to the new operations introduced with YOLOv10, not all export formats provided
    by Ultralytics are currently supported. The following table outlines which formats
    have been successfully converted using Ultralytics for YOLOv10\. Feel free to
    open a pull request if you're able to provide a contribution change for adding
    export support of additional formats for YOLOv10.
  prefs: []
  type: TYPE_NORMAL
- en: '| Export Format | Supported |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| TorchScript | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| ONNX | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| OpenVINO | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| TensorRT | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| CoreML | ❌ |'
  prefs: []
  type: TYPE_TB
- en: '| TF SavedModel | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| TF GraphDef | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| TF Lite | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| TF Edge TPU | ❌ |'
  prefs: []
  type: TYPE_TB
- en: '| TF.js | ❌ |'
  prefs: []
  type: TYPE_TB
- en: '| PaddlePaddle | ❌ |'
  prefs: []
  type: TYPE_TB
- en: '| NCNN | ❌ |'
  prefs: []
  type: TYPE_TB
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: YOLOv10 sets a new standard in real-time object detection by addressing the
    shortcomings of previous YOLO versions and incorporating innovative design strategies.
    Its ability to deliver high accuracy with low computational cost makes it an ideal
    choice for a wide range of real-world applications.
  prefs: []
  type: TYPE_NORMAL
- en: Citations and Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We would like to acknowledge the YOLOv10 authors from [Tsinghua University](https://www.tsinghua.edu.cn/en/)
    for their extensive research and significant contributions to the [Ultralytics](https://ultralytics.com)
    framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: For detailed implementation, architectural innovations, and experimental results,
    please refer to the YOLOv10 [research paper](https://arxiv.org/pdf/2405.14458)
    and [GitHub repository](https://github.com/THU-MIG/yolov10) by the Tsinghua University
    team.
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is YOLOv10 and how does it differ from previous YOLO versions?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv10, developed by researchers at [Tsinghua University](https://www.tsinghua.edu.cn/en/),
    introduces several key innovations to real-time object detection. It eliminates
    the need for non-maximum suppression (NMS) by employing consistent dual assignments
    during training and optimized model components for superior performance with reduced
    computational overhead. For more details on its architecture and key features,
    check out the YOLOv10 overview section.
  prefs: []
  type: TYPE_NORMAL
- en: How can I get started with running inference using YOLOv10?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For easy inference, you can use the Ultralytics YOLO Python library or the
    command line interface (CLI). Below are examples of predicting new images using
    YOLOv10:'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: For more usage examples, visit our Usage Examples section.
  prefs: []
  type: TYPE_NORMAL
- en: Which model variants does YOLOv10 offer and what are their use cases?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'YOLOv10 offers several model variants to cater to different use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**YOLOv10-N**: Suitable for extremely resource-constrained environments'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YOLOv10-S**: Balances speed and accuracy'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YOLOv10-M**: General-purpose use'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YOLOv10-B**: Higher accuracy with increased width'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YOLOv10-L**: High accuracy at the cost of computational resources'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YOLOv10-X**: Maximum accuracy and performance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each variant is designed for different computational needs and accuracy requirements,
    making them versatile for a variety of applications. Explore the Model Variants
    section for more information.
  prefs: []
  type: TYPE_NORMAL
- en: How does the NMS-free approach in YOLOv10 improve performance?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv10 eliminates the need for non-maximum suppression (NMS) during inference
    by employing consistent dual assignments for training. This approach reduces inference
    latency and enhances prediction efficiency. The architecture also includes a one-to-one
    head for inference, ensuring that each object gets a single best prediction. For
    a detailed explanation, see the Consistent Dual Assignments for NMS-Free Training
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Where can I find the export options for YOLOv10 models?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv10 supports several export formats, including TorchScript, ONNX, OpenVINO,
    and TensorRT. However, not all export formats provided by Ultralytics are currently
    supported for YOLOv10 due to its new operations. For details on the supported
    formats and instructions on exporting, visit the Exporting YOLOv10 section.
  prefs: []
  type: TYPE_NORMAL
- en: What are the performance benchmarks for YOLOv10 models?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv10 outperforms previous YOLO versions and other state-of-the-art models
    in both accuracy and efficiency. For example, YOLOv10-S is 1.8x faster than RT-DETR-R18
    with a similar AP on the COCO dataset. YOLOv10-B shows 46% less latency and 25%
    fewer parameters than YOLOv9-C with the same performance. Detailed benchmarks
    can be found in the Comparisons section.
  prefs: []
  type: TYPE_NORMAL
