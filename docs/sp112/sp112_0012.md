# 压缩稀疏图例程（scipy.sparse.csgraph）

> 原文：[https://docs.scipy.org/doc/scipy-1.12.0/tutorial/csgraph.html](https://docs.scipy.org/doc/scipy-1.12.0/tutorial/csgraph.html)

## 示例：单词阶梯

[单词阶梯](https://zh.wikipedia.org/wiki/Word_ladder)是由刘易斯·卡罗尔发明的一种文字游戏，玩家通过逐个改变一个字母来找出单词之间的路径。例如，可以这样连接“ape”和“man”：

\[{\rm ape \to apt \to ait \to bit \to big \to bag \to mag \to man}\]

请注意，每一步都涉及更改单词中的一个字母。这只是从“ape”到“man”的一条可能路径，但是否是最短路径呢？如果我们希望找到两个给定单词之间的最短单词阶梯路径，稀疏图子模块可以帮助。

首先，我们需要一个有效单词的列表。许多操作系统都内置了这样的列表。例如，在Linux上，可以在以下位置之一找到单词列表：

```py
/usr/share/dict
/var/lib/dict 
```

另一个获取单词的简单来源是各种互联网上的Scrabble单词列表（使用您喜爱的搜索引擎进行搜索）。我们首先要创建这个列表。系统单词列表由一个每行一个单词的文件组成。以下内容应修改以使用您现有的单词列表：

```py
>>> word_list = open('/usr/share/dict/words').readlines()
>>> word_list = map(str.strip, word_list) 
```

我们想要查看长度为3的单词，所以让我们只选择正确长度的单词。我们还将消除以大写字母开头（专有名词）或包含非字母数字字符（如撇号和连字符）的单词。最后，我们会确保为后续比较转换为小写：

```py
>>> word_list = [word for word in word_list if len(word) == 3]
>>> word_list = [word for word in word_list if word[0].islower()]
>>> word_list = [word for word in word_list if word.isalpha()]
>>> word_list = list(map(str.lower, word_list))
>>> len(word_list)
586    # may vary 
```

现在我们有一个包含586个有效的三个字母单词的列表（具体数字可能根据特定列表而变化）。这些单词中的每一个将成为我们图中的一个节点，并且我们将创建连接每对仅相差一个字母的单词节点的边。

有有效的方法来做到这一点，也有低效的方法。为了尽可能高效地完成这个任务，我们将使用一些复杂的numpy数组操作：

```py
>>> import numpy as np
>>> word_list = np.asarray(word_list)
>>> word_list.dtype   # these are unicode characters in Python 3
dtype('<U3')
>>> word_list.sort()  # sort for quick searching later 
```

我们有一个数组，其中每个条目都是三个Unicode字符长。我们希望找到所有只有一个字符不同的配对。我们将从将每个单词转换为三维向量开始：

```py
>>> word_bytes = np.ndarray((word_list.size, word_list.itemsize),
...                         dtype='uint8',
...                         buffer=word_list.data)
>>> # each unicode character is four bytes long. We only need first byte
>>> # we know that there are three characters in each word
>>> word_bytes = word_bytes[:, ::word_list.itemsize//3]
>>> word_bytes.shape
(586, 3)    # may vary 
```

现在，我们将使用[汉明距离](https://zh.wikipedia.org/wiki/汉明距离)来确定哪些单词对之间存在连接。汉明距离衡量两个向量之间不同条目的比例：任何两个汉明距离等于\(1/N\)的单词，其中\(N\)是字母数，将在单词阶梯中连接起来：

```py
>>> from scipy.spatial.distance import pdist, squareform
>>> from scipy.sparse import csr_matrix
>>> hamming_dist = pdist(word_bytes, metric='hamming')
>>> # there are three characters in each word
>>> graph = csr_matrix(squareform(hamming_dist < 1.5 / 3)) 
```

在比较距离时，我们不使用相等性，因为这对于浮点值来说可能不稳定。不等式产生了期望的结果，只要单词列表中没有两个条目完全相同。现在，我们的图已经设置好了，我们将使用最短路径搜索来找到图中任意两个单词之间的路径：

```py
>>> i1 = word_list.searchsorted('ape')
>>> i2 = word_list.searchsorted('man')
>>> word_list[i1]
'ape'
>>> word_list[i2]
'man' 
```

我们需要检查这些是否匹配，因为如果单词不在列表中，情况就不同。现在，我们只需要找到图中这两个索引之间的最短路径。我们将使用[Dijkstra算法](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm)，因为它允许我们仅为一个节点找到路径：

```py
>>> from scipy.sparse.csgraph import dijkstra
>>> distances, predecessors = dijkstra(graph, indices=i1,
...                                    return_predecessors=True)
>>> print(distances[i2])
5.0    # may vary 
```

因此，我们看到“猿”和“人”之间的最短路径只包含五步。我们可以使用算法返回的前导来重构这条路径：

```py
>>> path = []
>>> i = i2
>>> while i != i1:
...     path.append(word_list[i])
...     i = predecessors[i]
>>> path.append(word_list[i1])
>>> print(path[::-1])
['ape', 'apt', 'opt', 'oat', 'mat', 'man']    # may vary 
```

比我们最初的例子少了三个链接：从“猿”到“人”的路径只有五步。

使用模块中的其他工具，我们可以回答其他问题。例如，有没有在单词梯子中没有链接的三个字母单词？这是关于图中连通分量的一个问题：

```py
>>> from scipy.sparse.csgraph import connected_components
>>> N_components, component_list = connected_components(graph)
>>> print(N_components)
15    # may vary 
```

在这个特定的三个字母单词样本中，有15个连通分量：即，有15个不同的单词集合，这些集合之间没有路径。每个集合中有多少个单词？我们可以从连通分量的列表中学到这些信息：

```py
>>> [np.sum(component_list == i) for i in range(N_components)]
[571, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]    # may vary 
```

有一个大的连通集和14个较小的连通集。让我们来看看较小连通集中的单词：

```py
>>> [list(word_list[np.nonzero(component_list == i)]) for i in range(1, N_components)]
[['aha'],    # may vary
 ['chi'],
 ['ebb'],
 ['ems', 'emu'],
 ['gnu'],
 ['ism'],
 ['khz'],
 ['nth'],
 ['ova'],
 ['qua'],
 ['ugh'],
 ['ups'],
 ['urn'],
 ['use']] 
```

这些都是不通过单词梯子与其他单词连接的三个字母单词。

我们可能还对哪些单词之间的分离最大感到好奇。哪两个单词需要最多的链接才能连接起来？我们可以通过计算所有最短路径的矩阵来确定这一点。请注意，按照惯例，两个非连接点之间的距离被报告为无穷大，因此在找到最大值之前我们需要将这些移除：

```py
>>> distances, predecessors = dijkstra(graph, return_predecessors=True)
>>> max_distance = np.max(distances[~np.isinf(distances)])
>>> print(max_distance)
13.0    # may vary 
```

因此，至少有一对单词需要13步才能从一个单词到另一个单词！让我们确定这些是哪些：

```py
>>> i1, i2 = np.nonzero(distances == max_distance)
>>> list(zip(word_list[i1], word_list[i2]))
[('imp', 'ohm'),    # may vary
 ('imp', 'ohs'),
 ('ohm', 'imp'),
 ('ohm', 'ump'),
 ('ohs', 'imp'),
 ('ohs', 'ump'),
 ('ump', 'ohm'),
 ('ump', 'ohs')] 
```

我们看到有两对单词彼此之间的最大分离：一方面是‘imp’和‘ump’，另一方面是‘ohm’和‘ohs’。我们可以以与上述相同的方式找到连接列表：

```py
>>> path = []
>>> i = i2[0]
>>> while i != i1[0]:
...     path.append(word_list[i])
...     i = predecessors[i1[0], i]
>>> path.append(word_list[i1[0]])
>>> print(path[::-1])
['imp', 'amp', 'asp', 'ass', 'ads', 'add', 'aid', 'mid', 'mod', 'moo', 'too', 'tho', 'oho', 'ohm']    # may vary 
```

这给我们展示了我们所期望看到的路径。

单词梯子只是scipy稀疏矩阵快速图算法的一个潜在应用。图论在数学、数据分析和机器学习的许多领域中都有出现。稀疏图工具足够灵活，可以处理许多这些情况。
