["```py\nIn [1]: df = pd.DataFrame({\"id\": [1, 2, 3, 4, 5, 6],\n ...:                   \"raw_grade\": ['a', 'b', 'b', 'a', 'a', 'e']})\n ...: \n\nIn [2]: df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\n\nIn [3]: df[\"grade\"]\nOut[3]: \n0    a\n1    b\n2    b\n3    a\n4    a\n5    e\nName: grade, Length: 6, dtype: category\nCategories (3, object): ['a', 'b', 'e']\n\n# Rename the categories\nIn [4]: df[\"grade\"] = df[\"grade\"].cat.rename_categories([\"very good\", \"good\", \"very bad\"])\n\n# Reorder the categories and simultaneously add the missing categories\nIn [5]: df[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\",\n ...:                                              \"medium\", \"good\", \"very good\"])\n ...: \n\nIn [6]: df[\"grade\"]\nOut[6]: \n0    very good\n1         good\n2         good\n3    very good\n4    very good\n5     very bad\nName: grade, Length: 6, dtype: category\nCategories (5, object): ['very bad', 'bad', 'medium', 'good', 'very good']\n\nIn [7]: df.sort_values(\"grade\")\nOut[7]: \n id raw_grade      grade\n5   6         e   very bad\n1   2         b       good\n2   3         b       good\n0   1         a  very good\n3   4         a  very good\n4   5         a  very good\n\n[6 rows x 3 columns]\n\nIn [8]: df.groupby(\"grade\", observed=False).size()\nOut[8]: \ngrade\nvery bad     1\nbad          0\nmedium       0\ngood         2\nvery good    3\nLength: 5, dtype: int64 \n```", "```py\n# Timedelta accessor\nIn [9]: tds = pd.Timedelta('31 days 5 min 3 sec')\n\nIn [10]: tds.minutes\nOut[10]: 5L\n\nIn [11]: tds.seconds\nOut[11]: 3L\n\n# datetime.timedelta accessor\n# this is 5 minutes * 60 + 3 seconds\nIn [12]: tds.to_pytimedelta().seconds\nOut[12]: 303 \n```", "```py\nIn [9]: pd.Timedelta('1 days 06:05:01.00003')\nOut[9]: Timedelta('1 days 06:05:01.000030')\n\nIn [10]: pd.Timedelta('15.5us')\nOut[10]: Timedelta('0 days 00:00:00.000015500')\n\nIn [11]: pd.Timedelta('1 hour 15.5us')\nOut[11]: Timedelta('0 days 01:00:00.000015500')\n\n# negative Timedeltas have this string repr\n# to be more consistent with datetime.timedelta conventions\nIn [12]: pd.Timedelta('-1us')\nOut[12]: Timedelta('-1 days +23:59:59.999999')\n\n# a NaT\nIn [13]: pd.Timedelta('nan')\nOut[13]: NaT \n```", "```py\nIn [14]: td = pd.Timedelta('1 hour 3m 15.5us')\n\nIn [15]: td.seconds\nOut[15]: 3780\n\nIn [16]: td.microseconds\nOut[16]: 15\n\nIn [17]: td.nanoseconds\nOut[17]: 500 \n```", "```py\nIn [18]: pd.TimedeltaIndex(['1 days', '1 days, 00:00:05',\n ....:                   np.timedelta64(2, 'D'),\n ....:                   datetime.timedelta(days=2, seconds=2)])\n ....: \nOut[18]: \nTimedeltaIndex(['1 days 00:00:00', '1 days 00:00:05', '2 days 00:00:00',\n '2 days 00:00:02'],\n dtype='timedelta64[ns]', freq=None) \n```", "```py\nIn [19]: pd.timedelta_range('1 days', periods=5, freq='D')\nOut[19]: TimedeltaIndex(['1 days', '2 days', '3 days', '4 days', '5 days'], dtype='timedelta64[ns]', freq='D') \n```", "```py\nIn [20]: pd.timedelta_range(start='1 days', end='2 days', freq='30T')\nOut[20]:\nTimedeltaIndex(['1 days 00:00:00', '1 days 00:30:00', '1 days 01:00:00',\n                '1 days 01:30:00', '1 days 02:00:00', '1 days 02:30:00',\n                '1 days 03:00:00', '1 days 03:30:00', '1 days 04:00:00',\n                '1 days 04:30:00', '1 days 05:00:00', '1 days 05:30:00',\n                '1 days 06:00:00', '1 days 06:30:00', '1 days 07:00:00',\n                '1 days 07:30:00', '1 days 08:00:00', '1 days 08:30:00',\n                '1 days 09:00:00', '1 days 09:30:00', '1 days 10:00:00',\n                '1 days 10:30:00', '1 days 11:00:00', '1 days 11:30:00',\n                '1 days 12:00:00', '1 days 12:30:00', '1 days 13:00:00',\n                '1 days 13:30:00', '1 days 14:00:00', '1 days 14:30:00',\n                '1 days 15:00:00', '1 days 15:30:00', '1 days 16:00:00',\n                '1 days 16:30:00', '1 days 17:00:00', '1 days 17:30:00',\n                '1 days 18:00:00', '1 days 18:30:00', '1 days 19:00:00',\n                '1 days 19:30:00', '1 days 20:00:00', '1 days 20:30:00',\n                '1 days 21:00:00', '1 days 21:30:00', '1 days 22:00:00',\n                '1 days 22:30:00', '1 days 23:00:00', '1 days 23:30:00',\n                '2 days 00:00:00'],\n               dtype='timedelta64[ns]', freq='30T') \n```", "```py\nIn [20]: s = pd.Series(np.arange(5),\n ....:              index=pd.timedelta_range('1 days', periods=5, freq='s'))\n ....: \n\nIn [21]: s\nOut[21]: \n1 days 00:00:00    0\n1 days 00:00:01    1\n1 days 00:00:02    2\n1 days 00:00:03    3\n1 days 00:00:04    4\nFreq: s, Length: 5, dtype: int64 \n```", "```py\nIn [22]: s['1 day 00:00:02']\nOut[22]: 2\n\nIn [23]: s['1 day':'1 day 00:00:02']\nOut[23]: \n1 days 00:00:00    0\n1 days 00:00:01    1\n1 days 00:00:02    2\nFreq: s, Length: 3, dtype: int64 \n```", "```py\nIn [24]: tdi = pd.TimedeltaIndex(['1 days', pd.NaT, '2 days'])\n\nIn [25]: tdi.tolist()\nOut[25]: [Timedelta('1 days 00:00:00'), NaT, Timedelta('2 days 00:00:00')]\n\nIn [26]: dti = pd.date_range('20130101', periods=3)\n\nIn [27]: dti.tolist()\nOut[27]: \n[Timestamp('2013-01-01 00:00:00'),\n Timestamp('2013-01-02 00:00:00'),\n Timestamp('2013-01-03 00:00:00')]\n\nIn [28]: (dti + tdi).tolist()\nOut[28]: [Timestamp('2013-01-02 00:00:00'), NaT, Timestamp('2013-01-05 00:00:00')]\n\nIn [29]: (dti - tdi).tolist()\nOut[29]: [Timestamp('2012-12-31 00:00:00'), NaT, Timestamp('2013-01-01 00:00:00')] \n```", "```py\nIn [30]: dtypes = ['int64', 'float64', 'datetime64[ns]', 'timedelta64[ns]',\n ....:          'complex128', 'object', 'bool']\n ....: \n\nIn [31]: n = 5000\n\nIn [32]: data = {t: np.random.randint(100, size=n).astype(t) for t in dtypes}\n\nIn [33]: df = pd.DataFrame(data)\n\nIn [34]: df['categorical'] = df['object'].astype('category')\n\nIn [35]: df.info()\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5000 entries, 0 to 4999\nData columns (total 8 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   int64            5000 non-null   int64 \n 1   float64          5000 non-null   float64 \n 2   datetime64[ns]   5000 non-null   datetime64[ns] \n 3   timedelta64[ns]  5000 non-null   timedelta64[ns]\n 4   complex128       5000 non-null   complex128 \n 5   object           5000 non-null   object \n 6   bool             5000 non-null   bool \n 7   categorical      5000 non-null   category \ndtypes: bool(1), category(1), complex128(1), datetime64[ns](1), float64(1), int64(1), object(1), timedelta64[ns](1)\nmemory usage: 288.2+ KB \n```", "```py\nIn [36]: df.memory_usage(index=True)\nOut[36]: \nIndex                128\nint64              40000\nfloat64            40000\ndatetime64[ns]     40000\ntimedelta64[ns]    40000\ncomplex128         80000\nobject             40000\nbool                5000\ncategorical         9968\nLength: 9, dtype: int64 \n```", "```py\n# datetime\nIn [37]: s = pd.Series(pd.date_range('20130101 09:10:12', periods=4))\n\nIn [38]: s\nOut[38]: \n0   2013-01-01 09:10:12\n1   2013-01-02 09:10:12\n2   2013-01-03 09:10:12\n3   2013-01-04 09:10:12\nLength: 4, dtype: datetime64[ns]\n\nIn [39]: s.dt.hour\nOut[39]: \n0    9\n1    9\n2    9\n3    9\nLength: 4, dtype: int32\n\nIn [40]: s.dt.second\nOut[40]: \n0    12\n1    12\n2    12\n3    12\nLength: 4, dtype: int32\n\nIn [41]: s.dt.day\nOut[41]: \n0    1\n1    2\n2    3\n3    4\nLength: 4, dtype: int32\n\nIn [42]: s.dt.freq\nOut[42]: 'D' \n```", "```py\nIn [43]: s[s.dt.day == 2]\nOut[43]: \n1   2013-01-02 09:10:12\nLength: 1, dtype: datetime64[ns] \n```", "```py\nIn [44]: stz = s.dt.tz_localize('US/Eastern')\n\nIn [45]: stz\nOut[45]: \n0   2013-01-01 09:10:12-05:00\n1   2013-01-02 09:10:12-05:00\n2   2013-01-03 09:10:12-05:00\n3   2013-01-04 09:10:12-05:00\nLength: 4, dtype: datetime64[ns, US/Eastern]\n\nIn [46]: stz.dt.tz\nOut[46]: <DstTzInfo 'US/Eastern' LMT-1 day, 19:04:00 STD> \n```", "```py\nIn [47]: s.dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\nOut[47]: \n0   2013-01-01 04:10:12-05:00\n1   2013-01-02 04:10:12-05:00\n2   2013-01-03 04:10:12-05:00\n3   2013-01-04 04:10:12-05:00\nLength: 4, dtype: datetime64[ns, US/Eastern] \n```", "```py\n# period\nIn [48]: s = pd.Series(pd.period_range('20130101', periods=4, freq='D'))\n\nIn [49]: s\nOut[49]: \n0    2013-01-01\n1    2013-01-02\n2    2013-01-03\n3    2013-01-04\nLength: 4, dtype: period[D]\n\nIn [50]: s.dt.year\nOut[50]: \n0    2013\n1    2013\n2    2013\n3    2013\nLength: 4, dtype: int64\n\nIn [51]: s.dt.day\nOut[51]: \n0    1\n1    2\n2    3\n3    4\nLength: 4, dtype: int64 \n```", "```py\n# timedelta\nIn [52]: s = pd.Series(pd.timedelta_range('1 day 00:00:05', periods=4, freq='s'))\n\nIn [53]: s\nOut[53]: \n0   1 days 00:00:05\n1   1 days 00:00:06\n2   1 days 00:00:07\n3   1 days 00:00:08\nLength: 4, dtype: timedelta64[ns]\n\nIn [54]: s.dt.days\nOut[54]: \n0    1\n1    1\n2    1\n3    1\nLength: 4, dtype: int64\n\nIn [55]: s.dt.seconds\nOut[55]: \n0    5\n1    6\n2    7\n3    8\nLength: 4, dtype: int32\n\nIn [56]: s.dt.components\nOut[56]: \n days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds\n0     1      0        0        5             0             0            0\n1     1      0        0        6             0             0            0\n2     1      0        0        7             0             0            0\n3     1      0        0        8             0             0            0\n\n[4 rows x 7 columns] \n```", "```py\n    In [58]: ts = pd.Timestamp('2014-08-01 09:00', tz='US/Eastern')\n\n    In[59]: ts\n    Out[59]: Timestamp('2014-08-01 09:00:00-0400', tz='US/Eastern')\n\n    In [60]: ts.tz_localize(None)\n    Out[60]: Timestamp('2014-08-01 09:00:00')\n\n    In [61]: didx = pd.date_range(start='2014-08-01 09:00', freq='H',\n     ....:                     periods=10, tz='US/Eastern')\n     ....:\n\n    In [62]: didx\n    Out[62]:\n    DatetimeIndex(['2014-08-01 09:00:00-04:00', '2014-08-01 10:00:00-04:00',\n     '2014-08-01 11:00:00-04:00', '2014-08-01 12:00:00-04:00',\n     '2014-08-01 13:00:00-04:00', '2014-08-01 14:00:00-04:00',\n     '2014-08-01 15:00:00-04:00', '2014-08-01 16:00:00-04:00',\n     '2014-08-01 17:00:00-04:00', '2014-08-01 18:00:00-04:00'],\n     dtype='datetime64[ns, US/Eastern]', freq='H')\n\n    In [63]: didx.tz_localize(None)\n    Out[63]:\n    DatetimeIndex(['2014-08-01 09:00:00', '2014-08-01 10:00:00',\n     '2014-08-01 11:00:00', '2014-08-01 12:00:00',\n     '2014-08-01 13:00:00', '2014-08-01 14:00:00',\n     '2014-08-01 15:00:00', '2014-08-01 16:00:00',\n     '2014-08-01 17:00:00', '2014-08-01 18:00:00'],\n     dtype='datetime64[ns]', freq=None) \n    ```", "```py\n    In [57]: s = pd.Series([10, 11, 12, 13]) \n    ```", "```py\n    In [15]: pd.rolling_min(s, window=10, min_periods=5)\n    ValueError: min_periods (5) must be <= window (4) \n    ```", "```py\n    In [4]: pd.rolling_min(s, window=10, min_periods=5)\n    Out[4]:\n    0   NaN\n    1   NaN\n    2   NaN\n    3   NaN\n    dtype: float64 \n    ```", "```py\n    In [7]: pd.rolling_sum(Series(range(4)), window=3, min_periods=0, center=True)\n    Out[7]:\n    0     1\n    1     3\n    2     6\n    3   NaN\n    dtype: float64 \n    ```", "```py\n    In [7]: pd.rolling_sum(pd.Series(range(4)), window=3,\n     ....:                min_periods=0, center=True)\n    Out[7]:\n    0    1\n    1    3\n    2    6\n    3    5\n    dtype: float64 \n    ```", "```py\n    In [58]: s = pd.Series([10.5, 8.8, 11.4, 9.7, 9.3]) \n    ```", "```py\n    In [39]: pd.rolling_window(s, window=3, win_type='triang', center=True)\n    Out[39]:\n    0         NaN\n    1    6.583333\n    2    6.883333\n    3    6.683333\n    4         NaN\n    dtype: float64 \n    ```", "```py\n    In [10]: pd.rolling_window(s, window=3, win_type='triang', center=True)\n    Out[10]:\n    0       NaN\n    1     9.875\n    2    10.325\n    3    10.025\n    4       NaN\n    dtype: float64 \n    ```", "```py\n    In [59]: s  = pd.Series([1, None, None, None, 2, 3]) \n    ```", "```py\n    In [51]: pd.ewma(s, com=3., min_periods=2)\n    Out[51]:\n    0         NaN\n    1         NaN\n    2    1.000000\n    3    1.000000\n    4    1.571429\n    5    2.189189\n    dtype: float64 \n    ```", "```py\n    In [2]: pd.ewma(s, com=3., min_periods=2)\n    Out[2]:\n    0         NaN\n    1         NaN\n    2         NaN\n    3         NaN\n    4    1.759644\n    5    2.383784\n    dtype: float64 \n    ```", "```py\n    In [7]: pd.ewma(pd.Series([None, 1., 8.]), com=2.)\n    Out[7]:\n    0    NaN\n    1    1.0\n    2    5.2\n    dtype: float64\n\n    In [8]: pd.ewma(pd.Series([1., None, 8.]), com=2.,\n     ....:         ignore_na=True)  # pre-0.15.0 behavior\n    Out[8]:\n    0    1.0\n    1    1.0\n    2    5.2\n    dtype: float64\n\n    In [9]: pd.ewma(pd.Series([1., None, 8.]), com=2.,\n     ....:         ignore_na=False)  # new default\n    Out[9]:\n    0    1.000000\n    1    1.000000\n    2    5.846154\n    dtype: float64 \n    ```", "```py\n    In [60]: s = pd.Series([1., 2., 0., 4.]) \n    ```", "```py\n    In [89]: pd.ewmvar(s, com=2., bias=False)\n    Out[89]:\n    0   -2.775558e-16\n    1    3.000000e-01\n    2    9.556787e-01\n    3    3.585799e+00\n    dtype: float64\n\n    In [90]: pd.ewmvar(s, com=2., bias=False) / pd.ewmvar(s, com=2., bias=True)\n    Out[90]:\n    0    1.25\n    1    1.25\n    2    1.25\n    3    1.25\n    dtype: float64 \n    ```", "```py\n    In [14]: pd.ewmvar(s, com=2., bias=False)\n    Out[14]:\n    0         NaN\n    1    0.500000\n    2    1.210526\n    3    4.089069\n    dtype: float64\n\n    In [15]: pd.ewmvar(s, com=2., bias=False) / pd.ewmvar(s, com=2., bias=True)\n    Out[15]:\n    0         NaN\n    1    2.083333\n    2    1.583333\n    3    1.425439\n    dtype: float64 \n    ```", "```py\n    df.to_sql('table', engine, schema='other_schema')  # noqa F821\n    pd.read_sql_table('table', engine, schema='other_schema')  # noqa F821 \n    ```", "```py\n    pd.Categorical([0,1,0,2,1], levels=['a', 'b', 'c']) \n    ```", "```py\n    In [2]: pd.Categorical.from_codes([0,1,0,2,1], categories=['a', 'b', 'c'])\n    Out[2]:\n    [a, b, a, c, b]\n    Categories (3, object): [a, b, c] \n    ```", "```py\n    In [61]: df = pd.DataFrame([['a'], ['b']], index=[1, 2])\n\n    In [62]: df\n    Out[62]: \n     0\n    1  a\n    2  b\n\n    [2 rows x 1 columns] \n    ```", "```py\n    In [3]: df.loc[[1, 3]]\n    Out[3]:\n     0\n    1    a\n    3  NaN\n\n    In [4]: df.loc[[1, 3], :]\n    Out[4]:\n     0\n    1    a\n    3  NaN \n    ```", "```py\n    >>> p = pd.Panel(np.arange(2 * 3 * 4).reshape(2, 3, 4),\n    ...              items=['ItemA', 'ItemB'],\n    ...              major_axis=[1, 2, 3],\n    ...              minor_axis=['A', 'B', 'C', 'D'])\n    >>> p\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 2 (items) x 3 (major_axis) x 4 (minor_axis)\n    Items axis: ItemA to ItemB\n    Major_axis axis: 1 to 3\n    Minor_axis axis: A to D \n    ```", "```py\n    In [5]:\n    Out[5]:\n     ItemA  ItemD\n    1      3    NaN\n    2      7    NaN\n    3     11    NaN \n    ```", "```py\n    In [63]: s = pd.Series(np.arange(3, dtype='int64'),\n     ....:              index=pd.MultiIndex.from_product([['A'],\n     ....:                                               ['foo', 'bar', 'baz']],\n     ....:                                               names=['one', 'two'])\n     ....:              ).sort_index()\n     ....: \n\n    In [64]: s\n    Out[64]: \n    one  two\n    A    bar    1\n     baz    2\n     foo    0\n    Length: 3, dtype: int64\n\n    In [65]: try:\n     ....:    s.loc[['D']]\n     ....: except KeyError as e:\n     ....:    print(\"KeyError: \" + str(e))\n     ....: \n    KeyError: \"['D'] not in index\" \n    ```", "```py\n    In [66]: s = pd.Series([1., 2., 3.])\n\n    In [67]: s.loc[0] = None\n\n    In [68]: s\n    Out[68]: \n    0    NaN\n    1    2.0\n    2    3.0\n    Length: 3, dtype: float64 \n    ```", "```py\n    In [69]: s = pd.Series([\"a\", \"b\", \"c\"])\n\n    In [70]: s.loc[0] = None\n\n    In [71]: s\n    Out[71]: \n    0    None\n    1       b\n    2       c\n    Length: 3, dtype: object \n    ```", "```py\n    In [72]: s = pd.Series([1, 2, 3])\n\n    In [73]: s2 = s\n\n    In [74]: s += 1.5 \n    ```", "```py\n    # the original object\n    In [5]: s\n    Out[5]:\n    0    2.5\n    1    3.5\n    2    4.5\n    dtype: float64\n\n    # a reference to the original object\n    In [7]: s2\n    Out[7]:\n    0    1\n    1    2\n    2    3\n    dtype: int64 \n    ```", "```py\n    # the original object\n    In [75]: s\n    Out[75]: \n    0    2.5\n    1    3.5\n    2    4.5\n    Length: 3, dtype: float64\n\n    # a reference to the original object\n    In [76]: s2\n    Out[76]: \n    0    2.5\n    1    3.5\n    2    4.5\n    Length: 3, dtype: float64 \n    ```", "```py\n    In [77]: i = pd.date_range('1/1/2011', periods=3, freq='10s', tz='US/Eastern')\n\n    In [78]: i\n    Out[78]: \n    DatetimeIndex(['2011-01-01 00:00:00-05:00', '2011-01-01 00:00:10-05:00',\n     '2011-01-01 00:00:20-05:00'],\n     dtype='datetime64[ns, US/Eastern]', freq='10s')\n\n    In [79]: df = pd.DataFrame({'a': i})\n\n    In [80]: df\n    Out[80]: \n     a\n    0 2011-01-01 00:00:00-05:00\n    1 2011-01-01 00:00:10-05:00\n    2 2011-01-01 00:00:20-05:00\n\n    [3 rows x 1 columns]\n\n    In [81]: df.dtypes\n    Out[81]: \n    a    datetime64[ns, US/Eastern]\n    Length: 1, dtype: object \n    ```", "```py\n    In [1]: df = pd.DataFrame(np.arange(0, 9), columns=['count'])\n\n    In [2]: df['group'] = 'b'\n\n    In [3]: df.iloc[0:5]['group'] = 'a'\n    /usr/local/bin/ipython:1: SettingWithCopyWarning:\n    A value is trying to be set on a copy of a slice from a DataFrame.\n    Try using .loc[row_indexer,col_indexer] = value instead\n\n    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy \n    ```", "```py\n    In [82]: df = pd.DataFrame([[True, 1], [False, 2]],\n     ....:                  columns=[\"female\", \"fitness\"])\n     ....: \n\n    In [83]: df\n    Out[83]: \n     female  fitness\n    0    True        1\n    1   False        2\n\n    [2 rows x 2 columns]\n\n    In [84]: df.dtypes\n    Out[84]: \n    female      bool\n    fitness    int64\n    Length: 2, dtype: object\n\n    # dtypes are now preserved\n    In [85]: df.loc[2] = df.loc[1]\n\n    In [86]: df\n    Out[86]: \n     female  fitness\n    0    True        1\n    1   False        2\n    2   False        2\n\n    [3 rows x 2 columns]\n\n    In [87]: df.dtypes\n    Out[87]: \n    female      bool\n    fitness    int64\n    Length: 2, dtype: object \n    ```", "```py\n    # +\n    pd.Index(['a', 'b', 'c']) + pd.Index(['b', 'c', 'd'])\n\n    # should be replaced by\n    pd.Index(['a', 'b', 'c']).union(pd.Index(['b', 'c', 'd'])) \n    ```", "```py\n    # -\n    pd.Index(['a', 'b', 'c']) - pd.Index(['b', 'c', 'd'])\n\n    # should be replaced by\n    pd.Index(['a', 'b', 'c']).difference(pd.Index(['b', 'c', 'd'])) \n    ```", "```py\n    In [88]: df = pd.DataFrame({'catA': ['foo', 'foo', 'bar'] * 8,\n     ....:                   'catB': ['a', 'b', 'c', 'd'] * 6,\n     ....:                   'numC': np.arange(24),\n     ....:                   'numD': np.arange(24.) + .5})\n     ....: \n\n    In [89]: df.describe(include=[\"object\"])\n    Out[89]: \n     catA catB\n    count    24   24\n    unique    2    4\n    top     foo    a\n    freq     16    6\n\n    [4 rows x 2 columns]\n\n    In [90]: df.describe(include=[\"number\", \"object\"], exclude=[\"float\"])\n    Out[90]: \n     catA catB       numC\n    count    24   24  24.000000\n    unique    2    4        NaN\n    top     foo    a        NaN\n    freq     16    6        NaN\n    mean    NaN  NaN  11.500000\n    std     NaN  NaN   7.071068\n    min     NaN  NaN   0.000000\n    25%     NaN  NaN   5.750000\n    50%     NaN  NaN  11.500000\n    75%     NaN  NaN  17.250000\n    max     NaN  NaN  23.000000\n\n    [11 rows x 3 columns] \n    ```", "```py\n    In [91]: df.describe(include='all')\n    Out[91]: \n     catA catB       numC       numD\n    count    24   24  24.000000  24.000000\n    unique    2    4        NaN        NaN\n    top     foo    a        NaN        NaN\n    freq     16    6        NaN        NaN\n    mean    NaN  NaN  11.500000  12.000000\n    std     NaN  NaN   7.071068   7.071068\n    min     NaN  NaN   0.000000   0.500000\n    25%     NaN  NaN   5.750000   6.250000\n    50%     NaN  NaN  11.500000  12.000000\n    75%     NaN  NaN  17.250000  17.750000\n    max     NaN  NaN  23.000000  23.500000\n\n    [11 rows x 4 columns] \n    ```", "```py\n    In [92]: df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['c', 'c', 'b'],\n     ....:                'C': [1, 2, 3]})\n     ....: \n\n    In [93]: pd.get_dummies(df)\n    Out[93]: \n     C    A_a    A_b    B_b    B_c\n    0  1   True  False  False   True\n    1  2  False   True  False   True\n    2  3   True  False   True  False\n\n    [3 rows x 5 columns] \n    ```", "```py\n    In [94]: business_dates = pd.date_range(start='4/1/2014', end='6/30/2014', freq='B')\n\n    In [95]: df = pd.DataFrame(1, index=business_dates, columns=['a', 'b'])\n\n    # get the first, 4th, and last date index for each month\n    In [96]: df.groupby([df.index.year, df.index.month]).nth([0, 3, -1])\n    Out[96]: \n     a  b\n    2014-04-01  1  1\n    2014-04-04  1  1\n    2014-04-30  1  1\n    2014-05-01  1  1\n    2014-05-06  1  1\n    2014-05-30  1  1\n    2014-06-02  1  1\n    2014-06-05  1  1\n    2014-06-30  1  1\n\n    [9 rows x 2 columns] \n    ```", "```py\n    In [104]: idx = pd.period_range('2014-07-01 09:00', periods=5, freq='H')\n\n    In [105]: idx\n    Out[105]:\n    PeriodIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',\n     '2014-07-01 12:00', '2014-07-01 13:00'],\n     dtype='period[H]')\n\n    In [106]: idx + pd.offsets.Hour(2)\n    Out[106]:\n    PeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',\n     '2014-07-01 14:00', '2014-07-01 15:00'],\n     dtype='period[H]')\n\n    In [107]: idx + pd.Timedelta('120m')\n    Out[107]:\n    PeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',\n     '2014-07-01 14:00', '2014-07-01 15:00'],\n     dtype='period[H]')\n\n    In [108]: idx = pd.period_range('2014-07', periods=5, freq='M')\n\n    In [109]: idx\n    Out[109]: PeriodIndex(['2014-07', '2014-08', '2014-09', '2014-10', '2014-11'], dtype='period[M]')\n\n    In [110]: idx + pd.offsets.MonthEnd(3)\n    Out[110]: PeriodIndex(['2014-10', '2014-11', '2014-12', '2015-01', '2015-02'], dtype='period[M]') \n    ```", "```py\n    In [97]: idx = pd.MultiIndex.from_product([['a'], range(3), list(\"pqr\")],\n     ....:                                 names=['foo', 'bar', 'baz'])\n     ....: \n\n    In [98]: idx.set_names('qux', level=0)\n    Out[98]: \n    MultiIndex([('a', 0, 'p'),\n     ('a', 0, 'q'),\n     ('a', 0, 'r'),\n     ('a', 1, 'p'),\n     ('a', 1, 'q'),\n     ('a', 1, 'r'),\n     ('a', 2, 'p'),\n     ('a', 2, 'q'),\n     ('a', 2, 'r')],\n     names=['qux', 'bar', 'baz'])\n\n    In [99]: idx.set_names(['qux', 'corge'], level=[0, 1])\n    Out[99]: \n    MultiIndex([('a', 0, 'p'),\n     ('a', 0, 'q'),\n     ('a', 0, 'r'),\n     ('a', 1, 'p'),\n     ('a', 1, 'q'),\n     ('a', 1, 'r'),\n     ('a', 2, 'p'),\n     ('a', 2, 'q'),\n     ('a', 2, 'r')],\n     names=['qux', 'corge', 'baz'])\n\n    In [100]: idx.set_levels(['a', 'b', 'c'], level='bar')\n    Out[100]: \n    MultiIndex([('a', 'a', 'p'),\n     ('a', 'a', 'q'),\n     ('a', 'a', 'r'),\n     ('a', 'b', 'p'),\n     ('a', 'b', 'q'),\n     ('a', 'b', 'r'),\n     ('a', 'c', 'p'),\n     ('a', 'c', 'q'),\n     ('a', 'c', 'r')],\n     names=['foo', 'bar', 'baz'])\n\n    In [101]: idx.set_levels([['a', 'b', 'c'], [1, 2, 3]], level=[1, 2])\n    Out[101]: \n    MultiIndex([('a', 'a', 1),\n     ('a', 'a', 2),\n     ('a', 'a', 3),\n     ('a', 'b', 1),\n     ('a', 'b', 2),\n     ('a', 'b', 3),\n     ('a', 'c', 1),\n     ('a', 'c', 2),\n     ('a', 'c', 3)],\n     names=['foo', 'bar', 'baz']) \n    ```", "```py\n    In [1]: idx = pd.MultiIndex.from_product([[0, 1], ['a', 'b', 'c']])\n\n    In [2]: idx.values\n    Out[2]: array([(0, 'a'), (0, 'b'), (0, 'c'), (1, 'a'), (1, 'b'), (1, 'c')], dtype=object)\n\n    In [3]: idx.isin(['a', 'c', 'e'], level=1)\n    Out[3]: array([ True, False,  True,  True, False,  True], dtype=bool) \n    ```", "```py\n    In [102]: idx = pd.Index([1, 2, 3, 4, 1, 2])\n\n    In [103]: idx\n    Out[103]: Index([1, 2, 3, 4, 1, 2], dtype='int64')\n\n    In [104]: idx.duplicated()\n    Out[104]: array([False, False, False, False,  True,  True])\n\n    In [105]: idx.drop_duplicates()\n    Out[105]: Index([1, 2, 3, 4], dtype='int64') \n    ```", "```py\nIn [1]: df = pd.DataFrame({\"id\": [1, 2, 3, 4, 5, 6],\n ...:                   \"raw_grade\": ['a', 'b', 'b', 'a', 'a', 'e']})\n ...: \n\nIn [2]: df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\n\nIn [3]: df[\"grade\"]\nOut[3]: \n0    a\n1    b\n2    b\n3    a\n4    a\n5    e\nName: grade, Length: 6, dtype: category\nCategories (3, object): ['a', 'b', 'e']\n\n# Rename the categories\nIn [4]: df[\"grade\"] = df[\"grade\"].cat.rename_categories([\"very good\", \"good\", \"very bad\"])\n\n# Reorder the categories and simultaneously add the missing categories\nIn [5]: df[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\",\n ...:                                              \"medium\", \"good\", \"very good\"])\n ...: \n\nIn [6]: df[\"grade\"]\nOut[6]: \n0    very good\n1         good\n2         good\n3    very good\n4    very good\n5     very bad\nName: grade, Length: 6, dtype: category\nCategories (5, object): ['very bad', 'bad', 'medium', 'good', 'very good']\n\nIn [7]: df.sort_values(\"grade\")\nOut[7]: \n id raw_grade      grade\n5   6         e   very bad\n1   2         b       good\n2   3         b       good\n0   1         a  very good\n3   4         a  very good\n4   5         a  very good\n\n[6 rows x 3 columns]\n\nIn [8]: df.groupby(\"grade\", observed=False).size()\nOut[8]: \ngrade\nvery bad     1\nbad          0\nmedium       0\ngood         2\nvery good    3\nLength: 5, dtype: int64 \n```", "```py\n# Timedelta accessor\nIn [9]: tds = pd.Timedelta('31 days 5 min 3 sec')\n\nIn [10]: tds.minutes\nOut[10]: 5L\n\nIn [11]: tds.seconds\nOut[11]: 3L\n\n# datetime.timedelta accessor\n# this is 5 minutes * 60 + 3 seconds\nIn [12]: tds.to_pytimedelta().seconds\nOut[12]: 303 \n```", "```py\nIn [9]: pd.Timedelta('1 days 06:05:01.00003')\nOut[9]: Timedelta('1 days 06:05:01.000030')\n\nIn [10]: pd.Timedelta('15.5us')\nOut[10]: Timedelta('0 days 00:00:00.000015500')\n\nIn [11]: pd.Timedelta('1 hour 15.5us')\nOut[11]: Timedelta('0 days 01:00:00.000015500')\n\n# negative Timedeltas have this string repr\n# to be more consistent with datetime.timedelta conventions\nIn [12]: pd.Timedelta('-1us')\nOut[12]: Timedelta('-1 days +23:59:59.999999')\n\n# a NaT\nIn [13]: pd.Timedelta('nan')\nOut[13]: NaT \n```", "```py\nIn [14]: td = pd.Timedelta('1 hour 3m 15.5us')\n\nIn [15]: td.seconds\nOut[15]: 3780\n\nIn [16]: td.microseconds\nOut[16]: 15\n\nIn [17]: td.nanoseconds\nOut[17]: 500 \n```", "```py\nIn [18]: pd.TimedeltaIndex(['1 days', '1 days, 00:00:05',\n ....:                   np.timedelta64(2, 'D'),\n ....:                   datetime.timedelta(days=2, seconds=2)])\n ....: \nOut[18]: \nTimedeltaIndex(['1 days 00:00:00', '1 days 00:00:05', '2 days 00:00:00',\n '2 days 00:00:02'],\n dtype='timedelta64[ns]', freq=None) \n```", "```py\nIn [19]: pd.timedelta_range('1 days', periods=5, freq='D')\nOut[19]: TimedeltaIndex(['1 days', '2 days', '3 days', '4 days', '5 days'], dtype='timedelta64[ns]', freq='D') \n```", "```py\nIn [20]: pd.timedelta_range(start='1 days', end='2 days', freq='30T')\nOut[20]:\nTimedeltaIndex(['1 days 00:00:00', '1 days 00:30:00', '1 days 01:00:00',\n                '1 days 01:30:00', '1 days 02:00:00', '1 days 02:30:00',\n                '1 days 03:00:00', '1 days 03:30:00', '1 days 04:00:00',\n                '1 days 04:30:00', '1 days 05:00:00', '1 days 05:30:00',\n                '1 days 06:00:00', '1 days 06:30:00', '1 days 07:00:00',\n                '1 days 07:30:00', '1 days 08:00:00', '1 days 08:30:00',\n                '1 days 09:00:00', '1 days 09:30:00', '1 days 10:00:00',\n                '1 days 10:30:00', '1 days 11:00:00', '1 days 11:30:00',\n                '1 days 12:00:00', '1 days 12:30:00', '1 days 13:00:00',\n                '1 days 13:30:00', '1 days 14:00:00', '1 days 14:30:00',\n                '1 days 15:00:00', '1 days 15:30:00', '1 days 16:00:00',\n                '1 days 16:30:00', '1 days 17:00:00', '1 days 17:30:00',\n                '1 days 18:00:00', '1 days 18:30:00', '1 days 19:00:00',\n                '1 days 19:30:00', '1 days 20:00:00', '1 days 20:30:00',\n                '1 days 21:00:00', '1 days 21:30:00', '1 days 22:00:00',\n                '1 days 22:30:00', '1 days 23:00:00', '1 days 23:30:00',\n                '2 days 00:00:00'],\n               dtype='timedelta64[ns]', freq='30T') \n```", "```py\nIn [20]: s = pd.Series(np.arange(5),\n ....:              index=pd.timedelta_range('1 days', periods=5, freq='s'))\n ....: \n\nIn [21]: s\nOut[21]: \n1 days 00:00:00    0\n1 days 00:00:01    1\n1 days 00:00:02    2\n1 days 00:00:03    3\n1 days 00:00:04    4\nFreq: s, Length: 5, dtype: int64 \n```", "```py\nIn [22]: s['1 day 00:00:02']\nOut[22]: 2\n\nIn [23]: s['1 day':'1 day 00:00:02']\nOut[23]: \n1 days 00:00:00    0\n1 days 00:00:01    1\n1 days 00:00:02    2\nFreq: s, Length: 3, dtype: int64 \n```", "```py\nIn [24]: tdi = pd.TimedeltaIndex(['1 days', pd.NaT, '2 days'])\n\nIn [25]: tdi.tolist()\nOut[25]: [Timedelta('1 days 00:00:00'), NaT, Timedelta('2 days 00:00:00')]\n\nIn [26]: dti = pd.date_range('20130101', periods=3)\n\nIn [27]: dti.tolist()\nOut[27]: \n[Timestamp('2013-01-01 00:00:00'),\n Timestamp('2013-01-02 00:00:00'),\n Timestamp('2013-01-03 00:00:00')]\n\nIn [28]: (dti + tdi).tolist()\nOut[28]: [Timestamp('2013-01-02 00:00:00'), NaT, Timestamp('2013-01-05 00:00:00')]\n\nIn [29]: (dti - tdi).tolist()\nOut[29]: [Timestamp('2012-12-31 00:00:00'), NaT, Timestamp('2013-01-01 00:00:00')] \n```", "```py\nIn [30]: dtypes = ['int64', 'float64', 'datetime64[ns]', 'timedelta64[ns]',\n ....:          'complex128', 'object', 'bool']\n ....: \n\nIn [31]: n = 5000\n\nIn [32]: data = {t: np.random.randint(100, size=n).astype(t) for t in dtypes}\n\nIn [33]: df = pd.DataFrame(data)\n\nIn [34]: df['categorical'] = df['object'].astype('category')\n\nIn [35]: df.info()\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5000 entries, 0 to 4999\nData columns (total 8 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   int64            5000 non-null   int64 \n 1   float64          5000 non-null   float64 \n 2   datetime64[ns]   5000 non-null   datetime64[ns] \n 3   timedelta64[ns]  5000 non-null   timedelta64[ns]\n 4   complex128       5000 non-null   complex128 \n 5   object           5000 non-null   object \n 6   bool             5000 non-null   bool \n 7   categorical      5000 non-null   category \ndtypes: bool(1), category(1), complex128(1), datetime64[ns](1), float64(1), int64(1), object(1), timedelta64[ns](1)\nmemory usage: 288.2+ KB \n```", "```py\nIn [36]: df.memory_usage(index=True)\nOut[36]: \nIndex                128\nint64              40000\nfloat64            40000\ndatetime64[ns]     40000\ntimedelta64[ns]    40000\ncomplex128         80000\nobject             40000\nbool                5000\ncategorical         9968\nLength: 9, dtype: int64 \n```", "```py\n# datetime\nIn [37]: s = pd.Series(pd.date_range('20130101 09:10:12', periods=4))\n\nIn [38]: s\nOut[38]: \n0   2013-01-01 09:10:12\n1   2013-01-02 09:10:12\n2   2013-01-03 09:10:12\n3   2013-01-04 09:10:12\nLength: 4, dtype: datetime64[ns]\n\nIn [39]: s.dt.hour\nOut[39]: \n0    9\n1    9\n2    9\n3    9\nLength: 4, dtype: int32\n\nIn [40]: s.dt.second\nOut[40]: \n0    12\n1    12\n2    12\n3    12\nLength: 4, dtype: int32\n\nIn [41]: s.dt.day\nOut[41]: \n0    1\n1    2\n2    3\n3    4\nLength: 4, dtype: int32\n\nIn [42]: s.dt.freq\nOut[42]: 'D' \n```", "```py\nIn [43]: s[s.dt.day == 2]\nOut[43]: \n1   2013-01-02 09:10:12\nLength: 1, dtype: datetime64[ns] \n```", "```py\nIn [44]: stz = s.dt.tz_localize('US/Eastern')\n\nIn [45]: stz\nOut[45]: \n0   2013-01-01 09:10:12-05:00\n1   2013-01-02 09:10:12-05:00\n2   2013-01-03 09:10:12-05:00\n3   2013-01-04 09:10:12-05:00\nLength: 4, dtype: datetime64[ns, US/Eastern]\n\nIn [46]: stz.dt.tz\nOut[46]: <DstTzInfo 'US/Eastern' LMT-1 day, 19:04:00 STD> \n```", "```py\nIn [47]: s.dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\nOut[47]: \n0   2013-01-01 04:10:12-05:00\n1   2013-01-02 04:10:12-05:00\n2   2013-01-03 04:10:12-05:00\n3   2013-01-04 04:10:12-05:00\nLength: 4, dtype: datetime64[ns, US/Eastern] \n```", "```py\n# period\nIn [48]: s = pd.Series(pd.period_range('20130101', periods=4, freq='D'))\n\nIn [49]: s\nOut[49]: \n0    2013-01-01\n1    2013-01-02\n2    2013-01-03\n3    2013-01-04\nLength: 4, dtype: period[D]\n\nIn [50]: s.dt.year\nOut[50]: \n0    2013\n1    2013\n2    2013\n3    2013\nLength: 4, dtype: int64\n\nIn [51]: s.dt.day\nOut[51]: \n0    1\n1    2\n2    3\n3    4\nLength: 4, dtype: int64 \n```", "```py\n# timedelta\nIn [52]: s = pd.Series(pd.timedelta_range('1 day 00:00:05', periods=4, freq='s'))\n\nIn [53]: s\nOut[53]: \n0   1 days 00:00:05\n1   1 days 00:00:06\n2   1 days 00:00:07\n3   1 days 00:00:08\nLength: 4, dtype: timedelta64[ns]\n\nIn [54]: s.dt.days\nOut[54]: \n0    1\n1    1\n2    1\n3    1\nLength: 4, dtype: int64\n\nIn [55]: s.dt.seconds\nOut[55]: \n0    5\n1    6\n2    7\n3    8\nLength: 4, dtype: int32\n\nIn [56]: s.dt.components\nOut[56]: \n days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds\n0     1      0        0        5             0             0            0\n1     1      0        0        6             0             0            0\n2     1      0        0        7             0             0            0\n3     1      0        0        8             0             0            0\n\n[4 rows x 7 columns] \n```", "```py\n    In [58]: ts = pd.Timestamp('2014-08-01 09:00', tz='US/Eastern')\n\n    In[59]: ts\n    Out[59]: Timestamp('2014-08-01 09:00:00-0400', tz='US/Eastern')\n\n    In [60]: ts.tz_localize(None)\n    Out[60]: Timestamp('2014-08-01 09:00:00')\n\n    In [61]: didx = pd.date_range(start='2014-08-01 09:00', freq='H',\n     ....:                     periods=10, tz='US/Eastern')\n     ....:\n\n    In [62]: didx\n    Out[62]:\n    DatetimeIndex(['2014-08-01 09:00:00-04:00', '2014-08-01 10:00:00-04:00',\n     '2014-08-01 11:00:00-04:00', '2014-08-01 12:00:00-04:00',\n     '2014-08-01 13:00:00-04:00', '2014-08-01 14:00:00-04:00',\n     '2014-08-01 15:00:00-04:00', '2014-08-01 16:00:00-04:00',\n     '2014-08-01 17:00:00-04:00', '2014-08-01 18:00:00-04:00'],\n     dtype='datetime64[ns, US/Eastern]', freq='H')\n\n    In [63]: didx.tz_localize(None)\n    Out[63]:\n    DatetimeIndex(['2014-08-01 09:00:00', '2014-08-01 10:00:00',\n     '2014-08-01 11:00:00', '2014-08-01 12:00:00',\n     '2014-08-01 13:00:00', '2014-08-01 14:00:00',\n     '2014-08-01 15:00:00', '2014-08-01 16:00:00',\n     '2014-08-01 17:00:00', '2014-08-01 18:00:00'],\n     dtype='datetime64[ns]', freq=None) \n    ```", "```py\n    In [57]: s = pd.Series([10, 11, 12, 13]) \n    ```", "```py\n    In [15]: pd.rolling_min(s, window=10, min_periods=5)\n    ValueError: min_periods (5) must be <= window (4) \n    ```", "```py\n    In [4]: pd.rolling_min(s, window=10, min_periods=5)\n    Out[4]:\n    0   NaN\n    1   NaN\n    2   NaN\n    3   NaN\n    dtype: float64 \n    ```", "```py\n    In [7]: pd.rolling_sum(Series(range(4)), window=3, min_periods=0, center=True)\n    Out[7]:\n    0     1\n    1     3\n    2     6\n    3   NaN\n    dtype: float64 \n    ```", "```py\n    In [7]: pd.rolling_sum(pd.Series(range(4)), window=3,\n     ....:                min_periods=0, center=True)\n    Out[7]:\n    0    1\n    1    3\n    2    6\n    3    5\n    dtype: float64 \n    ```", "```py\n    In [58]: s = pd.Series([10.5, 8.8, 11.4, 9.7, 9.3]) \n    ```", "```py\n    In [39]: pd.rolling_window(s, window=3, win_type='triang', center=True)\n    Out[39]:\n    0         NaN\n    1    6.583333\n    2    6.883333\n    3    6.683333\n    4         NaN\n    dtype: float64 \n    ```", "```py\n    In [10]: pd.rolling_window(s, window=3, win_type='triang', center=True)\n    Out[10]:\n    0       NaN\n    1     9.875\n    2    10.325\n    3    10.025\n    4       NaN\n    dtype: float64 \n    ```", "```py\n    In [59]: s  = pd.Series([1, None, None, None, 2, 3]) \n    ```", "```py\n    In [51]: pd.ewma(s, com=3., min_periods=2)\n    Out[51]:\n    0         NaN\n    1         NaN\n    2    1.000000\n    3    1.000000\n    4    1.571429\n    5    2.189189\n    dtype: float64 \n    ```", "```py\n    In [2]: pd.ewma(s, com=3., min_periods=2)\n    Out[2]:\n    0         NaN\n    1         NaN\n    2         NaN\n    3         NaN\n    4    1.759644\n    5    2.383784\n    dtype: float64 \n    ```", "```py\n    In [7]: pd.ewma(pd.Series([None, 1., 8.]), com=2.)\n    Out[7]:\n    0    NaN\n    1    1.0\n    2    5.2\n    dtype: float64\n\n    In [8]: pd.ewma(pd.Series([1., None, 8.]), com=2.,\n     ....:         ignore_na=True)  # pre-0.15.0 behavior\n    Out[8]:\n    0    1.0\n    1    1.0\n    2    5.2\n    dtype: float64\n\n    In [9]: pd.ewma(pd.Series([1., None, 8.]), com=2.,\n     ....:         ignore_na=False)  # new default\n    Out[9]:\n    0    1.000000\n    1    1.000000\n    2    5.846154\n    dtype: float64 \n    ```", "```py\n    In [60]: s = pd.Series([1., 2., 0., 4.]) \n    ```", "```py\n    In [89]: pd.ewmvar(s, com=2., bias=False)\n    Out[89]:\n    0   -2.775558e-16\n    1    3.000000e-01\n    2    9.556787e-01\n    3    3.585799e+00\n    dtype: float64\n\n    In [90]: pd.ewmvar(s, com=2., bias=False) / pd.ewmvar(s, com=2., bias=True)\n    Out[90]:\n    0    1.25\n    1    1.25\n    2    1.25\n    3    1.25\n    dtype: float64 \n    ```", "```py\n    In [14]: pd.ewmvar(s, com=2., bias=False)\n    Out[14]:\n    0         NaN\n    1    0.500000\n    2    1.210526\n    3    4.089069\n    dtype: float64\n\n    In [15]: pd.ewmvar(s, com=2., bias=False) / pd.ewmvar(s, com=2., bias=True)\n    Out[15]:\n    0         NaN\n    1    2.083333\n    2    1.583333\n    3    1.425439\n    dtype: float64 \n    ```", "```py\n    df.to_sql('table', engine, schema='other_schema')  # noqa F821\n    pd.read_sql_table('table', engine, schema='other_schema')  # noqa F821 \n    ```", "```py\nIn [1]: df = pd.DataFrame({\"id\": [1, 2, 3, 4, 5, 6],\n ...:                   \"raw_grade\": ['a', 'b', 'b', 'a', 'a', 'e']})\n ...: \n\nIn [2]: df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\n\nIn [3]: df[\"grade\"]\nOut[3]: \n0    a\n1    b\n2    b\n3    a\n4    a\n5    e\nName: grade, Length: 6, dtype: category\nCategories (3, object): ['a', 'b', 'e']\n\n# Rename the categories\nIn [4]: df[\"grade\"] = df[\"grade\"].cat.rename_categories([\"very good\", \"good\", \"very bad\"])\n\n# Reorder the categories and simultaneously add the missing categories\nIn [5]: df[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\",\n ...:                                              \"medium\", \"good\", \"very good\"])\n ...: \n\nIn [6]: df[\"grade\"]\nOut[6]: \n0    very good\n1         good\n2         good\n3    very good\n4    very good\n5     very bad\nName: grade, Length: 6, dtype: category\nCategories (5, object): ['very bad', 'bad', 'medium', 'good', 'very good']\n\nIn [7]: df.sort_values(\"grade\")\nOut[7]: \n id raw_grade      grade\n5   6         e   very bad\n1   2         b       good\n2   3         b       good\n0   1         a  very good\n3   4         a  very good\n4   5         a  very good\n\n[6 rows x 3 columns]\n\nIn [8]: df.groupby(\"grade\", observed=False).size()\nOut[8]: \ngrade\nvery bad     1\nbad          0\nmedium       0\ngood         2\nvery good    3\nLength: 5, dtype: int64 \n```", "```py\n# Timedelta accessor\nIn [9]: tds = pd.Timedelta('31 days 5 min 3 sec')\n\nIn [10]: tds.minutes\nOut[10]: 5L\n\nIn [11]: tds.seconds\nOut[11]: 3L\n\n# datetime.timedelta accessor\n# this is 5 minutes * 60 + 3 seconds\nIn [12]: tds.to_pytimedelta().seconds\nOut[12]: 303 \n```", "```py\nIn [9]: pd.Timedelta('1 days 06:05:01.00003')\nOut[9]: Timedelta('1 days 06:05:01.000030')\n\nIn [10]: pd.Timedelta('15.5us')\nOut[10]: Timedelta('0 days 00:00:00.000015500')\n\nIn [11]: pd.Timedelta('1 hour 15.5us')\nOut[11]: Timedelta('0 days 01:00:00.000015500')\n\n# negative Timedeltas have this string repr\n# to be more consistent with datetime.timedelta conventions\nIn [12]: pd.Timedelta('-1us')\nOut[12]: Timedelta('-1 days +23:59:59.999999')\n\n# a NaT\nIn [13]: pd.Timedelta('nan')\nOut[13]: NaT \n```", "```py\nIn [14]: td = pd.Timedelta('1 hour 3m 15.5us')\n\nIn [15]: td.seconds\nOut[15]: 3780\n\nIn [16]: td.microseconds\nOut[16]: 15\n\nIn [17]: td.nanoseconds\nOut[17]: 500 \n```", "```py\nIn [18]: pd.TimedeltaIndex(['1 days', '1 days, 00:00:05',\n ....:                   np.timedelta64(2, 'D'),\n ....:                   datetime.timedelta(days=2, seconds=2)])\n ....: \nOut[18]: \nTimedeltaIndex(['1 days 00:00:00', '1 days 00:00:05', '2 days 00:00:00',\n '2 days 00:00:02'],\n dtype='timedelta64[ns]', freq=None) \n```", "```py\nIn [19]: pd.timedelta_range('1 days', periods=5, freq='D')\nOut[19]: TimedeltaIndex(['1 days', '2 days', '3 days', '4 days', '5 days'], dtype='timedelta64[ns]', freq='D') \n```", "```py\nIn [20]: pd.timedelta_range(start='1 days', end='2 days', freq='30T')\nOut[20]:\nTimedeltaIndex(['1 days 00:00:00', '1 days 00:30:00', '1 days 01:00:00',\n                '1 days 01:30:00', '1 days 02:00:00', '1 days 02:30:00',\n                '1 days 03:00:00', '1 days 03:30:00', '1 days 04:00:00',\n                '1 days 04:30:00', '1 days 05:00:00', '1 days 05:30:00',\n                '1 days 06:00:00', '1 days 06:30:00', '1 days 07:00:00',\n                '1 days 07:30:00', '1 days 08:00:00', '1 days 08:30:00',\n                '1 days 09:00:00', '1 days 09:30:00', '1 days 10:00:00',\n                '1 days 10:30:00', '1 days 11:00:00', '1 days 11:30:00',\n                '1 days 12:00:00', '1 days 12:30:00', '1 days 13:00:00',\n                '1 days 13:30:00', '1 days 14:00:00', '1 days 14:30:00',\n                '1 days 15:00:00', '1 days 15:30:00', '1 days 16:00:00',\n                '1 days 16:30:00', '1 days 17:00:00', '1 days 17:30:00',\n                '1 days 18:00:00', '1 days 18:30:00', '1 days 19:00:00',\n                '1 days 19:30:00', '1 days 20:00:00', '1 days 20:30:00',\n                '1 days 21:00:00', '1 days 21:30:00', '1 days 22:00:00',\n                '1 days 22:30:00', '1 days 23:00:00', '1 days 23:30:00',\n                '2 days 00:00:00'],\n               dtype='timedelta64[ns]', freq='30T') \n```", "```py\nIn [20]: s = pd.Series(np.arange(5),\n ....:              index=pd.timedelta_range('1 days', periods=5, freq='s'))\n ....: \n\nIn [21]: s\nOut[21]: \n1 days 00:00:00    0\n1 days 00:00:01    1\n1 days 00:00:02    2\n1 days 00:00:03    3\n1 days 00:00:04    4\nFreq: s, Length: 5, dtype: int64 \n```", "```py\nIn [22]: s['1 day 00:00:02']\nOut[22]: 2\n\nIn [23]: s['1 day':'1 day 00:00:02']\nOut[23]: \n1 days 00:00:00    0\n1 days 00:00:01    1\n1 days 00:00:02    2\nFreq: s, Length: 3, dtype: int64 \n```", "```py\nIn [24]: tdi = pd.TimedeltaIndex(['1 days', pd.NaT, '2 days'])\n\nIn [25]: tdi.tolist()\nOut[25]: [Timedelta('1 days 00:00:00'), NaT, Timedelta('2 days 00:00:00')]\n\nIn [26]: dti = pd.date_range('20130101', periods=3)\n\nIn [27]: dti.tolist()\nOut[27]: \n[Timestamp('2013-01-01 00:00:00'),\n Timestamp('2013-01-02 00:00:00'),\n Timestamp('2013-01-03 00:00:00')]\n\nIn [28]: (dti + tdi).tolist()\nOut[28]: [Timestamp('2013-01-02 00:00:00'), NaT, Timestamp('2013-01-05 00:00:00')]\n\nIn [29]: (dti - tdi).tolist()\nOut[29]: [Timestamp('2012-12-31 00:00:00'), NaT, Timestamp('2013-01-01 00:00:00')] \n```", "```py\nIn [30]: dtypes = ['int64', 'float64', 'datetime64[ns]', 'timedelta64[ns]',\n ....:          'complex128', 'object', 'bool']\n ....: \n\nIn [31]: n = 5000\n\nIn [32]: data = {t: np.random.randint(100, size=n).astype(t) for t in dtypes}\n\nIn [33]: df = pd.DataFrame(data)\n\nIn [34]: df['categorical'] = df['object'].astype('category')\n\nIn [35]: df.info()\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5000 entries, 0 to 4999\nData columns (total 8 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   int64            5000 non-null   int64 \n 1   float64          5000 non-null   float64 \n 2   datetime64[ns]   5000 non-null   datetime64[ns] \n 3   timedelta64[ns]  5000 non-null   timedelta64[ns]\n 4   complex128       5000 non-null   complex128 \n 5   object           5000 non-null   object \n 6   bool             5000 non-null   bool \n 7   categorical      5000 non-null   category \ndtypes: bool(1), category(1), complex128(1), datetime64[ns](1), float64(1), int64(1), object(1), timedelta64[ns](1)\nmemory usage: 288.2+ KB \n```", "```py\nIn [36]: df.memory_usage(index=True)\nOut[36]: \nIndex                128\nint64              40000\nfloat64            40000\ndatetime64[ns]     40000\ntimedelta64[ns]    40000\ncomplex128         80000\nobject             40000\nbool                5000\ncategorical         9968\nLength: 9, dtype: int64 \n```", "```py\n# datetime\nIn [37]: s = pd.Series(pd.date_range('20130101 09:10:12', periods=4))\n\nIn [38]: s\nOut[38]: \n0   2013-01-01 09:10:12\n1   2013-01-02 09:10:12\n2   2013-01-03 09:10:12\n3   2013-01-04 09:10:12\nLength: 4, dtype: datetime64[ns]\n\nIn [39]: s.dt.hour\nOut[39]: \n0    9\n1    9\n2    9\n3    9\nLength: 4, dtype: int32\n\nIn [40]: s.dt.second\nOut[40]: \n0    12\n1    12\n2    12\n3    12\nLength: 4, dtype: int32\n\nIn [41]: s.dt.day\nOut[41]: \n0    1\n1    2\n2    3\n3    4\nLength: 4, dtype: int32\n\nIn [42]: s.dt.freq\nOut[42]: 'D' \n```", "```py\nIn [43]: s[s.dt.day == 2]\nOut[43]: \n1   2013-01-02 09:10:12\nLength: 1, dtype: datetime64[ns] \n```", "```py\nIn [44]: stz = s.dt.tz_localize('US/Eastern')\n\nIn [45]: stz\nOut[45]: \n0   2013-01-01 09:10:12-05:00\n1   2013-01-02 09:10:12-05:00\n2   2013-01-03 09:10:12-05:00\n3   2013-01-04 09:10:12-05:00\nLength: 4, dtype: datetime64[ns, US/Eastern]\n\nIn [46]: stz.dt.tz\nOut[46]: <DstTzInfo 'US/Eastern' LMT-1 day, 19:04:00 STD> \n```", "```py\nIn [47]: s.dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\nOut[47]: \n0   2013-01-01 04:10:12-05:00\n1   2013-01-02 04:10:12-05:00\n2   2013-01-03 04:10:12-05:00\n3   2013-01-04 04:10:12-05:00\nLength: 4, dtype: datetime64[ns, US/Eastern] \n```", "```py\n# period\nIn [48]: s = pd.Series(pd.period_range('20130101', periods=4, freq='D'))\n\nIn [49]: s\nOut[49]: \n0    2013-01-01\n1    2013-01-02\n2    2013-01-03\n3    2013-01-04\nLength: 4, dtype: period[D]\n\nIn [50]: s.dt.year\nOut[50]: \n0    2013\n1    2013\n2    2013\n3    2013\nLength: 4, dtype: int64\n\nIn [51]: s.dt.day\nOut[51]: \n0    1\n1    2\n2    3\n3    4\nLength: 4, dtype: int64 \n```", "```py\n# timedelta\nIn [52]: s = pd.Series(pd.timedelta_range('1 day 00:00:05', periods=4, freq='s'))\n\nIn [53]: s\nOut[53]: \n0   1 days 00:00:05\n1   1 days 00:00:06\n2   1 days 00:00:07\n3   1 days 00:00:08\nLength: 4, dtype: timedelta64[ns]\n\nIn [54]: s.dt.days\nOut[54]: \n0    1\n1    1\n2    1\n3    1\nLength: 4, dtype: int64\n\nIn [55]: s.dt.seconds\nOut[55]: \n0    5\n1    6\n2    7\n3    8\nLength: 4, dtype: int32\n\nIn [56]: s.dt.components\nOut[56]: \n days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds\n0     1      0        0        5             0             0            0\n1     1      0        0        6             0             0            0\n2     1      0        0        7             0             0            0\n3     1      0        0        8             0             0            0\n\n[4 rows x 7 columns] \n```", "```py\n    In [58]: ts = pd.Timestamp('2014-08-01 09:00', tz='US/Eastern')\n\n    In[59]: ts\n    Out[59]: Timestamp('2014-08-01 09:00:00-0400', tz='US/Eastern')\n\n    In [60]: ts.tz_localize(None)\n    Out[60]: Timestamp('2014-08-01 09:00:00')\n\n    In [61]: didx = pd.date_range(start='2014-08-01 09:00', freq='H',\n     ....:                     periods=10, tz='US/Eastern')\n     ....:\n\n    In [62]: didx\n    Out[62]:\n    DatetimeIndex(['2014-08-01 09:00:00-04:00', '2014-08-01 10:00:00-04:00',\n     '2014-08-01 11:00:00-04:00', '2014-08-01 12:00:00-04:00',\n     '2014-08-01 13:00:00-04:00', '2014-08-01 14:00:00-04:00',\n     '2014-08-01 15:00:00-04:00', '2014-08-01 16:00:00-04:00',\n     '2014-08-01 17:00:00-04:00', '2014-08-01 18:00:00-04:00'],\n     dtype='datetime64[ns, US/Eastern]', freq='H')\n\n    In [63]: didx.tz_localize(None)\n    Out[63]:\n    DatetimeIndex(['2014-08-01 09:00:00', '2014-08-01 10:00:00',\n     '2014-08-01 11:00:00', '2014-08-01 12:00:00',\n     '2014-08-01 13:00:00', '2014-08-01 14:00:00',\n     '2014-08-01 15:00:00', '2014-08-01 16:00:00',\n     '2014-08-01 17:00:00', '2014-08-01 18:00:00'],\n     dtype='datetime64[ns]', freq=None) \n    ```", "```py\n    In [57]: s = pd.Series([10, 11, 12, 13]) \n    ```", "```py\n    In [15]: pd.rolling_min(s, window=10, min_periods=5)\n    ValueError: min_periods (5) must be <= window (4) \n    ```", "```py\n    In [4]: pd.rolling_min(s, window=10, min_periods=5)\n    Out[4]:\n    0   NaN\n    1   NaN\n    2   NaN\n    3   NaN\n    dtype: float64 \n    ```", "```py\n    In [7]: pd.rolling_sum(Series(range(4)), window=3, min_periods=0, center=True)\n    Out[7]:\n    0     1\n    1     3\n    2     6\n    3   NaN\n    dtype: float64 \n    ```", "```py\n    In [7]: pd.rolling_sum(pd.Series(range(4)), window=3,\n     ....:                min_periods=0, center=True)\n    Out[7]:\n    0    1\n    1    3\n    2    6\n    3    5\n    dtype: float64 \n    ```", "```py\n    In [58]: s = pd.Series([10.5, 8.8, 11.4, 9.7, 9.3]) \n    ```", "```py\n    In [39]: pd.rolling_window(s, window=3, win_type='triang', center=True)\n    Out[39]:\n    0         NaN\n    1    6.583333\n    2    6.883333\n    3    6.683333\n    4         NaN\n    dtype: float64 \n    ```", "```py\n    In [10]: pd.rolling_window(s, window=3, win_type='triang', center=True)\n    Out[10]:\n    0       NaN\n    1     9.875\n    2    10.325\n    3    10.025\n    4       NaN\n    dtype: float64 \n    ```", "```py\n    In [59]: s  = pd.Series([1, None, None, None, 2, 3]) \n    ```", "```py\n    In [51]: pd.ewma(s, com=3., min_periods=2)\n    Out[51]:\n    0         NaN\n    1         NaN\n    2    1.000000\n    3    1.000000\n    4    1.571429\n    5    2.189189\n    dtype: float64 \n    ```", "```py\n    In [2]: pd.ewma(s, com=3., min_periods=2)\n    Out[2]:\n    0         NaN\n    1         NaN\n    2         NaN\n    3         NaN\n    4    1.759644\n    5    2.383784\n    dtype: float64 \n    ```", "```py\n    In [7]: pd.ewma(pd.Series([None, 1., 8.]), com=2.)\n    Out[7]:\n    0    NaN\n    1    1.0\n    2    5.2\n    dtype: float64\n\n    In [8]: pd.ewma(pd.Series([1., None, 8.]), com=2.,\n     ....:         ignore_na=True)  # pre-0.15.0 behavior\n    Out[8]:\n    0    1.0\n    1    1.0\n    2    5.2\n    dtype: float64\n\n    In [9]: pd.ewma(pd.Series([1., None, 8.]), com=2.,\n     ....:         ignore_na=False)  # new default\n    Out[9]:\n    0    1.000000\n    1    1.000000\n    2    5.846154\n    dtype: float64 \n    ```", "```py\n    In [60]: s = pd.Series([1., 2., 0., 4.]) \n    ```", "```py\n    In [89]: pd.ewmvar(s, com=2., bias=False)\n    Out[89]:\n    0   -2.775558e-16\n    1    3.000000e-01\n    2    9.556787e-01\n    3    3.585799e+00\n    dtype: float64\n\n    In [90]: pd.ewmvar(s, com=2., bias=False) / pd.ewmvar(s, com=2., bias=True)\n    Out[90]:\n    0    1.25\n    1    1.25\n    2    1.25\n    3    1.25\n    dtype: float64 \n    ```", "```py\n    In [14]: pd.ewmvar(s, com=2., bias=False)\n    Out[14]:\n    0         NaN\n    1    0.500000\n    2    1.210526\n    3    4.089069\n    dtype: float64\n\n    In [15]: pd.ewmvar(s, com=2., bias=False) / pd.ewmvar(s, com=2., bias=True)\n    Out[15]:\n    0         NaN\n    1    2.083333\n    2    1.583333\n    3    1.425439\n    dtype: float64 \n    ```", "```py\n    df.to_sql('table', engine, schema='other_schema')  # noqa F821\n    pd.read_sql_table('table', engine, schema='other_schema')  # noqa F821 \n    ```", "```py\n    pd.Categorical([0,1,0,2,1], levels=['a', 'b', 'c']) \n    ```", "```py\n    In [2]: pd.Categorical.from_codes([0,1,0,2,1], categories=['a', 'b', 'c'])\n    Out[2]:\n    [a, b, a, c, b]\n    Categories (3, object): [a, b, c] \n    ```", "```py\n    In [61]: df = pd.DataFrame([['a'], ['b']], index=[1, 2])\n\n    In [62]: df\n    Out[62]: \n     0\n    1  a\n    2  b\n\n    [2 rows x 1 columns] \n    ```", "```py\n    In [3]: df.loc[[1, 3]]\n    Out[3]:\n     0\n    1    a\n    3  NaN\n\n    In [4]: df.loc[[1, 3], :]\n    Out[4]:\n     0\n    1    a\n    3  NaN \n    ```", "```py\n    >>> p = pd.Panel(np.arange(2 * 3 * 4).reshape(2, 3, 4),\n    ...              items=['ItemA', 'ItemB'],\n    ...              major_axis=[1, 2, 3],\n    ...              minor_axis=['A', 'B', 'C', 'D'])\n    >>> p\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 2 (items) x 3 (major_axis) x 4 (minor_axis)\n    Items axis: ItemA to ItemB\n    Major_axis axis: 1 to 3\n    Minor_axis axis: A to D \n    ```", "```py\n    In [5]:\n    Out[5]:\n     ItemA  ItemD\n    1      3    NaN\n    2      7    NaN\n    3     11    NaN \n    ```", "```py\n    In [63]: s = pd.Series(np.arange(3, dtype='int64'),\n     ....:              index=pd.MultiIndex.from_product([['A'],\n     ....:                                               ['foo', 'bar', 'baz']],\n     ....:                                               names=['one', 'two'])\n     ....:              ).sort_index()\n     ....: \n\n    In [64]: s\n    Out[64]: \n    one  two\n    A    bar    1\n     baz    2\n     foo    0\n    Length: 3, dtype: int64\n\n    In [65]: try:\n     ....:    s.loc[['D']]\n     ....: except KeyError as e:\n     ....:    print(\"KeyError: \" + str(e))\n     ....: \n    KeyError: \"['D'] not in index\" \n    ```", "```py\n    In [66]: s = pd.Series([1., 2., 3.])\n\n    In [67]: s.loc[0] = None\n\n    In [68]: s\n    Out[68]: \n    0    NaN\n    1    2.0\n    2    3.0\n    Length: 3, dtype: float64 \n    ```", "```py\n    In [69]: s = pd.Series([\"a\", \"b\", \"c\"])\n\n    In [70]: s.loc[0] = None\n\n    In [71]: s\n    Out[71]: \n    0    None\n    1       b\n    2       c\n    Length: 3, dtype: object \n    ```", "```py\n    In [72]: s = pd.Series([1, 2, 3])\n\n    In [73]: s2 = s\n\n    In [74]: s += 1.5 \n    ```", "```py\n    # the original object\n    In [5]: s\n    Out[5]:\n    0    2.5\n    1    3.5\n    2    4.5\n    dtype: float64\n\n    # a reference to the original object\n    In [7]: s2\n    Out[7]:\n    0    1\n    1    2\n    2    3\n    dtype: int64 \n    ```", "```py\n    # the original object\n    In [75]: s\n    Out[75]: \n    0    2.5\n    1    3.5\n    2    4.5\n    Length: 3, dtype: float64\n\n    # a reference to the original object\n    In [76]: s2\n    Out[76]: \n    0    2.5\n    1    3.5\n    2    4.5\n    Length: 3, dtype: float64 \n    ```", "```py\n    In [77]: i = pd.date_range('1/1/2011', periods=3, freq='10s', tz='US/Eastern')\n\n    In [78]: i\n    Out[78]: \n    DatetimeIndex(['2011-01-01 00:00:00-05:00', '2011-01-01 00:00:10-05:00',\n     '2011-01-01 00:00:20-05:00'],\n     dtype='datetime64[ns, US/Eastern]', freq='10s')\n\n    In [79]: df = pd.DataFrame({'a': i})\n\n    In [80]: df\n    Out[80]: \n     a\n    0 2011-01-01 00:00:00-05:00\n    1 2011-01-01 00:00:10-05:00\n    2 2011-01-01 00:00:20-05:00\n\n    [3 rows x 1 columns]\n\n    In [81]: df.dtypes\n    Out[81]: \n    a    datetime64[ns, US/Eastern]\n    Length: 1, dtype: object \n    ```", "```py\n    In [1]: df = pd.DataFrame(np.arange(0, 9), columns=['count'])\n\n    In [2]: df['group'] = 'b'\n\n    In [3]: df.iloc[0:5]['group'] = 'a'\n    /usr/local/bin/ipython:1: SettingWithCopyWarning:\n    A value is trying to be set on a copy of a slice from a DataFrame.\n    Try using .loc[row_indexer,col_indexer] = value instead\n\n    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy \n    ```", "```py\n    In [82]: df = pd.DataFrame([[True, 1], [False, 2]],\n     ....:                  columns=[\"female\", \"fitness\"])\n     ....: \n\n    In [83]: df\n    Out[83]: \n     female  fitness\n    0    True        1\n    1   False        2\n\n    [2 rows x 2 columns]\n\n    In [84]: df.dtypes\n    Out[84]: \n    female      bool\n    fitness    int64\n    Length: 2, dtype: object\n\n    # dtypes are now preserved\n    In [85]: df.loc[2] = df.loc[1]\n\n    In [86]: df\n    Out[86]: \n     female  fitness\n    0    True        1\n    1   False        2\n    2   False        2\n\n    [3 rows x 2 columns]\n\n    In [87]: df.dtypes\n    Out[87]: \n    female      bool\n    fitness    int64\n    Length: 2, dtype: object \n    ```", "```py\n    # +\n    pd.Index(['a', 'b', 'c']) + pd.Index(['b', 'c', 'd'])\n\n    # should be replaced by\n    pd.Index(['a', 'b', 'c']).union(pd.Index(['b', 'c', 'd'])) \n    ```", "```py\n    # -\n    pd.Index(['a', 'b', 'c']) - pd.Index(['b', 'c', 'd'])\n\n    # should be replaced by\n    pd.Index(['a', 'b', 'c']).difference(pd.Index(['b', 'c', 'd'])) \n    ```", "```py\n    pd.Categorical([0,1,0,2,1], levels=['a', 'b', 'c']) \n    ```", "```py\n    In [2]: pd.Categorical.from_codes([0,1,0,2,1], categories=['a', 'b', 'c'])\n    Out[2]:\n    [a, b, a, c, b]\n    Categories (3, object): [a, b, c] \n    ```", "```py\n    In [61]: df = pd.DataFrame([['a'], ['b']], index=[1, 2])\n\n    In [62]: df\n    Out[62]: \n     0\n    1  a\n    2  b\n\n    [2 rows x 1 columns] \n    ```", "```py\n    In [3]: df.loc[[1, 3]]\n    Out[3]:\n     0\n    1    a\n    3  NaN\n\n    In [4]: df.loc[[1, 3], :]\n    Out[4]:\n     0\n    1    a\n    3  NaN \n    ```", "```py\n    >>> p = pd.Panel(np.arange(2 * 3 * 4).reshape(2, 3, 4),\n    ...              items=['ItemA', 'ItemB'],\n    ...              major_axis=[1, 2, 3],\n    ...              minor_axis=['A', 'B', 'C', 'D'])\n    >>> p\n    <class 'pandas.core.panel.Panel'>\n    Dimensions: 2 (items) x 3 (major_axis) x 4 (minor_axis)\n    Items axis: ItemA to ItemB\n    Major_axis axis: 1 to 3\n    Minor_axis axis: A to D \n    ```", "```py\n    In [5]:\n    Out[5]:\n     ItemA  ItemD\n    1      3    NaN\n    2      7    NaN\n    3     11    NaN \n    ```", "```py\n    In [63]: s = pd.Series(np.arange(3, dtype='int64'),\n     ....:              index=pd.MultiIndex.from_product([['A'],\n     ....:                                               ['foo', 'bar', 'baz']],\n     ....:                                               names=['one', 'two'])\n     ....:              ).sort_index()\n     ....: \n\n    In [64]: s\n    Out[64]: \n    one  two\n    A    bar    1\n     baz    2\n     foo    0\n    Length: 3, dtype: int64\n\n    In [65]: try:\n     ....:    s.loc[['D']]\n     ....: except KeyError as e:\n     ....:    print(\"KeyError: \" + str(e))\n     ....: \n    KeyError: \"['D'] not in index\" \n    ```", "```py\n    In [66]: s = pd.Series([1., 2., 3.])\n\n    In [67]: s.loc[0] = None\n\n    In [68]: s\n    Out[68]: \n    0    NaN\n    1    2.0\n    2    3.0\n    Length: 3, dtype: float64 \n    ```", "```py\n    In [69]: s = pd.Series([\"a\", \"b\", \"c\"])\n\n    In [70]: s.loc[0] = None\n\n    In [71]: s\n    Out[71]: \n    0    None\n    1       b\n    2       c\n    Length: 3, dtype: object \n    ```", "```py\n    In [72]: s = pd.Series([1, 2, 3])\n\n    In [73]: s2 = s\n\n    In [74]: s += 1.5 \n    ```", "```py\n    # the original object\n    In [5]: s\n    Out[5]:\n    0    2.5\n    1    3.5\n    2    4.5\n    dtype: float64\n\n    # a reference to the original object\n    In [7]: s2\n    Out[7]:\n    0    1\n    1    2\n    2    3\n    dtype: int64 \n    ```", "```py\n    # the original object\n    In [75]: s\n    Out[75]: \n    0    2.5\n    1    3.5\n    2    4.5\n    Length: 3, dtype: float64\n\n    # a reference to the original object\n    In [76]: s2\n    Out[76]: \n    0    2.5\n    1    3.5\n    2    4.5\n    Length: 3, dtype: float64 \n    ```", "```py\n    In [77]: i = pd.date_range('1/1/2011', periods=3, freq='10s', tz='US/Eastern')\n\n    In [78]: i\n    Out[78]: \n    DatetimeIndex(['2011-01-01 00:00:00-05:00', '2011-01-01 00:00:10-05:00',\n     '2011-01-01 00:00:20-05:00'],\n     dtype='datetime64[ns, US/Eastern]', freq='10s')\n\n    In [79]: df = pd.DataFrame({'a': i})\n\n    In [80]: df\n    Out[80]: \n     a\n    0 2011-01-01 00:00:00-05:00\n    1 2011-01-01 00:00:10-05:00\n    2 2011-01-01 00:00:20-05:00\n\n    [3 rows x 1 columns]\n\n    In [81]: df.dtypes\n    Out[81]: \n    a    datetime64[ns, US/Eastern]\n    Length: 1, dtype: object \n    ```", "```py\n    In [1]: df = pd.DataFrame(np.arange(0, 9), columns=['count'])\n\n    In [2]: df['group'] = 'b'\n\n    In [3]: df.iloc[0:5]['group'] = 'a'\n    /usr/local/bin/ipython:1: SettingWithCopyWarning:\n    A value is trying to be set on a copy of a slice from a DataFrame.\n    Try using .loc[row_indexer,col_indexer] = value instead\n\n    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy \n    ```", "```py\n    In [82]: df = pd.DataFrame([[True, 1], [False, 2]],\n     ....:                  columns=[\"female\", \"fitness\"])\n     ....: \n\n    In [83]: df\n    Out[83]: \n     female  fitness\n    0    True        1\n    1   False        2\n\n    [2 rows x 2 columns]\n\n    In [84]: df.dtypes\n    Out[84]: \n    female      bool\n    fitness    int64\n    Length: 2, dtype: object\n\n    # dtypes are now preserved\n    In [85]: df.loc[2] = df.loc[1]\n\n    In [86]: df\n    Out[86]: \n     female  fitness\n    0    True        1\n    1   False        2\n    2   False        2\n\n    [3 rows x 2 columns]\n\n    In [87]: df.dtypes\n    Out[87]: \n    female      bool\n    fitness    int64\n    Length: 2, dtype: object \n    ```", "```py\n    # +\n    pd.Index(['a', 'b', 'c']) + pd.Index(['b', 'c', 'd'])\n\n    # should be replaced by\n    pd.Index(['a', 'b', 'c']).union(pd.Index(['b', 'c', 'd'])) \n    ```", "```py\n    # -\n    pd.Index(['a', 'b', 'c']) - pd.Index(['b', 'c', 'd'])\n\n    # should be replaced by\n    pd.Index(['a', 'b', 'c']).difference(pd.Index(['b', 'c', 'd'])) \n    ```", "```py\n    In [88]: df = pd.DataFrame({'catA': ['foo', 'foo', 'bar'] * 8,\n     ....:                   'catB': ['a', 'b', 'c', 'd'] * 6,\n     ....:                   'numC': np.arange(24),\n     ....:                   'numD': np.arange(24.) + .5})\n     ....: \n\n    In [89]: df.describe(include=[\"object\"])\n    Out[89]: \n     catA catB\n    count    24   24\n    unique    2    4\n    top     foo    a\n    freq     16    6\n\n    [4 rows x 2 columns]\n\n    In [90]: df.describe(include=[\"number\", \"object\"], exclude=[\"float\"])\n    Out[90]: \n     catA catB       numC\n    count    24   24  24.000000\n    unique    2    4        NaN\n    top     foo    a        NaN\n    freq     16    6        NaN\n    mean    NaN  NaN  11.500000\n    std     NaN  NaN   7.071068\n    min     NaN  NaN   0.000000\n    25%     NaN  NaN   5.750000\n    50%     NaN  NaN  11.500000\n    75%     NaN  NaN  17.250000\n    max     NaN  NaN  23.000000\n\n    [11 rows x 3 columns] \n    ```", "```py\n    In [91]: df.describe(include='all')\n    Out[91]: \n     catA catB       numC       numD\n    count    24   24  24.000000  24.000000\n    unique    2    4        NaN        NaN\n    top     foo    a        NaN        NaN\n    freq     16    6        NaN        NaN\n    mean    NaN  NaN  11.500000  12.000000\n    std     NaN  NaN   7.071068   7.071068\n    min     NaN  NaN   0.000000   0.500000\n    25%     NaN  NaN   5.750000   6.250000\n    50%     NaN  NaN  11.500000  12.000000\n    75%     NaN  NaN  17.250000  17.750000\n    max     NaN  NaN  23.000000  23.500000\n\n    [11 rows x 4 columns] \n    ```", "```py\n    In [92]: df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['c', 'c', 'b'],\n     ....:                'C': [1, 2, 3]})\n     ....: \n\n    In [93]: pd.get_dummies(df)\n    Out[93]: \n     C    A_a    A_b    B_b    B_c\n    0  1   True  False  False   True\n    1  2  False   True  False   True\n    2  3   True  False   True  False\n\n    [3 rows x 5 columns] \n    ```", "```py\n    In [94]: business_dates = pd.date_range(start='4/1/2014', end='6/30/2014', freq='B')\n\n    In [95]: df = pd.DataFrame(1, index=business_dates, columns=['a', 'b'])\n\n    # get the first, 4th, and last date index for each month\n    In [96]: df.groupby([df.index.year, df.index.month]).nth([0, 3, -1])\n    Out[96]: \n     a  b\n    2014-04-01  1  1\n    2014-04-04  1  1\n    2014-04-30  1  1\n    2014-05-01  1  1\n    2014-05-06  1  1\n    2014-05-30  1  1\n    2014-06-02  1  1\n    2014-06-05  1  1\n    2014-06-30  1  1\n\n    [9 rows x 2 columns] \n    ```", "```py\n    In [104]: idx = pd.period_range('2014-07-01 09:00', periods=5, freq='H')\n\n    In [105]: idx\n    Out[105]:\n    PeriodIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',\n     '2014-07-01 12:00', '2014-07-01 13:00'],\n     dtype='period[H]')\n\n    In [106]: idx + pd.offsets.Hour(2)\n    Out[106]:\n    PeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',\n     '2014-07-01 14:00', '2014-07-01 15:00'],\n     dtype='period[H]')\n\n    In [107]: idx + pd.Timedelta('120m')\n    Out[107]:\n    PeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',\n     '2014-07-01 14:00', '2014-07-01 15:00'],\n     dtype='period[H]')\n\n    In [108]: idx = pd.period_range('2014-07', periods=5, freq='M')\n\n    In [109]: idx\n    Out[109]: PeriodIndex(['2014-07', '2014-08', '2014-09', '2014-10', '2014-11'], dtype='period[M]')\n\n    In [110]: idx + pd.offsets.MonthEnd(3)\n    Out[110]: PeriodIndex(['2014-10', '2014-11', '2014-12', '2015-01', '2015-02'], dtype='period[M]') \n    ```", "```py\n    In [97]: idx = pd.MultiIndex.from_product([['a'], range(3), list(\"pqr\")],\n     ....:                                 names=['foo', 'bar', 'baz'])\n     ....: \n\n    In [98]: idx.set_names('qux', level=0)\n    Out[98]: \n    MultiIndex([('a', 0, 'p'),\n     ('a', 0, 'q'),\n     ('a', 0, 'r'),\n     ('a', 1, 'p'),\n     ('a', 1, 'q'),\n     ('a', 1, 'r'),\n     ('a', 2, 'p'),\n     ('a', 2, 'q'),\n     ('a', 2, 'r')],\n     names=['qux', 'bar', 'baz'])\n\n    In [99]: idx.set_names(['qux', 'corge'], level=[0, 1])\n    Out[99]: \n    MultiIndex([('a', 0, 'p'),\n     ('a', 0, 'q'),\n     ('a', 0, 'r'),\n     ('a', 1, 'p'),\n     ('a', 1, 'q'),\n     ('a', 1, 'r'),\n     ('a', 2, 'p'),\n     ('a', 2, 'q'),\n     ('a', 2, 'r')],\n     names=['qux', 'corge', 'baz'])\n\n    In [100]: idx.set_levels(['a', 'b', 'c'], level='bar')\n    Out[100]: \n    MultiIndex([('a', 'a', 'p'),\n     ('a', 'a', 'q'),\n     ('a', 'a', 'r'),\n     ('a', 'b', 'p'),\n     ('a', 'b', 'q'),\n     ('a', 'b', 'r'),\n     ('a', 'c', 'p'),\n     ('a', 'c', 'q'),\n     ('a', 'c', 'r')],\n     names=['foo', 'bar', 'baz'])\n\n    In [101]: idx.set_levels([['a', 'b', 'c'], [1, 2, 3]], level=[1, 2])\n    Out[101]: \n    MultiIndex([('a', 'a', 1),\n     ('a', 'a', 2),\n     ('a', 'a', 3),\n     ('a', 'b', 1),\n     ('a', 'b', 2),\n     ('a', 'b', 3),\n     ('a', 'c', 1),\n     ('a', 'c', 2),\n     ('a', 'c', 3)],\n     names=['foo', 'bar', 'baz']) \n    ```", "```py\n    In [1]: idx = pd.MultiIndex.from_product([[0, 1], ['a', 'b', 'c']])\n\n    In [2]: idx.values\n    Out[2]: array([(0, 'a'), (0, 'b'), (0, 'c'), (1, 'a'), (1, 'b'), (1, 'c')], dtype=object)\n\n    In [3]: idx.isin(['a', 'c', 'e'], level=1)\n    Out[3]: array([ True, False,  True,  True, False,  True], dtype=bool) \n    ```", "```py\n    In [102]: idx = pd.Index([1, 2, 3, 4, 1, 2])\n\n    In [103]: idx\n    Out[103]: Index([1, 2, 3, 4, 1, 2], dtype='int64')\n\n    In [104]: idx.duplicated()\n    Out[104]: array([False, False, False, False,  True,  True])\n\n    In [105]: idx.drop_duplicates()\n    Out[105]: Index([1, 2, 3, 4], dtype='int64') \n    ```"]