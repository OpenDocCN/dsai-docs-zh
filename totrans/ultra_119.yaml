- en: A Guide on Model Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/guides/model-testing/`](https://docs.ultralytics.com/guides/model-testing/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After training and evaluating your model, it's time to test it. Model testing
    involves assessing how well it performs in real-world scenarios. Testing considers
    factors like accuracy, reliability, fairness, and how easy it is to understand
    the model's decisions. The goal is to make sure the model performs as intended,
    delivers the expected results, and fits into the overall objective of your application
    or project.
  prefs: []
  type: TYPE_NORMAL
- en: Model testing is quite similar to model evaluation, but they are two distinct
    steps in a computer vision project. Model evaluation involves metrics and plots
    to assess the model's accuracy. On the other hand, model testing checks if the
    model's learned behavior is the same as expectations. In this guide, we'll explore
    strategies for testing your computer vision models.
  prefs: []
  type: TYPE_NORMAL
- en: Model Testing Vs. Model Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let's understand the difference between model evaluation and testing
    with an example.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose you have trained a computer vision model to recognize cats and dogs,
    and you want to deploy this model at a pet store to monitor the animals. During
    the model evaluation phase, you use a labeled dataset to calculate metrics like
    accuracy, precision, recall, and F1 score. For instance, the model might have
    an accuracy of 98% in distinguishing between cats and dogs in a given dataset.
  prefs: []
  type: TYPE_NORMAL
- en: After evaluation, you test the model using images from a pet store to see how
    well it identifies cats and dogs in more varied and realistic conditions. You
    check if it can correctly label cats and dogs when they are moving, in different
    lighting conditions, or partially obscured by objects like toys or furniture.
    Model testing checks that the model behaves as expected outside the controlled
    evaluation environment.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing for Model Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Computer vision models learn from datasets by detecting patterns, making predictions,
    and evaluating their performance. These datasets are usually divided into training
    and testing sets to simulate real-world conditions. Training data teaches the
    model while testing data verifies its accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are two points to keep in mind before testing your model:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Realistic Representation:** The previously unseen testing data should be
    similar to the data that the model will have to handle when deployed. This helps
    get a realistic understanding of the model''s capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sufficient Size:** The size of the testing dataset needs to be large enough
    to provide reliable insights into how well the model performs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing Your Computer Vision Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here are the key steps to take to test your computer vision model and understand
    its performance.
  prefs: []
  type: TYPE_NORMAL
- en: '**Run Predictions:** Use the model to make predictions on the test dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compare Predictions:** Check how well the model''s predictions match the
    actual labels (ground truth).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Calculate Performance Metrics:** Compute metrics like accuracy, precision,
    recall, and F1 score to understand the model''s strengths and weaknesses. Testing
    focuses on how these metrics reflect real-world performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visualize Results:** Create visual aids like confusion matrices and ROC curves.
    These help you spot specific areas where the model might not be performing well
    in practical applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, the testing results can be analyzed:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Misclassified Images:** Identify and review images that the model misclassified
    to understand where it is going wrong.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Error Analysis:** Perform a thorough error analysis to understand the types
    of errors (e.g., false positives vs. false negatives) and their potential causes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bias and Fairness:** Check for any biases in the model''s predictions. Ensure
    that the model performs equally well across different subsets of the data, especially
    if it includes sensitive attributes like race, gender, or age.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing Your YOLOv8 Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To test your YOLOv8 model, you can use the validation mode. It's a straightforward
    way to understand the model's strengths and areas that need improvement. Also,
    you'll need to format your test dataset correctly for YOLOv8\. For more details
    on how to use the validation mode, check out the Model Validation docs page.
  prefs: []
  type: TYPE_NORMAL
- en: Using YOLOv8 to Predict on Multiple Test Images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you want to test your trained YOLOv8 model on multiple images stored in a
    folder, you can easily do so in one go. Instead of using the validation mode,
    which is typically used to evaluate model performance on a validation set and
    provide detailed metrics, you might just want to see predictions on all images
    in your test set. For this, you can use the prediction mode.
  prefs: []
  type: TYPE_NORMAL
- en: Difference Between Validation and Prediction Modes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Validation Mode:** Used to evaluate the model''s performance by comparing
    predictions against known labels (ground truth). It provides detailed metrics
    such as accuracy, precision, recall, and F1 score.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prediction Mode:** Used to run the model on new, unseen data to generate
    predictions. It does not provide detailed performance metrics but allows you to
    see how the model performs on real-world images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running YOLOv8 Predictions Without Custom Training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are interested in testing the basic YOLOv8 model to understand whether
    it can be used for your application without custom training, you can use the prediction
    mode. While the model is pre-trained on datasets like COCO, running predictions
    on your own dataset can give you a quick sense of how well it might perform in
    your specific context.
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting and Underfitting in Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When testing a machine learning model, especially in computer vision, it's important
    to watch out for overfitting and underfitting. These issues can significantly
    affect how well your model works with new data.
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Overfitting happens when your model learns the training data too well, including
    the noise and details that don't generalize to new data. In computer vision, this
    means your model might do great with training images but struggle with new ones.
  prefs: []
  type: TYPE_NORMAL
- en: Signs of Overfitting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**High Training Accuracy, Low Validation Accuracy:** If your model performs
    very well on training data but poorly on validation or test data, it''s likely
    overfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visual Inspection:** Sometimes, you can see overfitting if your model is
    too sensitive to minor changes or irrelevant details in images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Underfitting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Underfitting occurs when your model can't capture the underlying patterns in
    the data. In computer vision, an underfitted model might not even recognize objects
    correctly in the training images.
  prefs: []
  type: TYPE_NORMAL
- en: Signs of Underfitting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**Low Training Accuracy:** If your model can''t achieve high accuracy on the
    training set, it might be underfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visual Misclassification:** Consistent failure to recognize obvious features
    or objects suggests underfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Balancing Overfitting and Underfitting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The key is to find a balance between overfitting and underfitting. Ideally,
    a model should perform well on both training and validation datasets. Regularly
    monitoring your model's performance through metrics and visual inspections, along
    with applying the right strategies, can help you achieve the best results.
  prefs: []
  type: TYPE_NORMAL
- en: '![Overfitting and Underfitting Overview](img/262d58651fa4d6104d298c47446dc558.png)'
  prefs: []
  type: TYPE_IMG
- en: Data Leakage in Computer Vision and How to Avoid It
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While testing your model, something important to keep in mind is data leakage.
    Data leakage happens when information from outside the training dataset accidentally
    gets used to train the model. The model may seem very accurate during training,
    but it won't perform well on new, unseen data when data leakage occurs.
  prefs: []
  type: TYPE_NORMAL
- en: Why Data Leakage Happens
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Data leakage can be tricky to spot and often comes from hidden biases in the
    training data. Here are some common ways it can happen in computer vision:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Camera Bias:** Different angles, lighting, shadows, and camera movements
    can introduce unwanted patterns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overlay Bias:** Logos, timestamps, or other overlays in images can mislead
    the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Font and Object Bias:** Specific fonts or objects that frequently appear
    in certain classes can skew the model''s learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spatial Bias:** Imbalances in foreground-background, bounding box distributions,
    and object locations can affect training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label and Domain Bias:** Incorrect labels or shifts in data types can lead
    to leakage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting Data Leakage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To find data leakage, you can:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Check Performance:** If the model''s results are surprisingly good, it might
    be leaking.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Look at Feature Importance:** If one feature is much more important than
    others, it could indicate leakage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visual Inspection:** Double-check that the model''s decisions make sense
    intuitively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Verify Data Separation:** Make sure data was divided correctly before any
    processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding Data Leakage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To prevent data leakage, use a diverse dataset with images or videos from different
    cameras and environments. Carefully review your data and check that there are
    no hidden biases, such as all positive samples being taken at a specific time
    of day. Avoiding data leakage will help make your computer vision models more
    reliable and effective in real-world situations.
  prefs: []
  type: TYPE_NORMAL
- en: What Comes After Model Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After testing your model, the next steps depend on the results. If your model
    performs well, you can deploy it into a real-world environment. If the results
    aren't satisfactory, you'll need to make improvements. This might involve analyzing
    errors, gathering more data, improving data quality, adjusting hyperparameters,
    and retraining the model.
  prefs: []
  type: TYPE_NORMAL
- en: Join the AI Conversation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Becoming part of a community of computer vision enthusiasts can aid in solving
    problems and learning more efficiently. Here are some ways to connect, seek help,
    and share your thoughts.
  prefs: []
  type: TYPE_NORMAL
- en: Community Resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**GitHub Issues:** Explore the [YOLOv8 GitHub repository](https://github.com/ultralytics/ultralytics/issues)
    and use the Issues tab to ask questions, report bugs, and suggest new features.
    The community and maintainers are very active and ready to help.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ultralytics Discord Server:** Join the [Ultralytics Discord server](https://ultralytics.com/discord/)
    to chat with other users and developers, get support, and share your experiences.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Official Documentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Ultralytics YOLOv8 Documentation:** Check out the official YOLOv8 documentation
    for detailed guides and helpful tips on various computer vision projects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These resources will help you navigate challenges and remain updated on the
    latest trends and practices within the computer vision community.
  prefs: []
  type: TYPE_NORMAL
- en: In Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Building trustworthy computer vision models relies on rigorous model testing.
    By testing the model with previously unseen data, we can analyze it and spot weaknesses
    like overfitting and data leakage. Addressing these issues before deployment helps
    the model perform well in real-world applications. It's important to remember
    that model testing is just as crucial as model evaluation in guaranteeing the
    model's long-term success and effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What are the key differences between model evaluation and model testing in computer
    vision?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Model evaluation and model testing are distinct steps in a computer vision project.
    Model evaluation involves using a labeled dataset to compute metrics such as accuracy,
    precision, recall, and F1 score, providing insights into the model's performance
    with a controlled dataset. Model testing, on the other hand, assesses the model's
    performance in real-world scenarios by applying it to new, unseen data, ensuring
    the model's learned behavior aligns with expectations outside the evaluation environment.
    For a detailed guide, refer to the steps in a computer vision project.
  prefs: []
  type: TYPE_NORMAL
- en: How can I test my Ultralytics YOLOv8 model on multiple images?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To test your Ultralytics YOLOv8 model on multiple images, you can use the prediction
    mode. This mode allows you to run the model on new, unseen data to generate predictions
    without providing detailed metrics. This is ideal for real-world performance testing
    on larger image sets stored in a folder. For evaluating performance metrics, use
    the validation mode instead.
  prefs: []
  type: TYPE_NORMAL
- en: What should I do if my computer vision model shows signs of overfitting or underfitting?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To address **overfitting**:'
  prefs: []
  type: TYPE_NORMAL
- en: Regularization techniques like dropout.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase the size of the training dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simplify the model architecture.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To address **underfitting**:'
  prefs: []
  type: TYPE_NORMAL
- en: Use a more complex model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide more relevant features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase training iterations or epochs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Review misclassified images, perform thorough error analysis, and regularly
    track performance metrics to maintain a balance. For more information on these
    concepts, explore our section on Overfitting and Underfitting.
  prefs: []
  type: TYPE_NORMAL
- en: How can I detect and avoid data leakage in computer vision?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To detect data leakage:'
  prefs: []
  type: TYPE_NORMAL
- en: Verify that the testing performance is not unusually high.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check feature importance for unexpected insights.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intuitively review model decisions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure correct data division before processing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To avoid data leakage:'
  prefs: []
  type: TYPE_NORMAL
- en: Use diverse datasets with various environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Carefully review data for hidden biases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure no overlapping information between training and testing sets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For detailed strategies on preventing data leakage, refer to our section on
    Data Leakage in Computer Vision.
  prefs: []
  type: TYPE_NORMAL
- en: What steps should I take after testing my computer vision model?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Post-testing, if the model performance meets the project goals, proceed with
    deployment. If the results are unsatisfactory, consider:'
  prefs: []
  type: TYPE_NORMAL
- en: Error analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gathering more diverse and high-quality data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyperparameter tuning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retraining the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gain insights from the Model Testing Vs. Model Evaluation section to refine
    and enhance model effectiveness in real-world applications.
  prefs: []
  type: TYPE_NORMAL
- en: How do I run YOLOv8 predictions without custom training?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can run predictions using the pre-trained YOLOv8 model on your dataset to
    see if it suits your application needs. Utilize the prediction mode to get a quick
    sense of performance results without diving into custom training.
  prefs: []
  type: TYPE_NORMAL
