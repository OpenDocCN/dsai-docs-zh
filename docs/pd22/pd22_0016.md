# 与 R/R 库的比较

> 译文：[`pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html`](https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html)

由于 pandas 旨在提供许多人们使用[R](https://www.r-project.org/)的数据操作和分析功能，因此本页面旨在更详细地查看[R 语言](https://en.wikipedia.org/wiki/R_(programming_language))及其许多第三方库与 pandas 的关系。在与 R 和 CRAN 库的比较中，我们关心以下几点：

+   **功能性/灵活性**：每个工具可以/不可以做什么

+   **性能**：操作有多快。最好提供硬性数据/基准

+   **易用性**：一个工具更容易/更难使用（您可能需要通过并排代码比较来判断）

本页面还提供了一个为这些 R 包的用户提供一点翻译指南的页面。

## 快速参考

我们将从一个快速参考指南开始，将一些常见的 R 操作（使用[dplyr](https://cran.r-project.org/web/packages/dplyr/index.html)）与 pandas 的等效操作进行配对。

### 查询、过滤、抽样

| R | pandas |
| --- | --- |
| `dim(df)` | `df.shape` |
| `head(df)` | `df.head()` |
| `slice(df, 1:10)` | `df.iloc[:9]` |
| `filter(df, col1 == 1, col2 == 1)` | `df.query('col1 == 1 & col2 == 1')` |
| `df[df$col1 == 1 & df$col2 == 1,]` | `df[(df.col1 == 1) & (df.col2 == 1)]` |
| `select(df, col1, col2)` | `df[['col1', 'col2']]` |
| `select(df, col1:col3)` | `df.loc[:, 'col1':'col3']` |
| `select(df, -(col1:col3))` | `df.drop(cols_to_drop, axis=1)` 但请参见[[1]](#select-range) |
| `distinct(select(df, col1))` | `df[['col1']].drop_duplicates()` |
| `distinct(select(df, col1, col2))` | `df[['col1', 'col2']].drop_duplicates()` |
| `sample_n(df, 10)` | `df.sample(n=10)` |
| `sample_frac(df, 0.01)` | `df.sample(frac=0.01)` |

### 排序

| R | pandas |
| --- | --- |
| `arrange(df, col1, col2)` | `df.sort_values(['col1', 'col2'])` |
| `arrange(df, desc(col1))` | `df.sort_values('col1', ascending=False)` |

### 转换

| R | pandas |
| --- | --- |
| `select(df, col_one = col1)` | `df.rename(columns={'col1': 'col_one'})['col_one']` |
| `rename(df, col_one = col1)` | `df.rename(columns={'col1': 'col_one'})` |
| `mutate(df, c=a-b)` | `df.assign(c=df['a']-df['b'])` |

### 分组和汇总

| R | pandas |
| --- | --- |
| `summary(df)` | `df.describe()` |
| `gdf <- group_by(df, col1)` | `gdf = df.groupby('col1')` |
| `summarise(gdf, avg=mean(col1, na.rm=TRUE))` | `df.groupby('col1').agg({'col1': 'mean'})` |
| `summarise(gdf, total=sum(col1))` | `df.groupby('col1').sum()` |

## 基础 R

### 使用 R 的[`c`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/c.html)进行切片

R 使得通过名称轻松访问 `data.frame` 列成为可能

```py
df  <-  data.frame(a=rnorm(5),  b=rnorm(5),  c=rnorm(5),  d=rnorm(5),  e=rnorm(5))
df[,  c("a",  "c",  "e")] 
```

或按整数位置

```py
df  <-  data.frame(matrix(rnorm(1000),  ncol=100))
df[,  c(1:10,  25:30,  40,  50:100)] 
```

在 pandas 中按名称选择多列很简单

```py
In [1]: df = pd.DataFrame(np.random.randn(10, 3), columns=list("abc"))

In [2]: df[["a", "c"]]
Out[2]: 
 a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892

In [3]: df.loc[:, ["a", "c"]]
Out[3]: 
 a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892 
```

通过整数位置选择多个不连续列可以通过`iloc`索引器属性和`numpy.r_`的组合实现。

```py
In [4]: named = list("abcdefg")

In [5]: n = 30

In [6]: columns = named + np.arange(len(named), n).tolist()

In [7]: df = pd.DataFrame(np.random.randn(n, n), columns=columns)

In [8]: df.iloc[:, np.r_[:10, 24:30]]
Out[8]: 
 a         b         c  ...        27        28        29
0  -1.344312  0.844885  1.075770  ...  0.813850  0.132003 -0.827317
1  -0.076467 -1.187678  1.130127  ...  0.149748 -0.732339  0.687738
2   0.176444  0.403310 -0.154951  ... -0.493662  0.600178  0.274230
3   0.132885 -0.023688  2.410179  ...  0.109121  1.126203 -0.977349
4   1.474071 -0.064034 -1.282782  ... -0.858447  0.306996 -0.028665
..       ...       ...       ...  ...       ...       ...       ...
25  1.492125 -0.068190  0.681456  ...  0.428572  0.880609  0.487645
26  0.725238  0.624607 -0.141185  ...  1.008500  1.424017  0.717110
27  1.262419  1.950057  0.301038  ...  1.007824  2.826008  1.458383
28 -1.585746 -0.899734  0.921494  ...  0.577223 -1.088417  0.326687
29 -0.986248  0.169729 -1.158091  ... -2.013086 -1.602549  0.333109

[30 rows x 16 columns] 
```

### [`aggregate`](https://stat.ethz.ch/R-manual/R-patched/library/stats/html/aggregate.html)

在 R 中，您可能希望将数据拆分为子集并为每个子集计算平均值。使用名为`df`的数据框，并将其拆分为`by1`和`by2`组：

```py
df  <-  data.frame(
  v1  =  c(1,3,5,7,8,3,5,NA,4,5,7,9),
  v2  =  c(11,33,55,77,88,33,55,NA,44,55,77,99),
  by1  =  c("red",  "blue",  1,  2,  NA,  "big",  1,  2,  "red",  1,  NA,  12),
  by2  =  c("wet",  "dry",  99,  95,  NA,  "damp",  95,  99,  "red",  99,  NA,  NA))
aggregate(x=df[,  c("v1",  "v2")],  by=list(mydf2$by1,  mydf2$by2),  FUN  =  mean) 
```

`groupby()`方法类似于基本的 R `aggregate`函数。

```py
In [9]: df = pd.DataFrame(
 ...:    {
 ...:        "v1": [1, 3, 5, 7, 8, 3, 5, np.nan, 4, 5, 7, 9],
 ...:        "v2": [11, 33, 55, 77, 88, 33, 55, np.nan, 44, 55, 77, 99],
 ...:        "by1": ["red", "blue", 1, 2, np.nan, "big", 1, 2, "red", 1, np.nan, 12],
 ...:        "by2": [
 ...:            "wet",
 ...:            "dry",
 ...:            99,
 ...:            95,
 ...:            np.nan,
 ...:            "damp",
 ...:            95,
 ...:            99,
 ...:            "red",
 ...:            99,
 ...:            np.nan,
 ...:            np.nan,
 ...:        ],
 ...:    }
 ...: )
 ...: 

In [10]: g = df.groupby(["by1", "by2"])

In [11]: g[["v1", "v2"]].mean()
Out[11]: 
 v1    v2
by1  by2 
1    95    5.0  55.0
 99    5.0  55.0
2    95    7.0  77.0
 99    NaN   NaN
big  damp  3.0  33.0
blue dry   3.0  33.0
red  red   4.0  44.0
 wet   1.0  11.0 
```

有关更多详细信息和示例，请参阅分组文档。

### [`match` / `%in%`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/match.html)

在 R 中选择数据的常见方法是使用`%in%`，该运算符使用函数`match`定义。运算符`%in%`用于返回指示是否存在匹配项的逻辑向量：

```py
s  <-  0:4
s  %in%  c(2,4) 
```

`isin()`方法类似于 R 的`%in%`运算符：

```py
In [12]: s = pd.Series(np.arange(5), dtype=np.float32)

In [13]: s.isin([2, 4])
Out[13]: 
0    False
1    False
2     True
3    False
4     True
dtype: bool 
```

`match`函数返回其第一个参数在第二个参数中匹配位置的向量：

```py
s  <-  0:4
match(s,  c(2,4)) 
```

有关更多详细信息和示例，请参阅重塑文档。

### [`tapply`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/tapply.html)

`tapply`类似于`aggregate`，但数据可以是不规则的数组，因为子类大小可能不规则。使用名为`baseball`的数据框，并根据数组`team`检索信息：

```py
baseball  <-
  data.frame(team  =  gl(5,  5,
  labels  =  paste("Team",  LETTERS[1:5])),
  player  =  sample(letters,  25),
  batting.average  =  runif(25,  .200,  .400))

tapply(baseball$batting.average,  baseball.example$team,
  max) 
```

在 pandas 中，我们可以使用`pivot_table()`方法来处理这个问题：

```py
In [14]: import random

In [15]: import string

In [16]: baseball = pd.DataFrame(
 ....:    {
 ....:        "team": ["team %d" % (x + 1) for x in range(5)] * 5,
 ....:        "player": random.sample(list(string.ascii_lowercase), 25),
 ....:        "batting avg": np.random.uniform(0.200, 0.400, 25),
 ....:    }
 ....: )
 ....: 

In [17]: baseball.pivot_table(values="batting avg", columns="team", aggfunc="max")
Out[17]: 
team           team 1    team 2    team 3    team 4    team 5
batting avg  0.352134  0.295327  0.397191  0.394457  0.396194 
```

有关更多详细信息和示例，请参阅重塑文档。

### [`subset`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/subset.html)

`query()`方法类似于基本的 R `subset`函数。在 R 中，您可能希望获取`data.frame`的行，其中一列的值小于另一列的值：

```py
df  <-  data.frame(a=rnorm(10),  b=rnorm(10))
subset(df,  a  <=  b)
df[df$a  <=  df$b,]  # note the comma 
```

在 pandas 中，有几种方法可以执行子集。您可以使用`query()`或将表达式传递为索引/切片，以及标准布尔索引：

```py
In [18]: df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})

In [19]: df.query("a <= b")
Out[19]: 
 a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [20]: df[df["a"] <= df["b"]]
Out[20]: 
 a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [21]: df.loc[df["a"] <= df["b"]]
Out[21]: 
 a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550 
```

有关更多详细信息和示例，请参阅查询文档。

### [`with`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/with.html)

在 R 中使用名为`df`的数据框，其中包含`a`和`b`列的表达式将使用`with`进行评估：

```py
df  <-  data.frame(a=rnorm(10),  b=rnorm(10))
with(df,  a  +  b)
df$a  +  df$b  # same as the previous expression 
```

在 pandas 中，使用`eval()`方法的等效表达式将是：

```py
In [22]: df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})

In [23]: df.eval("a + b")
Out[23]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64

In [24]: df["a"] + df["b"]  # same as the previous expression
Out[24]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64 
```

在某些情况下，`eval()` 比纯 Python 中的评估要快得多。更多详细信息和示例请参见 eval 文档。

## plyr

`plyr` 是一个用于数据分析的 R 库，围绕着 R 中的三种数据结构 `a`（数组）、`l`（列表）和 `d`（数据框）展开。下表显示了这些数据结构在 Python 中的映射方式。

| R | Python |
| --- | --- |
| 数组 | 列表 |
| 列表 | 字典或对象列表 |
| data.frame | 数据框 |

### ddply

在 R 中使用名为 `df` 的 data.frame 来按 `month` 汇总 `x` 的表达式：

```py
require(plyr)
df  <-  data.frame(
  x  =  runif(120,  1,  168),
  y  =  runif(120,  7,  334),
  z  =  runif(120,  1.7,  20.7),
  month  =  rep(c(5,6,7,8),30),
  week  =  sample(1:4,  120,  TRUE)
)

ddply(df,  .(month,  week),  summarize,
  mean  =  round(mean(x),  2),
  sd  =  round(sd(x),  2)) 
```

在 pandas 中，等效的表达式，使用 `groupby()` 方法，将是：

```py
In [25]: df = pd.DataFrame(
 ....:    {
 ....:        "x": np.random.uniform(1.0, 168.0, 120),
 ....:        "y": np.random.uniform(7.0, 334.0, 120),
 ....:        "z": np.random.uniform(1.7, 20.7, 120),
 ....:        "month": [5, 6, 7, 8] * 30,
 ....:        "week": np.random.randint(1, 4, 120),
 ....:    }
 ....: )
 ....: 

In [26]: grouped = df.groupby(["month", "week"])

In [27]: grouped["x"].agg(["mean", "std"])
Out[27]: 
 mean        std
month week 
5     1      63.653367  40.601965
 2      78.126605  53.342400
 3      92.091886  57.630110
6     1      81.747070  54.339218
 2      70.971205  54.687287
 3     100.968344  54.010081
7     1      61.576332  38.844274
 2      61.733510  48.209013
 3      71.688795  37.595638
8     1      62.741922  34.618153
 2      91.774627  49.790202
 3      73.936856  60.773900 
```

更多详细信息和示例请参见 分组文档。

## reshape / reshape2

### meltarray

在 R 中使用名为 `a` 的 3 维数组来将其融合成一个 data.frame 的表达式：

```py
a  <-  array(c(1:23,  NA),  c(2,3,4))
data.frame(melt(a)) 
```

在 Python 中，由于 `a` 是一个列表，你可以简单地使用列表推导式。

```py
In [28]: a = np.array(list(range(1, 24)) + [np.NAN]).reshape(2, 3, 4)

In [29]: pd.DataFrame([tuple(list(x) + [val]) for x, val in np.ndenumerate(a)])
Out[29]: 
 0  1  2     3
0   0  0  0   1.0
1   0  0  1   2.0
2   0  0  2   3.0
3   0  0  3   4.0
4   0  1  0   5.0
.. .. .. ..   ...
19  1  1  3  20.0
20  1  2  0  21.0
21  1  2  1  22.0
22  1  2  2  23.0
23  1  2  3   NaN

[24 rows x 4 columns] 
```

### meltlist

在 R 中使用名为 `a` 的列表来将其融合成一个 data.frame 的表达式：

```py
a  <-  as.list(c(1:4,  NA))
data.frame(melt(a)) 
```

在 Python 中，这个列表将是一个元组的列表，因此 `DataFrame()` 方法将其转换为所需的数据框。

```py
In [30]: a = list(enumerate(list(range(1, 5)) + [np.NAN]))

In [31]: pd.DataFrame(a)
Out[31]: 
 0    1
0  0  1.0
1  1  2.0
2  2  3.0
3  3  4.0
4  4  NaN 
```

更多详细信息和示例请参见 数据结构入门文档。

### meltdf

在 R 中使用名为 `cheese` 的 data.frame 来重新塑造数据框的表达式：

```py
cheese  <-  data.frame(
  first  =  c('John',  'Mary'),
  last  =  c('Doe',  'Bo'),
  height  =  c(5.5,  6.0),
  weight  =  c(130,  150)
)
melt(cheese,  id=c("first",  "last")) 
```

在 Python 中，`melt()` 方法是 R 中的等效方法：

```py
In [32]: cheese = pd.DataFrame(
 ....:    {
 ....:        "first": ["John", "Mary"],
 ....:        "last": ["Doe", "Bo"],
 ....:        "height": [5.5, 6.0],
 ....:        "weight": [130, 150],
 ....:    }
 ....: )
 ....: 

In [33]: pd.melt(cheese, id_vars=["first", "last"])
Out[33]: 
 first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [34]: cheese.set_index(["first", "last"]).stack(future_stack=True)  # alternative way
Out[34]: 
first  last 
John   Doe   height      5.5
 weight    130.0
Mary   Bo    height      6.0
 weight    150.0
dtype: float64 
```

更多详细信息和示例请参见 重塑文档。

### cast

在 R 中，`acast` 是使用名为 `df` 的 data.frame 来转换为更高维数组的表达式：

```py
df  <-  data.frame(
  x  =  runif(12,  1,  168),
  y  =  runif(12,  7,  334),
  z  =  runif(12,  1.7,  20.7),
  month  =  rep(c(5,6,7),4),
  week  =  rep(c(1,2),  6)
)

mdf  <-  melt(df,  id=c("month",  "week"))
acast(mdf,  week  ~  month  ~  variable,  mean) 
```

在 Python 中，最好的方法是利用 `pivot_table()`：

```py
In [35]: df = pd.DataFrame(
 ....:    {
 ....:        "x": np.random.uniform(1.0, 168.0, 12),
 ....:        "y": np.random.uniform(7.0, 334.0, 12),
 ....:        "z": np.random.uniform(1.7, 20.7, 12),
 ....:        "month": [5, 6, 7] * 4,
 ....:        "week": [1, 2] * 6,
 ....:    }
 ....: )
 ....: 

In [36]: mdf = pd.melt(df, id_vars=["month", "week"])

In [37]: pd.pivot_table(
 ....:    mdf,
 ....:    values="value",
 ....:    index=["variable", "week"],
 ....:    columns=["month"],
 ....:    aggfunc="mean",
 ....: )
 ....: 
Out[37]: 
month                  5           6           7
variable week 
x        1     93.888747   98.762034   55.219673
 2     94.391427   38.112932   83.942781
y        1     94.306912  279.454811  227.840449
 2     87.392662  193.028166  173.899260
z        1     11.016009   10.079307   16.170549
 2      8.476111   17.638509   19.003494 
```

类似于在 R 中使用名为 `df` 的 data.frame 来基于 `Animal` 和 `FeedType` 聚合信息的 `dcast`：

```py
df  <-  data.frame(
  Animal  =  c('Animal1',  'Animal2',  'Animal3',  'Animal2',  'Animal1',
  'Animal2',  'Animal3'),
  FeedType  =  c('A',  'B',  'A',  'A',  'B',  'B',  'A'),
  Amount  =  c(10,  7,  4,  2,  5,  6,  2)
)

dcast(df,  Animal  ~  FeedType,  sum,  fill=NaN)
# Alternative method using base R
with(df,  tapply(Amount,  list(Animal,  FeedType),  sum)) 
```

Python 可以通过两种不同的方式来处理这个问题。首先，类似于上面使用 `pivot_table()`：

```py
In [38]: df = pd.DataFrame(
 ....:    {
 ....:        "Animal": [
 ....:            "Animal1",
 ....:            "Animal2",
 ....:            "Animal3",
 ....:            "Animal2",
 ....:            "Animal1",
 ....:            "Animal2",
 ....:            "Animal3",
 ....:        ],
 ....:        "FeedType": ["A", "B", "A", "A", "B", "B", "A"],
 ....:        "Amount": [10, 7, 4, 2, 5, 6, 2],
 ....:    }
 ....: )
 ....: 

In [39]: df.pivot_table(values="Amount", index="Animal", columns="FeedType", aggfunc="sum")
Out[39]: 
FeedType     A     B
Animal 
Animal1   10.0   5.0
Animal2    2.0  13.0
Animal3    6.0   NaN 
```

第二种方法是使用 `groupby()` 方法：

```py
In [40]: df.groupby(["Animal", "FeedType"])["Amount"].sum()
Out[40]: 
Animal   FeedType
Animal1  A           10
 B            5
Animal2  A            2
 B           13
Animal3  A            6
Name: Amount, dtype: int64 
```

更多详细信息和示例请参见 重塑文档 或 分组文档。

### [`factor`](https://stat.ethz.ch/R-manual/R-devel/library/base/html/factor.html)

pandas 有一种用于分类数据的数据类型。

```py
cut(c(1,2,3,4,5,6),  3)
factor(c(1,2,3,2,2,3)) 
```

在 pandas 中可以用 `pd.cut` 和 `astype("category")` 实现：

```py
In [41]: pd.cut(pd.Series([1, 2, 3, 4, 5, 6]), 3)
Out[41]: 
0    (0.995, 2.667]
1    (0.995, 2.667]
2    (2.667, 4.333]
3    (2.667, 4.333]
4      (4.333, 6.0]
5      (4.333, 6.0]
dtype: category
Categories (3, interval[float64, right]): [(0.995, 2.667] < (2.667, 4.333] < (4.333, 6.0]]

In [42]: pd.Series([1, 2, 3, 2, 2, 3]).astype("category")
Out[42]: 
0    1
1    2
2    3
3    2
4    2
5    3
dtype: category
Categories (3, int64): [1, 2, 3] 
```

更多详情和示例请参阅 分类简介 和 API 文档。还有关于 与 R 的因子的区别 的文档。

## 快速参考

我们将从一个快速参考指南开始，将一些常见的 R 操作（使用 [dplyr](https://cran.r-project.org/web/packages/dplyr/index.html)）与 pandas 的等价操作进行对比。

### 查询、过滤、抽样

| R | pandas |
| --- | --- |
| `dim(df)` | `df.shape` |
| `head(df)` | `df.head()` |
| `slice(df, 1:10)` | `df.iloc[:9]` |
| `filter(df, col1 == 1, col2 == 1)` | `df.query('col1 == 1 & col2 == 1')` |
| `df[df$col1 == 1 & df$col2 == 1,]` | `df[(df.col1 == 1) & (df.col2 == 1)]` |
| `select(df, col1, col2)` | `df[['col1', 'col2']]` |
| `select(df, col1:col3)` | `df.loc[:, 'col1':'col3']` |
| `select(df, -(col1:col3))` | `df.drop(cols_to_drop, axis=1)` 但见 [[1]](#select-range) |
| `distinct(select(df, col1))` | `df[['col1']].drop_duplicates()` |
| `distinct(select(df, col1, col2))` | `df[['col1', 'col2']].drop_duplicates()` |
| `sample_n(df, 10)` | `df.sample(n=10)` |
| `sample_frac(df, 0.01)` | `df.sample(frac=0.01)` |

### 排序

| R | pandas |
| --- | --- |
| `arrange(df, col1, col2)` | `df.sort_values(['col1', 'col2'])` |
| `arrange(df, desc(col1))` | `df.sort_values('col1', ascending=False)` |

### 转换

| R | pandas |
| --- | --- |
| `select(df, col_one = col1)` | `df.rename(columns={'col1': 'col_one'})['col_one']` |
| `rename(df, col_one = col1)` | `df.rename(columns={'col1': 'col_one'})` |
| `mutate(df, c=a-b)` | `df.assign(c=df['a']-df['b'])` |

### 分组和汇总

| R | pandas |
| --- | --- |
| `summary(df)` | `df.describe()` |
| `gdf <- group_by(df, col1)` | `gdf = df.groupby('col1')` |
| `summarise(gdf, avg=mean(col1, na.rm=TRUE))` | `df.groupby('col1').agg({'col1': 'mean'})` |
| `summarise(gdf, total=sum(col1))` | `df.groupby('col1').sum()` |

### 查询、过滤、抽样

| R | pandas |
| --- | --- |
| `dim(df)` | `df.shape` |
| `head(df)` | `df.head()` |
| `slice(df, 1:10)` | `df.iloc[:9]` |
| `filter(df, col1 == 1, col2 == 1)` | `df.query('col1 == 1 & col2 == 1')` |
| `df[df$col1 == 1 & df$col2 == 1,]` | `df[(df.col1 == 1) & (df.col2 == 1)]` |
| `select(df, col1, col2)` | `df[['col1', 'col2']]` |
| `select(df, col1:col3)` | `df.loc[:, 'col1':'col3']` |
| `select(df, -(col1:col3))` | `df.drop(cols_to_drop, axis=1)` 但见 [[1]](#select-range) |
| `distinct(select(df, col1))` | `df[['col1']].drop_duplicates()` |
| `distinct(select(df, col1, col2))` | `df[['col1', 'col2']].drop_duplicates()` |
| `sample_n(df, 10)` | `df.sample(n=10)` |
| `sample_frac(df, 0.01)` | `df.sample(frac=0.01)` |

### 排序

| R | pandas |
| --- | --- |
| `arrange(df, col1, col2)` | `df.sort_values(['col1', 'col2'])` |
| `arrange(df, desc(col1))` | `df.sort_values('col1', ascending=False)` |

### 转换

| R | pandas |
| --- | --- |
| `select(df, col_one = col1)` | `df.rename(columns={'col1': 'col_one'})['col_one']` |
| `rename(df, col_one = col1)` | `df.rename(columns={'col1': 'col_one'})` |
| `mutate(df, c=a-b)` | `df.assign(c=df['a']-df['b'])` |

### 分组和汇总

| R | pandas |
| --- | --- |
| `summary(df)` | `df.describe()` |
| `gdf <- group_by(df, col1)` | `gdf = df.groupby('col1')` |
| `summarise(gdf, avg=mean(col1, na.rm=TRUE))` | `df.groupby('col1').agg({'col1': 'mean'})` |
| `summarise(gdf, total=sum(col1))` | `df.groupby('col1').sum()` |

## 基本 R

### 使用 R 的 [`c`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/c.html) 进行切片

R 使得通过名称轻松访问 `data.frame` 列

```py
df  <-  data.frame(a=rnorm(5),  b=rnorm(5),  c=rnorm(5),  d=rnorm(5),  e=rnorm(5))
df[,  c("a",  "c",  "e")] 
```

或通过整数位置

```py
df  <-  data.frame(matrix(rnorm(1000),  ncol=100))
df[,  c(1:10,  25:30,  40,  50:100)] 
```

在 pandas 中通过名称选择多列很简单

```py
In [1]: df = pd.DataFrame(np.random.randn(10, 3), columns=list("abc"))

In [2]: df[["a", "c"]]
Out[2]: 
 a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892

In [3]: df.loc[:, ["a", "c"]]
Out[3]: 
 a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892 
```

通过整数位置选择多个不连续的列可以通过 `iloc` 索引器属性和 `numpy.r_` 的组合实现。

```py
In [4]: named = list("abcdefg")

In [5]: n = 30

In [6]: columns = named + np.arange(len(named), n).tolist()

In [7]: df = pd.DataFrame(np.random.randn(n, n), columns=columns)

In [8]: df.iloc[:, np.r_[:10, 24:30]]
Out[8]: 
 a         b         c  ...        27        28        29
0  -1.344312  0.844885  1.075770  ...  0.813850  0.132003 -0.827317
1  -0.076467 -1.187678  1.130127  ...  0.149748 -0.732339  0.687738
2   0.176444  0.403310 -0.154951  ... -0.493662  0.600178  0.274230
3   0.132885 -0.023688  2.410179  ...  0.109121  1.126203 -0.977349
4   1.474071 -0.064034 -1.282782  ... -0.858447  0.306996 -0.028665
..       ...       ...       ...  ...       ...       ...       ...
25  1.492125 -0.068190  0.681456  ...  0.428572  0.880609  0.487645
26  0.725238  0.624607 -0.141185  ...  1.008500  1.424017  0.717110
27  1.262419  1.950057  0.301038  ...  1.007824  2.826008  1.458383
28 -1.585746 -0.899734  0.921494  ...  0.577223 -1.088417  0.326687
29 -0.986248  0.169729 -1.158091  ... -2.013086 -1.602549  0.333109

[30 rows x 16 columns] 
```

### [`aggregate`](https://stat.ethz.ch/R-manual/R-patched/library/stats/html/aggregate.html)

在 R 中，您可能希望将数据拆分为子集，并为每个子集计算平均值。使用名为 `df` 的数据框，并将其拆分为 `by1` 和 `by2` 组：

```py
df  <-  data.frame(
  v1  =  c(1,3,5,7,8,3,5,NA,4,5,7,9),
  v2  =  c(11,33,55,77,88,33,55,NA,44,55,77,99),
  by1  =  c("red",  "blue",  1,  2,  NA,  "big",  1,  2,  "red",  1,  NA,  12),
  by2  =  c("wet",  "dry",  99,  95,  NA,  "damp",  95,  99,  "red",  99,  NA,  NA))
aggregate(x=df[,  c("v1",  "v2")],  by=list(mydf2$by1,  mydf2$by2),  FUN  =  mean) 
```

`groupby()` 方法类似于基本的 R `aggregate` 函数。

```py
In [9]: df = pd.DataFrame(
 ...:    {
 ...:        "v1": [1, 3, 5, 7, 8, 3, 5, np.nan, 4, 5, 7, 9],
 ...:        "v2": [11, 33, 55, 77, 88, 33, 55, np.nan, 44, 55, 77, 99],
 ...:        "by1": ["red", "blue", 1, 2, np.nan, "big", 1, 2, "red", 1, np.nan, 12],
 ...:        "by2": [
 ...:            "wet",
 ...:            "dry",
 ...:            99,
 ...:            95,
 ...:            np.nan,
 ...:            "damp",
 ...:            95,
 ...:            99,
 ...:            "red",
 ...:            99,
 ...:            np.nan,
 ...:            np.nan,
 ...:        ],
 ...:    }
 ...: )
 ...: 

In [10]: g = df.groupby(["by1", "by2"])

In [11]: g[["v1", "v2"]].mean()
Out[11]: 
 v1    v2
by1  by2 
1    95    5.0  55.0
 99    5.0  55.0
2    95    7.0  77.0
 99    NaN   NaN
big  damp  3.0  33.0
blue dry   3.0  33.0
red  red   4.0  44.0
 wet   1.0  11.0 
```

有关更多详细信息和示例，请参阅分组文档。

### [`match` / `%in%`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/match.html)

用 `%in%` 在 R 中选择数据的常见方法是使用 `match` 函数定义的。操作符 `%in%` 用于返回一个逻辑向量，指示是否有匹配项：

```py
s  <-  0:4
s  %in%  c(2,4) 
```

`isin()` 方法类似于 R 的 `%in%` 操作符：

```py
In [12]: s = pd.Series(np.arange(5), dtype=np.float32)

In [13]: s.isin([2, 4])
Out[13]: 
0    False
1    False
2     True
3    False
4     True
dtype: bool 
```

`match` 函数返回其第一个参数在第二个参数中的匹配位置的向量：

```py
s  <-  0:4
match(s,  c(2,4)) 
```

有关更多详细信息和示例，请参阅重塑文档。

### [`tapply`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/tapply.html)

`tapply` 类似于 `aggregate`，但数据可以是不规则的，因为子类大小可能不规则。使用名为 `baseball` 的数据框，并根据数组 `team` 检索信息：

```py
baseball  <-
  data.frame(team  =  gl(5,  5,
  labels  =  paste("Team",  LETTERS[1:5])),
  player  =  sample(letters,  25),
  batting.average  =  runif(25,  .200,  .400))

tapply(baseball$batting.average,  baseball.example$team,
  max) 
```

在 pandas 中，我们可以使用 `pivot_table()` 方法来处理这个问题：

```py
In [14]: import random

In [15]: import string

In [16]: baseball = pd.DataFrame(
 ....:    {
 ....:        "team": ["team %d" % (x + 1) for x in range(5)] * 5,
 ....:        "player": random.sample(list(string.ascii_lowercase), 25),
 ....:        "batting avg": np.random.uniform(0.200, 0.400, 25),
 ....:    }
 ....: )
 ....: 

In [17]: baseball.pivot_table(values="batting avg", columns="team", aggfunc="max")
Out[17]: 
team           team 1    team 2    team 3    team 4    team 5
batting avg  0.352134  0.295327  0.397191  0.394457  0.396194 
```

有关更多详细信息和示例，请参阅重塑文档。

### [`subset`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/subset.html)

`query()`方法类似于基本的 R `subset` 函数。在 R 中，您可能希望获取`data.frame`的行，其中一列的值小于另一列的值：

```py
df  <-  data.frame(a=rnorm(10),  b=rnorm(10))
subset(df,  a  <=  b)
df[df$a  <=  df$b,]  # note the comma 
```

在 pandas 中，有几种执行子集的方法。您可以使用`query()`或将表达式传递为索引/切片，以及标准布尔索引：

```py
In [18]: df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})

In [19]: df.query("a <= b")
Out[19]: 
 a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [20]: df[df["a"] <= df["b"]]
Out[20]: 
 a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [21]: df.loc[df["a"] <= df["b"]]
Out[21]: 
 a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550 
```

更多详细信息和示例请参见查询文档。

### [`with`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/with.html)

在 R 中使用名为`df`的数据框（data.frame）和列`a`和`b`的表达式将使用`with`进行评估，如下所示：

```py
df  <-  data.frame(a=rnorm(10),  b=rnorm(10))
with(df,  a  +  b)
df$a  +  df$b  # same as the previous expression 
```

在 pandas 中，使用`eval()`方法的等价表达式将是：

```py
In [22]: df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})

In [23]: df.eval("a + b")
Out[23]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64

In [24]: df["a"] + df["b"]  # same as the previous expression
Out[24]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64 
```

在某些情况下，`eval()`比纯 Python 中的评估要快得多。更多详细信息和示例请参见评估文档。

### 使用 R 的[`c`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/c.html)进行切片

R 可以轻松通过名称访问`data.frame`列

```py
df  <-  data.frame(a=rnorm(5),  b=rnorm(5),  c=rnorm(5),  d=rnorm(5),  e=rnorm(5))
df[,  c("a",  "c",  "e")] 
```

或通过整数位置

```py
df  <-  data.frame(matrix(rnorm(1000),  ncol=100))
df[,  c(1:10,  25:30,  40,  50:100)] 
```

在 pandas 中按名称选择多个列非常简单

```py
In [1]: df = pd.DataFrame(np.random.randn(10, 3), columns=list("abc"))

In [2]: df[["a", "c"]]
Out[2]: 
 a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892

In [3]: df.loc[:, ["a", "c"]]
Out[3]: 
 a         c
0  0.469112 -1.509059
1 -1.135632 -0.173215
2  0.119209 -0.861849
3 -2.104569  1.071804
4  0.721555 -1.039575
5  0.271860  0.567020
6  0.276232 -0.673690
7  0.113648  0.524988
8  0.404705 -1.715002
9 -1.039268 -1.157892 
```

通过`iloc`索引器属性和`numpy.r_`的组合可以实现通过整数位置选择多个非连续列。

```py
In [4]: named = list("abcdefg")

In [5]: n = 30

In [6]: columns = named + np.arange(len(named), n).tolist()

In [7]: df = pd.DataFrame(np.random.randn(n, n), columns=columns)

In [8]: df.iloc[:, np.r_[:10, 24:30]]
Out[8]: 
 a         b         c  ...        27        28        29
0  -1.344312  0.844885  1.075770  ...  0.813850  0.132003 -0.827317
1  -0.076467 -1.187678  1.130127  ...  0.149748 -0.732339  0.687738
2   0.176444  0.403310 -0.154951  ... -0.493662  0.600178  0.274230
3   0.132885 -0.023688  2.410179  ...  0.109121  1.126203 -0.977349
4   1.474071 -0.064034 -1.282782  ... -0.858447  0.306996 -0.028665
..       ...       ...       ...  ...       ...       ...       ...
25  1.492125 -0.068190  0.681456  ...  0.428572  0.880609  0.487645
26  0.725238  0.624607 -0.141185  ...  1.008500  1.424017  0.717110
27  1.262419  1.950057  0.301038  ...  1.007824  2.826008  1.458383
28 -1.585746 -0.899734  0.921494  ...  0.577223 -1.088417  0.326687
29 -0.986248  0.169729 -1.158091  ... -2.013086 -1.602549  0.333109

[30 rows x 16 columns] 
```

### [`aggregate`](https://stat.ethz.ch/R-manual/R-patched/library/stats/html/aggregate.html)

在 R 中，您可能希望将数据拆分为子集并为每个子集计算平均值。使用名为`df`的数据框，并将其拆分为组`by1`和`by2`：

```py
df  <-  data.frame(
  v1  =  c(1,3,5,7,8,3,5,NA,4,5,7,9),
  v2  =  c(11,33,55,77,88,33,55,NA,44,55,77,99),
  by1  =  c("red",  "blue",  1,  2,  NA,  "big",  1,  2,  "red",  1,  NA,  12),
  by2  =  c("wet",  "dry",  99,  95,  NA,  "damp",  95,  99,  "red",  99,  NA,  NA))
aggregate(x=df[,  c("v1",  "v2")],  by=list(mydf2$by1,  mydf2$by2),  FUN  =  mean) 
```

`groupby()`方法类似于基本的 R `aggregate` 函数。

```py
In [9]: df = pd.DataFrame(
 ...:    {
 ...:        "v1": [1, 3, 5, 7, 8, 3, 5, np.nan, 4, 5, 7, 9],
 ...:        "v2": [11, 33, 55, 77, 88, 33, 55, np.nan, 44, 55, 77, 99],
 ...:        "by1": ["red", "blue", 1, 2, np.nan, "big", 1, 2, "red", 1, np.nan, 12],
 ...:        "by2": [
 ...:            "wet",
 ...:            "dry",
 ...:            99,
 ...:            95,
 ...:            np.nan,
 ...:            "damp",
 ...:            95,
 ...:            99,
 ...:            "red",
 ...:            99,
 ...:            np.nan,
 ...:            np.nan,
 ...:        ],
 ...:    }
 ...: )
 ...: 

In [10]: g = df.groupby(["by1", "by2"])

In [11]: g[["v1", "v2"]].mean()
Out[11]: 
 v1    v2
by1  by2 
1    95    5.0  55.0
 99    5.0  55.0
2    95    7.0  77.0
 99    NaN   NaN
big  damp  3.0  33.0
blue dry   3.0  33.0
red  red   4.0  44.0
 wet   1.0  11.0 
```

更多详细信息和示例请参见分组文档。

### [`match` / `%in%`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/match.html)

在 R 中选择数据的常见方式是使用`%in%`，该运算符使用`match`函数定义。运算符`%in%`用于返回一个逻辑向量，指示是否存在匹配项：

```py
s  <-  0:4
s  %in%  c(2,4) 
```

`isin()`方法类似于 R 的`%in%`运算符：

```py
In [12]: s = pd.Series(np.arange(5), dtype=np.float32)

In [13]: s.isin([2, 4])
Out[13]: 
0    False
1    False
2     True
3    False
4     True
dtype: bool 
```

`match`函数返回其第一个参数在第二个参数中匹配位置的向量：

```py
s  <-  0:4
match(s,  c(2,4)) 
```

更多详细信息和示例请参见重塑文档。

### [`tapply`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/tapply.html)

`tapply` 类似于 `aggregate`，但数据可以是不规则的数组，因为子类大小可能不规则。使用名为 `baseball` 的 data.frame，并根据数组 `team` 检索信息：

```py
baseball  <-
  data.frame(team  =  gl(5,  5,
  labels  =  paste("Team",  LETTERS[1:5])),
  player  =  sample(letters,  25),
  batting.average  =  runif(25,  .200,  .400))

tapply(baseball$batting.average,  baseball.example$team,
  max) 
```

在 pandas 中，我们可以使用`pivot_table()`方法来处理这个问题：

```py
In [14]: import random

In [15]: import string

In [16]: baseball = pd.DataFrame(
 ....:    {
 ....:        "team": ["team %d" % (x + 1) for x in range(5)] * 5,
 ....:        "player": random.sample(list(string.ascii_lowercase), 25),
 ....:        "batting avg": np.random.uniform(0.200, 0.400, 25),
 ....:    }
 ....: )
 ....: 

In [17]: baseball.pivot_table(values="batting avg", columns="team", aggfunc="max")
Out[17]: 
team           team 1    team 2    team 3    team 4    team 5
batting avg  0.352134  0.295327  0.397191  0.394457  0.396194 
```

更多详细信息和示例请参见重塑文档。

### [`subset`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/subset.html)

`query()`方法类似于基本的 R `subset` 函数。在 R 中，您可能希望获取 `data.frame` 的行，其中一个列的值小于另一个列的值：

```py
df  <-  data.frame(a=rnorm(10),  b=rnorm(10))
subset(df,  a  <=  b)
df[df$a  <=  df$b,]  # note the comma 
```

在 pandas 中，有几种方法可以执行子集。您可以使用`query()`或将表达式传递为索引/切片，以及标准布尔索引：

```py
In [18]: df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})

In [19]: df.query("a <= b")
Out[19]: 
 a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [20]: df[df["a"] <= df["b"]]
Out[20]: 
 a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550

In [21]: df.loc[df["a"] <= df["b"]]
Out[21]: 
 a         b
1  0.174950  0.552887
2 -0.023167  0.148084
3 -0.495291 -0.300218
4 -0.860736  0.197378
5 -1.134146  1.720780
7 -0.290098  0.083515
8  0.238636  0.946550 
```

更多详细信息和示例请参见查询文档。

### [`with`](https://stat.ethz.ch/R-manual/R-patched/library/base/html/with.html)

在 R 中使用名为 `df` 的 data.frame，具有列 `a` 和 `b`，将使用 `with` 进行评估，如下所示：

```py
df  <-  data.frame(a=rnorm(10),  b=rnorm(10))
with(df,  a  +  b)
df$a  +  df$b  # same as the previous expression 
```

在 pandas 中，等效的��达式，使用`eval()`方法，将是：

```py
In [22]: df = pd.DataFrame({"a": np.random.randn(10), "b": np.random.randn(10)})

In [23]: df.eval("a + b")
Out[23]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64

In [24]: df["a"] + df["b"]  # same as the previous expression
Out[24]: 
0   -0.091430
1   -2.483890
2   -0.252728
3   -0.626444
4   -0.261740
5    2.149503
6   -0.332214
7    0.799331
8   -2.377245
9    2.104677
dtype: float64 
```

在某些情况下，`eval()`比纯 Python 中的评估要快得多。更多详细信息和示例请参见 eval 文档。

## plyr

`plyr` 是用于数据分析的分割-应用-组合策略的 R 库。这些函数围绕 R 中的三种数据结构展开，`a` 代表 `arrays`，`l` 代表 `lists`，`d` 代表 `data.frame`。下表显示了这些数据结构在 Python 中的映射方式。

| R | Python |
| --- | --- |
| array | list |
| lists | 字典或对象列表 |
| data.frame | dataframe |

### ddply

在 R 中使用名为 `df` 的 data.frame 表达式，您想要按 `month` 汇总 `x`：

```py
require(plyr)
df  <-  data.frame(
  x  =  runif(120,  1,  168),
  y  =  runif(120,  7,  334),
  z  =  runif(120,  1.7,  20.7),
  month  =  rep(c(5,6,7,8),30),
  week  =  sample(1:4,  120,  TRUE)
)

ddply(df,  .(month,  week),  summarize,
  mean  =  round(mean(x),  2),
  sd  =  round(sd(x),  2)) 
```

在 pandas 中，等效的表达式，使用`groupby()`方法，将是：

```py
In [25]: df = pd.DataFrame(
 ....:    {
 ....:        "x": np.random.uniform(1.0, 168.0, 120),
 ....:        "y": np.random.uniform(7.0, 334.0, 120),
 ....:        "z": np.random.uniform(1.7, 20.7, 120),
 ....:        "month": [5, 6, 7, 8] * 30,
 ....:        "week": np.random.randint(1, 4, 120),
 ....:    }
 ....: )
 ....: 

In [26]: grouped = df.groupby(["month", "week"])

In [27]: grouped["x"].agg(["mean", "std"])
Out[27]: 
 mean        std
month week 
5     1      63.653367  40.601965
 2      78.126605  53.342400
 3      92.091886  57.630110
6     1      81.747070  54.339218
 2      70.971205  54.687287
 3     100.968344  54.010081
7     1      61.576332  38.844274
 2      61.733510  48.209013
 3      71.688795  37.595638
8     1      62.741922  34.618153
 2      91.774627  49.790202
 3      73.936856  60.773900 
```

更多详细信息和示例请参见分组文档。

### ddply

在 R 中使用名为 `df` 的 data.frame 表达式，您想要按 `month` 汇总 `x`：

```py
require(plyr)
df  <-  data.frame(
  x  =  runif(120,  1,  168),
  y  =  runif(120,  7,  334),
  z  =  runif(120,  1.7,  20.7),
  month  =  rep(c(5,6,7,8),30),
  week  =  sample(1:4,  120,  TRUE)
)

ddply(df,  .(month,  week),  summarize,
  mean  =  round(mean(x),  2),
  sd  =  round(sd(x),  2)) 
```

在 pandas 中，等效的表达式，使用`groupby()`方法，将是：

```py
In [25]: df = pd.DataFrame(
 ....:    {
 ....:        "x": np.random.uniform(1.0, 168.0, 120),
 ....:        "y": np.random.uniform(7.0, 334.0, 120),
 ....:        "z": np.random.uniform(1.7, 20.7, 120),
 ....:        "month": [5, 6, 7, 8] * 30,
 ....:        "week": np.random.randint(1, 4, 120),
 ....:    }
 ....: )
 ....: 

In [26]: grouped = df.groupby(["month", "week"])

In [27]: grouped["x"].agg(["mean", "std"])
Out[27]: 
 mean        std
month week 
5     1      63.653367  40.601965
 2      78.126605  53.342400
 3      92.091886  57.630110
6     1      81.747070  54.339218
 2      70.971205  54.687287
 3     100.968344  54.010081
7     1      61.576332  38.844274
 2      61.733510  48.209013
 3      71.688795  37.595638
8     1      62.741922  34.618153
 2      91.774627  49.790202
 3      73.936856  60.773900 
```

更多细节和示例请参见分组文档。

## reshape / reshape2

### meltarray

在 R 中使用名为`a`的三维数组的表达式，你想要将其融化成数据框：

```py
a  <-  array(c(1:23,  NA),  c(2,3,4))
data.frame(melt(a)) 
```

在 Python 中，由于`a`是一个列表，你可以简单地使用列表推导式。

```py
In [28]: a = np.array(list(range(1, 24)) + [np.NAN]).reshape(2, 3, 4)

In [29]: pd.DataFrame([tuple(list(x) + [val]) for x, val in np.ndenumerate(a)])
Out[29]: 
 0  1  2     3
0   0  0  0   1.0
1   0  0  1   2.0
2   0  0  2   3.0
3   0  0  3   4.0
4   0  1  0   5.0
.. .. .. ..   ...
19  1  1  3  20.0
20  1  2  0  21.0
21  1  2  1  22.0
22  1  2  2  23.0
23  1  2  3   NaN

[24 rows x 4 columns] 
```

### meltlist

在 R 中使用名为`a`的列表的表达式，你想要将其融化成数据框：

```py
a  <-  as.list(c(1:4,  NA))
data.frame(melt(a)) 
```

在 Python 中，这个列表将是一个元组的列表，所以`DataFrame()`方法会将其转换为所需的数据框。

```py
In [30]: a = list(enumerate(list(range(1, 5)) + [np.NAN]))

In [31]: pd.DataFrame(a)
Out[31]: 
 0    1
0  0  1.0
1  1  2.0
2  2  3.0
3  3  4.0
4  4  NaN 
```

更多细节和示例请参见数据结构介绍文档。

### meltdf

在 R 中使用名为`cheese`的数据框的表达式，你想要重塑数据框：

```py
cheese  <-  data.frame(
  first  =  c('John',  'Mary'),
  last  =  c('Doe',  'Bo'),
  height  =  c(5.5,  6.0),
  weight  =  c(130,  150)
)
melt(cheese,  id=c("first",  "last")) 
```

在 Python 中，`melt()`方法是 R 的等价物：

```py
In [32]: cheese = pd.DataFrame(
 ....:    {
 ....:        "first": ["John", "Mary"],
 ....:        "last": ["Doe", "Bo"],
 ....:        "height": [5.5, 6.0],
 ....:        "weight": [130, 150],
 ....:    }
 ....: )
 ....: 

In [33]: pd.melt(cheese, id_vars=["first", "last"])
Out[33]: 
 first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [34]: cheese.set_index(["first", "last"]).stack(future_stack=True)  # alternative way
Out[34]: 
first  last 
John   Doe   height      5.5
 weight    130.0
Mary   Bo    height      6.0
 weight    150.0
dtype: float64 
```

更多细节和示��请参见重塑文档。

### 转换

在 R 中，`acast`是一个使用名为`df`的数据框来转换为更高维数组的表达式：

```py
df  <-  data.frame(
  x  =  runif(12,  1,  168),
  y  =  runif(12,  7,  334),
  z  =  runif(12,  1.7,  20.7),
  month  =  rep(c(5,6,7),4),
  week  =  rep(c(1,2),  6)
)

mdf  <-  melt(df,  id=c("month",  "week"))
acast(mdf,  week  ~  month  ~  variable,  mean) 
```

在 Python 中，最好的方法是利用`pivot_table()`：

```py
In [35]: df = pd.DataFrame(
 ....:    {
 ....:        "x": np.random.uniform(1.0, 168.0, 12),
 ....:        "y": np.random.uniform(7.0, 334.0, 12),
 ....:        "z": np.random.uniform(1.7, 20.7, 12),
 ....:        "month": [5, 6, 7] * 4,
 ....:        "week": [1, 2] * 6,
 ....:    }
 ....: )
 ....: 

In [36]: mdf = pd.melt(df, id_vars=["month", "week"])

In [37]: pd.pivot_table(
 ....:    mdf,
 ....:    values="value",
 ....:    index=["variable", "week"],
 ....:    columns=["month"],
 ....:    aggfunc="mean",
 ....: )
 ....: 
Out[37]: 
month                  5           6           7
variable week 
x        1     93.888747   98.762034   55.219673
 2     94.391427   38.112932   83.942781
y        1     94.306912  279.454811  227.840449
 2     87.392662  193.028166  173.899260
z        1     11.016009   10.079307   16.170549
 2      8.476111   17.638509   19.003494 
```

类似于`dcast`，它使用在 R 中名为`df`的数据框来根据`Animal`和`FeedType`聚合信息的表达式：

```py
df  <-  data.frame(
  Animal  =  c('Animal1',  'Animal2',  'Animal3',  'Animal2',  'Animal1',
  'Animal2',  'Animal3'),
  FeedType  =  c('A',  'B',  'A',  'A',  'B',  'B',  'A'),
  Amount  =  c(10,  7,  4,  2,  5,  6,  2)
)

dcast(df,  Animal  ~  FeedType,  sum,  fill=NaN)
# Alternative method using base R
with(df,  tapply(Amount,  list(Animal,  FeedType),  sum)) 
```

Python 可以用两种不同的方式来处理这个问题。首先，类似于上面使用`pivot_table()`：

```py
In [38]: df = pd.DataFrame(
 ....:    {
 ....:        "Animal": [
 ....:            "Animal1",
 ....:            "Animal2",
 ....:            "Animal3",
 ....:            "Animal2",
 ....:            "Animal1",
 ....:            "Animal2",
 ....:            "Animal3",
 ....:        ],
 ....:        "FeedType": ["A", "B", "A", "A", "B", "B", "A"],
 ....:        "Amount": [10, 7, 4, 2, 5, 6, 2],
 ....:    }
 ....: )
 ....: 

In [39]: df.pivot_table(values="Amount", index="Animal", columns="FeedType", aggfunc="sum")
Out[39]: 
FeedType     A     B
Animal 
Animal1   10.0   5.0
Animal2    2.0  13.0
Animal3    6.0   NaN 
```

第二种方法是使用`groupby()`方法：

```py
In [40]: df.groupby(["Animal", "FeedType"])["Amount"].sum()
Out[40]: 
Animal   FeedType
Animal1  A           10
 B            5
Animal2  A            2
 B           13
Animal3  A            6
Name: Amount, dtype: int64 
```

更多细节和示例请参见重塑文档或分组文档。

### [`factor`](https://stat.ethz.ch/R-manual/R-devel/library/base/html/factor.html)

pandas 有一个用于分类数据的数据类型。

```py
cut(c(1,2,3,4,5,6),  3)
factor(c(1,2,3,2,2,3)) 
```

在 pandas 中，可以通过`pd.cut`和`astype("category")`来实现：

```py
In [41]: pd.cut(pd.Series([1, 2, 3, 4, 5, 6]), 3)
Out[41]: 
0    (0.995, 2.667]
1    (0.995, 2.667]
2    (2.667, 4.333]
3    (2.667, 4.333]
4      (4.333, 6.0]
5      (4.333, 6.0]
dtype: category
Categories (3, interval[float64, right]): [(0.995, 2.667] < (2.667, 4.333] < (4.333, 6.0]]

In [42]: pd.Series([1, 2, 3, 2, 2, 3]).astype("category")
Out[42]: 
0    1
1    2
2    3
3    2
4    2
5    3
dtype: category
Categories (3, int64): [1, 2, 3] 
```

更多细节和示例请参见分类介绍和 API 文档。还有关于 R 的因子的差异的文档。

### meltarray

在 R 中使用名为`a`的三维数组的表达式，你想要将其融化成数据框：

```py
a  <-  array(c(1:23,  NA),  c(2,3,4))
data.frame(melt(a)) 
```

在 Python 中，由于`a`是一个列表，你可以简单地使用列表推导式。

```py
In [28]: a = np.array(list(range(1, 24)) + [np.NAN]).reshape(2, 3, 4)

In [29]: pd.DataFrame([tuple(list(x) + [val]) for x, val in np.ndenumerate(a)])
Out[29]: 
 0  1  2     3
0   0  0  0   1.0
1   0  0  1   2.0
2   0  0  2   3.0
3   0  0  3   4.0
4   0  1  0   5.0
.. .. .. ..   ...
19  1  1  3  20.0
20  1  2  0  21.0
21  1  2  1  22.0
22  1  2  2  23.0
23  1  2  3   NaN

[24 rows x 4 columns] 
```

### meltlist

在 R 中使用名为`a`的列表的表达式，你想要将其融化成数据框：

```py
a  <-  as.list(c(1:4,  NA))
data.frame(melt(a)) 
```

在 Python 中，这个列表将是一个元组的列表，所以`DataFrame()`方法会将其转换为所需的数据框。

```py
In [30]: a = list(enumerate(list(range(1, 5)) + [np.NAN]))

In [31]: pd.DataFrame(a)
Out[31]: 
 0    1
0  0  1.0
1  1  2.0
2  2  3.0
3  3  4.0
4  4  NaN 
```

更多详细信息和示例请参见数据结构介绍文档。

### meltdf

在 R 中使用名为`cheese`的数据框进行数据重塑的表达式：

```py
cheese  <-  data.frame(
  first  =  c('John',  'Mary'),
  last  =  c('Doe',  'Bo'),
  height  =  c(5.5,  6.0),
  weight  =  c(130,  150)
)
melt(cheese,  id=c("first",  "last")) 
```

在 Python 中，`melt()`方法相当于 R 中的：

```py
In [32]: cheese = pd.DataFrame(
 ....:    {
 ....:        "first": ["John", "Mary"],
 ....:        "last": ["Doe", "Bo"],
 ....:        "height": [5.5, 6.0],
 ....:        "weight": [130, 150],
 ....:    }
 ....: )
 ....: 

In [33]: pd.melt(cheese, id_vars=["first", "last"])
Out[33]: 
 first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0

In [34]: cheese.set_index(["first", "last"]).stack(future_stack=True)  # alternative way
Out[34]: 
first  last 
John   Doe   height      5.5
 weight    130.0
Mary   Bo    height      6.0
 weight    150.0
dtype: float64 
```

更多详细信息和示例请参见重塑文档。

### cast

在 R 中，`acast`是使用名为`df`的数据框进行高维数组转换的表达式：

```py
df  <-  data.frame(
  x  =  runif(12,  1,  168),
  y  =  runif(12,  7,  334),
  z  =  runif(12,  1.7,  20.7),
  month  =  rep(c(5,6,7),4),
  week  =  rep(c(1,2),  6)
)

mdf  <-  melt(df,  id=c("month",  "week"))
acast(mdf,  week  ~  month  ~  variable,  mean) 
```

在 Python 中，最佳方式是利用`pivot_table()`：

```py
In [35]: df = pd.DataFrame(
 ....:    {
 ....:        "x": np.random.uniform(1.0, 168.0, 12),
 ....:        "y": np.random.uniform(7.0, 334.0, 12),
 ....:        "z": np.random.uniform(1.7, 20.7, 12),
 ....:        "month": [5, 6, 7] * 4,
 ....:        "week": [1, 2] * 6,
 ....:    }
 ....: )
 ....: 

In [36]: mdf = pd.melt(df, id_vars=["month", "week"])

In [37]: pd.pivot_table(
 ....:    mdf,
 ....:    values="value",
 ....:    index=["variable", "week"],
 ....:    columns=["month"],
 ....:    aggfunc="mean",
 ....: )
 ....: 
Out[37]: 
month                  5           6           7
variable week 
x        1     93.888747   98.762034   55.219673
 2     94.391427   38.112932   83.942781
y        1     94.306912  279.454811  227.840449
 2     87.392662  193.028166  173.899260
z        1     11.016009   10.079307   16.170549
 2      8.476111   17.638509   19.003494 
```

类似于`dcast`，它使用 R 中名为`df`的数据框根据`Animal`和`FeedType`聚合信息：

```py
df  <-  data.frame(
  Animal  =  c('Animal1',  'Animal2',  'Animal3',  'Animal2',  'Animal1',
  'Animal2',  'Animal3'),
  FeedType  =  c('A',  'B',  'A',  'A',  'B',  'B',  'A'),
  Amount  =  c(10,  7,  4,  2,  5,  6,  2)
)

dcast(df,  Animal  ~  FeedType,  sum,  fill=NaN)
# Alternative method using base R
with(df,  tapply(Amount,  list(Animal,  FeedType),  sum)) 
```

Python 可以通过两种不同的方式来实现。首先，类似于上面使用`pivot_table()`：

```py
In [38]: df = pd.DataFrame(
 ....:    {
 ....:        "Animal": [
 ....:            "Animal1",
 ....:            "Animal2",
 ....:            "Animal3",
 ....:            "Animal2",
 ....:            "Animal1",
 ....:            "Animal2",
 ....:            "Animal3",
 ....:        ],
 ....:        "FeedType": ["A", "B", "A", "A", "B", "B", "A"],
 ....:        "Amount": [10, 7, 4, 2, 5, 6, 2],
 ....:    }
 ....: )
 ....: 

In [39]: df.pivot_table(values="Amount", index="Animal", columns="FeedType", aggfunc="sum")
Out[39]: 
FeedType     A     B
Animal 
Animal1   10.0   5.0
Animal2    2.0  13.0
Animal3    6.0   NaN 
```

第二种方法是使用`groupby()`方法：

```py
In [40]: df.groupby(["Animal", "FeedType"])["Amount"].sum()
Out[40]: 
Animal   FeedType
Animal1  A           10
 B            5
Animal2  A            2
 B           13
Animal3  A            6
Name: Amount, dtype: int64 
```

更多详细信息和示例请参见重塑文档或分组文档。

### [`factor`](https://stat.ethz.ch/R-manual/R-devel/library/base/html/factor.html)

pandas 有一种用于分类数据的数据类型。

```py
cut(c(1,2,3,4,5,6),  3)
factor(c(1,2,3,2,2,3)) 
```

在 pandas 中，可以通过`pd.cut`和`astype("category")`来实现：

```py
In [41]: pd.cut(pd.Series([1, 2, 3, 4, 5, 6]), 3)
Out[41]: 
0    (0.995, 2.667]
1    (0.995, 2.667]
2    (2.667, 4.333]
3    (2.667, 4.333]
4      (4.333, 6.0]
5      (4.333, 6.0]
dtype: category
Categories (3, interval[float64, right]): [(0.995, 2.667] < (2.667, 4.333] < (4.333, 6.0]]

In [42]: pd.Series([1, 2, 3, 2, 2, 3]).astype("category")
Out[42]: 
0    1
1    2
2    3
3    2
4    2
5    3
dtype: category
Categories (3, int64): [1, 2, 3] 
```

更多详细信息和示例请参见分类介绍和 API 文档。还有一份关于 R 中因子的差异的文档。
