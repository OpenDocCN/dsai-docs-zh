# 版本 0.10.1（2013 年 1 月 22 日）

> 原文：[`pandas.pydata.org/docs/whatsnew/v0.10.1.html`](https://pandas.pydata.org/docs/whatsnew/v0.10.1.html)

这是从 0.10.0 的一个小版本，包括新功能、增强功能和错误修复。特别是，由 Jeff Reback 贡献的新的 HDFStore 功能。

与接受`inplace`选项的函数发生的不良 API 中断已被撤销并添加了弃用警告。

## API 更改

+   接受`inplace`选项的函数将像以前一样返回调用对象。已添加弃用消息

+   Groupby 聚合 Max/Min 不再排除非数字数据（[GH 2700](https://github.com/pandas-dev/pandas/issues/2700)）

+   对空 DataFrame 进行重新采样现在返回空 DataFrame 而不是引发异常（[GH 2640](https://github.com/pandas-dev/pandas/issues/2640)）

+   文件读取器现在在明确指定的整数列中发现 NA 值时将引发异常，而不是将列转换为浮点数（[GH 2631](https://github.com/pandas-dev/pandas/issues/2631)）

+   DatetimeIndex.unique 现在返回具有相同名称和的 DatetimeIndex

+   时区而不是数组（[GH 2563](https://github.com/pandas-dev/pandas/issues/2563)）

## 新功能

+   MySQL 数据库支持（Dan Allan 的贡献）

## HDFStore

您可能需要升级现有数据文件。请访问主文档中的**兼容性**部分。

您可以指定（并索引）您希望能够在表上执行查询的某些列，通过将列表传递给`data_columns`

```py
In [1]: store = pd.HDFStore("store.h5")

In [2]: df = pd.DataFrame(
 ...:    np.random.randn(8, 3),
 ...:    index=pd.date_range("1/1/2000", periods=8),
 ...:    columns=["A", "B", "C"],
 ...: )
 ...: 

In [3]: df["string"] = "foo"

In [4]: df.loc[df.index[4:6], "string"] = np.nan

In [5]: df.loc[df.index[7:9], "string"] = "bar"

In [6]: df["string2"] = "cool"

In [7]: df
Out[7]: 
 A         B         C string string2
2000-01-01  0.469112 -0.282863 -1.509059    foo    cool
2000-01-02 -1.135632  1.212112 -0.173215    foo    cool
2000-01-03  0.119209 -1.044236 -0.861849    foo    cool
2000-01-04 -2.104569 -0.494929  1.071804    foo    cool
2000-01-05  0.721555 -0.706771 -1.039575    NaN    cool
2000-01-06  0.271860 -0.424972  0.567020    NaN    cool
2000-01-07  0.276232 -1.087401 -0.673690    foo    cool
2000-01-08  0.113648 -1.478427  0.524988    bar    cool

# on-disk operations
In [8]: store.append("df", df, data_columns=["B", "C", "string", "string2"])

In [9]: store.select("df", "B>0 and string=='foo'")
Out[9]: 
 A         B         C string string2
2000-01-02 -1.135632  1.212112 -0.173215    foo    cool

# this is in-memory version of this type of selection
In [10]: df[(df.B > 0) & (df.string == "foo")]
Out[10]: 
 A         B         C string string2
2000-01-02 -1.135632  1.212112 -0.173215    foo    cool 
```

检索可索引或数据列中的唯一值。

```py
# note that this is deprecated as of 0.14.0
# can be replicated by: store.select_column('df','index').unique()
store.unique("df", "index")
store.unique("df", "string") 
```

现在可以在数据列中存储`datetime64`

```py
In [11]: df_mixed = df.copy()

In [12]: df_mixed["datetime64"] = pd.Timestamp("20010102")

In [13]: df_mixed.loc[df_mixed.index[3:4], ["A", "B"]] = np.nan

In [14]: store.append("df_mixed", df_mixed)

In [15]: df_mixed1 = store.select("df_mixed")

In [16]: df_mixed1
Out[16]: 
 A         B  ...  string2                    datetime64
2000-01-01  0.469112 -0.282863  ...     cool 1970-01-01 00:00:00.978393600
2000-01-02 -1.135632  1.212112  ...     cool 1970-01-01 00:00:00.978393600
2000-01-03  0.119209 -1.044236  ...     cool 1970-01-01 00:00:00.978393600
2000-01-04       NaN       NaN  ...     cool 1970-01-01 00:00:00.978393600
2000-01-05  0.721555 -0.706771  ...     cool 1970-01-01 00:00:00.978393600
2000-01-06  0.271860 -0.424972  ...     cool 1970-01-01 00:00:00.978393600
2000-01-07  0.276232 -1.087401  ...     cool 1970-01-01 00:00:00.978393600
2000-01-08  0.113648 -1.478427  ...     cool 1970-01-01 00:00:00.978393600

[8 rows x 6 columns]

In [17]: df_mixed1.dtypes.value_counts()
Out[17]: 
float64           3
object            2
datetime64[ns]    1
Name: count, dtype: int64 
```

您可以将`columns`关键字传递给 select 以过滤返回列的列表，这相当于传递一个`Term('columns',list_of_columns_to_filter)`

```py
In [18]: store.select("df", columns=["A", "B"])
Out[18]: 
 A         B
2000-01-01  0.469112 -0.282863
2000-01-02 -1.135632  1.212112
2000-01-03  0.119209 -1.044236
2000-01-04 -2.104569 -0.494929
2000-01-05  0.721555 -0.706771
2000-01-06  0.271860 -0.424972
2000-01-07  0.276232 -1.087401
2000-01-08  0.113648 -1.478427 
```

`HDFStore`现在在追加表时序列化 MultiIndex 数据帧。

```py
In [19]: index = pd.MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],
 ....:                              ['one', 'two', 'three']],
 ....:                      labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
 ....:                              [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
 ....:                      names=['foo', 'bar'])
 ....:

In [20]: df = pd.DataFrame(np.random.randn(10, 3), index=index,
 ....:                  columns=['A', 'B', 'C'])
 ....:

In [21]: df
Out[21]:
 A         B         C
foo bar
foo one   -0.116619  0.295575 -1.047704
 two    1.640556  1.905836  2.772115
 three  0.088787 -1.144197 -0.633372
bar one    0.925372 -0.006438 -0.820408
 two   -0.600874 -1.039266  0.824758
baz two   -0.824095 -0.337730 -0.927764
 three -0.840123  0.248505 -0.109250
qux one    0.431977 -0.460710  0.336505
 two   -3.207595 -1.535854  0.409769
 three -0.673145 -0.741113 -0.110891

In [22]: store.append('mi', df)

In [23]: store.select('mi')
Out[23]:
 A         B         C
foo bar
foo one   -0.116619  0.295575 -1.047704
 two    1.640556  1.905836  2.772115
 three  0.088787 -1.144197 -0.633372
bar one    0.925372 -0.006438 -0.820408
 two   -0.600874 -1.039266  0.824758
baz two   -0.824095 -0.337730 -0.927764
 three -0.840123  0.248505 -0.109250
qux one    0.431977 -0.460710  0.336505
 two   -3.207595 -1.535854  0.409769
 three -0.673145 -0.741113 -0.110891

# the levels are automatically included as data columns
In [24]: store.select('mi', "foo='bar'")
Out[24]:
 A         B         C
foo bar
bar one  0.925372 -0.006438 -0.820408
 two -0.600874 -1.039266  0.824758 
```

通过`append_to_multiple`进行多表创建和通过`select_as_multiple`进行选择可以创建/选择多个表并返回合并结果，通过在选择器表上使用`where`。

```py
In [19]: df_mt = pd.DataFrame(
 ....:    np.random.randn(8, 6),
 ....:    index=pd.date_range("1/1/2000", periods=8),
 ....:    columns=["A", "B", "C", "D", "E", "F"],
 ....: )
 ....: 

In [20]: df_mt["foo"] = "bar"

# you can also create the tables individually
In [21]: store.append_to_multiple(
 ....:    {"df1_mt": ["A", "B"], "df2_mt": None}, df_mt, selector="df1_mt"
 ....: )
 ....: 

In [22]: store
Out[22]: 
<class 'pandas.io.pytables.HDFStore'>
File path: store.h5

# individual tables were created
In [23]: store.select("df1_mt")
Out[23]: 
 A         B
2000-01-01  0.404705  0.577046
2000-01-02 -1.344312  0.844885
2000-01-03  0.357021 -0.674600
2000-01-04  0.276662 -0.472035
2000-01-05  0.895717  0.805244
2000-01-06 -1.170299 -0.226169
2000-01-07 -0.076467 -1.187678
2000-01-08  1.024180  0.569605

In [24]: store.select("df2_mt")
Out[24]: 
 C         D         E         F  foo
2000-01-01 -1.715002 -1.039268 -0.370647 -1.157892  bar
2000-01-02  1.075770 -0.109050  1.643563 -1.469388  bar
2000-01-03 -1.776904 -0.968914 -1.294524  0.413738  bar
2000-01-04 -0.013960 -0.362543 -0.006154 -0.923061  bar
2000-01-05 -1.206412  2.565646  1.431256  1.340309  bar
2000-01-06  0.410835  0.813850  0.132003 -0.827317  bar
2000-01-07  1.130127 -1.436737 -1.413681  1.607920  bar
2000-01-08  0.875906 -2.211372  0.974466 -2.006747  bar

# as a multiple
In [25]: store.select_as_multiple(
 ....:    ["df1_mt", "df2_mt"], where=["A>0", "B>0"], selector="df1_mt"
 ....: )
 ....: 
Out[25]: 
 A         B         C         D         E         F  foo
2000-01-01  0.404705  0.577046 -1.715002 -1.039268 -0.370647 -1.157892  bar
2000-01-05  0.895717  0.805244 -1.206412  2.565646  1.431256  1.340309  bar
2000-01-08  1.024180  0.569605  0.875906 -2.211372  0.974466 -2.006747  bar 
```

**增强功能**

+   `HDFStore`现在可以读取本机 PyTables 表格格式表

+   您可以将`nan_rep = 'my_nan_rep'`传递给 append，以更改磁盘上的默认 nan 表示（将转换为/从`np.nan`），默认为`nan`。

+   您可以将`index`传递给`append`。默认为`True`。这将自动在表的*可索引*和*数据列*上创建索引

+   您可以将`chunksize=一个整数`传递给`append`，以更改写入块大小（默认为 50000）。这将显着降低写入时的内存使用。

+   您可以将`expectedrows=一个整数`传递给第一个`append`，以设置`PyTables`预期的总行数。这将优化读/写性能。

+   `Select`现在支持传递`start`和`stop`以提供选择空间限制。

+   大大改进了文件解析器的 ISO8601（例如，yyyy-mm-dd）日期解析能力（[GH 2698](https://github.com/pandas-dev/pandas/issues/2698))

+   允许`DataFrame.merge`处理对 64 位整数过大的组合大小（[GH 2690](https://github.com/pandas-dev/pandas/issues/2690))

+   Series 现在具有一元否定（-series）和反转（~series）运算符（[GH 2686](https://github.com/pandas-dev/pandas/issues/2686))

+   DataFrame.plot 现在包括一个`logx`参数，以将 x 轴更改为对数刻度（[GH 2327](https://github.com/pandas-dev/pandas/issues/2327))

+   Series 算术运算符现在可以处理常量和 ndarray 输入（[GH 2574](https://github.com/pandas-dev/pandas/issues/2574))

+   ExcelFile 现在接受一个`kind`参数来指定文件类型（[GH 2613](https://github.com/pandas-dev/pandas/issues/2613))

+   Series.str 方法的更快实现（[GH 2602](https://github.com/pandas-dev/pandas/issues/2602))

**错误修复**

+   `HDFStore`表现在可以正确存储`float32`类型（但不能与`float64`混合使用）

+   修复了在指定请求段时修复 Google Analytics 前缀的问题（[GH 2713](https://github.com/pandas-dev/pandas/issues/2713)).

+   重置 Google Analytics 令牌存储的功能，以便用户可以从不正确设置的客户端密钥中恢复（[GH 2687](https://github.com/pandas-dev/pandas/issues/2687)).

+   修复了在传递 MultiIndex 时导致段错误的 groupby 错误（[GH 2706](https://github.com/pandas-dev/pandas/issues/2706))

+   修复了将具有 datetime64 值的 Series 传递到`to_datetime`时导致虚假输出值的错误（[GH 2699](https://github.com/pandas-dev/pandas/issues/2699))

+   修复了在`pattern in HDFStore`表达式中传递无效正则表达式时的错误（[GH 2694](https://github.com/pandas-dev/pandas/issues/2694))

+   在聚合布尔数据时大大提高了性能（[GH 2692](https://github.com/pandas-dev/pandas/issues/2692))

+   当给定布尔掩码键和一系列新值时，Series __setitem__ 现在将传入的值与原始 Series 对齐（[GH 2686](https://github.com/pandas-dev/pandas/issues/2686))

+   修复了在具有非常大数量的组合值的 MultiIndex 级别上执行计数排序时导致 MemoryError 的错误（[GH 2684](https://github.com/pandas-dev/pandas/issues/2684))

+   修复了当索引是具有固定偏移时区的 DatetimeIndex 时绘图失败的错误（[GH 2683](https://github.com/pandas-dev/pandas/issues/2683))

+   当偏移超过 5 个工作日且起始日期为周末时，修正了工作日减法逻辑（[GH 2680](https://github.com/pandas-dev/pandas/issues/2680))

+   修复了当文件的列数多于数据时 C 文件解析器的行为（[GH 2668](https://github.com/pandas-dev/pandas/issues/2668))

+   修复了文件读取器错误，当存在隐式列和指定的`usecols`值时，列与数据不对齐

+   具有数值或日期时间索引的数据框现在在绘图之前进行排序([GH 2609](https://github.com/pandas-dev/pandas/issues/2609))

+   当传递列、索引但是空记录时，修复了 DataFrame.from_records 的错误([GH 2633](https://github.com/pandas-dev/pandas/issues/2633))

+   当 dtype 为 datetime64 时，Series 操作的若干错误已经修复([GH 2689](https://github.com/pandas-dev/pandas/issues/2689), [GH 2629](https://github.com/pandas-dev/pandas/issues/2629), [GH 2626](https://github.com/pandas-dev/pandas/issues/2626))

请查看完整的发布说明或 GitHub 上的问题跟踪器以获取完整列表。

## 贡献者

总共有 17 人为此版本贡献了补丁。名字后面有“+”符号的人第一次贡献了补丁。

+   Andy Hayden +

+   Anton I. Sipos +

+   Chang She

+   Christopher Whelan

+   Damien Garaud +

+   Dan Allan +

+   Dieter Vandenbussche

+   Garrett Drapala +

+   Jay Parlar +

+   Thouis（Ray）Jones +

+   Vincent Arel-Bundock +

+   Wes McKinney

+   elpres

+   herrfz +

+   jreback

+   svaksha +

+   y-p

## API 变更

+   以前采用`inplace`选项的函数返回调用对象。已添加了一条弃用消息

+   Groupby 聚合 Max/Min 不再排除非数字数据([GH 2700](https://github.com/pandas-dev/pandas/issues/2700))

+   对空 DataFrame 进行重新采样现在会返回一个空 DataFrame，而不是引发异常([GH 2640](https://github.com/pandas-dev/pandas/issues/2640))

+   当在显式指定的整数列中找到 NA 值时，文件读取器现在会引发异常，而不是将列转换为浮点数([GH 2631](https://github.com/pandas-dev/pandas/issues/2631))

+   DatetimeIndex.unique 现在返回一个具有相同名称的 DatetimeIndex 和

+   时区而不是数组([GH 2563](https://github.com/pandas-dev/pandas/issues/2563))

## 新功能

+   MySQL 支持数据库（Dan Allan 的贡献）

## HDFStore

您可能需要升级现有的数据文件。请访问主文档中的**兼容性**部分。

您可以指定（并索引）希望在表上执行查询的某些列，方法是将列表传递给`data_columns`

```py
In [1]: store = pd.HDFStore("store.h5")

In [2]: df = pd.DataFrame(
 ...:    np.random.randn(8, 3),
 ...:    index=pd.date_range("1/1/2000", periods=8),
 ...:    columns=["A", "B", "C"],
 ...: )
 ...: 

In [3]: df["string"] = "foo"

In [4]: df.loc[df.index[4:6], "string"] = np.nan

In [5]: df.loc[df.index[7:9], "string"] = "bar"

In [6]: df["string2"] = "cool"

In [7]: df
Out[7]: 
 A         B         C string string2
2000-01-01  0.469112 -0.282863 -1.509059    foo    cool
2000-01-02 -1.135632  1.212112 -0.173215    foo    cool
2000-01-03  0.119209 -1.044236 -0.861849    foo    cool
2000-01-04 -2.104569 -0.494929  1.071804    foo    cool
2000-01-05  0.721555 -0.706771 -1.039575    NaN    cool
2000-01-06  0.271860 -0.424972  0.567020    NaN    cool
2000-01-07  0.276232 -1.087401 -0.673690    foo    cool
2000-01-08  0.113648 -1.478427  0.524988    bar    cool

# on-disk operations
In [8]: store.append("df", df, data_columns=["B", "C", "string", "string2"])

In [9]: store.select("df", "B>0 and string=='foo'")
Out[9]: 
 A         B         C string string2
2000-01-02 -1.135632  1.212112 -0.173215    foo    cool

# this is in-memory version of this type of selection
In [10]: df[(df.B > 0) & (df.string == "foo")]
Out[10]: 
 A         B         C string string2
2000-01-02 -1.135632  1.212112 -0.173215    foo    cool 
```

在可索引或数据列中检索唯一值。

```py
# note that this is deprecated as of 0.14.0
# can be replicated by: store.select_column('df','index').unique()
store.unique("df", "index")
store.unique("df", "string") 
```

现在可以在数据列中存储`datetime64`

```py
In [11]: df_mixed = df.copy()

In [12]: df_mixed["datetime64"] = pd.Timestamp("20010102")

In [13]: df_mixed.loc[df_mixed.index[3:4], ["A", "B"]] = np.nan

In [14]: store.append("df_mixed", df_mixed)

In [15]: df_mixed1 = store.select("df_mixed")

In [16]: df_mixed1
Out[16]: 
 A         B  ...  string2                    datetime64
2000-01-01  0.469112 -0.282863  ...     cool 1970-01-01 00:00:00.978393600
2000-01-02 -1.135632  1.212112  ...     cool 1970-01-01 00:00:00.978393600
2000-01-03  0.119209 -1.044236  ...     cool 1970-01-01 00:00:00.978393600
2000-01-04       NaN       NaN  ...     cool 1970-01-01 00:00:00.978393600
2000-01-05  0.721555 -0.706771  ...     cool 1970-01-01 00:00:00.978393600
2000-01-06  0.271860 -0.424972  ...     cool 1970-01-01 00:00:00.978393600
2000-01-07  0.276232 -1.087401  ...     cool 1970-01-01 00:00:00.978393600
2000-01-08  0.113648 -1.478427  ...     cool 1970-01-01 00:00:00.978393600

[8 rows x 6 columns]

In [17]: df_mixed1.dtypes.value_counts()
Out[17]: 
float64           3
object            2
datetime64[ns]    1
Name: count, dtype: int64 
```

您可以传递`columns`关键字以选择过滤返回列的列表，这相当于传递`Term('columns',list_of_columns_to_filter)`

```py
In [18]: store.select("df", columns=["A", "B"])
Out[18]: 
 A         B
2000-01-01  0.469112 -0.282863
2000-01-02 -1.135632  1.212112
2000-01-03  0.119209 -1.044236
2000-01-04 -2.104569 -0.494929
2000-01-05  0.721555 -0.706771
2000-01-06  0.271860 -0.424972
2000-01-07  0.276232 -1.087401
2000-01-08  0.113648 -1.478427 
```

在追加表时，`HDFStore`现在序列化多重索引数据框。

```py
In [19]: index = pd.MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],
 ....:                              ['one', 'two', 'three']],
 ....:                      labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
 ....:                              [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
 ....:                      names=['foo', 'bar'])
 ....:

In [20]: df = pd.DataFrame(np.random.randn(10, 3), index=index,
 ....:                  columns=['A', 'B', 'C'])
 ....:

In [21]: df
Out[21]:
 A         B         C
foo bar
foo one   -0.116619  0.295575 -1.047704
 two    1.640556  1.905836  2.772115
 three  0.088787 -1.144197 -0.633372
bar one    0.925372 -0.006438 -0.820408
 two   -0.600874 -1.039266  0.824758
baz two   -0.824095 -0.337730 -0.927764
 three -0.840123  0.248505 -0.109250
qux one    0.431977 -0.460710  0.336505
 two   -3.207595 -1.535854  0.409769
 three -0.673145 -0.741113 -0.110891

In [22]: store.append('mi', df)

In [23]: store.select('mi')
Out[23]:
 A         B         C
foo bar
foo one   -0.116619  0.295575 -1.047704
 two    1.640556  1.905836  2.772115
 three  0.088787 -1.144197 -0.633372
bar one    0.925372 -0.006438 -0.820408
 two   -0.600874 -1.039266  0.824758
baz two   -0.824095 -0.337730 -0.927764
 three -0.840123  0.248505 -0.109250
qux one    0.431977 -0.460710  0.336505
 two   -3.207595 -1.535854  0.409769
 three -0.673145 -0.741113 -0.110891

# the levels are automatically included as data columns
In [24]: store.select('mi', "foo='bar'")
Out[24]:
 A         B         C
foo bar
bar one  0.925372 -0.006438 -0.820408
 two -0.600874 -1.039266  0.824758 
```

通过`append_to_multiple`进行多表创建，并通过`select_as_multiple`进行选择，可以从多个表中创建/选择并返回一个合并的结果，在选择器表上使用`where`。

```py
In [19]: df_mt = pd.DataFrame(
 ....:    np.random.randn(8, 6),
 ....:    index=pd.date_range("1/1/2000", periods=8),
 ....:    columns=["A", "B", "C", "D", "E", "F"],
 ....: )
 ....: 

In [20]: df_mt["foo"] = "bar"

# you can also create the tables individually
In [21]: store.append_to_multiple(
 ....:    {"df1_mt": ["A", "B"], "df2_mt": None}, df_mt, selector="df1_mt"
 ....: )
 ....: 

In [22]: store
Out[22]: 
<class 'pandas.io.pytables.HDFStore'>
File path: store.h5

# individual tables were created
In [23]: store.select("df1_mt")
Out[23]: 
 A         B
2000-01-01  0.404705  0.577046
2000-01-02 -1.344312  0.844885
2000-01-03  0.357021 -0.674600
2000-01-04  0.276662 -0.472035
2000-01-05  0.895717  0.805244
2000-01-06 -1.170299 -0.226169
2000-01-07 -0.076467 -1.187678
2000-01-08  1.024180  0.569605

In [24]: store.select("df2_mt")
Out[24]: 
 C         D         E         F  foo
2000-01-01 -1.715002 -1.039268 -0.370647 -1.157892  bar
2000-01-02  1.075770 -0.109050  1.643563 -1.469388  bar
2000-01-03 -1.776904 -0.968914 -1.294524  0.413738  bar
2000-01-04 -0.013960 -0.362543 -0.006154 -0.923061  bar
2000-01-05 -1.206412  2.565646  1.431256  1.340309  bar
2000-01-06  0.410835  0.813850  0.132003 -0.827317  bar
2000-01-07  1.130127 -1.436737 -1.413681  1.607920  bar
2000-01-08  0.875906 -2.211372  0.974466 -2.006747  bar

# as a multiple
In [25]: store.select_as_multiple(
 ....:    ["df1_mt", "df2_mt"], where=["A>0", "B>0"], selector="df1_mt"
 ....: )
 ....: 
Out[25]: 
 A         B         C         D         E         F  foo
2000-01-01  0.404705  0.577046 -1.715002 -1.039268 -0.370647 -1.157892  bar
2000-01-05  0.895717  0.805244 -1.206412  2.565646  1.431256  1.340309  bar
2000-01-08  1.024180  0.569605  0.875906 -2.211372  0.974466 -2.006747  bar 
```

**增强**

+   `HDFStore`现在可以读取本地 PyTables 表格式的表格

+   您可以传递`nan_rep = 'my_nan_rep'`以更改磁盘上的默认 nan 表示（将其转换为/from`np.nan`），默认为`nan`。

+   您可以将`index`传递给`append`。默认为`True`。这将自动在表的*索引*和*数据列*上创建索引

+   您可以将`chunksize=一个整数`传递给`append`，以更改写入块大小（默认为 50000）。这将显著降低写入时的内存使用。

+   您可以将`expectedrows=一个整数`传递给第一个`append`，以设置`PyTables`将期望的总行数。这将优化读/写性能。

+   `Select`现在支持传递`start`和`stop`以提供选择空间限制的选择。

+   大大改进了 ISO8601（例如，yyyy-mm-dd）日期解析的文件解析器（[GH 2698](https://github.com/pandas-dev/pandas/issues/2698)）

+   允许`DataFrame.merge`处理组合大小过大以至于超出 64 位整数范围的情况（[GH 2690](https://github.com/pandas-dev/pandas/issues/2690)）

+   Series 现在具有一元否定（-series）和反转（~series）运算符（[GH 2686](https://github.com/pandas-dev/pandas/issues/2686)）

+   DataFrame.plot 现在包括一个`logx`参数，以将 x 轴更改为对数刻度（[GH 2327](https://github.com/pandas-dev/pandas/issues/2327)）

+   Series 算术运算符现在可以处理常量和 ndarray 输入（[GH 2574](https://github.com/pandas-dev/pandas/issues/2574)）

+   ExcelFile 现在接受一个`kind`参数来指定文件类型（[GH 2613](https://github.com/pandas-dev/pandas/issues/2613)）

+   Series.str 方法的更快实现（[GH 2602](https://github.com/pandas-dev/pandas/issues/2602)）

**错误修复**

+   `HDFStore`表现在可以正确存储`float32`类型（但不能与`float64`混合）

+   修复了指定请求段时的 Google Analytics 前缀错误（[GH 2713](https://github.com/pandas-dev/pandas/issues/2713)）。

+   重置 Google Analytics 令牌存储的功能，以便用户可以从不正确设置的客户端密钥中恢复（[GH 2687](https://github.com/pandas-dev/pandas/issues/2687)）。

+   修复了传入 MultiIndex 时导致分组错误的 bug（[GH 2706](https://github.com/pandas-dev/pandas/issues/2706)）

+   修复了将包含 datetime64 值的 Series 传递给`to_datetime`时产生错误输出值的 bug（[GH 2699](https://github.com/pandas-dev/pandas/issues/2699)）

+   修复了在`pattern in HDFStore`表达式中，当模式不是有效的正则表达式时的 bug（[GH 2694](https://github.com/pandas-dev/pandas/issues/2694))

+   修复了在聚合布尔数据时的性能问题（[GH 2692](https://github.com/pandas-dev/pandas/issues/2692)）

+   当给定布尔掩码键和一系列新值时，Series __setitem__ 现在将传入值与原始 Series 对齐（[GH 2686](https://github.com/pandas-dev/pandas/issues/2686)）

+   修复了在具有非常大数量的组合值的 MultiIndex 级别上执行计数排序时导致的 MemoryError（[GH 2684](https://github.com/pandas-dev/pandas/issues/2684)）

+   修复了当索引为具有固定偏移时区的 DatetimeIndex 时绘图失败的 bug（[GH 2683](https://github.com/pandas-dev/pandas/issues/2683)）

+   当偏移量超过 5 个工作日且起始日期为周末时，修正了工作日减法逻辑（[GH 2680](https://github.com/pandas-dev/pandas/issues/2680)）

+   修复了 C 文件解析器行为，当文件列数多于数据时（[GH 2668](https://github.com/pandas-dev/pandas/issues/2668)）

+   修复了文件读取器错误，当存在隐式列和指定的`usecols`值时，列与数据对齐不正确

+   具有数字或日期时间索引的 DataFrames 现在在绘图之前进行排序（[GH 2609](https://github.com/pandas-dev/pandas/issues/2609)）

+   修复了当传递列、索引但记录为空时的 DataFrame.from_records 错误（[GH 2633](https://github.com/pandas-dev/pandas/issues/2633)）

+   修复了 Series 操作中 dtype 为 datetime64 时的几个 bug（[GH 2689](https://github.com/pandas-dev/pandas/issues/2689)，[GH 2629](https://github.com/pandas-dev/pandas/issues/2629)，[GH 2626](https://github.com/pandas-dev/pandas/issues/2626)）

查看完整的发布说明或 GitHub 上的问题跟踪器以获取完整列表。

## 贡献者

总共有 17 人为此版本贡献了补丁。名字后面带有“+”的人第一次贡献了补丁。

+   Andy Hayden +

+   Anton I. Sipos +

+   Chang She

+   Christopher Whelan

+   Damien Garaud +

+   Dan Allan +

+   Dieter Vandenbussche

+   Garrett Drapala +

+   Jay Parlar +

+   Thouis (Ray) Jones +

+   Vincent Arel-Bundock +

+   Wes McKinney

+   elpres

+   herrfz +

+   jreback

+   svaksha +

+   y-p
