- en: Models Supported by Ultralytics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ultralyticsæ”¯æŒçš„æ¨¡å‹
- en: åŸæ–‡ï¼š[`docs.ultralytics.com/models/`](https://docs.ultralytics.com/models/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[`docs.ultralytics.com/models/`](https://docs.ultralytics.com/models/)
- en: Welcome to Ultralytics' model documentation! We offer support for a wide range
    of models, each tailored to specific tasks like object detection, instance segmentation,
    image classification, pose estimation, and multi-object tracking. If you're interested
    in contributing your model architecture to Ultralytics, check out our Contributing
    Guide.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ¬¢è¿è®¿é—®Ultralyticsçš„æ¨¡å‹æ–‡æ¡£ï¼æˆ‘ä»¬æ”¯æŒå¤šç§æ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹éƒ½ä¸“ä¸ºç‰¹å®šä»»åŠ¡å¦‚å¯¹è±¡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€å›¾åƒåˆ†ç±»ã€å§¿æ€ä¼°è®¡å’Œå¤šå¯¹è±¡è·Ÿè¸ªè€Œè®¾è®¡ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£å°†æ‚¨çš„æ¨¡å‹æ¶æ„è´¡çŒ®ç»™Ultralyticsï¼Œè¯·æŸ¥é˜…æˆ‘ä»¬çš„è´¡çŒ®æŒ‡å—ã€‚
- en: Featured Models
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç‰¹è‰²æ¨¡å‹
- en: 'Here are some of the key models supported:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œåˆ—å‡ºäº†ä¸€äº›ä¸»è¦æ”¯æŒçš„æ¨¡å‹ï¼š
- en: '**YOLOv3**: The third iteration of the YOLO model family, originally by Joseph
    Redmon, known for its efficient real-time object detection capabilities.'
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**YOLOv3**: YOLOæ¨¡å‹ç³»åˆ—çš„ç¬¬ä¸‰ä¸ªç‰ˆæœ¬ï¼Œæœ€åˆç”±Joseph Redmonå¼€å‘ï¼Œä»¥å…¶é«˜æ•ˆçš„å®æ—¶å¯¹è±¡æ£€æµ‹èƒ½åŠ›è€Œé—»åã€‚'
- en: '**YOLOv4**: A darknet-native update to YOLOv3, released by Alexey Bochkovskiy
    in 2020.'
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**YOLOv4**: ç”±Alexey Bochkovskiyåœ¨2020å¹´å‘å¸ƒçš„darknetåŸç”Ÿæ›´æ–°ç‰ˆYOLOv3ã€‚'
- en: '**YOLOv5**: An improved version of the YOLO architecture by Ultralytics, offering
    better performance and speed trade-offs compared to previous versions.'
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**YOLOv5**: Ultralyticsæ”¹è¿›çš„YOLOæ¶æ„ç‰ˆæœ¬ï¼Œæä¾›æ¯”ä¹‹å‰ç‰ˆæœ¬æ›´å¥½çš„æ€§èƒ½å’Œé€Ÿåº¦æƒè¡¡ã€‚'
- en: '**YOLOv6**: Released by [Meituan](https://about.meituan.com/) in 2022, and
    in use in many of the company''s autonomous delivery robots.'
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**YOLOv6**: 2022å¹´ç”±[ç¾å›¢](https://about.meituan.com/)å‘å¸ƒï¼Œå¹¶åœ¨è¯¥å…¬å¸è®¸å¤šè‡ªä¸»é€é¤æœºå™¨äººä¸­ä½¿ç”¨ã€‚'
- en: '**YOLOv7**: Updated YOLO models released in 2022 by the authors of YOLOv4.'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**YOLOv7**: 2022å¹´å‘å¸ƒçš„æ›´æ–°ç‰ˆYOLOæ¨¡å‹ï¼Œç”±YOLOv4çš„ä½œè€…å‘å¸ƒã€‚'
- en: '**YOLOv8 NEW ğŸš€**: The latest version of the YOLO family, featuring enhanced
    capabilities such as instance segmentation, pose/keypoints estimation, and classification.'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**YOLOv8 NEW ğŸš€**: YOLOç³»åˆ—çš„æœ€æ–°ç‰ˆæœ¬ï¼Œå…·æœ‰å¢å¼ºçš„èƒ½åŠ›ï¼Œå¦‚å®ä¾‹åˆ†å‰²ã€å§¿æ€/å…³é”®ç‚¹ä¼°è®¡å’Œåˆ†ç±»ã€‚'
- en: '**YOLOv9**: An experimental model trained on the Ultralytics YOLOv5 codebase
    implementing Programmable Gradient Information (PGI).'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**YOLOv9**: åœ¨Ultralytics YOLOv5ä»£ç åº“ä¸Šè®­ç»ƒçš„å®éªŒæ€§æ¨¡å‹ï¼Œå®ç°å¯ç¼–ç¨‹æ¢¯åº¦ä¿¡æ¯ï¼ˆPGIï¼‰ã€‚'
- en: '**YOLOv10**: By Tsinghua University, featuring NMS-free training and efficiency-accuracy
    driven architecture, delivering state-of-the-art performance and latency.'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**YOLOv10**: æ¸…åå¤§å­¦å‘å¸ƒï¼Œé‡‡ç”¨æ— NMSè®­ç»ƒå’Œæ•ˆç‡-ç²¾åº¦é©±åŠ¨æ¶æ„ï¼Œæä¾›æœ€å…ˆè¿›çš„æ€§èƒ½å’Œå»¶è¿Ÿã€‚'
- en: '**Segment Anything Model (SAM)**: Meta''s original Segment Anything Model (SAM).'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Segment Anything Model (SAM)**: MetaåŸå§‹çš„Segment Anythingæ¨¡å‹ï¼ˆSAMï¼‰ã€‚'
- en: '**Segment Anything Model 2 (SAM2)**: The next generation of Meta''s Segment
    Anything Model (SAM) for videos and images.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Segment Anything Model 2 (SAM2)**: Metaçš„ä¸‹ä¸€ä»£è§†é¢‘å’Œå›¾åƒSegment Anythingæ¨¡å‹ï¼ˆSAMï¼‰ã€‚'
- en: '**Mobile Segment Anything Model (MobileSAM)**: MobileSAM for mobile applications,
    by Kyung Hee University.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Mobile Segment Anything Model (MobileSAM)**: MobileSAM æ˜¯ç”±åº†ç†™å¤§å­¦æ¨å‡ºçš„é¢å‘ç§»åŠ¨åº”ç”¨çš„æ¨¡å‹ã€‚'
- en: '**Fast Segment Anything Model (FastSAM)**: FastSAM by Image & Video Analysis
    Group, Institute of Automation, Chinese Academy of Sciences.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Fast Segment Anything Model (FastSAM)**: ä¸­å›½ç§‘å­¦é™¢è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€çš„Image & Video Analysis
    Groupæ¨å‡ºçš„FastSAMã€‚'
- en: '**YOLO-NAS**: YOLO Neural Architecture Search (NAS) Models.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**YOLO-NAS**: YOLOç¥ç»æ¶æ„æœç´¢ï¼ˆNASï¼‰æ¨¡å‹ã€‚'
- en: '**Realtime Detection Transformers (RT-DETR)**: Baidu''s PaddlePaddle Realtime
    Detection Transformer (RT-DETR) models.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Realtime Detection Transformers (RT-DETR)**: ç™¾åº¦çš„PaddlePaddleå®æ—¶æ£€æµ‹å˜æ¢å™¨ï¼ˆRT-DETRï¼‰æ¨¡å‹ã€‚'
- en: '**YOLO-World**: Real-time Open Vocabulary Object Detection models from Tencent
    AI Lab.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**YOLO-World**: è…¾è®¯AIå®éªŒå®¤å‘å¸ƒçš„å®æ—¶å¼€æ”¾è¯æ±‡å¯¹è±¡æ£€æµ‹æ¨¡å‹ã€‚'
- en: '[`www.youtube.com/embed/MWq1UxqTClU?si=nHAW-lYDzrz68jR0`](https://www.youtube.com/embed/MWq1UxqTClU?si=nHAW-lYDzrz68jR0)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[`www.youtube.com/embed/MWq1UxqTClU?si=nHAW-lYDzrz68jR0`](https://www.youtube.com/embed/MWq1UxqTClU?si=nHAW-lYDzrz68jR0)'
- en: '**Watch:** Run Ultralytics YOLO models in just a few lines of code.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**Watch:** ä»…éœ€å‡ è¡Œä»£ç å³å¯è¿è¡ŒUltralyticsçš„YOLOæ¨¡å‹ã€‚'
- en: 'Getting Started: Usage Examples'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…¥é—¨ï¼šä½¿ç”¨ç¤ºä¾‹
- en: This example provides simple YOLO training and inference examples. For full
    documentation on these and other modes see the Predict, Train, Val and Export
    docs pages.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç¤ºä¾‹æä¾›äº†ç®€å•çš„YOLOè®­ç»ƒå’Œæ¨æ–­ç¤ºä¾‹ã€‚æœ‰å…³è¿™äº›å’Œå…¶ä»–æ¨¡å¼çš„å®Œæ•´æ–‡æ¡£ï¼Œè¯·å‚é˜…Predictã€Trainã€Valå’ŒExportæ–‡æ¡£é¡µé¢ã€‚
- en: Note the below example is for YOLOv8 Detect models for object detection. For
    additional supported tasks see the Segment, Classify and Pose docs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ä¸‹é¢çš„ä¾‹å­æ˜¯å…³äºYOLOv8 Detectæ¨¡å‹è¿›è¡Œå¯¹è±¡æ£€æµ‹ã€‚æœ‰å…³å…¶ä»–æ”¯æŒçš„ä»»åŠ¡ï¼Œè¯·å‚é˜…Segmentã€Classifyå’ŒPoseæ–‡æ¡£ã€‚
- en: Example
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å­
- en: 'PyTorch pretrained `*.pt` models as well as configuration `*.yaml` files can
    be passed to the `YOLO()`, `SAM()`, `NAS()` and `RTDETR()` classes to create a
    model instance in Python:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥å°†é¢„è®­ç»ƒçš„PyTorch `*.pt`æ¨¡å‹ä»¥åŠé…ç½®`*.yaml`æ–‡ä»¶ä¼ é€’ç»™`YOLO()`ã€`SAM()`ã€`NAS()`å’Œ`RTDETR()`ç±»ï¼Œåœ¨Pythonä¸­åˆ›å»ºä¸€ä¸ªæ¨¡å‹å®ä¾‹ï¼š
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'CLI commands are available to directly run the models:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨CLIå‘½ä»¤ç›´æ¥è¿è¡Œæ¨¡å‹ï¼š
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Contributing New Models
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è´¡çŒ®æ–°æ¨¡å‹
- en: Interested in contributing your model to Ultralytics? Great! We're always open
    to expanding our model portfolio.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿå…´è¶£å°†æ‚¨çš„æ¨¡å‹è´¡çŒ®ç»™Ultralyticså—ï¼Ÿå¤ªæ£’äº†ï¼æˆ‘ä»¬å§‹ç»ˆæ¬¢è¿æ‰©å±•æˆ‘ä»¬çš„æ¨¡å‹ç»„åˆã€‚
- en: '**Fork the Repository**: Start by forking the [Ultralytics GitHub repository](https://github.com/ultralytics/ultralytics).'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åˆ†å‰å­˜å‚¨åº“**ï¼šé¦–å…ˆåˆ†å‰[Ultralytics GitHubå­˜å‚¨åº“](https://github.com/ultralytics/ultralytics)ã€‚'
- en: '**Clone Your Fork**: Clone your fork to your local machine and create a new
    branch to work on.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å…‹éš†æ‚¨çš„åˆ†æ”¯**ï¼šå°†æ‚¨çš„åˆ†æ”¯å…‹éš†åˆ°æœ¬åœ°æœºå™¨ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªæ–°åˆ†æ”¯è¿›è¡Œæ“ä½œã€‚'
- en: '**Implement Your Model**: Add your model following the coding standards and
    guidelines provided in our Contributing Guide.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å®ç°æ‚¨çš„æ¨¡å‹**ï¼šæŒ‰ç…§æˆ‘ä»¬æä¾›çš„è´¡çŒ®æŒ‡å—ä¸­çš„ç¼–ç æ ‡å‡†å’Œå‡†åˆ™æ·»åŠ æ‚¨çš„æ¨¡å‹ã€‚'
- en: '**Test Thoroughly**: Make sure to test your model rigorously, both in isolation
    and as part of the pipeline.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å½»åº•æµ‹è¯•**ï¼šåŠ¡å¿…å¯¹æ‚¨çš„æ¨¡å‹è¿›è¡Œä¸¥æ ¼æµ‹è¯•ï¼Œæ— è®ºæ˜¯ç‹¬ç«‹è¿›è¡Œè¿˜æ˜¯ä½œä¸ºç®¡é“çš„ä¸€éƒ¨åˆ†ã€‚'
- en: '**Create a Pull Request**: Once you''re satisfied with your model, create a
    pull request to the main repository for review.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åˆ›å»ºæ‹‰å–è¯·æ±‚**ï¼šä¸€æ—¦æ‚¨æ»¡æ„æ‚¨çš„æ¨¡å‹ï¼Œè¯·åˆ›å»ºä¸€ä¸ªæ‹‰å–è¯·æ±‚åˆ°ä¸»å­˜å‚¨åº“è¿›è¡Œå®¡æŸ¥ã€‚'
- en: '**Code Review & Merging**: After review, if your model meets our criteria,
    it will be merged into the main repository.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä»£ç å®¡æŸ¥å’Œåˆå¹¶**ï¼šç»è¿‡å®¡æŸ¥ï¼Œå¦‚æœæ‚¨çš„æ¨¡å‹ç¬¦åˆæˆ‘ä»¬çš„æ ‡å‡†ï¼Œå°†åˆå¹¶åˆ°ä¸»å­˜å‚¨åº“ä¸­ã€‚'
- en: For detailed steps, consult our Contributing Guide.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¦ç»†æ­¥éª¤ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„è´¡çŒ®æŒ‡å—ã€‚
- en: FAQ
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¸¸è§é—®é¢˜
- en: What are the key advantages of using Ultralytics YOLOv8 for object detection?
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Ultralytics YOLOv8è¿›è¡Œç›®æ ‡æ£€æµ‹çš„å…³é”®ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ
- en: Ultralytics YOLOv8 offers enhanced capabilities such as real-time object detection,
    instance segmentation, pose estimation, and classification. Its optimized architecture
    ensures high-speed performance without sacrificing accuracy, making it ideal for
    a variety of applications. YOLOv8 also includes built-in compatibility with popular
    datasets and models, as detailed on the YOLOv8 documentation page.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics YOLOv8æä¾›äº†å¢å¼ºåŠŸèƒ½ï¼Œå¦‚å®æ—¶ç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€å§¿æ€ä¼°è®¡å’Œåˆ†ç±»ã€‚å…¶ä¼˜åŒ–çš„æ¶æ„ç¡®ä¿é«˜é€Ÿæ€§èƒ½ï¼Œä¸ä¼šç‰ºç‰²å‡†ç¡®æ€§ï¼Œä½¿å…¶éå¸¸é€‚åˆå„ç§åº”ç”¨ã€‚YOLOv8è¿˜åŒ…æ‹¬ä¸æµè¡Œæ•°æ®é›†å’Œæ¨¡å‹çš„å†…ç½®å…¼å®¹æ€§ï¼Œè¯¦ç»†ä¿¡æ¯è¯·å‚é˜…YOLOv8æ–‡æ¡£é¡µé¢ã€‚
- en: How can I train a YOLOv8 model on custom data?
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¦‚ä½•åœ¨è‡ªå®šä¹‰æ•°æ®ä¸Šè®­ç»ƒYOLOv8æ¨¡å‹ï¼Ÿ
- en: 'Training a YOLOv8 model on custom data can be easily accomplished using Ultralytics''
    libraries. Here''s a quick example:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Ultralyticsåº“å¯ä»¥è½»æ¾åœ°åœ¨è‡ªå®šä¹‰æ•°æ®ä¸Šè®­ç»ƒYOLOv8æ¨¡å‹ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªå¿«é€Ÿç¤ºä¾‹ï¼š
- en: Example
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: For more detailed instructions, visit the Train documentation page.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è·å–æ›´è¯¦ç»†çš„æŒ‡å¯¼ï¼Œè¯·è®¿é—®Trainæ–‡æ¡£é¡µé¢ã€‚
- en: Which YOLO versions are supported by Ultralytics?
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Ultralyticsæ”¯æŒå“ªäº›YOLOç‰ˆæœ¬ï¼Ÿ
- en: Ultralytics supports a comprehensive range of YOLO (You Only Look Once) versions
    from YOLOv3 to YOLOv10, along with models like NAS, SAM, and RT-DETR. Each version
    is optimized for various tasks such as detection, segmentation, and classification.
    For detailed information on each model, refer to the Models Supported by Ultralytics
    documentation.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralyticsæ”¯æŒä»YOLOv3åˆ°YOLOv10ç­‰å…¨é¢çš„YOLOï¼ˆYou Only Look Onceï¼‰ç‰ˆæœ¬ï¼Œä»¥åŠNASã€SAMå’ŒRT-DETRç­‰æ¨¡å‹ã€‚æ¯ä¸ªç‰ˆæœ¬éƒ½é’ˆå¯¹æ£€æµ‹ã€åˆ†å‰²å’Œåˆ†ç±»ç­‰å„ç§ä»»åŠ¡è¿›è¡Œäº†ä¼˜åŒ–ã€‚æœ‰å…³æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…Ultralyticsæ”¯æŒçš„æ¨¡å‹æ–‡æ¡£ã€‚
- en: Why should I use Ultralytics HUB for machine learning projects?
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æˆ‘ä¸ºä»€ä¹ˆåº”è¯¥ä½¿ç”¨Ultralytics HUBè¿›è¡Œæœºå™¨å­¦ä¹ é¡¹ç›®ï¼Ÿ
- en: Ultralytics HUB provides a no-code, end-to-end platform for training, deploying,
    and managing YOLO models. It simplifies complex workflows, enabling users to focus
    on model performance and application. The HUB also offers cloud training capabilities,
    comprehensive dataset management, and user-friendly interfaces. Learn more about
    it on the Ultralytics HUB documentation page.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics HUBä¸ºè®­ç»ƒã€éƒ¨ç½²å’Œç®¡ç†YOLOæ¨¡å‹æä¾›äº†ä¸€ä¸ªæ— ä»£ç ã€ç«¯åˆ°ç«¯çš„å¹³å°ã€‚å®ƒç®€åŒ–äº†å¤æ‚çš„å·¥ä½œæµç¨‹ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿä¸“æ³¨äºæ¨¡å‹æ€§èƒ½å’Œåº”ç”¨ã€‚HUBè¿˜æä¾›äº‘è®­ç»ƒèƒ½åŠ›ã€å…¨é¢çš„æ•°æ®é›†ç®¡ç†å’Œç”¨æˆ·å‹å¥½çš„ç•Œé¢ã€‚æ›´å¤šä¿¡æ¯è¯·è®¿é—®Ultralytics
    HUBæ–‡æ¡£é¡µé¢ã€‚
- en: What types of tasks can YOLOv8 perform, and how does it compare to other YOLO
    versions?
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: YOLOv8å¯ä»¥æ‰§è¡Œå“ªäº›ç±»å‹çš„ä»»åŠ¡ï¼Œä»¥åŠä¸å…¶ä»–YOLOç‰ˆæœ¬ç›¸æ¯”æœ‰ä½•ä¼˜åŠ¿ï¼Ÿ
- en: YOLOv8 is a versatile model capable of performing tasks including object detection,
    instance segmentation, classification, and pose estimation. Compared to earlier
    versions like YOLOv3 and YOLOv4, YOLOv8 offers significant improvements in speed
    and accuracy due to its optimized architecture. For a deeper comparison, refer
    to the YOLOv8 documentation and the Task pages for more details on specific tasks.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv8 æ˜¯ä¸€ä¸ªå¤šåŠŸèƒ½æ¨¡å‹ï¼Œèƒ½å¤Ÿæ‰§è¡ŒåŒ…æ‹¬ç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€åˆ†ç±»å’Œå§¿æ€ä¼°è®¡ç­‰ä»»åŠ¡ã€‚ä¸ YOLOv3 å’Œ YOLOv4 ç­‰æ—©æœŸç‰ˆæœ¬ç›¸æ¯”ï¼ŒYOLOv8
    åœ¨é€Ÿåº¦å’Œå‡†ç¡®æ€§æ–¹é¢éƒ½æœ‰æ˜¾è‘—æå‡ï¼Œè¿™å½’åŠŸäºå…¶ä¼˜åŒ–çš„æ¶æ„ã€‚æœ‰å…³æ›´è¯¦ç»†çš„æ¯”è¾ƒï¼Œè¯·å‚è€ƒ YOLOv8 æ–‡æ¡£å’Œä»»åŠ¡é¡µé¢ï¼Œäº†è§£ç‰¹å®šä»»åŠ¡çš„æ›´å¤šç»†èŠ‚ã€‚
