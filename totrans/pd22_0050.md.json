["```py\nIn [1]: df = pd.DataFrame(\n ...:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ...: )\n ...: \n\nIn [2]: df\nOut[2]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50 \n```", "```py\nIn [3]: df.loc[df.AAA >= 5, \"BBB\"] = -1\n\nIn [4]: df\nOut[4]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   -1   50\n2    6   -1  -30\n3    7   -1  -50 \n```", "```py\nIn [5]: df.loc[df.AAA >= 5, [\"BBB\", \"CCC\"]] = 555\n\nIn [6]: df\nOut[6]: \n AAA  BBB  CCC\n0    4   10  100\n1    5  555  555\n2    6  555  555\n3    7  555  555 \n```", "```py\nIn [7]: df.loc[df.AAA < 5, [\"BBB\", \"CCC\"]] = 2000\n\nIn [8]: df\nOut[8]: \n AAA   BBB   CCC\n0    4  2000  2000\n1    5   555   555\n2    6   555   555\n3    7   555   555 \n```", "```py\nIn [9]: df_mask = pd.DataFrame(\n ...:    {\"AAA\": [True] * 4, \"BBB\": [False] * 4, \"CCC\": [True, False] * 2}\n ...: )\n ...: \n\nIn [10]: df.where(df_mask, -1000)\nOut[10]: \n AAA   BBB   CCC\n0    4 -1000  2000\n1    5 -1000 -1000\n2    6 -1000   555\n3    7 -1000 -1000 \n```", "```py\nIn [11]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [12]: df\nOut[12]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [13]: df[\"logic\"] = np.where(df[\"AAA\"] > 5, \"high\", \"low\")\n\nIn [14]: df\nOut[14]: \n AAA  BBB  CCC logic\n0    4   10  100   low\n1    5   20   50   low\n2    6   30  -30  high\n3    7   40  -50  high \n```", "```py\nIn [15]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [16]: df\nOut[16]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [17]: df[df.AAA <= 5]\nOut[17]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n\nIn [18]: df[df.AAA > 5]\nOut[18]: \n AAA  BBB  CCC\n2    6   30  -30\n3    7   40  -50 \n```", "```py\nIn [19]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [20]: df\nOut[20]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50 \n```", "```py\nIn [21]: df.loc[(df[\"BBB\"] < 25) & (df[\"CCC\"] >= -40), \"AAA\"]\nOut[21]: \n0    4\n1    5\nName: AAA, dtype: int64 \n```", "```py\nIn [22]: df.loc[(df[\"BBB\"] > 25) | (df[\"CCC\"] >= -40), \"AAA\"]\nOut[22]: \n0    4\n1    5\n2    6\n3    7\nName: AAA, dtype: int64 \n```", "```py\nIn [23]: df.loc[(df[\"BBB\"] > 25) | (df[\"CCC\"] >= 75), \"AAA\"] = 999\n\nIn [24]: df\nOut[24]: \n AAA  BBB  CCC\n0  999   10  100\n1    5   20   50\n2  999   30  -30\n3  999   40  -50 \n```", "```py\nIn [25]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [26]: df\nOut[26]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [27]: aValue = 43.0\n\nIn [28]: df.loc[(df.CCC - aValue).abs().argsort()]\nOut[28]: \n AAA  BBB  CCC\n1    5   20   50\n0    4   10  100\n2    6   30  -30\n3    7   40  -50 \n```", "```py\nIn [29]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [30]: df\nOut[30]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [31]: Crit1 = df.AAA <= 5.5\n\nIn [32]: Crit2 = df.BBB == 10.0\n\nIn [33]: Crit3 = df.CCC > -40.0 \n```", "```py\nIn [34]: AllCrit = Crit1 & Crit2 & Crit3 \n```", "```py\nIn [35]: import functools\n\nIn [36]: CritList = [Crit1, Crit2, Crit3]\n\nIn [37]: AllCrit = functools.reduce(lambda x, y: x & y, CritList)\n\nIn [38]: df[AllCrit]\nOut[38]: \n AAA  BBB  CCC\n0    4   10  100 \n```", "```py\nIn [39]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [40]: df\nOut[40]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [41]: df[(df.AAA <= 6) & (df.index.isin([0, 2, 4]))]\nOut[41]: \n AAA  BBB  CCC\n0    4   10  100\n2    6   30  -30 \n```", "```py\nIn [42]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]},\n ....:    index=[\"foo\", \"bar\", \"boo\", \"kar\"],\n ....: )\n ....: \n```", "```py\nIn [43]: df.loc[\"bar\":\"kar\"]  # Label\nOut[43]: \n AAA  BBB  CCC\nbar    5   20   50\nboo    6   30  -30\nkar    7   40  -50\n\n# Generic\nIn [44]: df[0:3]\nOut[44]: \n AAA  BBB  CCC\nfoo    4   10  100\nbar    5   20   50\nboo    6   30  -30\n\nIn [45]: df[\"bar\":\"kar\"]\nOut[45]: \n AAA  BBB  CCC\nbar    5   20   50\nboo    6   30  -30\nkar    7   40  -50 \n```", "```py\nIn [46]: data = {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n\nIn [47]: df2 = pd.DataFrame(data=data, index=[1, 2, 3, 4])  # Note index starts at 1.\n\nIn [48]: df2.iloc[1:3]  # Position-oriented\nOut[48]: \n AAA  BBB  CCC\n2    5   20   50\n3    6   30  -30\n\nIn [49]: df2.loc[1:3]  # Label-oriented\nOut[49]: \n AAA  BBB  CCC\n1    4   10  100\n2    5   20   50\n3    6   30  -30 \n```", "```py\nIn [50]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [51]: df\nOut[51]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [52]: df[~((df.AAA <= 6) & (df.index.isin([0, 2, 4])))]\nOut[52]: \n AAA  BBB  CCC\n1    5   20   50\n3    7   40  -50 \n```", "```py\nIn [53]: df = pd.DataFrame({\"AAA\": [1, 2, 1, 3], \"BBB\": [1, 1, 2, 2], \"CCC\": [2, 1, 3, 1]})\n\nIn [54]: df\nOut[54]: \n AAA  BBB  CCC\n0    1    1    2\n1    2    1    1\n2    1    2    3\n3    3    2    1\n\nIn [55]: source_cols = df.columns  # Or some subset would work too\n\nIn [56]: new_cols = [str(x) + \"_cat\" for x in source_cols]\n\nIn [57]: categories = {1: \"Alpha\", 2: \"Beta\", 3: \"Charlie\"}\n\nIn [58]: df[new_cols] = df[source_cols].map(categories.get)\n\nIn [59]: df\nOut[59]: \n AAA  BBB  CCC  AAA_cat BBB_cat  CCC_cat\n0    1    1    2    Alpha   Alpha     Beta\n1    2    1    1     Beta   Alpha    Alpha\n2    1    2    3    Alpha    Beta  Charlie\n3    3    2    1  Charlie    Beta    Alpha \n```", "```py\nIn [60]: df = pd.DataFrame(\n ....:    {\"AAA\": [1, 1, 1, 2, 2, 2, 3, 3], \"BBB\": [2, 1, 3, 4, 5, 1, 2, 3]}\n ....: )\n ....: \n\nIn [61]: df\nOut[61]: \n AAA  BBB\n0    1    2\n1    1    1\n2    1    3\n3    2    4\n4    2    5\n5    2    1\n6    3    2\n7    3    3 \n```", "```py\nIn [62]: df.loc[df.groupby(\"AAA\")[\"BBB\"].idxmin()]\nOut[62]: \n AAA  BBB\n1    1    1\n5    2    1\n6    3    2 \n```", "```py\nIn [63]: df.sort_values(by=\"BBB\").groupby(\"AAA\", as_index=False).first()\nOut[63]: \n AAA  BBB\n0    1    1\n1    2    1\n2    3    2 \n```", "```py\nIn [64]: df = pd.DataFrame(\n ....:    {\n ....:        \"row\": [0, 1, 2],\n ....:        \"One_X\": [1.1, 1.1, 1.1],\n ....:        \"One_Y\": [1.2, 1.2, 1.2],\n ....:        \"Two_X\": [1.11, 1.11, 1.11],\n ....:        \"Two_Y\": [1.22, 1.22, 1.22],\n ....:    }\n ....: )\n ....: \n\nIn [65]: df\nOut[65]: \n row  One_X  One_Y  Two_X  Two_Y\n0    0    1.1    1.2   1.11   1.22\n1    1    1.1    1.2   1.11   1.22\n2    2    1.1    1.2   1.11   1.22\n\n# As Labelled Index\nIn [66]: df = df.set_index(\"row\")\n\nIn [67]: df\nOut[67]: \n One_X  One_Y  Two_X  Two_Y\nrow \n0      1.1    1.2   1.11   1.22\n1      1.1    1.2   1.11   1.22\n2      1.1    1.2   1.11   1.22\n\n# With Hierarchical Columns\nIn [68]: df.columns = pd.MultiIndex.from_tuples([tuple(c.split(\"_\")) for c in df.columns])\n\nIn [69]: df\nOut[69]: \n One        Two \n X    Y     X     Y\nrow \n0    1.1  1.2  1.11  1.22\n1    1.1  1.2  1.11  1.22\n2    1.1  1.2  1.11  1.22\n\n# Now stack & Reset\nIn [70]: df = df.stack(0, future_stack=True).reset_index(1)\n\nIn [71]: df\nOut[71]: \n level_1     X     Y\nrow \n0       One  1.10  1.20\n0       Two  1.11  1.22\n1       One  1.10  1.20\n1       Two  1.11  1.22\n2       One  1.10  1.20\n2       Two  1.11  1.22\n\n# And fix the labels (Notice the label 'level_1' got added automatically)\nIn [72]: df.columns = [\"Sample\", \"All_X\", \"All_Y\"]\n\nIn [73]: df\nOut[73]: \n Sample  All_X  All_Y\nrow \n0      One   1.10   1.20\n0      Two   1.11   1.22\n1      One   1.10   1.20\n1      Two   1.11   1.22\n2      One   1.10   1.20\n2      Two   1.11   1.22 \n```", "```py\nIn [74]: cols = pd.MultiIndex.from_tuples(\n ....:    [(x, y) for x in [\"A\", \"B\", \"C\"] for y in [\"O\", \"I\"]]\n ....: )\n ....: \n\nIn [75]: df = pd.DataFrame(np.random.randn(2, 6), index=[\"n\", \"m\"], columns=cols)\n\nIn [76]: df\nOut[76]: \n A                   B                   C \n O         I         O         I         O         I\nn  0.469112 -0.282863 -1.509059 -1.135632  1.212112 -0.173215\nm  0.119209 -1.044236 -0.861849 -2.104569 -0.494929  1.071804\n\nIn [77]: df = df.div(df[\"C\"], level=1)\n\nIn [78]: df\nOut[78]: \n A                   B              C \n O         I         O         I    O    I\nn  0.387021  1.633022 -1.244983  6.556214  1.0  1.0\nm -0.240860 -0.974279  1.741358 -1.963577  1.0  1.0 \n```", "```py\nIn [79]: coords = [(\"AA\", \"one\"), (\"AA\", \"six\"), (\"BB\", \"one\"), (\"BB\", \"two\"), (\"BB\", \"six\")]\n\nIn [80]: index = pd.MultiIndex.from_tuples(coords)\n\nIn [81]: df = pd.DataFrame([11, 22, 33, 44, 55], index, [\"MyData\"])\n\nIn [82]: df\nOut[82]: \n MyData\nAA one      11\n six      22\nBB one      33\n two      44\n six      55 \n```", "```py\n# Note : level and axis are optional, and default to zero\nIn [83]: df.xs(\"BB\", level=0, axis=0)\nOut[83]: \n MyData\none      33\ntwo      44\nsix      55 \n```", "```py\nIn [84]: df.xs(\"six\", level=1, axis=0)\nOut[84]: \n MyData\nAA      22\nBB      55 \n```", "```py\nIn [85]: import itertools\n\nIn [86]: index = list(itertools.product([\"Ada\", \"Quinn\", \"Violet\"], [\"Comp\", \"Math\", \"Sci\"]))\n\nIn [87]: headr = list(itertools.product([\"Exams\", \"Labs\"], [\"I\", \"II\"]))\n\nIn [88]: indx = pd.MultiIndex.from_tuples(index, names=[\"Student\", \"Course\"])\n\nIn [89]: cols = pd.MultiIndex.from_tuples(headr)  # Notice these are un-named\n\nIn [90]: data = [[70 + x + y + (x * y) % 3 for x in range(4)] for y in range(9)]\n\nIn [91]: df = pd.DataFrame(data, indx, cols)\n\nIn [92]: df\nOut[92]: \n Exams     Labs \n I  II    I  II\nStudent Course \nAda     Comp      70  71   72  73\n Math      71  73   75  74\n Sci       72  75   75  75\nQuinn   Comp      73  74   75  76\n Math      74  76   78  77\n Sci       75  78   78  78\nViolet  Comp      76  77   78  79\n Math      77  79   81  80\n Sci       78  81   81  81\n\nIn [93]: All = slice(None)\n\nIn [94]: df.loc[\"Violet\"]\nOut[94]: \n Exams     Labs \n I  II    I  II\nCourse \nComp      76  77   78  79\nMath      77  79   81  80\nSci       78  81   81  81\n\nIn [95]: df.loc[(All, \"Math\"), All]\nOut[95]: \n Exams     Labs \n I  II    I  II\nStudent Course \nAda     Math      71  73   75  74\nQuinn   Math      74  76   78  77\nViolet  Math      77  79   81  80\n\nIn [96]: df.loc[(slice(\"Ada\", \"Quinn\"), \"Math\"), All]\nOut[96]: \n Exams     Labs \n I  II    I  II\nStudent Course \nAda     Math      71  73   75  74\nQuinn   Math      74  76   78  77\n\nIn [97]: df.loc[(All, \"Math\"), (\"Exams\")]\nOut[97]: \n I  II\nStudent Course \nAda     Math    71  73\nQuinn   Math    74  76\nViolet  Math    77  79\n\nIn [98]: df.loc[(All, \"Math\"), (All, \"II\")]\nOut[98]: \n Exams Labs\n II   II\nStudent Course \nAda     Math      73   74\nQuinn   Math      76   77\nViolet  Math      79   80 \n```", "```py\nIn [99]: df.sort_values(by=(\"Labs\", \"II\"), ascending=False)\nOut[99]: \n Exams     Labs \n I  II    I  II\nStudent Course \nViolet  Sci       78  81   81  81\n Math      77  79   81  80\n Comp      76  77   78  79\nQuinn   Sci       75  78   78  78\n Math      74  76   78  77\n Comp      73  74   75  76\nAda     Sci       72  75   75  75\n Math      71  73   75  74\n Comp      70  71   72  73 \n```", "```py\nIn [100]: df = pd.DataFrame(\n .....:    np.random.randn(6, 1),\n .....:    index=pd.date_range(\"2013-08-01\", periods=6, freq=\"B\"),\n .....:    columns=list(\"A\"),\n .....: )\n .....: \n\nIn [101]: df.loc[df.index[3], \"A\"] = np.nan\n\nIn [102]: df\nOut[102]: \n A\n2013-08-01  0.721555\n2013-08-02 -0.706771\n2013-08-05 -1.039575\n2013-08-06       NaN\n2013-08-07 -0.424972\n2013-08-08  0.567020\n\nIn [103]: df.bfill()\nOut[103]: \n A\n2013-08-01  0.721555\n2013-08-02 -0.706771\n2013-08-05 -1.039575\n2013-08-06 -0.424972\n2013-08-07 -0.424972\n2013-08-08  0.567020 \n```", "```py\nIn [104]: df = pd.DataFrame(\n .....:    {\n .....:        \"animal\": \"cat dog cat fish dog cat cat\".split(),\n .....:        \"size\": list(\"SSMMMLL\"),\n .....:        \"weight\": [8, 10, 11, 1, 20, 12, 12],\n .....:        \"adult\": [False] * 5 + [True] * 2,\n .....:    }\n .....: )\n .....: \n\nIn [105]: df\nOut[105]: \n animal size  weight  adult\n0    cat    S       8  False\n1    dog    S      10  False\n2    cat    M      11  False\n3   fish    M       1  False\n4    dog    M      20  False\n5    cat    L      12   True\n6    cat    L      12   True\n\n# List the size of the animals with the highest weight.\nIn [106]: df.groupby(\"animal\").apply(lambda subf: subf[\"size\"][subf[\"weight\"].idxmax()], include_groups=False)\nOut[106]: \nanimal\ncat     L\ndog     M\nfish    M\ndtype: object \n```", "```py\nIn [107]: gb = df.groupby(\"animal\")\n\nIn [108]: gb.get_group(\"cat\")\nOut[108]: \n animal size  weight  adult\n0    cat    S       8  False\n2    cat    M      11  False\n5    cat    L      12   True\n6    cat    L      12   True \n```", "```py\nIn [109]: def GrowUp(x):\n .....:    avg_weight = sum(x[x[\"size\"] == \"S\"].weight * 1.5)\n .....:    avg_weight += sum(x[x[\"size\"] == \"M\"].weight * 1.25)\n .....:    avg_weight += sum(x[x[\"size\"] == \"L\"].weight)\n .....:    avg_weight /= len(x)\n .....:    return pd.Series([\"L\", avg_weight, True], index=[\"size\", \"weight\", \"adult\"])\n .....: \n\nIn [110]: expected_df = gb.apply(GrowUp, include_groups=False)\n\nIn [111]: expected_df\nOut[111]: \n size   weight  adult\nanimal \ncat       L  12.4375   True\ndog       L  20.0000   True\nfish      L   1.2500   True \n```", "```py\nIn [112]: S = pd.Series([i / 100.0 for i in range(1, 11)])\n\nIn [113]: def cum_ret(x, y):\n .....:    return x * (1 + y)\n .....: \n\nIn [114]: def red(x):\n .....:    return functools.reduce(cum_ret, x, 1.0)\n .....: \n\nIn [115]: S.expanding().apply(red, raw=True)\nOut[115]: \n0    1.010000\n1    1.030200\n2    1.061106\n3    1.103550\n4    1.158728\n5    1.228251\n6    1.314229\n7    1.419367\n8    1.547110\n9    1.701821\ndtype: float64 \n```", "```py\nIn [116]: df = pd.DataFrame({\"A\": [1, 1, 2, 2], \"B\": [1, -1, 1, 2]})\n\nIn [117]: gb = df.groupby(\"A\")\n\nIn [118]: def replace(g):\n .....:    mask = g < 0\n .....:    return g.where(~mask, g[~mask].mean())\n .....: \n\nIn [119]: gb.transform(replace)\nOut[119]: \n B\n0  1\n1  1\n2  1\n3  2 \n```", "```py\nIn [120]: df = pd.DataFrame(\n .....:    {\n .....:        \"code\": [\"foo\", \"bar\", \"baz\"] * 2,\n .....:        \"data\": [0.16, -0.21, 0.33, 0.45, -0.59, 0.62],\n .....:        \"flag\": [False, True] * 3,\n .....:    }\n .....: )\n .....: \n\nIn [121]: code_groups = df.groupby(\"code\")\n\nIn [122]: agg_n_sort_order = code_groups[[\"data\"]].transform(\"sum\").sort_values(by=\"data\")\n\nIn [123]: sorted_df = df.loc[agg_n_sort_order.index]\n\nIn [124]: sorted_df\nOut[124]: \n code  data   flag\n1  bar -0.21   True\n4  bar -0.59  False\n0  foo  0.16  False\n3  foo  0.45   True\n2  baz  0.33  False\n5  baz  0.62   True \n```", "```py\nIn [125]: rng = pd.date_range(start=\"2014-10-07\", periods=10, freq=\"2min\")\n\nIn [126]: ts = pd.Series(data=list(range(10)), index=rng)\n\nIn [127]: def MyCust(x):\n .....:    if len(x) > 2:\n .....:        return x.iloc[1] * 1.234\n .....:    return pd.NaT\n .....: \n\nIn [128]: mhc = {\"Mean\": \"mean\", \"Max\": \"max\", \"Custom\": MyCust}\n\nIn [129]: ts.resample(\"5min\").apply(mhc)\nOut[129]: \n Mean  Max Custom\n2014-10-07 00:00:00   1.0    2  1.234\n2014-10-07 00:05:00   3.5    4    NaT\n2014-10-07 00:10:00   6.0    7  7.404\n2014-10-07 00:15:00   8.5    9    NaT\n\nIn [130]: ts\nOut[130]: \n2014-10-07 00:00:00    0\n2014-10-07 00:02:00    1\n2014-10-07 00:04:00    2\n2014-10-07 00:06:00    3\n2014-10-07 00:08:00    4\n2014-10-07 00:10:00    5\n2014-10-07 00:12:00    6\n2014-10-07 00:14:00    7\n2014-10-07 00:16:00    8\n2014-10-07 00:18:00    9\nFreq: 2min, dtype: int64 \n```", "```py\nIn [131]: df = pd.DataFrame(\n .....:    {\"Color\": \"Red Red Red Blue\".split(), \"Value\": [100, 150, 50, 50]}\n .....: )\n .....: \n\nIn [132]: df\nOut[132]: \n Color  Value\n0   Red    100\n1   Red    150\n2   Red     50\n3  Blue     50\n\nIn [133]: df[\"Counts\"] = df.groupby([\"Color\"]).transform(len)\n\nIn [134]: df\nOut[134]: \n Color  Value  Counts\n0   Red    100       3\n1   Red    150       3\n2   Red     50       3\n3  Blue     50       1 \n```", "```py\nIn [135]: df = pd.DataFrame(\n .....:    {\"line_race\": [10, 10, 8, 10, 10, 8], \"beyer\": [99, 102, 103, 103, 88, 100]},\n .....:    index=[\n .....:        \"Last Gunfighter\",\n .....:        \"Last Gunfighter\",\n .....:        \"Last Gunfighter\",\n .....:        \"Paynter\",\n .....:        \"Paynter\",\n .....:        \"Paynter\",\n .....:    ],\n .....: )\n .....: \n\nIn [136]: df\nOut[136]: \n line_race  beyer\nLast Gunfighter         10     99\nLast Gunfighter         10    102\nLast Gunfighter          8    103\nPaynter                 10    103\nPaynter                 10     88\nPaynter                  8    100\n\nIn [137]: df[\"beyer_shifted\"] = df.groupby(level=0)[\"beyer\"].shift(1)\n\nIn [138]: df\nOut[138]: \n line_race  beyer  beyer_shifted\nLast Gunfighter         10     99            NaN\nLast Gunfighter         10    102           99.0\nLast Gunfighter          8    103          102.0\nPaynter                 10    103            NaN\nPaynter                 10     88          103.0\nPaynter                  8    100           88.0 \n```", "```py\nIn [139]: df = pd.DataFrame(\n .....:    {\n .....:        \"host\": [\"other\", \"other\", \"that\", \"this\", \"this\"],\n .....:        \"service\": [\"mail\", \"web\", \"mail\", \"mail\", \"web\"],\n .....:        \"no\": [1, 2, 1, 2, 1],\n .....:    }\n .....: ).set_index([\"host\", \"service\"])\n .....: \n\nIn [140]: mask = df.groupby(level=0).agg(\"idxmax\")\n\nIn [141]: df_count = df.loc[mask[\"no\"]].reset_index()\n\nIn [142]: df_count\nOut[142]: \n host service  no\n0  other     web   2\n1   that    mail   1\n2   this    mail   2 \n```", "```py\nIn [143]: df = pd.DataFrame([0, 1, 0, 1, 1, 1, 0, 1, 1], columns=[\"A\"])\n\nIn [144]: df[\"A\"].groupby((df[\"A\"] != df[\"A\"].shift()).cumsum()).groups\nOut[144]: {1: [0], 2: [1], 3: [2], 4: [3, 4, 5], 5: [6], 6: [7, 8]}\n\nIn [145]: df[\"A\"].groupby((df[\"A\"] != df[\"A\"].shift()).cumsum()).cumsum()\nOut[145]: \n0    0\n1    1\n2    0\n3    1\n4    2\n5    3\n6    0\n7    1\n8    2\nName: A, dtype: int64 \n```", "```py\nIn [146]: df = pd.DataFrame(\n .....:    data={\n .....:        \"Case\": [\"A\", \"A\", \"A\", \"B\", \"A\", \"A\", \"B\", \"A\", \"A\"],\n .....:        \"Data\": np.random.randn(9),\n .....:    }\n .....: )\n .....: \n\nIn [147]: dfs = list(\n .....:    zip(\n .....:        *df.groupby(\n .....:            (1 * (df[\"Case\"] == \"B\"))\n .....:            .cumsum()\n .....:            .rolling(window=3, min_periods=1)\n .....:            .median()\n .....:        )\n .....:    )\n .....: )[-1]\n .....: \n\nIn [148]: dfs[0]\nOut[148]: \n Case      Data\n0    A  0.276232\n1    A -1.087401\n2    A -0.673690\n3    B  0.113648\n\nIn [149]: dfs[1]\nOut[149]: \n Case      Data\n4    A -1.478427\n5    A  0.524988\n6    B  0.404705\n\nIn [150]: dfs[2]\nOut[150]: \n Case      Data\n7    A  0.577046\n8    A -1.715002 \n```", "```py\nIn [151]: df = pd.DataFrame(\n .....:    data={\n .....:        \"Province\": [\"ON\", \"QC\", \"BC\", \"AL\", \"AL\", \"MN\", \"ON\"],\n .....:        \"City\": [\n .....:            \"Toronto\",\n .....:            \"Montreal\",\n .....:            \"Vancouver\",\n .....:            \"Calgary\",\n .....:            \"Edmonton\",\n .....:            \"Winnipeg\",\n .....:            \"Windsor\",\n .....:        ],\n .....:        \"Sales\": [13, 6, 16, 8, 4, 3, 1],\n .....:    }\n .....: )\n .....: \n\nIn [152]: table = pd.pivot_table(\n .....:    df,\n .....:    values=[\"Sales\"],\n .....:    index=[\"Province\"],\n .....:    columns=[\"City\"],\n .....:    aggfunc=\"sum\",\n .....:    margins=True,\n .....: )\n .....: \n\nIn [153]: table.stack(\"City\", future_stack=True)\nOut[153]: \n Sales\nProvince City \nAL       Calgary      8.0\n Edmonton     4.0\n Montreal     NaN\n Toronto      NaN\n Vancouver    NaN\n...                   ...\nAll      Toronto     13.0\n Vancouver   16.0\n Windsor      1.0\n Winnipeg     3.0\n All         51.0\n\n[48 rows x 1 columns] \n```", "```py\nIn [154]: grades = [48, 99, 75, 80, 42, 80, 72, 68, 36, 78]\n\nIn [155]: df = pd.DataFrame(\n .....:    {\n .....:        \"ID\": [\"x%d\" % r for r in range(10)],\n .....:        \"Gender\": [\"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"M\", \"M\"],\n .....:        \"ExamYear\": [\n .....:            \"2007\",\n .....:            \"2007\",\n .....:            \"2007\",\n .....:            \"2008\",\n .....:            \"2008\",\n .....:            \"2008\",\n .....:            \"2008\",\n .....:            \"2009\",\n .....:            \"2009\",\n .....:            \"2009\",\n .....:        ],\n .....:        \"Class\": [\n .....:            \"algebra\",\n .....:            \"stats\",\n .....:            \"bio\",\n .....:            \"algebra\",\n .....:            \"algebra\",\n .....:            \"stats\",\n .....:            \"stats\",\n .....:            \"algebra\",\n .....:            \"bio\",\n .....:            \"bio\",\n .....:        ],\n .....:        \"Participated\": [\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"no\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:        ],\n .....:        \"Passed\": [\"yes\" if x > 50 else \"no\" for x in grades],\n .....:        \"Employed\": [\n .....:            True,\n .....:            True,\n .....:            True,\n .....:            False,\n .....:            False,\n .....:            False,\n .....:            False,\n .....:            True,\n .....:            True,\n .....:            False,\n .....:        ],\n .....:        \"Grade\": grades,\n .....:    }\n .....: )\n .....: \n\nIn [156]: df.groupby(\"ExamYear\").agg(\n .....:    {\n .....:        \"Participated\": lambda x: x.value_counts()[\"yes\"],\n .....:        \"Passed\": lambda x: sum(x == \"yes\"),\n .....:        \"Employed\": lambda x: sum(x),\n .....:        \"Grade\": lambda x: sum(x) / len(x),\n .....:    }\n .....: )\n .....: \nOut[156]: \n Participated  Passed  Employed      Grade\nExamYear \n2007                 3       2         3  74.000000\n2008                 3       3         0  68.500000\n2009                 3       2         2  60.666667 \n```", "```py\nIn [157]: df = pd.DataFrame(\n .....:    {\"value\": np.random.randn(36)},\n .....:    index=pd.date_range(\"2011-01-01\", freq=\"ME\", periods=36),\n .....: )\n .....: \n\nIn [158]: pd.pivot_table(\n .....:    df, index=df.index.month, columns=df.index.year, values=\"value\", aggfunc=\"sum\"\n .....: )\n .....: \nOut[158]: \n 2011      2012      2013\n1  -1.039268 -0.968914  2.565646\n2  -0.370647 -1.294524  1.431256\n3  -1.157892  0.413738  1.340309\n4  -1.344312  0.276662 -1.170299\n5   0.844885 -0.472035 -0.226169\n6   1.075770 -0.013960  0.410835\n7  -0.109050 -0.362543  0.813850\n8   1.643563 -0.006154  0.132003\n9  -1.469388 -0.923061 -0.827317\n10  0.357021  0.895717 -0.076467\n11 -0.674600  0.805244 -1.187678\n12 -1.776904 -1.206412  1.130127 \n```", "```py\nIn [159]: df = pd.DataFrame(\n .....:    data={\n .....:        \"A\": [[2, 4, 8, 16], [100, 200], [10, 20, 30]],\n .....:        \"B\": [[\"a\", \"b\", \"c\"], [\"jj\", \"kk\"], [\"ccc\"]],\n .....:    },\n .....:    index=[\"I\", \"II\", \"III\"],\n .....: )\n .....: \n\nIn [160]: def SeriesFromSubList(aList):\n .....:    return pd.Series(aList)\n .....: \n\nIn [161]: df_orgz = pd.concat(\n .....:    {ind: row.apply(SeriesFromSubList) for ind, row in df.iterrows()}\n .....: )\n .....: \n\nIn [162]: df_orgz\nOut[162]: \n 0     1     2     3\nI   A    2     4     8  16.0\n B    a     b     c   NaN\nII  A  100   200   NaN   NaN\n B   jj    kk   NaN   NaN\nIII A   10  20.0  30.0   NaN\n B  ccc   NaN   NaN   NaN \n```", "```py\nIn [163]: df = pd.DataFrame(\n .....:    data=np.random.randn(2000, 2) / 10000,\n .....:    index=pd.date_range(\"2001-01-01\", periods=2000),\n .....:    columns=[\"A\", \"B\"],\n .....: )\n .....: \n\nIn [164]: df\nOut[164]: \n A         B\n2001-01-01 -0.000144 -0.000141\n2001-01-02  0.000161  0.000102\n2001-01-03  0.000057  0.000088\n2001-01-04 -0.000221  0.000097\n2001-01-05 -0.000201 -0.000041\n...              ...       ...\n2006-06-19  0.000040 -0.000235\n2006-06-20 -0.000123 -0.000021\n2006-06-21 -0.000113  0.000114\n2006-06-22  0.000136  0.000109\n2006-06-23  0.000027  0.000030\n\n[2000 rows x 2 columns]\n\nIn [165]: def gm(df, const):\n .....:    v = ((((df[\"A\"] + df[\"B\"]) + 1).cumprod()) - 1) * const\n .....:    return v.iloc[-1]\n .....: \n\nIn [166]: s = pd.Series(\n .....:    {\n .....:        df.index[i]: gm(df.iloc[i: min(i + 51, len(df) - 1)], 5)\n .....:        for i in range(len(df) - 50)\n .....:    }\n .....: )\n .....: \n\nIn [167]: s\nOut[167]: \n2001-01-01    0.000930\n2001-01-02    0.002615\n2001-01-03    0.001281\n2001-01-04    0.001117\n2001-01-05    0.002772\n ... \n2006-04-30    0.003296\n2006-05-01    0.002629\n2006-05-02    0.002081\n2006-05-03    0.004247\n2006-05-04    0.003928\nLength: 1950, dtype: float64 \n```", "```py\nIn [168]: rng = pd.date_range(start=\"2014-01-01\", periods=100)\n\nIn [169]: df = pd.DataFrame(\n .....:    {\n .....:        \"Open\": np.random.randn(len(rng)),\n .....:        \"Close\": np.random.randn(len(rng)),\n .....:        \"Volume\": np.random.randint(100, 2000, len(rng)),\n .....:    },\n .....:    index=rng,\n .....: )\n .....: \n\nIn [170]: df\nOut[170]: \n Open     Close  Volume\n2014-01-01 -1.611353 -0.492885    1219\n2014-01-02 -3.000951  0.445794    1054\n2014-01-03 -0.138359 -0.076081    1381\n2014-01-04  0.301568  1.198259    1253\n2014-01-05  0.276381 -0.669831    1728\n...              ...       ...     ...\n2014-04-06 -0.040338  0.937843    1188\n2014-04-07  0.359661 -0.285908    1864\n2014-04-08  0.060978  1.714814     941\n2014-04-09  1.759055 -0.455942    1065\n2014-04-10  0.138185 -1.147008    1453\n\n[100 rows x 3 columns]\n\nIn [171]: def vwap(bars):\n .....:    return (bars.Close * bars.Volume).sum() / bars.Volume.sum()\n .....: \n\nIn [172]: window = 5\n\nIn [173]: s = pd.concat(\n .....:    [\n .....:        (pd.Series(vwap(df.iloc[i: i + window]), index=[df.index[i + window]]))\n .....:        for i in range(len(df) - window)\n .....:    ]\n .....: )\n .....: \n\nIn [174]: s.round(2)\nOut[174]: \n2014-01-06    0.02\n2014-01-07    0.11\n2014-01-08    0.10\n2014-01-09    0.07\n2014-01-10   -0.29\n ... \n2014-04-06   -0.63\n2014-04-07   -0.02\n2014-04-08   -0.03\n2014-04-09    0.34\n2014-04-10    0.29\nLength: 95, dtype: float64 \n```", "```py\nIn [175]: dates = pd.date_range(\"2000-01-01\", periods=5)\n\nIn [176]: dates.to_period(freq=\"M\").to_timestamp()\nOut[176]: \nDatetimeIndex(['2000-01-01', '2000-01-01', '2000-01-01', '2000-01-01',\n '2000-01-01'],\n dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [177]: rng = pd.date_range(\"2000-01-01\", periods=6)\n\nIn [178]: df1 = pd.DataFrame(np.random.randn(6, 3), index=rng, columns=[\"A\", \"B\", \"C\"])\n\nIn [179]: df2 = df1.copy() \n```", "```py\nIn [180]: df = pd.concat([df1, df2], ignore_index=True)\n\nIn [181]: df\nOut[181]: \n A         B         C\n0  -0.870117 -0.479265 -0.790855\n1   0.144817  1.726395 -0.464535\n2  -0.821906  1.597605  0.187307\n3  -0.128342 -1.511638 -0.289858\n4   0.399194 -1.430030 -0.639760\n5   1.115116 -2.012600  1.810662\n6  -0.870117 -0.479265 -0.790855\n7   0.144817  1.726395 -0.464535\n8  -0.821906  1.597605  0.187307\n9  -0.128342 -1.511638 -0.289858\n10  0.399194 -1.430030 -0.639760\n11  1.115116 -2.012600  1.810662 \n```", "```py\nIn [182]: df = pd.DataFrame(\n .....:    data={\n .....:        \"Area\": [\"A\"] * 5 + [\"C\"] * 2,\n .....:        \"Bins\": [110] * 2 + [160] * 3 + [40] * 2,\n .....:        \"Test_0\": [0, 1, 0, 1, 2, 0, 1],\n .....:        \"Data\": np.random.randn(7),\n .....:    }\n .....: )\n .....: \n\nIn [183]: df\nOut[183]: \n Area  Bins  Test_0      Data\n0    A   110       0 -0.433937\n1    A   110       1 -0.160552\n2    A   160       0  0.744434\n3    A   160       1  1.754213\n4    A   160       2  0.000850\n5    C    40       0  0.342243\n6    C    40       1  1.070599\n\nIn [184]: df[\"Test_1\"] = df[\"Test_0\"] - 1\n\nIn [185]: pd.merge(\n .....:    df,\n .....:    df,\n .....:    left_on=[\"Bins\", \"Area\", \"Test_0\"],\n .....:    right_on=[\"Bins\", \"Area\", \"Test_1\"],\n .....:    suffixes=(\"_L\", \"_R\"),\n .....: )\n .....: \nOut[185]: \n Area  Bins  Test_0_L    Data_L  Test_1_L  Test_0_R    Data_R  Test_1_R\n0    A   110         0 -0.433937        -1         1 -0.160552         0\n1    A   160         0  0.744434        -1         1  1.754213         0\n2    A   160         1  1.754213         0         2  0.000850         1\n3    C    40         0  0.342243        -1         1  1.070599         0 \n```", "```py\nIn [186]: df = pd.DataFrame(\n .....:    {\n .....:        \"stratifying_var\": np.random.uniform(0, 100, 20),\n .....:        \"price\": np.random.normal(100, 5, 20),\n .....:    }\n .....: )\n .....: \n\nIn [187]: df[\"quartiles\"] = pd.qcut(\n .....:    df[\"stratifying_var\"], 4, labels=[\"0-25%\", \"25-50%\", \"50-75%\", \"75-100%\"]\n .....: )\n .....: \n\nIn [188]: df.boxplot(column=\"price\", by=\"quartiles\")\nOut[188]: <Axes: title={'center': 'price'}, xlabel='quartiles'> \n```", "```py\nIn [189]: for i in range(3):\n .....:    data = pd.DataFrame(np.random.randn(10, 4))\n .....:    data.to_csv(\"file_{}.csv\".format(i))\n .....: \n\nIn [190]: files = [\"file_0.csv\", \"file_1.csv\", \"file_2.csv\"]\n\nIn [191]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True) \n```", "```py\nIn [192]: import glob\n\nIn [193]: import os\n\nIn [194]: files = glob.glob(\"file_*.csv\")\n\nIn [195]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True) \n```", "```py\nIn [196]: i = pd.date_range(\"20000101\", periods=10000)\n\nIn [197]: df = pd.DataFrame({\"year\": i.year, \"month\": i.month, \"day\": i.day})\n\nIn [198]: df.head()\nOut[198]: \n year  month  day\n0  2000      1    1\n1  2000      1    2\n2  2000      1    3\n3  2000      1    4\n4  2000      1    5\n\nIn [199]: %timeit pd.to_datetime(df.year * 10000 + df.month * 100 + df.day, format='%Y%m%d')\n .....: ds = df.apply(lambda x: \"%04d%02d%02d\" % (x[\"year\"], x[\"month\"], x[\"day\"]), axis=1)\n .....: ds.head()\n .....: %timeit pd.to_datetime(ds)\n .....: \n4.01 ms +- 635 us per loop (mean +- std. dev. of 7 runs, 100 loops each)\n1.05 ms +- 7.39 us per loop (mean +- std. dev. of 7 runs, 1,000 loops each) \n```", "```py\nIn [200]: data = \"\"\";;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: date;Param1;Param2;Param4;Param5\n .....:    ;m\u00b2;\u00b0C;m\u00b2;m\n .....: ;;;;\n .....: 01.01.1990 00:00;1;1;2;3\n .....: 01.01.1990 01:00;5;3;4;5\n .....: 01.01.1990 02:00;9;5;6;7\n .....: 01.01.1990 03:00;13;7;8;9\n .....: 01.01.1990 04:00;17;9;10;11\n .....: 01.01.1990 05:00;21;11;12;13\n .....: \"\"\"\n .....: \n```", "```py\nIn [201]: from io import StringIO\n\nIn [202]: pd.read_csv(\n .....:    StringIO(data),\n .....:    sep=\";\",\n .....:    skiprows=[11, 12],\n .....:    index_col=0,\n .....:    parse_dates=True,\n .....:    header=10,\n .....: )\n .....: \nOut[202]: \n Param1  Param2  Param4  Param5\ndate \n1990-01-01 00:00:00       1       1       2       3\n1990-01-01 01:00:00       5       3       4       5\n1990-01-01 02:00:00       9       5       6       7\n1990-01-01 03:00:00      13       7       8       9\n1990-01-01 04:00:00      17       9      10      11\n1990-01-01 05:00:00      21      11      12      13 \n```", "```py\nIn [203]: pd.read_csv(StringIO(data), sep=\";\", header=10, nrows=10).columns\nOut[203]: Index(['date', 'Param1', 'Param2', 'Param4', 'Param5'], dtype='object')\n\nIn [204]: columns = pd.read_csv(StringIO(data), sep=\";\", header=10, nrows=10).columns\n\nIn [205]: pd.read_csv(\n .....:    StringIO(data), sep=\";\", index_col=0, header=12, parse_dates=True, names=columns\n .....: )\n .....: \nOut[205]: \n Param1  Param2  Param4  Param5\ndate \n1990-01-01 00:00:00       1       1       2       3\n1990-01-01 01:00:00       5       3       4       5\n1990-01-01 02:00:00       9       5       6       7\n1990-01-01 03:00:00      13       7       8       9\n1990-01-01 04:00:00      17       9      10      11\n1990-01-01 05:00:00      21      11      12      13 \n```", "```py\nIn [206]: df = pd.DataFrame(np.random.randn(8, 3))\n\nIn [207]: store = pd.HDFStore(\"test.h5\")\n\nIn [208]: store.put(\"df\", df)\n\n# you can store an arbitrary Python object via pickle\nIn [209]: store.get_storer(\"df\").attrs.my_attribute = {\"A\": 10}\n\nIn [210]: store.get_storer(\"df\").attrs.my_attribute\nOut[210]: {'A': 10} \n```", "```py\nIn [211]: store = pd.HDFStore(\"test.h5\", \"w\", driver=\"H5FD_CORE\")\n\nIn [212]: df = pd.DataFrame(np.random.randn(8, 3))\n\nIn [213]: store[\"test\"] = df\n\n# only after closing the store, data is written to disk:\nIn [214]: store.close() \n```", "```py\n#include  <stdio.h>\n#include  <stdint.h>\n\ntypedef  struct  _Data\n{\n  int32_t  count;\n  double  avg;\n  float  scale;\n}  Data;\n\nint  main(int  argc,  const  char  *argv[])\n{\n  size_t  n  =  10;\n  Data  d[n];\n\n  for  (int  i  =  0;  i  <  n;  ++i)\n  {\n  d[i].count  =  i;\n  d[i].avg  =  i  +  1.0;\n  d[i].scale  =  (float)  i  +  2.0f;\n  }\n\n  FILE  *file  =  fopen(\"binary.dat\",  \"wb\");\n  fwrite(&d,  sizeof(Data),  n,  file);\n  fclose(file);\n\n  return  0;\n} \n```", "```py\nnames = \"count\", \"avg\", \"scale\"\n\n# note that the offsets are larger than the size of the type because of\n# struct padding\noffsets = 0, 8, 16\nformats = \"i4\", \"f8\", \"f4\"\ndt = np.dtype({\"names\": names, \"offsets\": offsets, \"formats\": formats}, align=True)\ndf = pd.DataFrame(np.fromfile(\"binary.dat\", dt)) \n```", "```py\nIn [215]: df = pd.DataFrame(np.random.random(size=(100, 5)))\n\nIn [216]: corr_mat = df.corr()\n\nIn [217]: mask = np.tril(np.ones_like(corr_mat, dtype=np.bool_), k=-1)\n\nIn [218]: corr_mat.where(mask)\nOut[218]: \n 0         1         2        3   4\n0       NaN       NaN       NaN      NaN NaN\n1 -0.079861       NaN       NaN      NaN NaN\n2 -0.236573  0.183801       NaN      NaN NaN\n3 -0.013795 -0.051975  0.037235      NaN NaN\n4 -0.031974  0.118342 -0.073499 -0.02063 NaN \n```", "```py\nIn [219]: def distcorr(x, y):\n .....:    n = len(x)\n .....:    a = np.zeros(shape=(n, n))\n .....:    b = np.zeros(shape=(n, n))\n .....:    for i in range(n):\n .....:        for j in range(i + 1, n):\n .....:            a[i, j] = abs(x[i] - x[j])\n .....:            b[i, j] = abs(y[i] - y[j])\n .....:    a += a.T\n .....:    b += b.T\n .....:    a_bar = np.vstack([np.nanmean(a, axis=0)] * n)\n .....:    b_bar = np.vstack([np.nanmean(b, axis=0)] * n)\n .....:    A = a - a_bar - a_bar.T + np.full(shape=(n, n), fill_value=a_bar.mean())\n .....:    B = b - b_bar - b_bar.T + np.full(shape=(n, n), fill_value=b_bar.mean())\n .....:    cov_ab = np.sqrt(np.nansum(A * B)) / n\n .....:    std_a = np.sqrt(np.sqrt(np.nansum(A ** 2)) / n)\n .....:    std_b = np.sqrt(np.sqrt(np.nansum(B ** 2)) / n)\n .....:    return cov_ab / std_a / std_b\n .....: \n\nIn [220]: df = pd.DataFrame(np.random.normal(size=(100, 3)))\n\nIn [221]: df.corr(method=distcorr)\nOut[221]: \n 0         1         2\n0  1.000000  0.197613  0.216328\n1  0.197613  1.000000  0.208749\n2  0.216328  0.208749  1.000000 \n```", "```py\nIn [222]: import datetime\n\nIn [223]: s = pd.Series(pd.date_range(\"2012-1-1\", periods=3, freq=\"D\"))\n\nIn [224]: s - s.max()\nOut[224]: \n0   -2 days\n1   -1 days\n2    0 days\ndtype: timedelta64[ns]\n\nIn [225]: s.max() - s\nOut[225]: \n0   2 days\n1   1 days\n2   0 days\ndtype: timedelta64[ns]\n\nIn [226]: s - datetime.datetime(2011, 1, 1, 3, 5)\nOut[226]: \n0   364 days 20:55:00\n1   365 days 20:55:00\n2   366 days 20:55:00\ndtype: timedelta64[ns]\n\nIn [227]: s + datetime.timedelta(minutes=5)\nOut[227]: \n0   2012-01-01 00:05:00\n1   2012-01-02 00:05:00\n2   2012-01-03 00:05:00\ndtype: datetime64[ns]\n\nIn [228]: datetime.datetime(2011, 1, 1, 3, 5) - s\nOut[228]: \n0   -365 days +03:05:00\n1   -366 days +03:05:00\n2   -367 days +03:05:00\ndtype: timedelta64[ns]\n\nIn [229]: datetime.timedelta(minutes=5) + s\nOut[229]: \n0   2012-01-01 00:05:00\n1   2012-01-02 00:05:00\n2   2012-01-03 00:05:00\ndtype: datetime64[ns] \n```", "```py\nIn [230]: deltas = pd.Series([datetime.timedelta(days=i) for i in range(3)])\n\nIn [231]: df = pd.DataFrame({\"A\": s, \"B\": deltas})\n\nIn [232]: df\nOut[232]: \n A      B\n0 2012-01-01 0 days\n1 2012-01-02 1 days\n2 2012-01-03 2 days\n\nIn [233]: df[\"New Dates\"] = df[\"A\"] + df[\"B\"]\n\nIn [234]: df[\"Delta\"] = df[\"A\"] - df[\"New Dates\"]\n\nIn [235]: df\nOut[235]: \n A      B  New Dates   Delta\n0 2012-01-01 0 days 2012-01-01  0 days\n1 2012-01-02 1 days 2012-01-03 -1 days\n2 2012-01-03 2 days 2012-01-05 -2 days\n\nIn [236]: df.dtypes\nOut[236]: \nA             datetime64[ns]\nB            timedelta64[ns]\nNew Dates     datetime64[ns]\nDelta        timedelta64[ns]\ndtype: object \n```", "```py\nIn [237]: y = s - s.shift()\n\nIn [238]: y\nOut[238]: \n0      NaT\n1   1 days\n2   1 days\ndtype: timedelta64[ns]\n\nIn [239]: y[1] = np.nan\n\nIn [240]: y\nOut[240]: \n0      NaT\n1      NaT\n2   1 days\ndtype: timedelta64[ns] \n```", "```py\nIn [241]: def expand_grid(data_dict):\n .....:    rows = itertools.product(*data_dict.values())\n .....:    return pd.DataFrame.from_records(rows, columns=data_dict.keys())\n .....: \n\nIn [242]: df = expand_grid(\n .....:    {\"height\": [60, 70], \"weight\": [100, 140, 180], \"sex\": [\"Male\", \"Female\"]}\n .....: )\n .....: \n\nIn [243]: df\nOut[243]: \n height  weight     sex\n0       60     100    Male\n1       60     100  Female\n2       60     140    Male\n3       60     140  Female\n4       60     180    Male\n5       60     180  Female\n6       70     100    Male\n7       70     100  Female\n8       70     140    Male\n9       70     140  Female\n10      70     180    Male\n11      70     180  Female \n```", "```py\nIn [244]: v = s.to_numpy()\n\nIn [245]: is_constant = v.shape[0] == 0 or (s[0] == s).all() \n```", "```py\nIn [246]: v = s.dropna().to_numpy()\n\nIn [247]: is_constant = v.shape[0] == 0 or (s[0] == s).all() \n```", "```py\nIn [248]: v = s.to_numpy()\n\nIn [249]: is_constant = v.shape[0] == 0 or (s[0] == s).all() or not pd.notna(v).any() \n```", "```py\nIn [1]: df = pd.DataFrame(\n ...:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ...: )\n ...: \n\nIn [2]: df\nOut[2]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50 \n```", "```py\nIn [3]: df.loc[df.AAA >= 5, \"BBB\"] = -1\n\nIn [4]: df\nOut[4]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   -1   50\n2    6   -1  -30\n3    7   -1  -50 \n```", "```py\nIn [5]: df.loc[df.AAA >= 5, [\"BBB\", \"CCC\"]] = 555\n\nIn [6]: df\nOut[6]: \n AAA  BBB  CCC\n0    4   10  100\n1    5  555  555\n2    6  555  555\n3    7  555  555 \n```", "```py\nIn [7]: df.loc[df.AAA < 5, [\"BBB\", \"CCC\"]] = 2000\n\nIn [8]: df\nOut[8]: \n AAA   BBB   CCC\n0    4  2000  2000\n1    5   555   555\n2    6   555   555\n3    7   555   555 \n```", "```py\nIn [9]: df_mask = pd.DataFrame(\n ...:    {\"AAA\": [True] * 4, \"BBB\": [False] * 4, \"CCC\": [True, False] * 2}\n ...: )\n ...: \n\nIn [10]: df.where(df_mask, -1000)\nOut[10]: \n AAA   BBB   CCC\n0    4 -1000  2000\n1    5 -1000 -1000\n2    6 -1000   555\n3    7 -1000 -1000 \n```", "```py\nIn [11]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [12]: df\nOut[12]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [13]: df[\"logic\"] = np.where(df[\"AAA\"] > 5, \"high\", \"low\")\n\nIn [14]: df\nOut[14]: \n AAA  BBB  CCC logic\n0    4   10  100   low\n1    5   20   50   low\n2    6   30  -30  high\n3    7   40  -50  high \n```", "```py\nIn [15]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [16]: df\nOut[16]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [17]: df[df.AAA <= 5]\nOut[17]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n\nIn [18]: df[df.AAA > 5]\nOut[18]: \n AAA  BBB  CCC\n2    6   30  -30\n3    7   40  -50 \n```", "```py\nIn [19]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [20]: df\nOut[20]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50 \n```", "```py\nIn [21]: df.loc[(df[\"BBB\"] < 25) & (df[\"CCC\"] >= -40), \"AAA\"]\nOut[21]: \n0    4\n1    5\nName: AAA, dtype: int64 \n```", "```py\nIn [22]: df.loc[(df[\"BBB\"] > 25) | (df[\"CCC\"] >= -40), \"AAA\"]\nOut[22]: \n0    4\n1    5\n2    6\n3    7\nName: AAA, dtype: int64 \n```", "```py\nIn [23]: df.loc[(df[\"BBB\"] > 25) | (df[\"CCC\"] >= 75), \"AAA\"] = 999\n\nIn [24]: df\nOut[24]: \n AAA  BBB  CCC\n0  999   10  100\n1    5   20   50\n2  999   30  -30\n3  999   40  -50 \n```", "```py\nIn [25]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [26]: df\nOut[26]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [27]: aValue = 43.0\n\nIn [28]: df.loc[(df.CCC - aValue).abs().argsort()]\nOut[28]: \n AAA  BBB  CCC\n1    5   20   50\n0    4   10  100\n2    6   30  -30\n3    7   40  -50 \n```", "```py\nIn [29]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [30]: df\nOut[30]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [31]: Crit1 = df.AAA <= 5.5\n\nIn [32]: Crit2 = df.BBB == 10.0\n\nIn [33]: Crit3 = df.CCC > -40.0 \n```", "```py\nIn [34]: AllCrit = Crit1 & Crit2 & Crit3 \n```", "```py\nIn [35]: import functools\n\nIn [36]: CritList = [Crit1, Crit2, Crit3]\n\nIn [37]: AllCrit = functools.reduce(lambda x, y: x & y, CritList)\n\nIn [38]: df[AllCrit]\nOut[38]: \n AAA  BBB  CCC\n0    4   10  100 \n```", "```py\nIn [3]: df.loc[df.AAA >= 5, \"BBB\"] = -1\n\nIn [4]: df\nOut[4]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   -1   50\n2    6   -1  -30\n3    7   -1  -50 \n```", "```py\nIn [5]: df.loc[df.AAA >= 5, [\"BBB\", \"CCC\"]] = 555\n\nIn [6]: df\nOut[6]: \n AAA  BBB  CCC\n0    4   10  100\n1    5  555  555\n2    6  555  555\n3    7  555  555 \n```", "```py\nIn [7]: df.loc[df.AAA < 5, [\"BBB\", \"CCC\"]] = 2000\n\nIn [8]: df\nOut[8]: \n AAA   BBB   CCC\n0    4  2000  2000\n1    5   555   555\n2    6   555   555\n3    7   555   555 \n```", "```py\nIn [9]: df_mask = pd.DataFrame(\n ...:    {\"AAA\": [True] * 4, \"BBB\": [False] * 4, \"CCC\": [True, False] * 2}\n ...: )\n ...: \n\nIn [10]: df.where(df_mask, -1000)\nOut[10]: \n AAA   BBB   CCC\n0    4 -1000  2000\n1    5 -1000 -1000\n2    6 -1000   555\n3    7 -1000 -1000 \n```", "```py\nIn [11]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [12]: df\nOut[12]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [13]: df[\"logic\"] = np.where(df[\"AAA\"] > 5, \"high\", \"low\")\n\nIn [14]: df\nOut[14]: \n AAA  BBB  CCC logic\n0    4   10  100   low\n1    5   20   50   low\n2    6   30  -30  high\n3    7   40  -50  high \n```", "```py\nIn [15]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [16]: df\nOut[16]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [17]: df[df.AAA <= 5]\nOut[17]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n\nIn [18]: df[df.AAA > 5]\nOut[18]: \n AAA  BBB  CCC\n2    6   30  -30\n3    7   40  -50 \n```", "```py\nIn [19]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [20]: df\nOut[20]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50 \n```", "```py\nIn [21]: df.loc[(df[\"BBB\"] < 25) & (df[\"CCC\"] >= -40), \"AAA\"]\nOut[21]: \n0    4\n1    5\nName: AAA, dtype: int64 \n```", "```py\nIn [22]: df.loc[(df[\"BBB\"] > 25) | (df[\"CCC\"] >= -40), \"AAA\"]\nOut[22]: \n0    4\n1    5\n2    6\n3    7\nName: AAA, dtype: int64 \n```", "```py\nIn [23]: df.loc[(df[\"BBB\"] > 25) | (df[\"CCC\"] >= 75), \"AAA\"] = 999\n\nIn [24]: df\nOut[24]: \n AAA  BBB  CCC\n0  999   10  100\n1    5   20   50\n2  999   30  -30\n3  999   40  -50 \n```", "```py\nIn [25]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [26]: df\nOut[26]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [27]: aValue = 43.0\n\nIn [28]: df.loc[(df.CCC - aValue).abs().argsort()]\nOut[28]: \n AAA  BBB  CCC\n1    5   20   50\n0    4   10  100\n2    6   30  -30\n3    7   40  -50 \n```", "```py\nIn [29]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [30]: df\nOut[30]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [31]: Crit1 = df.AAA <= 5.5\n\nIn [32]: Crit2 = df.BBB == 10.0\n\nIn [33]: Crit3 = df.CCC > -40.0 \n```", "```py\nIn [34]: AllCrit = Crit1 & Crit2 & Crit3 \n```", "```py\nIn [35]: import functools\n\nIn [36]: CritList = [Crit1, Crit2, Crit3]\n\nIn [37]: AllCrit = functools.reduce(lambda x, y: x & y, CritList)\n\nIn [38]: df[AllCrit]\nOut[38]: \n AAA  BBB  CCC\n0    4   10  100 \n```", "```py\nIn [39]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [40]: df\nOut[40]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [41]: df[(df.AAA <= 6) & (df.index.isin([0, 2, 4]))]\nOut[41]: \n AAA  BBB  CCC\n0    4   10  100\n2    6   30  -30 \n```", "```py\nIn [42]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]},\n ....:    index=[\"foo\", \"bar\", \"boo\", \"kar\"],\n ....: )\n ....: \n```", "```py\nIn [43]: df.loc[\"bar\":\"kar\"]  # Label\nOut[43]: \n AAA  BBB  CCC\nbar    5   20   50\nboo    6   30  -30\nkar    7   40  -50\n\n# Generic\nIn [44]: df[0:3]\nOut[44]: \n AAA  BBB  CCC\nfoo    4   10  100\nbar    5   20   50\nboo    6   30  -30\n\nIn [45]: df[\"bar\":\"kar\"]\nOut[45]: \n AAA  BBB  CCC\nbar    5   20   50\nboo    6   30  -30\nkar    7   40  -50 \n```", "```py\nIn [46]: data = {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n\nIn [47]: df2 = pd.DataFrame(data=data, index=[1, 2, 3, 4])  # Note index starts at 1.\n\nIn [48]: df2.iloc[1:3]  # Position-oriented\nOut[48]: \n AAA  BBB  CCC\n2    5   20   50\n3    6   30  -30\n\nIn [49]: df2.loc[1:3]  # Label-oriented\nOut[49]: \n AAA  BBB  CCC\n1    4   10  100\n2    5   20   50\n3    6   30  -30 \n```", "```py\nIn [50]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [51]: df\nOut[51]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [52]: df[~((df.AAA <= 6) & (df.index.isin([0, 2, 4])))]\nOut[52]: \n AAA  BBB  CCC\n1    5   20   50\n3    7   40  -50 \n```", "```py\nIn [53]: df = pd.DataFrame({\"AAA\": [1, 2, 1, 3], \"BBB\": [1, 1, 2, 2], \"CCC\": [2, 1, 3, 1]})\n\nIn [54]: df\nOut[54]: \n AAA  BBB  CCC\n0    1    1    2\n1    2    1    1\n2    1    2    3\n3    3    2    1\n\nIn [55]: source_cols = df.columns  # Or some subset would work too\n\nIn [56]: new_cols = [str(x) + \"_cat\" for x in source_cols]\n\nIn [57]: categories = {1: \"Alpha\", 2: \"Beta\", 3: \"Charlie\"}\n\nIn [58]: df[new_cols] = df[source_cols].map(categories.get)\n\nIn [59]: df\nOut[59]: \n AAA  BBB  CCC  AAA_cat BBB_cat  CCC_cat\n0    1    1    2    Alpha   Alpha     Beta\n1    2    1    1     Beta   Alpha    Alpha\n2    1    2    3    Alpha    Beta  Charlie\n3    3    2    1  Charlie    Beta    Alpha \n```", "```py\nIn [60]: df = pd.DataFrame(\n ....:    {\"AAA\": [1, 1, 1, 2, 2, 2, 3, 3], \"BBB\": [2, 1, 3, 4, 5, 1, 2, 3]}\n ....: )\n ....: \n\nIn [61]: df\nOut[61]: \n AAA  BBB\n0    1    2\n1    1    1\n2    1    3\n3    2    4\n4    2    5\n5    2    1\n6    3    2\n7    3    3 \n```", "```py\nIn [62]: df.loc[df.groupby(\"AAA\")[\"BBB\"].idxmin()]\nOut[62]: \n AAA  BBB\n1    1    1\n5    2    1\n6    3    2 \n```", "```py\nIn [63]: df.sort_values(by=\"BBB\").groupby(\"AAA\", as_index=False).first()\nOut[63]: \n AAA  BBB\n0    1    1\n1    2    1\n2    3    2 \n```", "```py\nIn [39]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [40]: df\nOut[40]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [41]: df[(df.AAA <= 6) & (df.index.isin([0, 2, 4]))]\nOut[41]: \n AAA  BBB  CCC\n0    4   10  100\n2    6   30  -30 \n```", "```py\nIn [42]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]},\n ....:    index=[\"foo\", \"bar\", \"boo\", \"kar\"],\n ....: )\n ....: \n```", "```py\nIn [43]: df.loc[\"bar\":\"kar\"]  # Label\nOut[43]: \n AAA  BBB  CCC\nbar    5   20   50\nboo    6   30  -30\nkar    7   40  -50\n\n# Generic\nIn [44]: df[0:3]\nOut[44]: \n AAA  BBB  CCC\nfoo    4   10  100\nbar    5   20   50\nboo    6   30  -30\n\nIn [45]: df[\"bar\":\"kar\"]\nOut[45]: \n AAA  BBB  CCC\nbar    5   20   50\nboo    6   30  -30\nkar    7   40  -50 \n```", "```py\nIn [46]: data = {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n\nIn [47]: df2 = pd.DataFrame(data=data, index=[1, 2, 3, 4])  # Note index starts at 1.\n\nIn [48]: df2.iloc[1:3]  # Position-oriented\nOut[48]: \n AAA  BBB  CCC\n2    5   20   50\n3    6   30  -30\n\nIn [49]: df2.loc[1:3]  # Label-oriented\nOut[49]: \n AAA  BBB  CCC\n1    4   10  100\n2    5   20   50\n3    6   30  -30 \n```", "```py\nIn [50]: df = pd.DataFrame(\n ....:    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n ....: )\n ....: \n\nIn [51]: df\nOut[51]: \n AAA  BBB  CCC\n0    4   10  100\n1    5   20   50\n2    6   30  -30\n3    7   40  -50\n\nIn [52]: df[~((df.AAA <= 6) & (df.index.isin([0, 2, 4])))]\nOut[52]: \n AAA  BBB  CCC\n1    5   20   50\n3    7   40  -50 \n```", "```py\nIn [53]: df = pd.DataFrame({\"AAA\": [1, 2, 1, 3], \"BBB\": [1, 1, 2, 2], \"CCC\": [2, 1, 3, 1]})\n\nIn [54]: df\nOut[54]: \n AAA  BBB  CCC\n0    1    1    2\n1    2    1    1\n2    1    2    3\n3    3    2    1\n\nIn [55]: source_cols = df.columns  # Or some subset would work too\n\nIn [56]: new_cols = [str(x) + \"_cat\" for x in source_cols]\n\nIn [57]: categories = {1: \"Alpha\", 2: \"Beta\", 3: \"Charlie\"}\n\nIn [58]: df[new_cols] = df[source_cols].map(categories.get)\n\nIn [59]: df\nOut[59]: \n AAA  BBB  CCC  AAA_cat BBB_cat  CCC_cat\n0    1    1    2    Alpha   Alpha     Beta\n1    2    1    1     Beta   Alpha    Alpha\n2    1    2    3    Alpha    Beta  Charlie\n3    3    2    1  Charlie    Beta    Alpha \n```", "```py\nIn [60]: df = pd.DataFrame(\n ....:    {\"AAA\": [1, 1, 1, 2, 2, 2, 3, 3], \"BBB\": [2, 1, 3, 4, 5, 1, 2, 3]}\n ....: )\n ....: \n\nIn [61]: df\nOut[61]: \n AAA  BBB\n0    1    2\n1    1    1\n2    1    3\n3    2    4\n4    2    5\n5    2    1\n6    3    2\n7    3    3 \n```", "```py\nIn [62]: df.loc[df.groupby(\"AAA\")[\"BBB\"].idxmin()]\nOut[62]: \n AAA  BBB\n1    1    1\n5    2    1\n6    3    2 \n```", "```py\nIn [63]: df.sort_values(by=\"BBB\").groupby(\"AAA\", as_index=False).first()\nOut[63]: \n AAA  BBB\n0    1    1\n1    2    1\n2    3    2 \n```", "```py\nIn [64]: df = pd.DataFrame(\n ....:    {\n ....:        \"row\": [0, 1, 2],\n ....:        \"One_X\": [1.1, 1.1, 1.1],\n ....:        \"One_Y\": [1.2, 1.2, 1.2],\n ....:        \"Two_X\": [1.11, 1.11, 1.11],\n ....:        \"Two_Y\": [1.22, 1.22, 1.22],\n ....:    }\n ....: )\n ....: \n\nIn [65]: df\nOut[65]: \n row  One_X  One_Y  Two_X  Two_Y\n0    0    1.1    1.2   1.11   1.22\n1    1    1.1    1.2   1.11   1.22\n2    2    1.1    1.2   1.11   1.22\n\n# As Labelled Index\nIn [66]: df = df.set_index(\"row\")\n\nIn [67]: df\nOut[67]: \n One_X  One_Y  Two_X  Two_Y\nrow \n0      1.1    1.2   1.11   1.22\n1      1.1    1.2   1.11   1.22\n2      1.1    1.2   1.11   1.22\n\n# With Hierarchical Columns\nIn [68]: df.columns = pd.MultiIndex.from_tuples([tuple(c.split(\"_\")) for c in df.columns])\n\nIn [69]: df\nOut[69]: \n One        Two \n X    Y     X     Y\nrow \n0    1.1  1.2  1.11  1.22\n1    1.1  1.2  1.11  1.22\n2    1.1  1.2  1.11  1.22\n\n# Now stack & Reset\nIn [70]: df = df.stack(0, future_stack=True).reset_index(1)\n\nIn [71]: df\nOut[71]: \n level_1     X     Y\nrow \n0       One  1.10  1.20\n0       Two  1.11  1.22\n1       One  1.10  1.20\n1       Two  1.11  1.22\n2       One  1.10  1.20\n2       Two  1.11  1.22\n\n# And fix the labels (Notice the label 'level_1' got added automatically)\nIn [72]: df.columns = [\"Sample\", \"All_X\", \"All_Y\"]\n\nIn [73]: df\nOut[73]: \n Sample  All_X  All_Y\nrow \n0      One   1.10   1.20\n0      Two   1.11   1.22\n1      One   1.10   1.20\n1      Two   1.11   1.22\n2      One   1.10   1.20\n2      Two   1.11   1.22 \n```", "```py\nIn [74]: cols = pd.MultiIndex.from_tuples(\n ....:    [(x, y) for x in [\"A\", \"B\", \"C\"] for y in [\"O\", \"I\"]]\n ....: )\n ....: \n\nIn [75]: df = pd.DataFrame(np.random.randn(2, 6), index=[\"n\", \"m\"], columns=cols)\n\nIn [76]: df\nOut[76]: \n A                   B                   C \n O         I         O         I         O         I\nn  0.469112 -0.282863 -1.509059 -1.135632  1.212112 -0.173215\nm  0.119209 -1.044236 -0.861849 -2.104569 -0.494929  1.071804\n\nIn [77]: df = df.div(df[\"C\"], level=1)\n\nIn [78]: df\nOut[78]: \n A                   B              C \n O         I         O         I    O    I\nn  0.387021  1.633022 -1.244983  6.556214  1.0  1.0\nm -0.240860 -0.974279  1.741358 -1.963577  1.0  1.0 \n```", "```py\nIn [79]: coords = [(\"AA\", \"one\"), (\"AA\", \"six\"), (\"BB\", \"one\"), (\"BB\", \"two\"), (\"BB\", \"six\")]\n\nIn [80]: index = pd.MultiIndex.from_tuples(coords)\n\nIn [81]: df = pd.DataFrame([11, 22, 33, 44, 55], index, [\"MyData\"])\n\nIn [82]: df\nOut[82]: \n MyData\nAA one      11\n six      22\nBB one      33\n two      44\n six      55 \n```", "```py\n# Note : level and axis are optional, and default to zero\nIn [83]: df.xs(\"BB\", level=0, axis=0)\nOut[83]: \n MyData\none      33\ntwo      44\nsix      55 \n```", "```py\nIn [84]: df.xs(\"six\", level=1, axis=0)\nOut[84]: \n MyData\nAA      22\nBB      55 \n```", "```py\nIn [85]: import itertools\n\nIn [86]: index = list(itertools.product([\"Ada\", \"Quinn\", \"Violet\"], [\"Comp\", \"Math\", \"Sci\"]))\n\nIn [87]: headr = list(itertools.product([\"Exams\", \"Labs\"], [\"I\", \"II\"]))\n\nIn [88]: indx = pd.MultiIndex.from_tuples(index, names=[\"Student\", \"Course\"])\n\nIn [89]: cols = pd.MultiIndex.from_tuples(headr)  # Notice these are un-named\n\nIn [90]: data = [[70 + x + y + (x * y) % 3 for x in range(4)] for y in range(9)]\n\nIn [91]: df = pd.DataFrame(data, indx, cols)\n\nIn [92]: df\nOut[92]: \n Exams     Labs \n I  II    I  II\nStudent Course \nAda     Comp      70  71   72  73\n Math      71  73   75  74\n Sci       72  75   75  75\nQuinn   Comp      73  74   75  76\n Math      74  76   78  77\n Sci       75  78   78  78\nViolet  Comp      76  77   78  79\n Math      77  79   81  80\n Sci       78  81   81  81\n\nIn [93]: All = slice(None)\n\nIn [94]: df.loc[\"Violet\"]\nOut[94]: \n Exams     Labs \n I  II    I  II\nCourse \nComp      76  77   78  79\nMath      77  79   81  80\nSci       78  81   81  81\n\nIn [95]: df.loc[(All, \"Math\"), All]\nOut[95]: \n Exams     Labs \n I  II    I  II\nStudent Course \nAda     Math      71  73   75  74\nQuinn   Math      74  76   78  77\nViolet  Math      77  79   81  80\n\nIn [96]: df.loc[(slice(\"Ada\", \"Quinn\"), \"Math\"), All]\nOut[96]: \n Exams     Labs \n I  II    I  II\nStudent Course \nAda     Math      71  73   75  74\nQuinn   Math      74  76   78  77\n\nIn [97]: df.loc[(All, \"Math\"), (\"Exams\")]\nOut[97]: \n I  II\nStudent Course \nAda     Math    71  73\nQuinn   Math    74  76\nViolet  Math    77  79\n\nIn [98]: df.loc[(All, \"Math\"), (All, \"II\")]\nOut[98]: \n Exams Labs\n II   II\nStudent Course \nAda     Math      73   74\nQuinn   Math      76   77\nViolet  Math      79   80 \n```", "```py\nIn [99]: df.sort_values(by=(\"Labs\", \"II\"), ascending=False)\nOut[99]: \n Exams     Labs \n I  II    I  II\nStudent Course \nViolet  Sci       78  81   81  81\n Math      77  79   81  80\n Comp      76  77   78  79\nQuinn   Sci       75  78   78  78\n Math      74  76   78  77\n Comp      73  74   75  76\nAda     Sci       72  75   75  75\n Math      71  73   75  74\n Comp      70  71   72  73 \n```", "```py\nIn [74]: cols = pd.MultiIndex.from_tuples(\n ....:    [(x, y) for x in [\"A\", \"B\", \"C\"] for y in [\"O\", \"I\"]]\n ....: )\n ....: \n\nIn [75]: df = pd.DataFrame(np.random.randn(2, 6), index=[\"n\", \"m\"], columns=cols)\n\nIn [76]: df\nOut[76]: \n A                   B                   C \n O         I         O         I         O         I\nn  0.469112 -0.282863 -1.509059 -1.135632  1.212112 -0.173215\nm  0.119209 -1.044236 -0.861849 -2.104569 -0.494929  1.071804\n\nIn [77]: df = df.div(df[\"C\"], level=1)\n\nIn [78]: df\nOut[78]: \n A                   B              C \n O         I         O         I    O    I\nn  0.387021  1.633022 -1.244983  6.556214  1.0  1.0\nm -0.240860 -0.974279  1.741358 -1.963577  1.0  1.0 \n```", "```py\nIn [79]: coords = [(\"AA\", \"one\"), (\"AA\", \"six\"), (\"BB\", \"one\"), (\"BB\", \"two\"), (\"BB\", \"six\")]\n\nIn [80]: index = pd.MultiIndex.from_tuples(coords)\n\nIn [81]: df = pd.DataFrame([11, 22, 33, 44, 55], index, [\"MyData\"])\n\nIn [82]: df\nOut[82]: \n MyData\nAA one      11\n six      22\nBB one      33\n two      44\n six      55 \n```", "```py\n# Note : level and axis are optional, and default to zero\nIn [83]: df.xs(\"BB\", level=0, axis=0)\nOut[83]: \n MyData\none      33\ntwo      44\nsix      55 \n```", "```py\nIn [84]: df.xs(\"six\", level=1, axis=0)\nOut[84]: \n MyData\nAA      22\nBB      55 \n```", "```py\nIn [85]: import itertools\n\nIn [86]: index = list(itertools.product([\"Ada\", \"Quinn\", \"Violet\"], [\"Comp\", \"Math\", \"Sci\"]))\n\nIn [87]: headr = list(itertools.product([\"Exams\", \"Labs\"], [\"I\", \"II\"]))\n\nIn [88]: indx = pd.MultiIndex.from_tuples(index, names=[\"Student\", \"Course\"])\n\nIn [89]: cols = pd.MultiIndex.from_tuples(headr)  # Notice these are un-named\n\nIn [90]: data = [[70 + x + y + (x * y) % 3 for x in range(4)] for y in range(9)]\n\nIn [91]: df = pd.DataFrame(data, indx, cols)\n\nIn [92]: df\nOut[92]: \n Exams     Labs \n I  II    I  II\nStudent Course \nAda     Comp      70  71   72  73\n Math      71  73   75  74\n Sci       72  75   75  75\nQuinn   Comp      73  74   75  76\n Math      74  76   78  77\n Sci       75  78   78  78\nViolet  Comp      76  77   78  79\n Math      77  79   81  80\n Sci       78  81   81  81\n\nIn [93]: All = slice(None)\n\nIn [94]: df.loc[\"Violet\"]\nOut[94]: \n Exams     Labs \n I  II    I  II\nCourse \nComp      76  77   78  79\nMath      77  79   81  80\nSci       78  81   81  81\n\nIn [95]: df.loc[(All, \"Math\"), All]\nOut[95]: \n Exams     Labs \n I  II    I  II\nStudent Course \nAda     Math      71  73   75  74\nQuinn   Math      74  76   78  77\nViolet  Math      77  79   81  80\n\nIn [96]: df.loc[(slice(\"Ada\", \"Quinn\"), \"Math\"), All]\nOut[96]: \n Exams     Labs \n I  II    I  II\nStudent Course \nAda     Math      71  73   75  74\nQuinn   Math      74  76   78  77\n\nIn [97]: df.loc[(All, \"Math\"), (\"Exams\")]\nOut[97]: \n I  II\nStudent Course \nAda     Math    71  73\nQuinn   Math    74  76\nViolet  Math    77  79\n\nIn [98]: df.loc[(All, \"Math\"), (All, \"II\")]\nOut[98]: \n Exams Labs\n II   II\nStudent Course \nAda     Math      73   74\nQuinn   Math      76   77\nViolet  Math      79   80 \n```", "```py\nIn [99]: df.sort_values(by=(\"Labs\", \"II\"), ascending=False)\nOut[99]: \n Exams     Labs \n I  II    I  II\nStudent Course \nViolet  Sci       78  81   81  81\n Math      77  79   81  80\n Comp      76  77   78  79\nQuinn   Sci       75  78   78  78\n Math      74  76   78  77\n Comp      73  74   75  76\nAda     Sci       72  75   75  75\n Math      71  73   75  74\n Comp      70  71   72  73 \n```", "```py\nIn [100]: df = pd.DataFrame(\n .....:    np.random.randn(6, 1),\n .....:    index=pd.date_range(\"2013-08-01\", periods=6, freq=\"B\"),\n .....:    columns=list(\"A\"),\n .....: )\n .....: \n\nIn [101]: df.loc[df.index[3], \"A\"] = np.nan\n\nIn [102]: df\nOut[102]: \n A\n2013-08-01  0.721555\n2013-08-02 -0.706771\n2013-08-05 -1.039575\n2013-08-06       NaN\n2013-08-07 -0.424972\n2013-08-08  0.567020\n\nIn [103]: df.bfill()\nOut[103]: \n A\n2013-08-01  0.721555\n2013-08-02 -0.706771\n2013-08-05 -1.039575\n2013-08-06 -0.424972\n2013-08-07 -0.424972\n2013-08-08  0.567020 \n```", "```py\nIn [104]: df = pd.DataFrame(\n .....:    {\n .....:        \"animal\": \"cat dog cat fish dog cat cat\".split(),\n .....:        \"size\": list(\"SSMMMLL\"),\n .....:        \"weight\": [8, 10, 11, 1, 20, 12, 12],\n .....:        \"adult\": [False] * 5 + [True] * 2,\n .....:    }\n .....: )\n .....: \n\nIn [105]: df\nOut[105]: \n animal size  weight  adult\n0    cat    S       8  False\n1    dog    S      10  False\n2    cat    M      11  False\n3   fish    M       1  False\n4    dog    M      20  False\n5    cat    L      12   True\n6    cat    L      12   True\n\n# List the size of the animals with the highest weight.\nIn [106]: df.groupby(\"animal\").apply(lambda subf: subf[\"size\"][subf[\"weight\"].idxmax()], include_groups=False)\nOut[106]: \nanimal\ncat     L\ndog     M\nfish    M\ndtype: object \n```", "```py\nIn [107]: gb = df.groupby(\"animal\")\n\nIn [108]: gb.get_group(\"cat\")\nOut[108]: \n animal size  weight  adult\n0    cat    S       8  False\n2    cat    M      11  False\n5    cat    L      12   True\n6    cat    L      12   True \n```", "```py\nIn [109]: def GrowUp(x):\n .....:    avg_weight = sum(x[x[\"size\"] == \"S\"].weight * 1.5)\n .....:    avg_weight += sum(x[x[\"size\"] == \"M\"].weight * 1.25)\n .....:    avg_weight += sum(x[x[\"size\"] == \"L\"].weight)\n .....:    avg_weight /= len(x)\n .....:    return pd.Series([\"L\", avg_weight, True], index=[\"size\", \"weight\", \"adult\"])\n .....: \n\nIn [110]: expected_df = gb.apply(GrowUp, include_groups=False)\n\nIn [111]: expected_df\nOut[111]: \n size   weight  adult\nanimal \ncat       L  12.4375   True\ndog       L  20.0000   True\nfish      L   1.2500   True \n```", "```py\nIn [112]: S = pd.Series([i / 100.0 for i in range(1, 11)])\n\nIn [113]: def cum_ret(x, y):\n .....:    return x * (1 + y)\n .....: \n\nIn [114]: def red(x):\n .....:    return functools.reduce(cum_ret, x, 1.0)\n .....: \n\nIn [115]: S.expanding().apply(red, raw=True)\nOut[115]: \n0    1.010000\n1    1.030200\n2    1.061106\n3    1.103550\n4    1.158728\n5    1.228251\n6    1.314229\n7    1.419367\n8    1.547110\n9    1.701821\ndtype: float64 \n```", "```py\nIn [116]: df = pd.DataFrame({\"A\": [1, 1, 2, 2], \"B\": [1, -1, 1, 2]})\n\nIn [117]: gb = df.groupby(\"A\")\n\nIn [118]: def replace(g):\n .....:    mask = g < 0\n .....:    return g.where(~mask, g[~mask].mean())\n .....: \n\nIn [119]: gb.transform(replace)\nOut[119]: \n B\n0  1\n1  1\n2  1\n3  2 \n```", "```py\nIn [120]: df = pd.DataFrame(\n .....:    {\n .....:        \"code\": [\"foo\", \"bar\", \"baz\"] * 2,\n .....:        \"data\": [0.16, -0.21, 0.33, 0.45, -0.59, 0.62],\n .....:        \"flag\": [False, True] * 3,\n .....:    }\n .....: )\n .....: \n\nIn [121]: code_groups = df.groupby(\"code\")\n\nIn [122]: agg_n_sort_order = code_groups[[\"data\"]].transform(\"sum\").sort_values(by=\"data\")\n\nIn [123]: sorted_df = df.loc[agg_n_sort_order.index]\n\nIn [124]: sorted_df\nOut[124]: \n code  data   flag\n1  bar -0.21   True\n4  bar -0.59  False\n0  foo  0.16  False\n3  foo  0.45   True\n2  baz  0.33  False\n5  baz  0.62   True \n```", "```py\nIn [125]: rng = pd.date_range(start=\"2014-10-07\", periods=10, freq=\"2min\")\n\nIn [126]: ts = pd.Series(data=list(range(10)), index=rng)\n\nIn [127]: def MyCust(x):\n .....:    if len(x) > 2:\n .....:        return x.iloc[1] * 1.234\n .....:    return pd.NaT\n .....: \n\nIn [128]: mhc = {\"Mean\": \"mean\", \"Max\": \"max\", \"Custom\": MyCust}\n\nIn [129]: ts.resample(\"5min\").apply(mhc)\nOut[129]: \n Mean  Max Custom\n2014-10-07 00:00:00   1.0    2  1.234\n2014-10-07 00:05:00   3.5    4    NaT\n2014-10-07 00:10:00   6.0    7  7.404\n2014-10-07 00:15:00   8.5    9    NaT\n\nIn [130]: ts\nOut[130]: \n2014-10-07 00:00:00    0\n2014-10-07 00:02:00    1\n2014-10-07 00:04:00    2\n2014-10-07 00:06:00    3\n2014-10-07 00:08:00    4\n2014-10-07 00:10:00    5\n2014-10-07 00:12:00    6\n2014-10-07 00:14:00    7\n2014-10-07 00:16:00    8\n2014-10-07 00:18:00    9\nFreq: 2min, dtype: int64 \n```", "```py\nIn [131]: df = pd.DataFrame(\n .....:    {\"Color\": \"Red Red Red Blue\".split(), \"Value\": [100, 150, 50, 50]}\n .....: )\n .....: \n\nIn [132]: df\nOut[132]: \n Color  Value\n0   Red    100\n1   Red    150\n2   Red     50\n3  Blue     50\n\nIn [133]: df[\"Counts\"] = df.groupby([\"Color\"]).transform(len)\n\nIn [134]: df\nOut[134]: \n Color  Value  Counts\n0   Red    100       3\n1   Red    150       3\n2   Red     50       3\n3  Blue     50       1 \n```", "```py\nIn [135]: df = pd.DataFrame(\n .....:    {\"line_race\": [10, 10, 8, 10, 10, 8], \"beyer\": [99, 102, 103, 103, 88, 100]},\n .....:    index=[\n .....:        \"Last Gunfighter\",\n .....:        \"Last Gunfighter\",\n .....:        \"Last Gunfighter\",\n .....:        \"Paynter\",\n .....:        \"Paynter\",\n .....:        \"Paynter\",\n .....:    ],\n .....: )\n .....: \n\nIn [136]: df\nOut[136]: \n line_race  beyer\nLast Gunfighter         10     99\nLast Gunfighter         10    102\nLast Gunfighter          8    103\nPaynter                 10    103\nPaynter                 10     88\nPaynter                  8    100\n\nIn [137]: df[\"beyer_shifted\"] = df.groupby(level=0)[\"beyer\"].shift(1)\n\nIn [138]: df\nOut[138]: \n line_race  beyer  beyer_shifted\nLast Gunfighter         10     99            NaN\nLast Gunfighter         10    102           99.0\nLast Gunfighter          8    103          102.0\nPaynter                 10    103            NaN\nPaynter                 10     88          103.0\nPaynter                  8    100           88.0 \n```", "```py\nIn [139]: df = pd.DataFrame(\n .....:    {\n .....:        \"host\": [\"other\", \"other\", \"that\", \"this\", \"this\"],\n .....:        \"service\": [\"mail\", \"web\", \"mail\", \"mail\", \"web\"],\n .....:        \"no\": [1, 2, 1, 2, 1],\n .....:    }\n .....: ).set_index([\"host\", \"service\"])\n .....: \n\nIn [140]: mask = df.groupby(level=0).agg(\"idxmax\")\n\nIn [141]: df_count = df.loc[mask[\"no\"]].reset_index()\n\nIn [142]: df_count\nOut[142]: \n host service  no\n0  other     web   2\n1   that    mail   1\n2   this    mail   2 \n```", "```py\nIn [143]: df = pd.DataFrame([0, 1, 0, 1, 1, 1, 0, 1, 1], columns=[\"A\"])\n\nIn [144]: df[\"A\"].groupby((df[\"A\"] != df[\"A\"].shift()).cumsum()).groups\nOut[144]: {1: [0], 2: [1], 3: [2], 4: [3, 4, 5], 5: [6], 6: [7, 8]}\n\nIn [145]: df[\"A\"].groupby((df[\"A\"] != df[\"A\"].shift()).cumsum()).cumsum()\nOut[145]: \n0    0\n1    1\n2    0\n3    1\n4    2\n5    3\n6    0\n7    1\n8    2\nName: A, dtype: int64 \n```", "```py\nIn [146]: df = pd.DataFrame(\n .....:    data={\n .....:        \"Case\": [\"A\", \"A\", \"A\", \"B\", \"A\", \"A\", \"B\", \"A\", \"A\"],\n .....:        \"Data\": np.random.randn(9),\n .....:    }\n .....: )\n .....: \n\nIn [147]: dfs = list(\n .....:    zip(\n .....:        *df.groupby(\n .....:            (1 * (df[\"Case\"] == \"B\"))\n .....:            .cumsum()\n .....:            .rolling(window=3, min_periods=1)\n .....:            .median()\n .....:        )\n .....:    )\n .....: )[-1]\n .....: \n\nIn [148]: dfs[0]\nOut[148]: \n Case      Data\n0    A  0.276232\n1    A -1.087401\n2    A -0.673690\n3    B  0.113648\n\nIn [149]: dfs[1]\nOut[149]: \n Case      Data\n4    A -1.478427\n5    A  0.524988\n6    B  0.404705\n\nIn [150]: dfs[2]\nOut[150]: \n Case      Data\n7    A  0.577046\n8    A -1.715002 \n```", "```py\nIn [151]: df = pd.DataFrame(\n .....:    data={\n .....:        \"Province\": [\"ON\", \"QC\", \"BC\", \"AL\", \"AL\", \"MN\", \"ON\"],\n .....:        \"City\": [\n .....:            \"Toronto\",\n .....:            \"Montreal\",\n .....:            \"Vancouver\",\n .....:            \"Calgary\",\n .....:            \"Edmonton\",\n .....:            \"Winnipeg\",\n .....:            \"Windsor\",\n .....:        ],\n .....:        \"Sales\": [13, 6, 16, 8, 4, 3, 1],\n .....:    }\n .....: )\n .....: \n\nIn [152]: table = pd.pivot_table(\n .....:    df,\n .....:    values=[\"Sales\"],\n .....:    index=[\"Province\"],\n .....:    columns=[\"City\"],\n .....:    aggfunc=\"sum\",\n .....:    margins=True,\n .....: )\n .....: \n\nIn [153]: table.stack(\"City\", future_stack=True)\nOut[153]: \n Sales\nProvince City \nAL       Calgary      8.0\n Edmonton     4.0\n Montreal     NaN\n Toronto      NaN\n Vancouver    NaN\n...                   ...\nAll      Toronto     13.0\n Vancouver   16.0\n Windsor      1.0\n Winnipeg     3.0\n All         51.0\n\n[48 rows x 1 columns] \n```", "```py\nIn [154]: grades = [48, 99, 75, 80, 42, 80, 72, 68, 36, 78]\n\nIn [155]: df = pd.DataFrame(\n .....:    {\n .....:        \"ID\": [\"x%d\" % r for r in range(10)],\n .....:        \"Gender\": [\"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"M\", \"M\"],\n .....:        \"ExamYear\": [\n .....:            \"2007\",\n .....:            \"2007\",\n .....:            \"2007\",\n .....:            \"2008\",\n .....:            \"2008\",\n .....:            \"2008\",\n .....:            \"2008\",\n .....:            \"2009\",\n .....:            \"2009\",\n .....:            \"2009\",\n .....:        ],\n .....:        \"Class\": [\n .....:            \"algebra\",\n .....:            \"stats\",\n .....:            \"bio\",\n .....:            \"algebra\",\n .....:            \"algebra\",\n .....:            \"stats\",\n .....:            \"stats\",\n .....:            \"algebra\",\n .....:            \"bio\",\n .....:            \"bio\",\n .....:        ],\n .....:        \"Participated\": [\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"no\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:        ],\n .....:        \"Passed\": [\"yes\" if x > 50 else \"no\" for x in grades],\n .....:        \"Employed\": [\n .....:            True,\n .....:            True,\n .....:            True,\n .....:            False,\n .....:            False,\n .....:            False,\n .....:            False,\n .....:            True,\n .....:            True,\n .....:            False,\n .....:        ],\n .....:        \"Grade\": grades,\n .....:    }\n .....: )\n .....: \n\nIn [156]: df.groupby(\"ExamYear\").agg(\n .....:    {\n .....:        \"Participated\": lambda x: x.value_counts()[\"yes\"],\n .....:        \"Passed\": lambda x: sum(x == \"yes\"),\n .....:        \"Employed\": lambda x: sum(x),\n .....:        \"Grade\": lambda x: sum(x) / len(x),\n .....:    }\n .....: )\n .....: \nOut[156]: \n Participated  Passed  Employed      Grade\nExamYear \n2007                 3       2         3  74.000000\n2008                 3       3         0  68.500000\n2009                 3       2         2  60.666667 \n```", "```py\nIn [157]: df = pd.DataFrame(\n .....:    {\"value\": np.random.randn(36)},\n .....:    index=pd.date_range(\"2011-01-01\", freq=\"ME\", periods=36),\n .....: )\n .....: \n\nIn [158]: pd.pivot_table(\n .....:    df, index=df.index.month, columns=df.index.year, values=\"value\", aggfunc=\"sum\"\n .....: )\n .....: \nOut[158]: \n 2011      2012      2013\n1  -1.039268 -0.968914  2.565646\n2  -0.370647 -1.294524  1.431256\n3  -1.157892  0.413738  1.340309\n4  -1.344312  0.276662 -1.170299\n5   0.844885 -0.472035 -0.226169\n6   1.075770 -0.013960  0.410835\n7  -0.109050 -0.362543  0.813850\n8   1.643563 -0.006154  0.132003\n9  -1.469388 -0.923061 -0.827317\n10  0.357021  0.895717 -0.076467\n11 -0.674600  0.805244 -1.187678\n12 -1.776904 -1.206412  1.130127 \n```", "```py\nIn [159]: df = pd.DataFrame(\n .....:    data={\n .....:        \"A\": [[2, 4, 8, 16], [100, 200], [10, 20, 30]],\n .....:        \"B\": [[\"a\", \"b\", \"c\"], [\"jj\", \"kk\"], [\"ccc\"]],\n .....:    },\n .....:    index=[\"I\", \"II\", \"III\"],\n .....: )\n .....: \n\nIn [160]: def SeriesFromSubList(aList):\n .....:    return pd.Series(aList)\n .....: \n\nIn [161]: df_orgz = pd.concat(\n .....:    {ind: row.apply(SeriesFromSubList) for ind, row in df.iterrows()}\n .....: )\n .....: \n\nIn [162]: df_orgz\nOut[162]: \n 0     1     2     3\nI   A    2     4     8  16.0\n B    a     b     c   NaN\nII  A  100   200   NaN   NaN\n B   jj    kk   NaN   NaN\nIII A   10  20.0  30.0   NaN\n B  ccc   NaN   NaN   NaN \n```", "```py\nIn [163]: df = pd.DataFrame(\n .....:    data=np.random.randn(2000, 2) / 10000,\n .....:    index=pd.date_range(\"2001-01-01\", periods=2000),\n .....:    columns=[\"A\", \"B\"],\n .....: )\n .....: \n\nIn [164]: df\nOut[164]: \n A         B\n2001-01-01 -0.000144 -0.000141\n2001-01-02  0.000161  0.000102\n2001-01-03  0.000057  0.000088\n2001-01-04 -0.000221  0.000097\n2001-01-05 -0.000201 -0.000041\n...              ...       ...\n2006-06-19  0.000040 -0.000235\n2006-06-20 -0.000123 -0.000021\n2006-06-21 -0.000113  0.000114\n2006-06-22  0.000136  0.000109\n2006-06-23  0.000027  0.000030\n\n[2000 rows x 2 columns]\n\nIn [165]: def gm(df, const):\n .....:    v = ((((df[\"A\"] + df[\"B\"]) + 1).cumprod()) - 1) * const\n .....:    return v.iloc[-1]\n .....: \n\nIn [166]: s = pd.Series(\n .....:    {\n .....:        df.index[i]: gm(df.iloc[i: min(i + 51, len(df) - 1)], 5)\n .....:        for i in range(len(df) - 50)\n .....:    }\n .....: )\n .....: \n\nIn [167]: s\nOut[167]: \n2001-01-01    0.000930\n2001-01-02    0.002615\n2001-01-03    0.001281\n2001-01-04    0.001117\n2001-01-05    0.002772\n ... \n2006-04-30    0.003296\n2006-05-01    0.002629\n2006-05-02    0.002081\n2006-05-03    0.004247\n2006-05-04    0.003928\nLength: 1950, dtype: float64 \n```", "```py\nIn [168]: rng = pd.date_range(start=\"2014-01-01\", periods=100)\n\nIn [169]: df = pd.DataFrame(\n .....:    {\n .....:        \"Open\": np.random.randn(len(rng)),\n .....:        \"Close\": np.random.randn(len(rng)),\n .....:        \"Volume\": np.random.randint(100, 2000, len(rng)),\n .....:    },\n .....:    index=rng,\n .....: )\n .....: \n\nIn [170]: df\nOut[170]: \n Open     Close  Volume\n2014-01-01 -1.611353 -0.492885    1219\n2014-01-02 -3.000951  0.445794    1054\n2014-01-03 -0.138359 -0.076081    1381\n2014-01-04  0.301568  1.198259    1253\n2014-01-05  0.276381 -0.669831    1728\n...              ...       ...     ...\n2014-04-06 -0.040338  0.937843    1188\n2014-04-07  0.359661 -0.285908    1864\n2014-04-08  0.060978  1.714814     941\n2014-04-09  1.759055 -0.455942    1065\n2014-04-10  0.138185 -1.147008    1453\n\n[100 rows x 3 columns]\n\nIn [171]: def vwap(bars):\n .....:    return (bars.Close * bars.Volume).sum() / bars.Volume.sum()\n .....: \n\nIn [172]: window = 5\n\nIn [173]: s = pd.concat(\n .....:    [\n .....:        (pd.Series(vwap(df.iloc[i: i + window]), index=[df.index[i + window]]))\n .....:        for i in range(len(df) - window)\n .....:    ]\n .....: )\n .....: \n\nIn [174]: s.round(2)\nOut[174]: \n2014-01-06    0.02\n2014-01-07    0.11\n2014-01-08    0.10\n2014-01-09    0.07\n2014-01-10   -0.29\n ... \n2014-04-06   -0.63\n2014-04-07   -0.02\n2014-04-08   -0.03\n2014-04-09    0.34\n2014-04-10    0.29\nLength: 95, dtype: float64 \n```", "```py\nIn [146]: df = pd.DataFrame(\n .....:    data={\n .....:        \"Case\": [\"A\", \"A\", \"A\", \"B\", \"A\", \"A\", \"B\", \"A\", \"A\"],\n .....:        \"Data\": np.random.randn(9),\n .....:    }\n .....: )\n .....: \n\nIn [147]: dfs = list(\n .....:    zip(\n .....:        *df.groupby(\n .....:            (1 * (df[\"Case\"] == \"B\"))\n .....:            .cumsum()\n .....:            .rolling(window=3, min_periods=1)\n .....:            .median()\n .....:        )\n .....:    )\n .....: )[-1]\n .....: \n\nIn [148]: dfs[0]\nOut[148]: \n Case      Data\n0    A  0.276232\n1    A -1.087401\n2    A -0.673690\n3    B  0.113648\n\nIn [149]: dfs[1]\nOut[149]: \n Case      Data\n4    A -1.478427\n5    A  0.524988\n6    B  0.404705\n\nIn [150]: dfs[2]\nOut[150]: \n Case      Data\n7    A  0.577046\n8    A -1.715002 \n```", "```py\nIn [151]: df = pd.DataFrame(\n .....:    data={\n .....:        \"Province\": [\"ON\", \"QC\", \"BC\", \"AL\", \"AL\", \"MN\", \"ON\"],\n .....:        \"City\": [\n .....:            \"Toronto\",\n .....:            \"Montreal\",\n .....:            \"Vancouver\",\n .....:            \"Calgary\",\n .....:            \"Edmonton\",\n .....:            \"Winnipeg\",\n .....:            \"Windsor\",\n .....:        ],\n .....:        \"Sales\": [13, 6, 16, 8, 4, 3, 1],\n .....:    }\n .....: )\n .....: \n\nIn [152]: table = pd.pivot_table(\n .....:    df,\n .....:    values=[\"Sales\"],\n .....:    index=[\"Province\"],\n .....:    columns=[\"City\"],\n .....:    aggfunc=\"sum\",\n .....:    margins=True,\n .....: )\n .....: \n\nIn [153]: table.stack(\"City\", future_stack=True)\nOut[153]: \n Sales\nProvince City \nAL       Calgary      8.0\n Edmonton     4.0\n Montreal     NaN\n Toronto      NaN\n Vancouver    NaN\n...                   ...\nAll      Toronto     13.0\n Vancouver   16.0\n Windsor      1.0\n Winnipeg     3.0\n All         51.0\n\n[48 rows x 1 columns] \n```", "```py\nIn [154]: grades = [48, 99, 75, 80, 42, 80, 72, 68, 36, 78]\n\nIn [155]: df = pd.DataFrame(\n .....:    {\n .....:        \"ID\": [\"x%d\" % r for r in range(10)],\n .....:        \"Gender\": [\"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"M\", \"M\"],\n .....:        \"ExamYear\": [\n .....:            \"2007\",\n .....:            \"2007\",\n .....:            \"2007\",\n .....:            \"2008\",\n .....:            \"2008\",\n .....:            \"2008\",\n .....:            \"2008\",\n .....:            \"2009\",\n .....:            \"2009\",\n .....:            \"2009\",\n .....:        ],\n .....:        \"Class\": [\n .....:            \"algebra\",\n .....:            \"stats\",\n .....:            \"bio\",\n .....:            \"algebra\",\n .....:            \"algebra\",\n .....:            \"stats\",\n .....:            \"stats\",\n .....:            \"algebra\",\n .....:            \"bio\",\n .....:            \"bio\",\n .....:        ],\n .....:        \"Participated\": [\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"no\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:            \"yes\",\n .....:        ],\n .....:        \"Passed\": [\"yes\" if x > 50 else \"no\" for x in grades],\n .....:        \"Employed\": [\n .....:            True,\n .....:            True,\n .....:            True,\n .....:            False,\n .....:            False,\n .....:            False,\n .....:            False,\n .....:            True,\n .....:            True,\n .....:            False,\n .....:        ],\n .....:        \"Grade\": grades,\n .....:    }\n .....: )\n .....: \n\nIn [156]: df.groupby(\"ExamYear\").agg(\n .....:    {\n .....:        \"Participated\": lambda x: x.value_counts()[\"yes\"],\n .....:        \"Passed\": lambda x: sum(x == \"yes\"),\n .....:        \"Employed\": lambda x: sum(x),\n .....:        \"Grade\": lambda x: sum(x) / len(x),\n .....:    }\n .....: )\n .....: \nOut[156]: \n Participated  Passed  Employed      Grade\nExamYear \n2007                 3       2         3  74.000000\n2008                 3       3         0  68.500000\n2009                 3       2         2  60.666667 \n```", "```py\nIn [157]: df = pd.DataFrame(\n .....:    {\"value\": np.random.randn(36)},\n .....:    index=pd.date_range(\"2011-01-01\", freq=\"ME\", periods=36),\n .....: )\n .....: \n\nIn [158]: pd.pivot_table(\n .....:    df, index=df.index.month, columns=df.index.year, values=\"value\", aggfunc=\"sum\"\n .....: )\n .....: \nOut[158]: \n 2011      2012      2013\n1  -1.039268 -0.968914  2.565646\n2  -0.370647 -1.294524  1.431256\n3  -1.157892  0.413738  1.340309\n4  -1.344312  0.276662 -1.170299\n5   0.844885 -0.472035 -0.226169\n6   1.075770 -0.013960  0.410835\n7  -0.109050 -0.362543  0.813850\n8   1.643563 -0.006154  0.132003\n9  -1.469388 -0.923061 -0.827317\n10  0.357021  0.895717 -0.076467\n11 -0.674600  0.805244 -1.187678\n12 -1.776904 -1.206412  1.130127 \n```", "```py\nIn [159]: df = pd.DataFrame(\n .....:    data={\n .....:        \"A\": [[2, 4, 8, 16], [100, 200], [10, 20, 30]],\n .....:        \"B\": [[\"a\", \"b\", \"c\"], [\"jj\", \"kk\"], [\"ccc\"]],\n .....:    },\n .....:    index=[\"I\", \"II\", \"III\"],\n .....: )\n .....: \n\nIn [160]: def SeriesFromSubList(aList):\n .....:    return pd.Series(aList)\n .....: \n\nIn [161]: df_orgz = pd.concat(\n .....:    {ind: row.apply(SeriesFromSubList) for ind, row in df.iterrows()}\n .....: )\n .....: \n\nIn [162]: df_orgz\nOut[162]: \n 0     1     2     3\nI   A    2     4     8  16.0\n B    a     b     c   NaN\nII  A  100   200   NaN   NaN\n B   jj    kk   NaN   NaN\nIII A   10  20.0  30.0   NaN\n B  ccc   NaN   NaN   NaN \n```", "```py\nIn [163]: df = pd.DataFrame(\n .....:    data=np.random.randn(2000, 2) / 10000,\n .....:    index=pd.date_range(\"2001-01-01\", periods=2000),\n .....:    columns=[\"A\", \"B\"],\n .....: )\n .....: \n\nIn [164]: df\nOut[164]: \n A         B\n2001-01-01 -0.000144 -0.000141\n2001-01-02  0.000161  0.000102\n2001-01-03  0.000057  0.000088\n2001-01-04 -0.000221  0.000097\n2001-01-05 -0.000201 -0.000041\n...              ...       ...\n2006-06-19  0.000040 -0.000235\n2006-06-20 -0.000123 -0.000021\n2006-06-21 -0.000113  0.000114\n2006-06-22  0.000136  0.000109\n2006-06-23  0.000027  0.000030\n\n[2000 rows x 2 columns]\n\nIn [165]: def gm(df, const):\n .....:    v = ((((df[\"A\"] + df[\"B\"]) + 1).cumprod()) - 1) * const\n .....:    return v.iloc[-1]\n .....: \n\nIn [166]: s = pd.Series(\n .....:    {\n .....:        df.index[i]: gm(df.iloc[i: min(i + 51, len(df) - 1)], 5)\n .....:        for i in range(len(df) - 50)\n .....:    }\n .....: )\n .....: \n\nIn [167]: s\nOut[167]: \n2001-01-01    0.000930\n2001-01-02    0.002615\n2001-01-03    0.001281\n2001-01-04    0.001117\n2001-01-05    0.002772\n ... \n2006-04-30    0.003296\n2006-05-01    0.002629\n2006-05-02    0.002081\n2006-05-03    0.004247\n2006-05-04    0.003928\nLength: 1950, dtype: float64 \n```", "```py\nIn [168]: rng = pd.date_range(start=\"2014-01-01\", periods=100)\n\nIn [169]: df = pd.DataFrame(\n .....:    {\n .....:        \"Open\": np.random.randn(len(rng)),\n .....:        \"Close\": np.random.randn(len(rng)),\n .....:        \"Volume\": np.random.randint(100, 2000, len(rng)),\n .....:    },\n .....:    index=rng,\n .....: )\n .....: \n\nIn [170]: df\nOut[170]: \n Open     Close  Volume\n2014-01-01 -1.611353 -0.492885    1219\n2014-01-02 -3.000951  0.445794    1054\n2014-01-03 -0.138359 -0.076081    1381\n2014-01-04  0.301568  1.198259    1253\n2014-01-05  0.276381 -0.669831    1728\n...              ...       ...     ...\n2014-04-06 -0.040338  0.937843    1188\n2014-04-07  0.359661 -0.285908    1864\n2014-04-08  0.060978  1.714814     941\n2014-04-09  1.759055 -0.455942    1065\n2014-04-10  0.138185 -1.147008    1453\n\n[100 rows x 3 columns]\n\nIn [171]: def vwap(bars):\n .....:    return (bars.Close * bars.Volume).sum() / bars.Volume.sum()\n .....: \n\nIn [172]: window = 5\n\nIn [173]: s = pd.concat(\n .....:    [\n .....:        (pd.Series(vwap(df.iloc[i: i + window]), index=[df.index[i + window]]))\n .....:        for i in range(len(df) - window)\n .....:    ]\n .....: )\n .....: \n\nIn [174]: s.round(2)\nOut[174]: \n2014-01-06    0.02\n2014-01-07    0.11\n2014-01-08    0.10\n2014-01-09    0.07\n2014-01-10   -0.29\n ... \n2014-04-06   -0.63\n2014-04-07   -0.02\n2014-04-08   -0.03\n2014-04-09    0.34\n2014-04-10    0.29\nLength: 95, dtype: float64 \n```", "```py\nIn [175]: dates = pd.date_range(\"2000-01-01\", periods=5)\n\nIn [176]: dates.to_period(freq=\"M\").to_timestamp()\nOut[176]: \nDatetimeIndex(['2000-01-01', '2000-01-01', '2000-01-01', '2000-01-01',\n '2000-01-01'],\n dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [177]: rng = pd.date_range(\"2000-01-01\", periods=6)\n\nIn [178]: df1 = pd.DataFrame(np.random.randn(6, 3), index=rng, columns=[\"A\", \"B\", \"C\"])\n\nIn [179]: df2 = df1.copy() \n```", "```py\nIn [180]: df = pd.concat([df1, df2], ignore_index=True)\n\nIn [181]: df\nOut[181]: \n A         B         C\n0  -0.870117 -0.479265 -0.790855\n1   0.144817  1.726395 -0.464535\n2  -0.821906  1.597605  0.187307\n3  -0.128342 -1.511638 -0.289858\n4   0.399194 -1.430030 -0.639760\n5   1.115116 -2.012600  1.810662\n6  -0.870117 -0.479265 -0.790855\n7   0.144817  1.726395 -0.464535\n8  -0.821906  1.597605  0.187307\n9  -0.128342 -1.511638 -0.289858\n10  0.399194 -1.430030 -0.639760\n11  1.115116 -2.012600  1.810662 \n```", "```py\nIn [182]: df = pd.DataFrame(\n .....:    data={\n .....:        \"Area\": [\"A\"] * 5 + [\"C\"] * 2,\n .....:        \"Bins\": [110] * 2 + [160] * 3 + [40] * 2,\n .....:        \"Test_0\": [0, 1, 0, 1, 2, 0, 1],\n .....:        \"Data\": np.random.randn(7),\n .....:    }\n .....: )\n .....: \n\nIn [183]: df\nOut[183]: \n Area  Bins  Test_0      Data\n0    A   110       0 -0.433937\n1    A   110       1 -0.160552\n2    A   160       0  0.744434\n3    A   160       1  1.754213\n4    A   160       2  0.000850\n5    C    40       0  0.342243\n6    C    40       1  1.070599\n\nIn [184]: df[\"Test_1\"] = df[\"Test_0\"] - 1\n\nIn [185]: pd.merge(\n .....:    df,\n .....:    df,\n .....:    left_on=[\"Bins\", \"Area\", \"Test_0\"],\n .....:    right_on=[\"Bins\", \"Area\", \"Test_1\"],\n .....:    suffixes=(\"_L\", \"_R\"),\n .....: )\n .....: \nOut[185]: \n Area  Bins  Test_0_L    Data_L  Test_1_L  Test_0_R    Data_R  Test_1_R\n0    A   110         0 -0.433937        -1         1 -0.160552         0\n1    A   160         0  0.744434        -1         1  1.754213         0\n2    A   160         1  1.754213         0         2  0.000850         1\n3    C    40         0  0.342243        -1         1  1.070599         0 \n```", "```py\nIn [186]: df = pd.DataFrame(\n .....:    {\n .....:        \"stratifying_var\": np.random.uniform(0, 100, 20),\n .....:        \"price\": np.random.normal(100, 5, 20),\n .....:    }\n .....: )\n .....: \n\nIn [187]: df[\"quartiles\"] = pd.qcut(\n .....:    df[\"stratifying_var\"], 4, labels=[\"0-25%\", \"25-50%\", \"50-75%\", \"75-100%\"]\n .....: )\n .....: \n\nIn [188]: df.boxplot(column=\"price\", by=\"quartiles\")\nOut[188]: <Axes: title={'center': 'price'}, xlabel='quartiles'> \n```", "```py\nIn [189]: for i in range(3):\n .....:    data = pd.DataFrame(np.random.randn(10, 4))\n .....:    data.to_csv(\"file_{}.csv\".format(i))\n .....: \n\nIn [190]: files = [\"file_0.csv\", \"file_1.csv\", \"file_2.csv\"]\n\nIn [191]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True) \n```", "```py\nIn [192]: import glob\n\nIn [193]: import os\n\nIn [194]: files = glob.glob(\"file_*.csv\")\n\nIn [195]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True) \n```", "```py\nIn [196]: i = pd.date_range(\"20000101\", periods=10000)\n\nIn [197]: df = pd.DataFrame({\"year\": i.year, \"month\": i.month, \"day\": i.day})\n\nIn [198]: df.head()\nOut[198]: \n year  month  day\n0  2000      1    1\n1  2000      1    2\n2  2000      1    3\n3  2000      1    4\n4  2000      1    5\n\nIn [199]: %timeit pd.to_datetime(df.year * 10000 + df.month * 100 + df.day, format='%Y%m%d')\n .....: ds = df.apply(lambda x: \"%04d%02d%02d\" % (x[\"year\"], x[\"month\"], x[\"day\"]), axis=1)\n .....: ds.head()\n .....: %timeit pd.to_datetime(ds)\n .....: \n4.01 ms +- 635 us per loop (mean +- std. dev. of 7 runs, 100 loops each)\n1.05 ms +- 7.39 us per loop (mean +- std. dev. of 7 runs, 1,000 loops each) \n```", "```py\nIn [200]: data = \"\"\";;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: date;Param1;Param2;Param4;Param5\n .....:    ;m\u00b2;\u00b0C;m\u00b2;m\n .....: ;;;;\n .....: 01.01.1990 00:00;1;1;2;3\n .....: 01.01.1990 01:00;5;3;4;5\n .....: 01.01.1990 02:00;9;5;6;7\n .....: 01.01.1990 03:00;13;7;8;9\n .....: 01.01.1990 04:00;17;9;10;11\n .....: 01.01.1990 05:00;21;11;12;13\n .....: \"\"\"\n .....: \n```", "```py\nIn [201]: from io import StringIO\n\nIn [202]: pd.read_csv(\n .....:    StringIO(data),\n .....:    sep=\";\",\n .....:    skiprows=[11, 12],\n .....:    index_col=0,\n .....:    parse_dates=True,\n .....:    header=10,\n .....: )\n .....: \nOut[202]: \n Param1  Param2  Param4  Param5\ndate \n1990-01-01 00:00:00       1       1       2       3\n1990-01-01 01:00:00       5       3       4       5\n1990-01-01 02:00:00       9       5       6       7\n1990-01-01 03:00:00      13       7       8       9\n1990-01-01 04:00:00      17       9      10      11\n1990-01-01 05:00:00      21      11      12      13 \n```", "```py\nIn [203]: pd.read_csv(StringIO(data), sep=\";\", header=10, nrows=10).columns\nOut[203]: Index(['date', 'Param1', 'Param2', 'Param4', 'Param5'], dtype='object')\n\nIn [204]: columns = pd.read_csv(StringIO(data), sep=\";\", header=10, nrows=10).columns\n\nIn [205]: pd.read_csv(\n .....:    StringIO(data), sep=\";\", index_col=0, header=12, parse_dates=True, names=columns\n .....: )\n .....: \nOut[205]: \n Param1  Param2  Param4  Param5\ndate \n1990-01-01 00:00:00       1       1       2       3\n1990-01-01 01:00:00       5       3       4       5\n1990-01-01 02:00:00       9       5       6       7\n1990-01-01 03:00:00      13       7       8       9\n1990-01-01 04:00:00      17       9      10      11\n1990-01-01 05:00:00      21      11      12      13 \n```", "```py\nIn [206]: df = pd.DataFrame(np.random.randn(8, 3))\n\nIn [207]: store = pd.HDFStore(\"test.h5\")\n\nIn [208]: store.put(\"df\", df)\n\n# you can store an arbitrary Python object via pickle\nIn [209]: store.get_storer(\"df\").attrs.my_attribute = {\"A\": 10}\n\nIn [210]: store.get_storer(\"df\").attrs.my_attribute\nOut[210]: {'A': 10} \n```", "```py\nIn [211]: store = pd.HDFStore(\"test.h5\", \"w\", driver=\"H5FD_CORE\")\n\nIn [212]: df = pd.DataFrame(np.random.randn(8, 3))\n\nIn [213]: store[\"test\"] = df\n\n# only after closing the store, data is written to disk:\nIn [214]: store.close() \n```", "```py\n#include  <stdio.h>\n#include  <stdint.h>\n\ntypedef  struct  _Data\n{\n  int32_t  count;\n  double  avg;\n  float  scale;\n}  Data;\n\nint  main(int  argc,  const  char  *argv[])\n{\n  size_t  n  =  10;\n  Data  d[n];\n\n  for  (int  i  =  0;  i  <  n;  ++i)\n  {\n  d[i].count  =  i;\n  d[i].avg  =  i  +  1.0;\n  d[i].scale  =  (float)  i  +  2.0f;\n  }\n\n  FILE  *file  =  fopen(\"binary.dat\",  \"wb\");\n  fwrite(&d,  sizeof(Data),  n,  file);\n  fclose(file);\n\n  return  0;\n} \n```", "```py\nnames = \"count\", \"avg\", \"scale\"\n\n# note that the offsets are larger than the size of the type because of\n# struct padding\noffsets = 0, 8, 16\nformats = \"i4\", \"f8\", \"f4\"\ndt = np.dtype({\"names\": names, \"offsets\": offsets, \"formats\": formats}, align=True)\ndf = pd.DataFrame(np.fromfile(\"binary.dat\", dt)) \n```", "```py\nIn [189]: for i in range(3):\n .....:    data = pd.DataFrame(np.random.randn(10, 4))\n .....:    data.to_csv(\"file_{}.csv\".format(i))\n .....: \n\nIn [190]: files = [\"file_0.csv\", \"file_1.csv\", \"file_2.csv\"]\n\nIn [191]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True) \n```", "```py\nIn [192]: import glob\n\nIn [193]: import os\n\nIn [194]: files = glob.glob(\"file_*.csv\")\n\nIn [195]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True) \n```", "```py\nIn [196]: i = pd.date_range(\"20000101\", periods=10000)\n\nIn [197]: df = pd.DataFrame({\"year\": i.year, \"month\": i.month, \"day\": i.day})\n\nIn [198]: df.head()\nOut[198]: \n year  month  day\n0  2000      1    1\n1  2000      1    2\n2  2000      1    3\n3  2000      1    4\n4  2000      1    5\n\nIn [199]: %timeit pd.to_datetime(df.year * 10000 + df.month * 100 + df.day, format='%Y%m%d')\n .....: ds = df.apply(lambda x: \"%04d%02d%02d\" % (x[\"year\"], x[\"month\"], x[\"day\"]), axis=1)\n .....: ds.head()\n .....: %timeit pd.to_datetime(ds)\n .....: \n4.01 ms +- 635 us per loop (mean +- std. dev. of 7 runs, 100 loops each)\n1.05 ms +- 7.39 us per loop (mean +- std. dev. of 7 runs, 1,000 loops each) \n```", "```py\nIn [200]: data = \"\"\";;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: date;Param1;Param2;Param4;Param5\n .....:    ;m\u00b2;\u00b0C;m\u00b2;m\n .....: ;;;;\n .....: 01.01.1990 00:00;1;1;2;3\n .....: 01.01.1990 01:00;5;3;4;5\n .....: 01.01.1990 02:00;9;5;6;7\n .....: 01.01.1990 03:00;13;7;8;9\n .....: 01.01.1990 04:00;17;9;10;11\n .....: 01.01.1990 05:00;21;11;12;13\n .....: \"\"\"\n .....: \n```", "```py\nIn [201]: from io import StringIO\n\nIn [202]: pd.read_csv(\n .....:    StringIO(data),\n .....:    sep=\";\",\n .....:    skiprows=[11, 12],\n .....:    index_col=0,\n .....:    parse_dates=True,\n .....:    header=10,\n .....: )\n .....: \nOut[202]: \n Param1  Param2  Param4  Param5\ndate \n1990-01-01 00:00:00       1       1       2       3\n1990-01-01 01:00:00       5       3       4       5\n1990-01-01 02:00:00       9       5       6       7\n1990-01-01 03:00:00      13       7       8       9\n1990-01-01 04:00:00      17       9      10      11\n1990-01-01 05:00:00      21      11      12      13 \n```", "```py\nIn [203]: pd.read_csv(StringIO(data), sep=\";\", header=10, nrows=10).columns\nOut[203]: Index(['date', 'Param1', 'Param2', 'Param4', 'Param5'], dtype='object')\n\nIn [204]: columns = pd.read_csv(StringIO(data), sep=\";\", header=10, nrows=10).columns\n\nIn [205]: pd.read_csv(\n .....:    StringIO(data), sep=\";\", index_col=0, header=12, parse_dates=True, names=columns\n .....: )\n .....: \nOut[205]: \n Param1  Param2  Param4  Param5\ndate \n1990-01-01 00:00:00       1       1       2       3\n1990-01-01 01:00:00       5       3       4       5\n1990-01-01 02:00:00       9       5       6       7\n1990-01-01 03:00:00      13       7       8       9\n1990-01-01 04:00:00      17       9      10      11\n1990-01-01 05:00:00      21      11      12      13 \n```", "```py\nIn [189]: for i in range(3):\n .....:    data = pd.DataFrame(np.random.randn(10, 4))\n .....:    data.to_csv(\"file_{}.csv\".format(i))\n .....: \n\nIn [190]: files = [\"file_0.csv\", \"file_1.csv\", \"file_2.csv\"]\n\nIn [191]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True) \n```", "```py\nIn [192]: import glob\n\nIn [193]: import os\n\nIn [194]: files = glob.glob(\"file_*.csv\")\n\nIn [195]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True) \n```", "```py\nIn [196]: i = pd.date_range(\"20000101\", periods=10000)\n\nIn [197]: df = pd.DataFrame({\"year\": i.year, \"month\": i.month, \"day\": i.day})\n\nIn [198]: df.head()\nOut[198]: \n year  month  day\n0  2000      1    1\n1  2000      1    2\n2  2000      1    3\n3  2000      1    4\n4  2000      1    5\n\nIn [199]: %timeit pd.to_datetime(df.year * 10000 + df.month * 100 + df.day, format='%Y%m%d')\n .....: ds = df.apply(lambda x: \"%04d%02d%02d\" % (x[\"year\"], x[\"month\"], x[\"day\"]), axis=1)\n .....: ds.head()\n .....: %timeit pd.to_datetime(ds)\n .....: \n4.01 ms +- 635 us per loop (mean +- std. dev. of 7 runs, 100 loops each)\n1.05 ms +- 7.39 us per loop (mean +- std. dev. of 7 runs, 1,000 loops each) \n```", "```py\nIn [200]: data = \"\"\";;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: ;;;;\n .....: date;Param1;Param2;Param4;Param5\n .....:    ;m\u00b2;\u00b0C;m\u00b2;m\n .....: ;;;;\n .....: 01.01.1990 00:00;1;1;2;3\n .....: 01.01.1990 01:00;5;3;4;5\n .....: 01.01.1990 02:00;9;5;6;7\n .....: 01.01.1990 03:00;13;7;8;9\n .....: 01.01.1990 04:00;17;9;10;11\n .....: 01.01.1990 05:00;21;11;12;13\n .....: \"\"\"\n .....: \n```", "```py\nIn [201]: from io import StringIO\n\nIn [202]: pd.read_csv(\n .....:    StringIO(data),\n .....:    sep=\";\",\n .....:    skiprows=[11, 12],\n .....:    index_col=0,\n .....:    parse_dates=True,\n .....:    header=10,\n .....: )\n .....: \nOut[202]: \n Param1  Param2  Param4  Param5\ndate \n1990-01-01 00:00:00       1       1       2       3\n1990-01-01 01:00:00       5       3       4       5\n1990-01-01 02:00:00       9       5       6       7\n1990-01-01 03:00:00      13       7       8       9\n1990-01-01 04:00:00      17       9      10      11\n1990-01-01 05:00:00      21      11      12      13 \n```", "```py\nIn [203]: pd.read_csv(StringIO(data), sep=\";\", header=10, nrows=10).columns\nOut[203]: Index(['date', 'Param1', 'Param2', 'Param4', 'Param5'], dtype='object')\n\nIn [204]: columns = pd.read_csv(StringIO(data), sep=\";\", header=10, nrows=10).columns\n\nIn [205]: pd.read_csv(\n .....:    StringIO(data), sep=\";\", index_col=0, header=12, parse_dates=True, names=columns\n .....: )\n .....: \nOut[205]: \n Param1  Param2  Param4  Param5\ndate \n1990-01-01 00:00:00       1       1       2       3\n1990-01-01 01:00:00       5       3       4       5\n1990-01-01 02:00:00       9       5       6       7\n1990-01-01 03:00:00      13       7       8       9\n1990-01-01 04:00:00      17       9      10      11\n1990-01-01 05:00:00      21      11      12      13 \n```", "```py\nIn [201]: from io import StringIO\n\nIn [202]: pd.read_csv(\n .....:    StringIO(data),\n .....:    sep=\";\",\n .....:    skiprows=[11, 12],\n .....:    index_col=0,\n .....:    parse_dates=True,\n .....:    header=10,\n .....: )\n .....: \nOut[202]: \n Param1  Param2  Param4  Param5\ndate \n1990-01-01 00:00:00       1       1       2       3\n1990-01-01 01:00:00       5       3       4       5\n1990-01-01 02:00:00       9       5       6       7\n1990-01-01 03:00:00      13       7       8       9\n1990-01-01 04:00:00      17       9      10      11\n1990-01-01 05:00:00      21      11      12      13 \n```", "```py\nIn [203]: pd.read_csv(StringIO(data), sep=\";\", header=10, nrows=10).columns\nOut[203]: Index(['date', 'Param1', 'Param2', 'Param4', 'Param5'], dtype='object')\n\nIn [204]: columns = pd.read_csv(StringIO(data), sep=\";\", header=10, nrows=10).columns\n\nIn [205]: pd.read_csv(\n .....:    StringIO(data), sep=\";\", index_col=0, header=12, parse_dates=True, names=columns\n .....: )\n .....: \nOut[205]: \n Param1  Param2  Param4  Param5\ndate \n1990-01-01 00:00:00       1       1       2       3\n1990-01-01 01:00:00       5       3       4       5\n1990-01-01 02:00:00       9       5       6       7\n1990-01-01 03:00:00      13       7       8       9\n1990-01-01 04:00:00      17       9      10      11\n1990-01-01 05:00:00      21      11      12      13 \n```", "```py\nIn [206]: df = pd.DataFrame(np.random.randn(8, 3))\n\nIn [207]: store = pd.HDFStore(\"test.h5\")\n\nIn [208]: store.put(\"df\", df)\n\n# you can store an arbitrary Python object via pickle\nIn [209]: store.get_storer(\"df\").attrs.my_attribute = {\"A\": 10}\n\nIn [210]: store.get_storer(\"df\").attrs.my_attribute\nOut[210]: {'A': 10} \n```", "```py\nIn [211]: store = pd.HDFStore(\"test.h5\", \"w\", driver=\"H5FD_CORE\")\n\nIn [212]: df = pd.DataFrame(np.random.randn(8, 3))\n\nIn [213]: store[\"test\"] = df\n\n# only after closing the store, data is written to disk:\nIn [214]: store.close() \n```", "```py\n#include  <stdio.h>\n#include  <stdint.h>\n\ntypedef  struct  _Data\n{\n  int32_t  count;\n  double  avg;\n  float  scale;\n}  Data;\n\nint  main(int  argc,  const  char  *argv[])\n{\n  size_t  n  =  10;\n  Data  d[n];\n\n  for  (int  i  =  0;  i  <  n;  ++i)\n  {\n  d[i].count  =  i;\n  d[i].avg  =  i  +  1.0;\n  d[i].scale  =  (float)  i  +  2.0f;\n  }\n\n  FILE  *file  =  fopen(\"binary.dat\",  \"wb\");\n  fwrite(&d,  sizeof(Data),  n,  file);\n  fclose(file);\n\n  return  0;\n} \n```", "```py\nnames = \"count\", \"avg\", \"scale\"\n\n# note that the offsets are larger than the size of the type because of\n# struct padding\noffsets = 0, 8, 16\nformats = \"i4\", \"f8\", \"f4\"\ndt = np.dtype({\"names\": names, \"offsets\": offsets, \"formats\": formats}, align=True)\ndf = pd.DataFrame(np.fromfile(\"binary.dat\", dt)) \n```", "```py\nIn [215]: df = pd.DataFrame(np.random.random(size=(100, 5)))\n\nIn [216]: corr_mat = df.corr()\n\nIn [217]: mask = np.tril(np.ones_like(corr_mat, dtype=np.bool_), k=-1)\n\nIn [218]: corr_mat.where(mask)\nOut[218]: \n 0         1         2        3   4\n0       NaN       NaN       NaN      NaN NaN\n1 -0.079861       NaN       NaN      NaN NaN\n2 -0.236573  0.183801       NaN      NaN NaN\n3 -0.013795 -0.051975  0.037235      NaN NaN\n4 -0.031974  0.118342 -0.073499 -0.02063 NaN \n```", "```py\nIn [219]: def distcorr(x, y):\n .....:    n = len(x)\n .....:    a = np.zeros(shape=(n, n))\n .....:    b = np.zeros(shape=(n, n))\n .....:    for i in range(n):\n .....:        for j in range(i + 1, n):\n .....:            a[i, j] = abs(x[i] - x[j])\n .....:            b[i, j] = abs(y[i] - y[j])\n .....:    a += a.T\n .....:    b += b.T\n .....:    a_bar = np.vstack([np.nanmean(a, axis=0)] * n)\n .....:    b_bar = np.vstack([np.nanmean(b, axis=0)] * n)\n .....:    A = a - a_bar - a_bar.T + np.full(shape=(n, n), fill_value=a_bar.mean())\n .....:    B = b - b_bar - b_bar.T + np.full(shape=(n, n), fill_value=b_bar.mean())\n .....:    cov_ab = np.sqrt(np.nansum(A * B)) / n\n .....:    std_a = np.sqrt(np.sqrt(np.nansum(A ** 2)) / n)\n .....:    std_b = np.sqrt(np.sqrt(np.nansum(B ** 2)) / n)\n .....:    return cov_ab / std_a / std_b\n .....: \n\nIn [220]: df = pd.DataFrame(np.random.normal(size=(100, 3)))\n\nIn [221]: df.corr(method=distcorr)\nOut[221]: \n 0         1         2\n0  1.000000  0.197613  0.216328\n1  0.197613  1.000000  0.208749\n2  0.216328  0.208749  1.000000 \n```", "```py\nIn [215]: df = pd.DataFrame(np.random.random(size=(100, 5)))\n\nIn [216]: corr_mat = df.corr()\n\nIn [217]: mask = np.tril(np.ones_like(corr_mat, dtype=np.bool_), k=-1)\n\nIn [218]: corr_mat.where(mask)\nOut[218]: \n 0         1         2        3   4\n0       NaN       NaN       NaN      NaN NaN\n1 -0.079861       NaN       NaN      NaN NaN\n2 -0.236573  0.183801       NaN      NaN NaN\n3 -0.013795 -0.051975  0.037235      NaN NaN\n4 -0.031974  0.118342 -0.073499 -0.02063 NaN \n```", "```py\nIn [219]: def distcorr(x, y):\n .....:    n = len(x)\n .....:    a = np.zeros(shape=(n, n))\n .....:    b = np.zeros(shape=(n, n))\n .....:    for i in range(n):\n .....:        for j in range(i + 1, n):\n .....:            a[i, j] = abs(x[i] - x[j])\n .....:            b[i, j] = abs(y[i] - y[j])\n .....:    a += a.T\n .....:    b += b.T\n .....:    a_bar = np.vstack([np.nanmean(a, axis=0)] * n)\n .....:    b_bar = np.vstack([np.nanmean(b, axis=0)] * n)\n .....:    A = a - a_bar - a_bar.T + np.full(shape=(n, n), fill_value=a_bar.mean())\n .....:    B = b - b_bar - b_bar.T + np.full(shape=(n, n), fill_value=b_bar.mean())\n .....:    cov_ab = np.sqrt(np.nansum(A * B)) / n\n .....:    std_a = np.sqrt(np.sqrt(np.nansum(A ** 2)) / n)\n .....:    std_b = np.sqrt(np.sqrt(np.nansum(B ** 2)) / n)\n .....:    return cov_ab / std_a / std_b\n .....: \n\nIn [220]: df = pd.DataFrame(np.random.normal(size=(100, 3)))\n\nIn [221]: df.corr(method=distcorr)\nOut[221]: \n 0         1         2\n0  1.000000  0.197613  0.216328\n1  0.197613  1.000000  0.208749\n2  0.216328  0.208749  1.000000 \n```", "```py\nIn [222]: import datetime\n\nIn [223]: s = pd.Series(pd.date_range(\"2012-1-1\", periods=3, freq=\"D\"))\n\nIn [224]: s - s.max()\nOut[224]: \n0   -2 days\n1   -1 days\n2    0 days\ndtype: timedelta64[ns]\n\nIn [225]: s.max() - s\nOut[225]: \n0   2 days\n1   1 days\n2   0 days\ndtype: timedelta64[ns]\n\nIn [226]: s - datetime.datetime(2011, 1, 1, 3, 5)\nOut[226]: \n0   364 days 20:55:00\n1   365 days 20:55:00\n2   366 days 20:55:00\ndtype: timedelta64[ns]\n\nIn [227]: s + datetime.timedelta(minutes=5)\nOut[227]: \n0   2012-01-01 00:05:00\n1   2012-01-02 00:05:00\n2   2012-01-03 00:05:00\ndtype: datetime64[ns]\n\nIn [228]: datetime.datetime(2011, 1, 1, 3, 5) - s\nOut[228]: \n0   -365 days +03:05:00\n1   -366 days +03:05:00\n2   -367 days +03:05:00\ndtype: timedelta64[ns]\n\nIn [229]: datetime.timedelta(minutes=5) + s\nOut[229]: \n0   2012-01-01 00:05:00\n1   2012-01-02 00:05:00\n2   2012-01-03 00:05:00\ndtype: datetime64[ns] \n```", "```py\nIn [230]: deltas = pd.Series([datetime.timedelta(days=i) for i in range(3)])\n\nIn [231]: df = pd.DataFrame({\"A\": s, \"B\": deltas})\n\nIn [232]: df\nOut[232]: \n A      B\n0 2012-01-01 0 days\n1 2012-01-02 1 days\n2 2012-01-03 2 days\n\nIn [233]: df[\"New Dates\"] = df[\"A\"] + df[\"B\"]\n\nIn [234]: df[\"Delta\"] = df[\"A\"] - df[\"New Dates\"]\n\nIn [235]: df\nOut[235]: \n A      B  New Dates   Delta\n0 2012-01-01 0 days 2012-01-01  0 days\n1 2012-01-02 1 days 2012-01-03 -1 days\n2 2012-01-03 2 days 2012-01-05 -2 days\n\nIn [236]: df.dtypes\nOut[236]: \nA             datetime64[ns]\nB            timedelta64[ns]\nNew Dates     datetime64[ns]\nDelta        timedelta64[ns]\ndtype: object \n```", "```py\nIn [237]: y = s - s.shift()\n\nIn [238]: y\nOut[238]: \n0      NaT\n1   1 days\n2   1 days\ndtype: timedelta64[ns]\n\nIn [239]: y[1] = np.nan\n\nIn [240]: y\nOut[240]: \n0      NaT\n1      NaT\n2   1 days\ndtype: timedelta64[ns] \n```", "```py\nIn [241]: def expand_grid(data_dict):\n .....:    rows = itertools.product(*data_dict.values())\n .....:    return pd.DataFrame.from_records(rows, columns=data_dict.keys())\n .....: \n\nIn [242]: df = expand_grid(\n .....:    {\"height\": [60, 70], \"weight\": [100, 140, 180], \"sex\": [\"Male\", \"Female\"]}\n .....: )\n .....: \n\nIn [243]: df\nOut[243]: \n height  weight     sex\n0       60     100    Male\n1       60     100  Female\n2       60     140    Male\n3       60     140  Female\n4       60     180    Male\n5       60     180  Female\n6       70     100    Male\n7       70     100  Female\n8       70     140    Male\n9       70     140  Female\n10      70     180    Male\n11      70     180  Female \n```", "```py\nIn [244]: v = s.to_numpy()\n\nIn [245]: is_constant = v.shape[0] == 0 or (s[0] == s).all() \n```", "```py\nIn [246]: v = s.dropna().to_numpy()\n\nIn [247]: is_constant = v.shape[0] == 0 or (s[0] == s).all() \n```", "```py\nIn [248]: v = s.to_numpy()\n\nIn [249]: is_constant = v.shape[0] == 0 or (s[0] == s).all() or not pd.notna(v).any() \n```"]