["```py\nIn [1]: df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n ...:                  index=pd.date_range('1/1/2000', periods=10))\n ...: \n\nIn [2]: df.iloc[3:7] = np.nan\n\nIn [3]: df\nOut[3]: \n A         B         C\n2000-01-01  0.469112 -0.282863 -1.509059\n2000-01-02 -1.135632  1.212112 -0.173215\n2000-01-03  0.119209 -1.044236 -0.861849\n2000-01-04       NaN       NaN       NaN\n2000-01-05       NaN       NaN       NaN\n2000-01-06       NaN       NaN       NaN\n2000-01-07       NaN       NaN       NaN\n2000-01-08  0.113648 -1.478427  0.524988\n2000-01-09  0.404705  0.577046 -1.715002\n2000-01-10 -1.039268 -0.370647 -1.157892\n\n[10 rows x 3 columns] \n```", "```py\nIn [4]: df.agg('sum')\nOut[4]: \nA   -1.068226\nB   -1.387015\nC   -4.892029\nLength: 3, dtype: float64 \n```", "```py\nIn [5]: df.agg(['sum', 'min'])\nOut[5]: \n A         B         C\nsum -1.068226 -1.387015 -4.892029\nmin -1.135632 -1.478427 -1.715002\n\n[2 rows x 3 columns] \n```", "```py\nIn [6]: df.agg({'A': ['sum', 'min'], 'B': ['min', 'max']})\nOut[6]: \n A         B\nsum -1.068226       NaN\nmin -1.135632 -1.478427\nmax       NaN  1.212112\n\n[3 rows x 2 columns] \n```", "```py\nIn [7]: df.transform(['abs', lambda x: x - x.min()])\nOut[7]: \n A                   B                   C \n abs  <lambda>       abs  <lambda>       abs  <lambda>\n2000-01-01  0.469112  1.604745  0.282863  1.195563  1.509059  0.205944\n2000-01-02  1.135632  0.000000  1.212112  2.690539  0.173215  1.541787\n2000-01-03  0.119209  1.254841  1.044236  0.434191  0.861849  0.853153\n2000-01-04       NaN       NaN       NaN       NaN       NaN       NaN\n2000-01-05       NaN       NaN       NaN       NaN       NaN       NaN\n2000-01-06       NaN       NaN       NaN       NaN       NaN       NaN\n2000-01-07       NaN       NaN       NaN       NaN       NaN       NaN\n2000-01-08  0.113648  1.249281  1.478427  0.000000  0.524988  2.239990\n2000-01-09  0.404705  1.540338  0.577046  2.055473  1.715002  0.000000\n2000-01-10  1.039268  0.096364  0.370647  1.107780  1.157892  0.557110\n\n[10 rows x 6 columns] \n```", "```py\nIn [8]: df = pd.DataFrame({'A': [1, 2, 3],\n ...:                   'B': [1., 2., 3.],\n ...:                   'C': ['foo', 'bar', 'baz'],\n ...:                   'D': pd.date_range('20130101', periods=3)})\n ...: \n\nIn [9]: df.dtypes\nOut[9]: \nA             int64\nB           float64\nC            object\nD    datetime64[ns]\nLength: 4, dtype: object \n```", "```py\nIn [10]: df.agg(['min', 'sum'])\nOut[10]:\n     A    B          C          D\nmin  1  1.0        bar 2013-01-01\nsum  6  6.0  foobarbaz        NaT \n```", "```py\nIn [10]: data = \"a  b\\n1  2\\n3  4\"\n\nIn [11]: pd.read_fwf(StringIO(data)).dtypes\nOut[11]: \na    int64\nb    int64\nLength: 2, dtype: object\n\nIn [12]: pd.read_fwf(StringIO(data), dtype={'a': 'float64', 'b': 'object'}).dtypes\nOut[12]: \na    float64\nb     object\nLength: 2, dtype: object \n```", "```py\nIn [13]: pd.to_datetime([1, 2, 3], unit='D', origin=pd.Timestamp('1960-01-01'))\nOut[13]: DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [14]: pd.to_datetime([1, 2, 3], unit='D')\nOut[14]: DatetimeIndex(['1970-01-02', '1970-01-03', '1970-01-04'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [15]: arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n ....:          ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n ....: \n\nIn [16]: index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])\n\nIn [17]: df = pd.DataFrame({'A': [1, 1, 1, 1, 2, 2, 3, 3],\n ....:                   'B': np.arange(8)},\n ....:                  index=index)\n ....: \n\nIn [18]: df\nOut[18]: \n A  B\nfirst second \nbar   one     1  0\n two     1  1\nbaz   one     1  2\n two     1  3\nfoo   one     2  4\n two     2  5\nqux   one     3  6\n two     3  7\n\n[8 rows x 2 columns]\n\nIn [19]: df.groupby(['second', 'A']).sum()\nOut[19]: \n B\nsecond A \none    1  2\n 2  4\n 3  6\ntwo    1  4\n 2  5\n 3  7\n\n[6 rows x 1 columns] \n```", "```py\nIn [20]: url = ('https://github.com/{repo}/raw/{branch}/{path}'\n ....:       .format(repo='pandas-dev/pandas',\n ....:               branch='main',\n ....:               path='pandas/tests/io/parser/data/salaries.csv.bz2'))\n ....: \n\n# default, infer compression\nIn [21]: df = pd.read_csv(url, sep='\\t', compression='infer')\n\n# explicitly specify compression\nIn [22]: df = pd.read_csv(url, sep='\\t', compression='bz2')\n\nIn [23]: df.head(2)\nOut[23]: \n S  X  E  M\n0  13876  1  1  1\n1  11608  1  3  0\n\n[2 rows x 4 columns] \n```", "```py\nIn [24]: df = pd.DataFrame({'A': np.random.randn(1000),\n ....:                   'B': 'foo',\n ....:                   'C': pd.date_range('20130101', periods=1000, freq='s')})\n ....: \n```", "```py\nIn [25]: df.to_pickle(\"data.pkl.compress\", compression=\"gzip\")\n\nIn [26]: rt = pd.read_pickle(\"data.pkl.compress\", compression=\"gzip\")\n\nIn [27]: rt.head()\nOut[27]: \n A    B                   C\n0 -1.344312  foo 2013-01-01 00:00:00\n1  0.844885  foo 2013-01-01 00:00:01\n2  1.075770  foo 2013-01-01 00:00:02\n3 -0.109050  foo 2013-01-01 00:00:03\n4  1.643563  foo 2013-01-01 00:00:04\n\n[5 rows x 3 columns] \n```", "```py\nIn [28]: df.to_pickle(\"data.pkl.gz\")\n\nIn [29]: rt = pd.read_pickle(\"data.pkl.gz\")\n\nIn [30]: rt.head()\nOut[30]: \n A    B                   C\n0 -1.344312  foo 2013-01-01 00:00:00\n1  0.844885  foo 2013-01-01 00:00:01\n2  1.075770  foo 2013-01-01 00:00:02\n3 -0.109050  foo 2013-01-01 00:00:03\n4  1.643563  foo 2013-01-01 00:00:04\n\n[5 rows x 3 columns]\n\nIn [31]: df[\"A\"].to_pickle(\"s1.pkl.bz2\")\n\nIn [32]: rt = pd.read_pickle(\"s1.pkl.bz2\")\n\nIn [33]: rt.head()\nOut[33]: \n0   -1.344312\n1    0.844885\n2    1.075770\n3   -0.109050\n4    1.643563\nName: A, Length: 5, dtype: float64 \n```", "```py\nIn [1]: idx = pd.UInt64Index([1, 2, 3])\nIn [2]: df = pd.DataFrame({'A': ['a', 'b', 'c']}, index=idx)\nIn [3]: df.index\nOut[3]: UInt64Index([1, 2, 3], dtype='uint64') \n```", "```py\nIn [34]: chromosomes = np.r_[np.arange(1, 23).astype(str), ['X', 'Y']]\n\nIn [35]: df = pd.DataFrame({\n ....:    'A': np.random.randint(100),\n ....:    'B': np.random.randint(100),\n ....:    'C': np.random.randint(100),\n ....:    'chromosomes': pd.Categorical(np.random.choice(chromosomes, 100),\n ....:                                  categories=chromosomes,\n ....:                                  ordered=True)})\n ....: \n\nIn [36]: df\nOut[36]: \n A   B   C chromosomes\n0   87  22  81           4\n1   87  22  81          13\n2   87  22  81          22\n3   87  22  81           2\n4   87  22  81           6\n..  ..  ..  ..         ...\n95  87  22  81           8\n96  87  22  81          11\n97  87  22  81           X\n98  87  22  81           1\n99  87  22  81          19\n\n[100 rows x 4 columns] \n```", "```py\nIn [3]: df[df.chromosomes != '1'].groupby('chromosomes', observed=False, sort=False).sum()\n---------------------------------------------------------------------------\nValueError: items in new_categories are not the same as in old categories \n```", "```py\nIn [37]: df[df.chromosomes != '1'].groupby('chromosomes', observed=False, sort=False).sum()\nOut[37]: \n A   B    C\nchromosomes \n4            348  88  324\n13           261  66  243\n22           348  88  324\n2            348  88  324\n6            174  44  162\n...          ...  ..  ...\n3            348  88  324\n11           348  88  324\n19           174  44  162\n1              0   0    0\n21             0   0    0\n\n[24 rows x 3 columns] \n```", "```py\nIn [38]: df = pd.DataFrame(\n ....:    {'A': [1, 2, 3],\n ....:     'B': ['a', 'b', 'c'],\n ....:     'C': pd.date_range('2016-01-01', freq='d', periods=3)},\n ....:    index=pd.Index(range(3), name='idx'))\n ....: \n\nIn [39]: df\nOut[39]: \n A  B          C\nidx \n0    1  a 2016-01-01\n1    2  b 2016-01-02\n2    3  c 2016-01-03\n\n[3 rows x 3 columns]\n\nIn [40]: df.to_json(orient='table')\nOut[40]: '{\"schema\":{\"fields\":[{\"name\":\"idx\",\"type\":\"integer\"},{\"name\":\"A\",\"type\":\"integer\"},{\"name\":\"B\",\"type\":\"string\"},{\"name\":\"C\",\"type\":\"datetime\"}],\"primaryKey\":[\"idx\"],\"pandas_version\":\"1.4.0\"},\"data\":[{\"idx\":0,\"A\":1,\"B\":\"a\",\"C\":\"2016-01-01T00:00:00.000\"},{\"idx\":1,\"A\":2,\"B\":\"b\",\"C\":\"2016-01-02T00:00:00.000\"},{\"idx\":2,\"A\":3,\"B\":\"c\",\"C\":\"2016-01-03T00:00:00.000\"}]}' \n```", "```py\nfrom scipy.sparse import csr_matrix\narr = np.random.random(size=(1000, 5))\narr[arr < .9] = 0\nsp_arr = csr_matrix(arr)\nsp_arr\nsdf = pd.SparseDataFrame(sp_arr)\nsdf \n```", "```py\nsdf.to_coo() \n```", "```py\nIn [41]: np.random.seed(24)\n\nIn [42]: df = pd.DataFrame({'A': np.linspace(1, 10, 10)})\n\nIn [43]: df = pd.concat([df, pd.DataFrame(np.random.RandomState(24).randn(10, 4),\n ....:                                 columns=list('BCDE'))],\n ....:               axis=1)\n ....: \n\nIn [44]: df.iloc[0, 2] = np.nan\n\nIn [45]: df\nOut[45]: \n A         B         C         D         E\n0   1.0  1.329212       NaN -0.316280 -0.990810\n1   2.0 -1.070816 -1.438713  0.564417  0.295722\n2   3.0 -1.626404  0.219565  0.678805  1.889273\n3   4.0  0.961538  0.104011 -0.481165  0.850229\n4   5.0  1.453425  1.057737  0.165562  0.515018\n5   6.0 -1.336936  0.562861  1.392855 -0.063328\n6   7.0  0.121668  1.207603 -0.002040  1.627796\n7   8.0  0.354493  1.037528 -0.385684  0.519818\n8   9.0  1.686583 -1.325963  1.428984 -2.089354\n9  10.0 -0.129820  0.631523 -0.586538  0.290720\n\n[10 rows x 5 columns]\n\nIn [46]: styled = (df.style\n ....:          .applymap(lambda val: 'color:red;' if val < 0 else 'color:black;')\n ....:          .highlight_max())\n ....: \n\nIn [47]: styled.to_excel('styled.xlsx', engine='openpyxl') \n```", "```py\nIn [1]: c = pd.cut(range(4), bins=2)\n\nIn [2]: c\nOut[2]:\n[(-0.003, 1.5], (-0.003, 1.5], (1.5, 3], (1.5, 3]]\nCategories (2, object): [(-0.003, 1.5] < (1.5, 3]]\n\nIn [3]: c.categories\nOut[3]: Index(['(-0.003, 1.5]', '(1.5, 3]'], dtype='object') \n```", "```py\nIn [48]: c = pd.cut(range(4), bins=2)\n\nIn [49]: c\nOut[49]: \n[(-0.003, 1.5], (-0.003, 1.5], (1.5, 3.0], (1.5, 3.0]]\nCategories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]]\n\nIn [50]: c.categories\nOut[50]: IntervalIndex([(-0.003, 1.5], (1.5, 3.0]], dtype='interval[float64, right]') \n```", "```py\nIn [51]: pd.cut([0, 3, 5, 1], bins=c.categories)\nOut[51]: \n[(-0.003, 1.5], (1.5, 3.0], NaN, (-0.003, 1.5]]\nCategories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]] \n```", "```py\nIn [52]: df = pd.DataFrame({'A': range(4),\n ....:                   'B': pd.cut([0, 3, 1, 1], bins=c.categories)\n ....:                   }).set_index('B')\n ....: \n\nIn [53]: df\nOut[53]: \n A\nB \n(-0.003, 1.5]  0\n(1.5, 3.0]     1\n(-0.003, 1.5]  2\n(-0.003, 1.5]  3\n\n[4 rows x 1 columns] \n```", "```py\nIn [54]: df.loc[pd.Interval(1.5, 3.0)]\nOut[54]: \nA    1\nName: (1.5, 3.0], Length: 1, dtype: int64 \n```", "```py\nIn [55]: df.loc[0]\nOut[55]: \n A\nB \n(-0.003, 1.5]  0\n(-0.003, 1.5]  2\n(-0.003, 1.5]  3\n\n[3 rows x 1 columns] \n```", "```py\nIn [2]: s = pd.TimeSeries([1, 2, 3], index=pd.date_range('20130101', periods=3))\n\nIn [3]: s\nOut[3]:\n2013-01-01    1\n2013-01-02    2\n2013-01-03    3\nFreq: D, dtype: int64\n\nIn [4]: type(s)\nOut[4]: pandas.core.series.TimeSeries\n\nIn [5]: s = pd.Series(s)\n\nIn [6]: s\nOut[6]:\n2013-01-01    1\n2013-01-02    2\n2013-01-03    3\nFreq: D, dtype: int64\n\nIn [7]: type(s)\nOut[7]: pandas.core.series.Series \n```", "```py\nIn [56]: idx = pd.Index([1, 2])\n\nIn [57]: idx\nOut[57]: Index([1, 2], dtype='int64')\n\nIn [58]: mi = pd.MultiIndex.from_tuples([(1, 2), (2, 4)])\n\nIn [59]: mi\nOut[59]: \nMultiIndex([(1, 2),\n (2, 4)],\n ) \n```", "```py\nIn [5]: idx.map(lambda x: x * 2)\nOut[5]: array([2, 4])\n\nIn [6]: idx.map(lambda x: (x, x * 2))\nOut[6]: array([(1, 2), (2, 4)], dtype=object)\n\nIn [7]: mi.map(lambda x: x)\nOut[7]: array([(1, 2), (2, 4)], dtype=object)\n\nIn [8]: mi.map(lambda x: x[0])\nOut[8]: array([1, 2]) \n```", "```py\nIn [60]: idx.map(lambda x: x * 2)\nOut[60]: Index([2, 4], dtype='int64')\n\nIn [61]: idx.map(lambda x: (x, x * 2))\nOut[61]: \nMultiIndex([(1, 2),\n (2, 4)],\n )\n\nIn [62]: mi.map(lambda x: x)\nOut[62]: \nMultiIndex([(1, 2),\n (2, 4)],\n )\n\nIn [63]: mi.map(lambda x: x[0])\nOut[63]: Index([1, 2], dtype='int64') \n```", "```py\nIn [64]: s = pd.Series(pd.date_range('2011-01-02T00:00', '2011-01-02T02:00', freq='H')\n ....:              .tz_localize('Asia/Tokyo'))\n ....:\n\nIn [65]: s\nOut[65]:\n0   2011-01-02 00:00:00+09:00\n1   2011-01-02 01:00:00+09:00\n2   2011-01-02 02:00:00+09:00\nLength: 3, dtype: datetime64[ns, Asia/Tokyo] \n```", "```py\nIn [9]: s.map(lambda x: x.hour)\nOut[9]:\n0    0\n1    1\n2    2\ndtype: int32 \n```", "```py\nIn [66]: s.map(lambda x: x.hour)\nOut[66]:\n0    0\n1    1\n2    2\nLength: 3, dtype: int64 \n```", "```py\nIn [1]: idx = pd.date_range(\"2015-01-01\", periods=5, freq='10H')\n\nIn [2]: idx.hour\nOut[2]: array([ 0, 10, 20,  6, 16], dtype=int32) \n```", "```py\nIn [67]: idx = pd.date_range(\"2015-01-01\", periods=5, freq='10H')\n\nIn [68]: idx.hour\nOut[68]: Index([0, 10, 20, 6, 16], dtype='int32') \n```", "```py\n    # Series\n    In [5]: pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n     ...:           pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n    Out[5]: array([Timestamp('2016-01-01 00:00:00-0500', tz='US/Eastern')], dtype=object)\n\n    In [6]: pd.unique(pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n     ...:                     pd.Timestamp('20160101', tz='US/Eastern')]))\n    Out[6]: array(['2016-01-01T05:00:00.000000000'], dtype='datetime64[ns]')\n\n    # Index\n    In [7]: pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n     ...:          pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n    Out[7]: DatetimeIndex(['2016-01-01 00:00:00-05:00'], dtype='datetime64[ns, US/Eastern]', freq=None)\n\n    In [8]: pd.unique([pd.Timestamp('20160101', tz='US/Eastern'),\n     ...:           pd.Timestamp('20160101', tz='US/Eastern')])\n    Out[8]: array(['2016-01-01T05:00:00.000000000'], dtype='datetime64[ns]') \n    ```", "```py\n    # Series, returns an array of Timestamp tz-aware\n    In [64]: pd.Series([pd.Timestamp(r'20160101', tz=r'US/Eastern'),\n     ....:           pd.Timestamp(r'20160101', tz=r'US/Eastern')]).unique()\n     ....: \n    Out[64]: \n    <DatetimeArray>\n    ['2016-01-01 00:00:00-05:00']\n    Length: 1, dtype: datetime64[ns, US/Eastern]\n\n    In [65]: pd.unique(pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n     ....:          pd.Timestamp('20160101', tz='US/Eastern')]))\n     ....: \n    Out[65]: \n    <DatetimeArray>\n    ['2016-01-01 00:00:00-05:00']\n    Length: 1, dtype: datetime64[ns, US/Eastern]\n\n    # Index, returns a DatetimeIndex\n    In [66]: pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n     ....:          pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n     ....: \n    Out[66]: DatetimeIndex(['2016-01-01 00:00:00-05:00'], dtype='datetime64[ns, US/Eastern]', freq=None)\n\n    In [67]: pd.unique(pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n     ....:                    pd.Timestamp('20160101', tz='US/Eastern')]))\n     ....: \n    Out[67]: DatetimeIndex(['2016-01-01 00:00:00-05:00'], dtype='datetime64[ns, US/Eastern]', freq=None) \n    ```", "```py\n    In [1]: pd.Series(list('baabc'), dtype='category').unique()\n    Out[1]:\n    [b, a, c]\n    Categories (3, object): [b, a, c]\n\n    In [2]: pd.unique(pd.Series(list('baabc'), dtype='category'))\n    Out[2]: array(['b', 'a', 'c'], dtype=object) \n    ```", "```py\n    # returns a Categorical\n    In [68]: pd.Series(list('baabc'), dtype='category').unique()\n    Out[68]: \n    ['b', 'a', 'c']\n    Categories (3, object): ['a', 'b', 'c']\n\n    In [69]: pd.unique(pd.Series(list('baabc'), dtype='category'))\n    Out[69]: \n    ['b', 'a', 'c']\n    Categories (3, object): ['a', 'b', 'c'] \n    ```", "```py\nIn [70]: df = pd.DataFrame({'a': [1, 2, 3]}, pd.DatetimeIndex(['2011-12-31 23:59:59',\n ....:                                                      '2012-01-01 00:00:00',\n ....:                                                      '2012-01-01 00:00:01']))\n ....: \n```", "```py\nIn [4]: df['2011-12-31 23:59:59']\nOut[4]:\n a\n2011-12-31 23:59:59  1\n\nIn [5]: df['a']['2011-12-31 23:59:59']\nOut[5]:\n2011-12-31 23:59:59    1\nName: a, dtype: int64 \n```", "```py\nIn [4]: df['2011-12-31 23:59:59']\nKeyError: '2011-12-31 23:59:59'\n\nIn [5]: df['a']['2011-12-31 23:59:59']\nOut[5]: 1 \n```", "```py\nIn [71]: df1 = pd.DataFrame(np.array([1.0], dtype=np.float32, ndmin=2))\n\nIn [72]: df1.dtypes\nOut[72]: \n0    float32\nLength: 1, dtype: object\n\nIn [73]: df2 = pd.DataFrame(np.array([np.nan], dtype=np.float32, ndmin=2))\n\nIn [74]: df2.dtypes\nOut[74]: \n0    float32\nLength: 1, dtype: object \n```", "```py\nIn [7]: pd.concat([df1, df2]).dtypes\nOut[7]:\n0    float64\ndtype: object \n```", "```py\nIn [75]: pd.concat([df1, df2]).dtypes\nOut[75]: \n0    float32\nLength: 1, dtype: object \n```", "```py\nIn [8]: index = pd.Index(['foo', 'bar', 'baz'])\n\nIn [9]: index.memory_usage(deep=True)\nOut[9]: 180\n\nIn [10]: index.get_loc('foo')\nOut[10]: 0\n\nIn [11]: index.memory_usage(deep=True)\nOut[11]: 180 \n```", "```py\nIn [8]: index = pd.Index(['foo', 'bar', 'baz'])\n\nIn [9]: index.memory_usage(deep=True)\nOut[9]: 180\n\nIn [10]: index.get_loc('foo')\nOut[10]: 0\n\nIn [11]: index.memory_usage(deep=True)\nOut[11]: 260 \n```", "```py\nIn [81]: df = pd.DataFrame(np.arange(6), columns=['value'],\n   ....:                   index=pd.MultiIndex.from_product([list('BA'), range(3)]))\n   ....:\nIn [82]: df\n\nOut[82]:\n     value\nB 0      0\n  1      1\n  2      2\nA 0      3\n  1      4\n  2      5\n\n[6 rows x 1 columns] \n```", "```py\nIn [87]: df.index.is_lexsorted()\nOut[87]: False\n\nIn [88]: df.index.is_monotonic\nOut[88]: False \n```", "```py\nIn [76]: df.sort_index()\nOut[76]: \n a\n2011-12-31 23:59:59  1\n2012-01-01 00:00:00  2\n2012-01-01 00:00:01  3\n\n[3 rows x 1 columns] \n```", "```py\nIn [90]: df.sort_index().index.is_lexsorted()\nOut[90]: True\n\nIn [91]: df.sort_index().index.is_monotonic\nOut[91]: True \n```", "```py\nIn [77]: df = pd.DataFrame({'value': [1, 2, 3, 4]},\n ....:                  index=pd.MultiIndex([['a', 'b'], ['bb', 'aa']],\n ....:                                      [[0, 0, 1, 1], [0, 1, 0, 1]]))\n ....: \n\nIn [78]: df\nOut[78]: \n value\na bb      1\n aa      2\nb bb      3\n aa      4\n\n[4 rows x 1 columns] \n```", "```py\nIn [11]: df.sort_index()\nOut[11]:\n      value\na bb      1\n  aa      2\nb bb      3\n  aa      4\n\nIn [14]: df.sort_index().index.is_lexsorted()\nOut[14]: True\n\nIn [15]: df.sort_index().index.is_monotonic\nOut[15]: False \n```", "```py\nIn [94]: df.sort_index()\nOut[94]:\n      value\na aa      2\n  bb      1\nb aa      4\n  bb      3\n\n[4 rows x 1 columns]\n\nIn [95]: df.sort_index().index.is_lexsorted()\nOut[95]: True\n\nIn [96]: df.sort_index().index.is_monotonic\nOut[96]: True \n```", "```py\nIn [1]: df = pd.DataFrame({'A': [1, 1, 2, 2], 'B': [1, 2, 3, 4]})\n\nIn [2]: df.groupby('A').describe()\nOut[2]:\n B\nA\n1 count  2.000000\n mean   1.500000\n std    0.707107\n min    1.000000\n 25%    1.250000\n 50%    1.500000\n 75%    1.750000\n max    2.000000\n2 count  2.000000\n mean   3.500000\n std    0.707107\n min    3.000000\n 25%    3.250000\n 50%    3.500000\n 75%    3.750000\n max    4.000000\n\nIn [3]: df.groupby('A').agg([\"mean\", \"std\", \"min\", \"max\"])\nOut[3]:\n B\n mean       std amin amax\nA\n1  1.5  0.707107    1    2\n2  3.5  0.707107    3    4 \n```", "```py\nIn [79]: df = pd.DataFrame({'A': [1, 1, 2, 2], 'B': [1, 2, 3, 4]})\n\nIn [80]: df.groupby('A').describe()\nOut[80]: \n B \n count mean       std  min   25%  50%   75%  max\nA \n1   2.0  1.5  0.707107  1.0  1.25  1.5  1.75  2.0\n2   2.0  3.5  0.707107  3.0  3.25  3.5  3.75  4.0\n\n[2 rows x 8 columns]\n\nIn [81]: df.groupby('A').agg([\"mean\", \"std\", \"min\", \"max\"])\nOut[81]: \n B \n mean       std min max\nA \n1  1.5  0.707107   1   2\n2  3.5  0.707107   3   4\n\n[2 rows x 4 columns] \n```", "```py\nIn [82]: np.random.seed(1234)\n\nIn [83]: df = pd.DataFrame(np.random.rand(100, 2),\n ....:                  columns=pd.Index(['A', 'B'], name='bar'),\n ....:                  index=pd.date_range('20160101',\n ....:                                      periods=100, freq='D', name='foo'))\n ....: \n\nIn [84]: df.tail()\nOut[84]: \nbar                A         B\nfoo \n2016-04-05  0.640880  0.126205\n2016-04-06  0.171465  0.737086\n2016-04-07  0.127029  0.369650\n2016-04-08  0.604334  0.103104\n2016-04-09  0.802374  0.945553\n\n[5 rows x 2 columns] \n```", "```py\nIn [2]: df.rolling(12).corr()\nOut[2]:\n<class 'pandas.core.panel.Panel'>\nDimensions: 100 (items) x 2 (major_axis) x 2 (minor_axis)\nItems axis: 2016-01-01 00:00:00 to 2016-04-09 00:00:00\nMajor_axis axis: A to B\nMinor_axis axis: A to B \n```", "```py\nIn [85]: res = df.rolling(12).corr()\n\nIn [86]: res.tail()\nOut[86]: \nbar                    A         B\nfoo        bar \n2016-04-07 B   -0.132090  1.000000\n2016-04-08 A    1.000000 -0.145775\n B   -0.145775  1.000000\n2016-04-09 A    1.000000  0.119645\n B    0.119645  1.000000\n\n[5 rows x 2 columns] \n```", "```py\nIn [87]: df.rolling(12).corr().loc['2016-04-07']\nOut[87]: \nbar        A        B\nbar \nA    1.00000 -0.13209\nB   -0.13209  1.00000\n\n[2 rows x 2 columns] \n```", "```py\nIn [88]: df = pd.DataFrame({'unparsed_date': ['2014-01-01', '2014-01-01']})\n\nIn [89]: df.to_hdf('store.h5', key='key', format='table', data_columns=True)\n\nIn [90]: df.dtypes\nOut[90]: \nunparsed_date    object\nLength: 1, dtype: object \n```", "```py\nIn [4]: pd.read_hdf('store.h5', 'key', where='unparsed_date > ts')\nFile \"<string>\", line 1\n (unparsed_date > 1970-01-01 00:00:01.388552400)\n ^\nSyntaxError: invalid token \n```", "```py\nIn [18]: ts = pd.Timestamp('2014-01-01')\n\nIn [19]: pd.read_hdf('store.h5', 'key', where='unparsed_date > ts')\nTypeError: Cannot compare 2014-01-01 00:00:00 of\ntype <class 'pandas.tslib.Timestamp'> to string column \n```", "```py\n    In [91]: left = pd.Index([2, 1, 0])\n\n    In [92]: left\n    Out[92]: Index([2, 1, 0], dtype='int64')\n\n    In [93]: right = pd.Index([1, 2, 3])\n\n    In [94]: right\n    Out[94]: Index([1, 2, 3], dtype='int64') \n    ```", "```py\n    In [4]: left.intersection(right)\n    Out[4]: Int64Index([1, 2], dtype='int64') \n    ```", "```py\n    In [95]: left.intersection(right)\n    Out[95]: Index([2, 1], dtype='int64') \n    ```", "```py\n    In [96]: left = pd.DataFrame({'a': [20, 10, 0]}, index=[2, 1, 0])\n\n    In [97]: left\n    Out[97]: \n     a\n    2  20\n    1  10\n    0   0\n\n    [3 rows x 1 columns]\n\n    In [98]: right = pd.DataFrame({'b': [100, 200, 300]}, index=[1, 2, 3])\n\n    In [99]: right\n    Out[99]: \n     b\n    1  100\n    2  200\n    3  300\n\n    [3 rows x 1 columns] \n    ```", "```py\n    In [4]: left.join(right, how='inner')\n    Out[4]:\n     a    b\n    1  10  100\n    2  20  200 \n    ```", "```py\n    In [100]: left.join(right, how='inner')\n    Out[100]: \n     a    b\n    2  20  200\n    1  10  100\n\n    [2 rows x 2 columns] \n    ```", "```py\nIn [101]: df = pd.DataFrame({'col1': [3, 4, 5],\n .....:                   'col2': ['C', 'D', 'E'],\n .....:                   'col3': [1, 3, 9]})\n .....: \n\nIn [102]: df\nOut[102]: \n col1 col2  col3\n0     3    C     1\n1     4    D     3\n2     5    E     9\n\n[3 rows x 3 columns] \n```", "```py\nIn [2]: df.pivot_table('col1', index=['col3', 'col2'], aggfunc=\"sum\")\nOut[2]:\ncol3  col2\n1     C       3\n3     D       4\n9     E       5\nName: col1, dtype: int64 \n```", "```py\nIn [103]: df.pivot_table('col1', index=['col3', 'col2'], aggfunc=\"sum\")\nOut[103]: \n col1\ncol3 col2 \n1    C        3\n3    D        4\n9    E        5\n\n[3 rows x 1 columns] \n```", "```py\n['DtypeWarning',\n 'EmptyDataError',\n 'OutOfBoundsDatetime',\n 'ParserError',\n 'ParserWarning',\n 'PerformanceWarning',\n 'UnsortedIndexError',\n 'UnsupportedFunctionCall'] \n```", "```py\nIn [104]: df = pd.DataFrame({'A': [1, 2, 3],\n .....:                   'B': [4, 5, 6]},\n .....:                  index=list('abc'))\n .....: \n\nIn [105]: df\nOut[105]: \n A  B\na  1  4\nb  2  5\nc  3  6\n\n[3 rows x 2 columns] \n```", "```py\nIn [3]: df.ix[[0, 2], 'A']\nOut[3]:\na    1\nc    3\nName: A, dtype: int64 \n```", "```py\nIn [106]: df.loc[df.index[[0, 2]], 'A']\nOut[106]: \na    1\nc    3\nName: A, Length: 2, dtype: int64 \n```", "```py\nIn [107]: df.iloc[[0, 2], df.columns.get_loc('A')]\nOut[107]: \na    1\nc    3\nName: A, Length: 2, dtype: int64 \n```", "```py\nIn [133]: import pandas._testing as tm\n\nIn [134]: p = tm.makePanel()\n\nIn [135]: p\nOut[135]:\n<class 'pandas.core.panel.Panel'>\nDimensions: 3 (items) x 3 (major_axis) x 4 (minor_axis)\nItems axis: ItemA to ItemC\nMajor_axis axis: 2000-01-03 00:00:00 to 2000-01-05 00:00:00\nMinor_axis axis: A to D \n```", "```py\nIn [136]: p.to_frame()\nOut[136]:\n ItemA     ItemB     ItemC\nmajor      minor\n2000-01-03 A      0.628776 -1.409432  0.209395\n B      0.988138 -1.347533 -0.896581\n C     -0.938153  1.272395 -0.161137\n D     -0.223019 -0.591863 -1.051539\n2000-01-04 A      0.186494  1.422986 -0.592886\n B     -0.072608  0.363565  1.104352\n C     -1.239072 -1.449567  0.889157\n D      2.123692 -0.414505 -0.319561\n2000-01-05 A      0.952478 -2.147855 -1.473116\n B     -0.550603 -0.014752 -0.431550\n C      0.139683 -1.195524  0.288377\n D      0.122273 -1.425795 -0.619993\n\n[12 rows x 3 columns] \n```", "```py\nIn [137]: p.to_xarray()\nOut[137]:\n<xarray.DataArray (items: 3, major_axis: 3, minor_axis: 4)>\narray([[[ 0.628776,  0.988138, -0.938153, -0.223019],\n [ 0.186494, -0.072608, -1.239072,  2.123692],\n [ 0.952478, -0.550603,  0.139683,  0.122273]],\n\n [[-1.409432, -1.347533,  1.272395, -0.591863],\n [ 1.422986,  0.363565, -1.449567, -0.414505],\n [-2.147855, -0.014752, -1.195524, -1.425795]],\n\n [[ 0.209395, -0.896581, -0.161137, -1.051539],\n [-0.592886,  1.104352,  0.889157, -0.319561],\n [-1.473116, -0.43155 ,  0.288377, -0.619993]]])\nCoordinates:\n * items       (items) object 'ItemA' 'ItemB' 'ItemC'\n * major_axis  (major_axis) datetime64[ns] 2000-01-03 2000-01-04 2000-01-05\n * minor_axis  (minor_axis) object 'A' 'B' 'C' 'D' \n```", "```py\nIn [108]: df = pd.DataFrame({'A': [1, 1, 1, 2, 2],\n .....:                   'B': range(5),\n .....:                   'C': range(5)})\n .....: \n\nIn [109]: df\nOut[109]: \n A  B  C\n0  1  0  0\n1  1  1  1\n2  1  2  2\n3  2  3  3\n4  2  4  4\n\n[5 rows x 3 columns] \n```", "```py\nIn [110]: df.groupby('A').agg({'B': 'sum', 'C': 'min'})\nOut[110]: \n B  C\nA \n1  3  0\n2  7  3\n\n[2 rows x 2 columns] \n```", "```py\nIn [6]: df.groupby('A').B.agg({'foo': 'count'})\nFutureWarning: using a dict on a Series for aggregation\nis deprecated and will be removed in a future version\n\nOut[6]:\n foo\nA\n1    3\n2    2 \n```", "```py\nIn [111]: df.groupby('A').B.agg(['count']).rename(columns={'count': 'foo'})\nOut[111]: \n foo\nA \n1    3\n2    2\n\n[2 rows x 1 columns] \n```", "```py\nIn [23]: (df.groupby('A')\n    ...:    .agg({'B': {'foo': 'sum'}, 'C': {'bar': 'min'}})\n    ...:  )\nFutureWarning: using a dict with renaming is deprecated and\nwill be removed in a future version\n\nOut[23]:\n     B   C\n   foo bar\nA\n1   3   0\n2   7   3 \n```", "```py\nIn [112]: (df.groupby('A')\n .....:   .agg({'B': 'sum', 'C': 'min'})\n .....:   .rename(columns={'B': 'foo', 'C': 'bar'})\n .....: )\n .....: \nOut[112]: \n foo  bar\nA \n1    3    0\n2    7    3\n\n[2 rows x 2 columns] \n```", "```py\npd.tools.plotting.scatter_matrix(df)\npd.scatter_matrix(df) \n```", "```py\npd.plotting.scatter_matrix(df) \n```", "```py\nIn [1]: df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n ...:                  index=pd.date_range('1/1/2000', periods=10))\n ...: \n\nIn [2]: df.iloc[3:7] = np.nan\n\nIn [3]: df\nOut[3]: \n A         B         C\n2000-01-01  0.469112 -0.282863 -1.509059\n2000-01-02 -1.135632  1.212112 -0.173215\n2000-01-03  0.119209 -1.044236 -0.861849\n2000-01-04       NaN       NaN       NaN\n2000-01-05       NaN       NaN       NaN\n2000-01-06       NaN       NaN       NaN\n2000-01-07       NaN       NaN       NaN\n2000-01-08  0.113648 -1.478427  0.524988\n2000-01-09  0.404705  0.577046 -1.715002\n2000-01-10 -1.039268 -0.370647 -1.157892\n\n[10 rows x 3 columns] \n```", "```py\nIn [4]: df.agg('sum')\nOut[4]: \nA   -1.068226\nB   -1.387015\nC   -4.892029\nLength: 3, dtype: float64 \n```", "```py\nIn [5]: df.agg(['sum', 'min'])\nOut[5]: \n A         B         C\nsum -1.068226 -1.387015 -4.892029\nmin -1.135632 -1.478427 -1.715002\n\n[2 rows x 3 columns] \n```", "```py\nIn [6]: df.agg({'A': ['sum', 'min'], 'B': ['min', 'max']})\nOut[6]: \n A         B\nsum -1.068226       NaN\nmin -1.135632 -1.478427\nmax       NaN  1.212112\n\n[3 rows x 2 columns] \n```", "```py\nIn [7]: df.transform(['abs', lambda x: x - x.min()])\nOut[7]: \n A                   B                   C \n abs  <lambda>       abs  <lambda>       abs  <lambda>\n2000-01-01  0.469112  1.604745  0.282863  1.195563  1.509059  0.205944\n2000-01-02  1.135632  0.000000  1.212112  2.690539  0.173215  1.541787\n2000-01-03  0.119209  1.254841  1.044236  0.434191  0.861849  0.853153\n2000-01-04       NaN       NaN       NaN       NaN       NaN       NaN\n2000-01-05       NaN       NaN       NaN       NaN       NaN       NaN\n2000-01-06       NaN       NaN       NaN       NaN       NaN       NaN\n2000-01-07       NaN       NaN       NaN       NaN       NaN       NaN\n2000-01-08  0.113648  1.249281  1.478427  0.000000  0.524988  2.239990\n2000-01-09  0.404705  1.540338  0.577046  2.055473  1.715002  0.000000\n2000-01-10  1.039268  0.096364  0.370647  1.107780  1.157892  0.557110\n\n[10 rows x 6 columns] \n```", "```py\nIn [8]: df = pd.DataFrame({'A': [1, 2, 3],\n ...:                   'B': [1., 2., 3.],\n ...:                   'C': ['foo', 'bar', 'baz'],\n ...:                   'D': pd.date_range('20130101', periods=3)})\n ...: \n\nIn [9]: df.dtypes\nOut[9]: \nA             int64\nB           float64\nC            object\nD    datetime64[ns]\nLength: 4, dtype: object \n```", "```py\nIn [10]: df.agg(['min', 'sum'])\nOut[10]:\n     A    B          C          D\nmin  1  1.0        bar 2013-01-01\nsum  6  6.0  foobarbaz        NaT \n```", "```py\nIn [10]: data = \"a  b\\n1  2\\n3  4\"\n\nIn [11]: pd.read_fwf(StringIO(data)).dtypes\nOut[11]: \na    int64\nb    int64\nLength: 2, dtype: object\n\nIn [12]: pd.read_fwf(StringIO(data), dtype={'a': 'float64', 'b': 'object'}).dtypes\nOut[12]: \na    float64\nb     object\nLength: 2, dtype: object \n```", "```py\nIn [13]: pd.to_datetime([1, 2, 3], unit='D', origin=pd.Timestamp('1960-01-01'))\nOut[13]: DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [14]: pd.to_datetime([1, 2, 3], unit='D')\nOut[14]: DatetimeIndex(['1970-01-02', '1970-01-03', '1970-01-04'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [15]: arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n ....:          ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n ....: \n\nIn [16]: index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])\n\nIn [17]: df = pd.DataFrame({'A': [1, 1, 1, 1, 2, 2, 3, 3],\n ....:                   'B': np.arange(8)},\n ....:                  index=index)\n ....: \n\nIn [18]: df\nOut[18]: \n A  B\nfirst second \nbar   one     1  0\n two     1  1\nbaz   one     1  2\n two     1  3\nfoo   one     2  4\n two     2  5\nqux   one     3  6\n two     3  7\n\n[8 rows x 2 columns]\n\nIn [19]: df.groupby(['second', 'A']).sum()\nOut[19]: \n B\nsecond A \none    1  2\n 2  4\n 3  6\ntwo    1  4\n 2  5\n 3  7\n\n[6 rows x 1 columns] \n```", "```py\nIn [20]: url = ('https://github.com/{repo}/raw/{branch}/{path}'\n ....:       .format(repo='pandas-dev/pandas',\n ....:               branch='main',\n ....:               path='pandas/tests/io/parser/data/salaries.csv.bz2'))\n ....: \n\n# default, infer compression\nIn [21]: df = pd.read_csv(url, sep='\\t', compression='infer')\n\n# explicitly specify compression\nIn [22]: df = pd.read_csv(url, sep='\\t', compression='bz2')\n\nIn [23]: df.head(2)\nOut[23]: \n S  X  E  M\n0  13876  1  1  1\n1  11608  1  3  0\n\n[2 rows x 4 columns] \n```", "```py\nIn [24]: df = pd.DataFrame({'A': np.random.randn(1000),\n ....:                   'B': 'foo',\n ....:                   'C': pd.date_range('20130101', periods=1000, freq='s')})\n ....: \n```", "```py\nIn [25]: df.to_pickle(\"data.pkl.compress\", compression=\"gzip\")\n\nIn [26]: rt = pd.read_pickle(\"data.pkl.compress\", compression=\"gzip\")\n\nIn [27]: rt.head()\nOut[27]: \n A    B                   C\n0 -1.344312  foo 2013-01-01 00:00:00\n1  0.844885  foo 2013-01-01 00:00:01\n2  1.075770  foo 2013-01-01 00:00:02\n3 -0.109050  foo 2013-01-01 00:00:03\n4  1.643563  foo 2013-01-01 00:00:04\n\n[5 rows x 3 columns] \n```", "```py\nIn [28]: df.to_pickle(\"data.pkl.gz\")\n\nIn [29]: rt = pd.read_pickle(\"data.pkl.gz\")\n\nIn [30]: rt.head()\nOut[30]: \n A    B                   C\n0 -1.344312  foo 2013-01-01 00:00:00\n1  0.844885  foo 2013-01-01 00:00:01\n2  1.075770  foo 2013-01-01 00:00:02\n3 -0.109050  foo 2013-01-01 00:00:03\n4  1.643563  foo 2013-01-01 00:00:04\n\n[5 rows x 3 columns]\n\nIn [31]: df[\"A\"].to_pickle(\"s1.pkl.bz2\")\n\nIn [32]: rt = pd.read_pickle(\"s1.pkl.bz2\")\n\nIn [33]: rt.head()\nOut[33]: \n0   -1.344312\n1    0.844885\n2    1.075770\n3   -0.109050\n4    1.643563\nName: A, Length: 5, dtype: float64 \n```", "```py\nIn [1]: idx = pd.UInt64Index([1, 2, 3])\nIn [2]: df = pd.DataFrame({'A': ['a', 'b', 'c']}, index=idx)\nIn [3]: df.index\nOut[3]: UInt64Index([1, 2, 3], dtype='uint64') \n```", "```py\nIn [34]: chromosomes = np.r_[np.arange(1, 23).astype(str), ['X', 'Y']]\n\nIn [35]: df = pd.DataFrame({\n ....:    'A': np.random.randint(100),\n ....:    'B': np.random.randint(100),\n ....:    'C': np.random.randint(100),\n ....:    'chromosomes': pd.Categorical(np.random.choice(chromosomes, 100),\n ....:                                  categories=chromosomes,\n ....:                                  ordered=True)})\n ....: \n\nIn [36]: df\nOut[36]: \n A   B   C chromosomes\n0   87  22  81           4\n1   87  22  81          13\n2   87  22  81          22\n3   87  22  81           2\n4   87  22  81           6\n..  ..  ..  ..         ...\n95  87  22  81           8\n96  87  22  81          11\n97  87  22  81           X\n98  87  22  81           1\n99  87  22  81          19\n\n[100 rows x 4 columns] \n```", "```py\nIn [3]: df[df.chromosomes != '1'].groupby('chromosomes', observed=False, sort=False).sum()\n---------------------------------------------------------------------------\nValueError: items in new_categories are not the same as in old categories \n```", "```py\nIn [37]: df[df.chromosomes != '1'].groupby('chromosomes', observed=False, sort=False).sum()\nOut[37]: \n A   B    C\nchromosomes \n4            348  88  324\n13           261  66  243\n22           348  88  324\n2            348  88  324\n6            174  44  162\n...          ...  ..  ...\n3            348  88  324\n11           348  88  324\n19           174  44  162\n1              0   0    0\n21             0   0    0\n\n[24 rows x 3 columns] \n```", "```py\nIn [38]: df = pd.DataFrame(\n ....:    {'A': [1, 2, 3],\n ....:     'B': ['a', 'b', 'c'],\n ....:     'C': pd.date_range('2016-01-01', freq='d', periods=3)},\n ....:    index=pd.Index(range(3), name='idx'))\n ....: \n\nIn [39]: df\nOut[39]: \n A  B          C\nidx \n0    1  a 2016-01-01\n1    2  b 2016-01-02\n2    3  c 2016-01-03\n\n[3 rows x 3 columns]\n\nIn [40]: df.to_json(orient='table')\nOut[40]: '{\"schema\":{\"fields\":[{\"name\":\"idx\",\"type\":\"integer\"},{\"name\":\"A\",\"type\":\"integer\"},{\"name\":\"B\",\"type\":\"string\"},{\"name\":\"C\",\"type\":\"datetime\"}],\"primaryKey\":[\"idx\"],\"pandas_version\":\"1.4.0\"},\"data\":[{\"idx\":0,\"A\":1,\"B\":\"a\",\"C\":\"2016-01-01T00:00:00.000\"},{\"idx\":1,\"A\":2,\"B\":\"b\",\"C\":\"2016-01-02T00:00:00.000\"},{\"idx\":2,\"A\":3,\"B\":\"c\",\"C\":\"2016-01-03T00:00:00.000\"}]}' \n```", "```py\nfrom scipy.sparse import csr_matrix\narr = np.random.random(size=(1000, 5))\narr[arr < .9] = 0\nsp_arr = csr_matrix(arr)\nsp_arr\nsdf = pd.SparseDataFrame(sp_arr)\nsdf \n```", "```py\nsdf.to_coo() \n```", "```py\nIn [41]: np.random.seed(24)\n\nIn [42]: df = pd.DataFrame({'A': np.linspace(1, 10, 10)})\n\nIn [43]: df = pd.concat([df, pd.DataFrame(np.random.RandomState(24).randn(10, 4),\n ....:                                 columns=list('BCDE'))],\n ....:               axis=1)\n ....: \n\nIn [44]: df.iloc[0, 2] = np.nan\n\nIn [45]: df\nOut[45]: \n A         B         C         D         E\n0   1.0  1.329212       NaN -0.316280 -0.990810\n1   2.0 -1.070816 -1.438713  0.564417  0.295722\n2   3.0 -1.626404  0.219565  0.678805  1.889273\n3   4.0  0.961538  0.104011 -0.481165  0.850229\n4   5.0  1.453425  1.057737  0.165562  0.515018\n5   6.0 -1.336936  0.562861  1.392855 -0.063328\n6   7.0  0.121668  1.207603 -0.002040  1.627796\n7   8.0  0.354493  1.037528 -0.385684  0.519818\n8   9.0  1.686583 -1.325963  1.428984 -2.089354\n9  10.0 -0.129820  0.631523 -0.586538  0.290720\n\n[10 rows x 5 columns]\n\nIn [46]: styled = (df.style\n ....:          .applymap(lambda val: 'color:red;' if val < 0 else 'color:black;')\n ....:          .highlight_max())\n ....: \n\nIn [47]: styled.to_excel('styled.xlsx', engine='openpyxl') \n```", "```py\nIn [1]: c = pd.cut(range(4), bins=2)\n\nIn [2]: c\nOut[2]:\n[(-0.003, 1.5], (-0.003, 1.5], (1.5, 3], (1.5, 3]]\nCategories (2, object): [(-0.003, 1.5] < (1.5, 3]]\n\nIn [3]: c.categories\nOut[3]: Index(['(-0.003, 1.5]', '(1.5, 3]'], dtype='object') \n```", "```py\nIn [48]: c = pd.cut(range(4), bins=2)\n\nIn [49]: c\nOut[49]: \n[(-0.003, 1.5], (-0.003, 1.5], (1.5, 3.0], (1.5, 3.0]]\nCategories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]]\n\nIn [50]: c.categories\nOut[50]: IntervalIndex([(-0.003, 1.5], (1.5, 3.0]], dtype='interval[float64, right]') \n```", "```py\nIn [51]: pd.cut([0, 3, 5, 1], bins=c.categories)\nOut[51]: \n[(-0.003, 1.5], (1.5, 3.0], NaN, (-0.003, 1.5]]\nCategories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]] \n```", "```py\nIn [52]: df = pd.DataFrame({'A': range(4),\n ....:                   'B': pd.cut([0, 3, 1, 1], bins=c.categories)\n ....:                   }).set_index('B')\n ....: \n\nIn [53]: df\nOut[53]: \n A\nB \n(-0.003, 1.5]  0\n(1.5, 3.0]     1\n(-0.003, 1.5]  2\n(-0.003, 1.5]  3\n\n[4 rows x 1 columns] \n```", "```py\nIn [54]: df.loc[pd.Interval(1.5, 3.0)]\nOut[54]: \nA    1\nName: (1.5, 3.0], Length: 1, dtype: int64 \n```", "```py\nIn [55]: df.loc[0]\nOut[55]: \n A\nB \n(-0.003, 1.5]  0\n(-0.003, 1.5]  2\n(-0.003, 1.5]  3\n\n[3 rows x 1 columns] \n```", "```py\nIn [1]: df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n ...:                  index=pd.date_range('1/1/2000', periods=10))\n ...: \n\nIn [2]: df.iloc[3:7] = np.nan\n\nIn [3]: df\nOut[3]: \n A         B         C\n2000-01-01  0.469112 -0.282863 -1.509059\n2000-01-02 -1.135632  1.212112 -0.173215\n2000-01-03  0.119209 -1.044236 -0.861849\n2000-01-04       NaN       NaN       NaN\n2000-01-05       NaN       NaN       NaN\n2000-01-06       NaN       NaN       NaN\n2000-01-07       NaN       NaN       NaN\n2000-01-08  0.113648 -1.478427  0.524988\n2000-01-09  0.404705  0.577046 -1.715002\n2000-01-10 -1.039268 -0.370647 -1.157892\n\n[10 rows x 3 columns] \n```", "```py\nIn [4]: df.agg('sum')\nOut[4]: \nA   -1.068226\nB   -1.387015\nC   -4.892029\nLength: 3, dtype: float64 \n```", "```py\nIn [5]: df.agg(['sum', 'min'])\nOut[5]: \n A         B         C\nsum -1.068226 -1.387015 -4.892029\nmin -1.135632 -1.478427 -1.715002\n\n[2 rows x 3 columns] \n```", "```py\nIn [6]: df.agg({'A': ['sum', 'min'], 'B': ['min', 'max']})\nOut[6]: \n A         B\nsum -1.068226       NaN\nmin -1.135632 -1.478427\nmax       NaN  1.212112\n\n[3 rows x 2 columns] \n```", "```py\nIn [7]: df.transform(['abs', lambda x: x - x.min()])\nOut[7]: \n A                   B                   C \n abs  <lambda>       abs  <lambda>       abs  <lambda>\n2000-01-01  0.469112  1.604745  0.282863  1.195563  1.509059  0.205944\n2000-01-02  1.135632  0.000000  1.212112  2.690539  0.173215  1.541787\n2000-01-03  0.119209  1.254841  1.044236  0.434191  0.861849  0.853153\n2000-01-04       NaN       NaN       NaN       NaN       NaN       NaN\n2000-01-05       NaN       NaN       NaN       NaN       NaN       NaN\n2000-01-06       NaN       NaN       NaN       NaN       NaN       NaN\n2000-01-07       NaN       NaN       NaN       NaN       NaN       NaN\n2000-01-08  0.113648  1.249281  1.478427  0.000000  0.524988  2.239990\n2000-01-09  0.404705  1.540338  0.577046  2.055473  1.715002  0.000000\n2000-01-10  1.039268  0.096364  0.370647  1.107780  1.157892  0.557110\n\n[10 rows x 6 columns] \n```", "```py\nIn [8]: df = pd.DataFrame({'A': [1, 2, 3],\n ...:                   'B': [1., 2., 3.],\n ...:                   'C': ['foo', 'bar', 'baz'],\n ...:                   'D': pd.date_range('20130101', periods=3)})\n ...: \n\nIn [9]: df.dtypes\nOut[9]: \nA             int64\nB           float64\nC            object\nD    datetime64[ns]\nLength: 4, dtype: object \n```", "```py\nIn [10]: df.agg(['min', 'sum'])\nOut[10]:\n     A    B          C          D\nmin  1  1.0        bar 2013-01-01\nsum  6  6.0  foobarbaz        NaT \n```", "```py\nIn [10]: data = \"a  b\\n1  2\\n3  4\"\n\nIn [11]: pd.read_fwf(StringIO(data)).dtypes\nOut[11]: \na    int64\nb    int64\nLength: 2, dtype: object\n\nIn [12]: pd.read_fwf(StringIO(data), dtype={'a': 'float64', 'b': 'object'}).dtypes\nOut[12]: \na    float64\nb     object\nLength: 2, dtype: object \n```", "```py\nIn [13]: pd.to_datetime([1, 2, 3], unit='D', origin=pd.Timestamp('1960-01-01'))\nOut[13]: DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [14]: pd.to_datetime([1, 2, 3], unit='D')\nOut[14]: DatetimeIndex(['1970-01-02', '1970-01-03', '1970-01-04'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [15]: arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n ....:          ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n ....: \n\nIn [16]: index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])\n\nIn [17]: df = pd.DataFrame({'A': [1, 1, 1, 1, 2, 2, 3, 3],\n ....:                   'B': np.arange(8)},\n ....:                  index=index)\n ....: \n\nIn [18]: df\nOut[18]: \n A  B\nfirst second \nbar   one     1  0\n two     1  1\nbaz   one     1  2\n two     1  3\nfoo   one     2  4\n two     2  5\nqux   one     3  6\n two     3  7\n\n[8 rows x 2 columns]\n\nIn [19]: df.groupby(['second', 'A']).sum()\nOut[19]: \n B\nsecond A \none    1  2\n 2  4\n 3  6\ntwo    1  4\n 2  5\n 3  7\n\n[6 rows x 1 columns] \n```", "```py\nIn [20]: url = ('https://github.com/{repo}/raw/{branch}/{path}'\n ....:       .format(repo='pandas-dev/pandas',\n ....:               branch='main',\n ....:               path='pandas/tests/io/parser/data/salaries.csv.bz2'))\n ....: \n\n# default, infer compression\nIn [21]: df = pd.read_csv(url, sep='\\t', compression='infer')\n\n# explicitly specify compression\nIn [22]: df = pd.read_csv(url, sep='\\t', compression='bz2')\n\nIn [23]: df.head(2)\nOut[23]: \n S  X  E  M\n0  13876  1  1  1\n1  11608  1  3  0\n\n[2 rows x 4 columns] \n```", "```py\nIn [24]: df = pd.DataFrame({'A': np.random.randn(1000),\n ....:                   'B': 'foo',\n ....:                   'C': pd.date_range('20130101', periods=1000, freq='s')})\n ....: \n```", "```py\nIn [25]: df.to_pickle(\"data.pkl.compress\", compression=\"gzip\")\n\nIn [26]: rt = pd.read_pickle(\"data.pkl.compress\", compression=\"gzip\")\n\nIn [27]: rt.head()\nOut[27]: \n A    B                   C\n0 -1.344312  foo 2013-01-01 00:00:00\n1  0.844885  foo 2013-01-01 00:00:01\n2  1.075770  foo 2013-01-01 00:00:02\n3 -0.109050  foo 2013-01-01 00:00:03\n4  1.643563  foo 2013-01-01 00:00:04\n\n[5 rows x 3 columns] \n```", "```py\nIn [28]: df.to_pickle(\"data.pkl.gz\")\n\nIn [29]: rt = pd.read_pickle(\"data.pkl.gz\")\n\nIn [30]: rt.head()\nOut[30]: \n A    B                   C\n0 -1.344312  foo 2013-01-01 00:00:00\n1  0.844885  foo 2013-01-01 00:00:01\n2  1.075770  foo 2013-01-01 00:00:02\n3 -0.109050  foo 2013-01-01 00:00:03\n4  1.643563  foo 2013-01-01 00:00:04\n\n[5 rows x 3 columns]\n\nIn [31]: df[\"A\"].to_pickle(\"s1.pkl.bz2\")\n\nIn [32]: rt = pd.read_pickle(\"s1.pkl.bz2\")\n\nIn [33]: rt.head()\nOut[33]: \n0   -1.344312\n1    0.844885\n2    1.075770\n3   -0.109050\n4    1.643563\nName: A, Length: 5, dtype: float64 \n```", "```py\nIn [1]: idx = pd.UInt64Index([1, 2, 3])\nIn [2]: df = pd.DataFrame({'A': ['a', 'b', 'c']}, index=idx)\nIn [3]: df.index\nOut[3]: UInt64Index([1, 2, 3], dtype='uint64') \n```", "```py\nIn [34]: chromosomes = np.r_[np.arange(1, 23).astype(str), ['X', 'Y']]\n\nIn [35]: df = pd.DataFrame({\n ....:    'A': np.random.randint(100),\n ....:    'B': np.random.randint(100),\n ....:    'C': np.random.randint(100),\n ....:    'chromosomes': pd.Categorical(np.random.choice(chromosomes, 100),\n ....:                                  categories=chromosomes,\n ....:                                  ordered=True)})\n ....: \n\nIn [36]: df\nOut[36]: \n A   B   C chromosomes\n0   87  22  81           4\n1   87  22  81          13\n2   87  22  81          22\n3   87  22  81           2\n4   87  22  81           6\n..  ..  ..  ..         ...\n95  87  22  81           8\n96  87  22  81          11\n97  87  22  81           X\n98  87  22  81           1\n99  87  22  81          19\n\n[100 rows x 4 columns] \n```", "```py\nIn [3]: df[df.chromosomes != '1'].groupby('chromosomes', observed=False, sort=False).sum()\n---------------------------------------------------------------------------\nValueError: items in new_categories are not the same as in old categories \n```", "```py\nIn [37]: df[df.chromosomes != '1'].groupby('chromosomes', observed=False, sort=False).sum()\nOut[37]: \n A   B    C\nchromosomes \n4            348  88  324\n13           261  66  243\n22           348  88  324\n2            348  88  324\n6            174  44  162\n...          ...  ..  ...\n3            348  88  324\n11           348  88  324\n19           174  44  162\n1              0   0    0\n21             0   0    0\n\n[24 rows x 3 columns] \n```", "```py\nIn [38]: df = pd.DataFrame(\n ....:    {'A': [1, 2, 3],\n ....:     'B': ['a', 'b', 'c'],\n ....:     'C': pd.date_range('2016-01-01', freq='d', periods=3)},\n ....:    index=pd.Index(range(3), name='idx'))\n ....: \n\nIn [39]: df\nOut[39]: \n A  B          C\nidx \n0    1  a 2016-01-01\n1    2  b 2016-01-02\n2    3  c 2016-01-03\n\n[3 rows x 3 columns]\n\nIn [40]: df.to_json(orient='table')\nOut[40]: '{\"schema\":{\"fields\":[{\"name\":\"idx\",\"type\":\"integer\"},{\"name\":\"A\",\"type\":\"integer\"},{\"name\":\"B\",\"type\":\"string\"},{\"name\":\"C\",\"type\":\"datetime\"}],\"primaryKey\":[\"idx\"],\"pandas_version\":\"1.4.0\"},\"data\":[{\"idx\":0,\"A\":1,\"B\":\"a\",\"C\":\"2016-01-01T00:00:00.000\"},{\"idx\":1,\"A\":2,\"B\":\"b\",\"C\":\"2016-01-02T00:00:00.000\"},{\"idx\":2,\"A\":3,\"B\":\"c\",\"C\":\"2016-01-03T00:00:00.000\"}]}' \n```", "```py\nfrom scipy.sparse import csr_matrix\narr = np.random.random(size=(1000, 5))\narr[arr < .9] = 0\nsp_arr = csr_matrix(arr)\nsp_arr\nsdf = pd.SparseDataFrame(sp_arr)\nsdf \n```", "```py\nsdf.to_coo() \n```", "```py\nIn [41]: np.random.seed(24)\n\nIn [42]: df = pd.DataFrame({'A': np.linspace(1, 10, 10)})\n\nIn [43]: df = pd.concat([df, pd.DataFrame(np.random.RandomState(24).randn(10, 4),\n ....:                                 columns=list('BCDE'))],\n ....:               axis=1)\n ....: \n\nIn [44]: df.iloc[0, 2] = np.nan\n\nIn [45]: df\nOut[45]: \n A         B         C         D         E\n0   1.0  1.329212       NaN -0.316280 -0.990810\n1   2.0 -1.070816 -1.438713  0.564417  0.295722\n2   3.0 -1.626404  0.219565  0.678805  1.889273\n3   4.0  0.961538  0.104011 -0.481165  0.850229\n4   5.0  1.453425  1.057737  0.165562  0.515018\n5   6.0 -1.336936  0.562861  1.392855 -0.063328\n6   7.0  0.121668  1.207603 -0.002040  1.627796\n7   8.0  0.354493  1.037528 -0.385684  0.519818\n8   9.0  1.686583 -1.325963  1.428984 -2.089354\n9  10.0 -0.129820  0.631523 -0.586538  0.290720\n\n[10 rows x 5 columns]\n\nIn [46]: styled = (df.style\n ....:          .applymap(lambda val: 'color:red;' if val < 0 else 'color:black;')\n ....:          .highlight_max())\n ....: \n\nIn [47]: styled.to_excel('styled.xlsx', engine='openpyxl') \n```", "```py\nIn [1]: c = pd.cut(range(4), bins=2)\n\nIn [2]: c\nOut[2]:\n[(-0.003, 1.5], (-0.003, 1.5], (1.5, 3], (1.5, 3]]\nCategories (2, object): [(-0.003, 1.5] < (1.5, 3]]\n\nIn [3]: c.categories\nOut[3]: Index(['(-0.003, 1.5]', '(1.5, 3]'], dtype='object') \n```", "```py\nIn [48]: c = pd.cut(range(4), bins=2)\n\nIn [49]: c\nOut[49]: \n[(-0.003, 1.5], (-0.003, 1.5], (1.5, 3.0], (1.5, 3.0]]\nCategories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]]\n\nIn [50]: c.categories\nOut[50]: IntervalIndex([(-0.003, 1.5], (1.5, 3.0]], dtype='interval[float64, right]') \n```", "```py\nIn [51]: pd.cut([0, 3, 5, 1], bins=c.categories)\nOut[51]: \n[(-0.003, 1.5], (1.5, 3.0], NaN, (-0.003, 1.5]]\nCategories (2, interval[float64, right]): [(-0.003, 1.5] < (1.5, 3.0]] \n```", "```py\nIn [52]: df = pd.DataFrame({'A': range(4),\n ....:                   'B': pd.cut([0, 3, 1, 1], bins=c.categories)\n ....:                   }).set_index('B')\n ....: \n\nIn [53]: df\nOut[53]: \n A\nB \n(-0.003, 1.5]  0\n(1.5, 3.0]     1\n(-0.003, 1.5]  2\n(-0.003, 1.5]  3\n\n[4 rows x 1 columns] \n```", "```py\nIn [54]: df.loc[pd.Interval(1.5, 3.0)]\nOut[54]: \nA    1\nName: (1.5, 3.0], Length: 1, dtype: int64 \n```", "```py\nIn [55]: df.loc[0]\nOut[55]: \n A\nB \n(-0.003, 1.5]  0\n(-0.003, 1.5]  2\n(-0.003, 1.5]  3\n\n[3 rows x 1 columns] \n```", "```py\nIn [2]: s = pd.TimeSeries([1, 2, 3], index=pd.date_range('20130101', periods=3))\n\nIn [3]: s\nOut[3]:\n2013-01-01    1\n2013-01-02    2\n2013-01-03    3\nFreq: D, dtype: int64\n\nIn [4]: type(s)\nOut[4]: pandas.core.series.TimeSeries\n\nIn [5]: s = pd.Series(s)\n\nIn [6]: s\nOut[6]:\n2013-01-01    1\n2013-01-02    2\n2013-01-03    3\nFreq: D, dtype: int64\n\nIn [7]: type(s)\nOut[7]: pandas.core.series.Series \n```", "```py\nIn [56]: idx = pd.Index([1, 2])\n\nIn [57]: idx\nOut[57]: Index([1, 2], dtype='int64')\n\nIn [58]: mi = pd.MultiIndex.from_tuples([(1, 2), (2, 4)])\n\nIn [59]: mi\nOut[59]: \nMultiIndex([(1, 2),\n (2, 4)],\n ) \n```", "```py\nIn [5]: idx.map(lambda x: x * 2)\nOut[5]: array([2, 4])\n\nIn [6]: idx.map(lambda x: (x, x * 2))\nOut[6]: array([(1, 2), (2, 4)], dtype=object)\n\nIn [7]: mi.map(lambda x: x)\nOut[7]: array([(1, 2), (2, 4)], dtype=object)\n\nIn [8]: mi.map(lambda x: x[0])\nOut[8]: array([1, 2]) \n```", "```py\nIn [60]: idx.map(lambda x: x * 2)\nOut[60]: Index([2, 4], dtype='int64')\n\nIn [61]: idx.map(lambda x: (x, x * 2))\nOut[61]: \nMultiIndex([(1, 2),\n (2, 4)],\n )\n\nIn [62]: mi.map(lambda x: x)\nOut[62]: \nMultiIndex([(1, 2),\n (2, 4)],\n )\n\nIn [63]: mi.map(lambda x: x[0])\nOut[63]: Index([1, 2], dtype='int64') \n```", "```py\nIn [64]: s = pd.Series(pd.date_range('2011-01-02T00:00', '2011-01-02T02:00', freq='H')\n ....:              .tz_localize('Asia/Tokyo'))\n ....:\n\nIn [65]: s\nOut[65]:\n0   2011-01-02 00:00:00+09:00\n1   2011-01-02 01:00:00+09:00\n2   2011-01-02 02:00:00+09:00\nLength: 3, dtype: datetime64[ns, Asia/Tokyo] \n```", "```py\nIn [9]: s.map(lambda x: x.hour)\nOut[9]:\n0    0\n1    1\n2    2\ndtype: int32 \n```", "```py\nIn [66]: s.map(lambda x: x.hour)\nOut[66]:\n0    0\n1    1\n2    2\nLength: 3, dtype: int64 \n```", "```py\nIn [1]: idx = pd.date_range(\"2015-01-01\", periods=5, freq='10H')\n\nIn [2]: idx.hour\nOut[2]: array([ 0, 10, 20,  6, 16], dtype=int32) \n```", "```py\nIn [67]: idx = pd.date_range(\"2015-01-01\", periods=5, freq='10H')\n\nIn [68]: idx.hour\nOut[68]: Index([0, 10, 20, 6, 16], dtype='int32') \n```", "```py\n    # Series\n    In [5]: pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n     ...:           pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n    Out[5]: array([Timestamp('2016-01-01 00:00:00-0500', tz='US/Eastern')], dtype=object)\n\n    In [6]: pd.unique(pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n     ...:                     pd.Timestamp('20160101', tz='US/Eastern')]))\n    Out[6]: array(['2016-01-01T05:00:00.000000000'], dtype='datetime64[ns]')\n\n    # Index\n    In [7]: pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n     ...:          pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n    Out[7]: DatetimeIndex(['2016-01-01 00:00:00-05:00'], dtype='datetime64[ns, US/Eastern]', freq=None)\n\n    In [8]: pd.unique([pd.Timestamp('20160101', tz='US/Eastern'),\n     ...:           pd.Timestamp('20160101', tz='US/Eastern')])\n    Out[8]: array(['2016-01-01T05:00:00.000000000'], dtype='datetime64[ns]') \n    ```", "```py\n    # Series, returns an array of Timestamp tz-aware\n    In [64]: pd.Series([pd.Timestamp(r'20160101', tz=r'US/Eastern'),\n     ....:           pd.Timestamp(r'20160101', tz=r'US/Eastern')]).unique()\n     ....: \n    Out[64]: \n    <DatetimeArray>\n    ['2016-01-01 00:00:00-05:00']\n    Length: 1, dtype: datetime64[ns, US/Eastern]\n\n    In [65]: pd.unique(pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n     ....:          pd.Timestamp('20160101', tz='US/Eastern')]))\n     ....: \n    Out[65]: \n    <DatetimeArray>\n    ['2016-01-01 00:00:00-05:00']\n    Length: 1, dtype: datetime64[ns, US/Eastern]\n\n    # Index, returns a DatetimeIndex\n    In [66]: pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n     ....:          pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n     ....: \n    Out[66]: DatetimeIndex(['2016-01-01 00:00:00-05:00'], dtype='datetime64[ns, US/Eastern]', freq=None)\n\n    In [67]: pd.unique(pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n     ....:                    pd.Timestamp('20160101', tz='US/Eastern')]))\n     ....: \n    Out[67]: DatetimeIndex(['2016-01-01 00:00:00-05:00'], dtype='datetime64[ns, US/Eastern]', freq=None) \n    ```", "```py\n    In [1]: pd.Series(list('baabc'), dtype='category').unique()\n    Out[1]:\n    [b, a, c]\n    Categories (3, object): [b, a, c]\n\n    In [2]: pd.unique(pd.Series(list('baabc'), dtype='category'))\n    Out[2]: array(['b', 'a', 'c'], dtype=object) \n    ```", "```py\n    # returns a Categorical\n    In [68]: pd.Series(list('baabc'), dtype='category').unique()\n    Out[68]: \n    ['b', 'a', 'c']\n    Categories (3, object): ['a', 'b', 'c']\n\n    In [69]: pd.unique(pd.Series(list('baabc'), dtype='category'))\n    Out[69]: \n    ['b', 'a', 'c']\n    Categories (3, object): ['a', 'b', 'c'] \n    ```", "```py\nIn [70]: df = pd.DataFrame({'a': [1, 2, 3]}, pd.DatetimeIndex(['2011-12-31 23:59:59',\n ....:                                                      '2012-01-01 00:00:00',\n ....:                                                      '2012-01-01 00:00:01']))\n ....: \n```", "```py\nIn [4]: df['2011-12-31 23:59:59']\nOut[4]:\n a\n2011-12-31 23:59:59  1\n\nIn [5]: df['a']['2011-12-31 23:59:59']\nOut[5]:\n2011-12-31 23:59:59    1\nName: a, dtype: int64 \n```", "```py\nIn [4]: df['2011-12-31 23:59:59']\nKeyError: '2011-12-31 23:59:59'\n\nIn [5]: df['a']['2011-12-31 23:59:59']\nOut[5]: 1 \n```", "```py\nIn [71]: df1 = pd.DataFrame(np.array([1.0], dtype=np.float32, ndmin=2))\n\nIn [72]: df1.dtypes\nOut[72]: \n0    float32\nLength: 1, dtype: object\n\nIn [73]: df2 = pd.DataFrame(np.array([np.nan], dtype=np.float32, ndmin=2))\n\nIn [74]: df2.dtypes\nOut[74]: \n0    float32\nLength: 1, dtype: object \n```", "```py\nIn [7]: pd.concat([df1, df2]).dtypes\nOut[7]:\n0    float64\ndtype: object \n```", "```py\nIn [75]: pd.concat([df1, df2]).dtypes\nOut[75]: \n0    float32\nLength: 1, dtype: object \n```", "```py\nIn [8]: index = pd.Index(['foo', 'bar', 'baz'])\n\nIn [9]: index.memory_usage(deep=True)\nOut[9]: 180\n\nIn [10]: index.get_loc('foo')\nOut[10]: 0\n\nIn [11]: index.memory_usage(deep=True)\nOut[11]: 180 \n```", "```py\nIn [8]: index = pd.Index(['foo', 'bar', 'baz'])\n\nIn [9]: index.memory_usage(deep=True)\nOut[9]: 180\n\nIn [10]: index.get_loc('foo')\nOut[10]: 0\n\nIn [11]: index.memory_usage(deep=True)\nOut[11]: 260 \n```", "```py\nIn [81]: df = pd.DataFrame(np.arange(6), columns=['value'],\n   ....:                   index=pd.MultiIndex.from_product([list('BA'), range(3)]))\n   ....:\nIn [82]: df\n\nOut[82]:\n     value\nB 0      0\n  1      1\n  2      2\nA 0      3\n  1      4\n  2      5\n\n[6 rows x 1 columns] \n```", "```py\nIn [87]: df.index.is_lexsorted()\nOut[87]: False\n\nIn [88]: df.index.is_monotonic\nOut[88]: False \n```", "```py\nIn [76]: df.sort_index()\nOut[76]: \n a\n2011-12-31 23:59:59  1\n2012-01-01 00:00:00  2\n2012-01-01 00:00:01  3\n\n[3 rows x 1 columns] \n```", "```py\nIn [90]: df.sort_index().index.is_lexsorted()\nOut[90]: True\n\nIn [91]: df.sort_index().index.is_monotonic\nOut[91]: True \n```", "```py\nIn [77]: df = pd.DataFrame({'value': [1, 2, 3, 4]},\n ....:                  index=pd.MultiIndex([['a', 'b'], ['bb', 'aa']],\n ....:                                      [[0, 0, 1, 1], [0, 1, 0, 1]]))\n ....: \n\nIn [78]: df\nOut[78]: \n value\na bb      1\n aa      2\nb bb      3\n aa      4\n\n[4 rows x 1 columns] \n```", "```py\nIn [11]: df.sort_index()\nOut[11]:\n      value\na bb      1\n  aa      2\nb bb      3\n  aa      4\n\nIn [14]: df.sort_index().index.is_lexsorted()\nOut[14]: True\n\nIn [15]: df.sort_index().index.is_monotonic\nOut[15]: False \n```", "```py\nIn [94]: df.sort_index()\nOut[94]:\n      value\na aa      2\n  bb      1\nb aa      4\n  bb      3\n\n[4 rows x 1 columns]\n\nIn [95]: df.sort_index().index.is_lexsorted()\nOut[95]: True\n\nIn [96]: df.sort_index().index.is_monotonic\nOut[96]: True \n```", "```py\nIn [1]: df = pd.DataFrame({'A': [1, 1, 2, 2], 'B': [1, 2, 3, 4]})\n\nIn [2]: df.groupby('A').describe()\nOut[2]:\n B\nA\n1 count  2.000000\n mean   1.500000\n std    0.707107\n min    1.000000\n 25%    1.250000\n 50%    1.500000\n 75%    1.750000\n max    2.000000\n2 count  2.000000\n mean   3.500000\n std    0.707107\n min    3.000000\n 25%    3.250000\n 50%    3.500000\n 75%    3.750000\n max    4.000000\n\nIn [3]: df.groupby('A').agg([\"mean\", \"std\", \"min\", \"max\"])\nOut[3]:\n B\n mean       std amin amax\nA\n1  1.5  0.707107    1    2\n2  3.5  0.707107    3    4 \n```", "```py\nIn [79]: df = pd.DataFrame({'A': [1, 1, 2, 2], 'B': [1, 2, 3, 4]})\n\nIn [80]: df.groupby('A').describe()\nOut[80]: \n B \n count mean       std  min   25%  50%   75%  max\nA \n1   2.0  1.5  0.707107  1.0  1.25  1.5  1.75  2.0\n2   2.0  3.5  0.707107  3.0  3.25  3.5  3.75  4.0\n\n[2 rows x 8 columns]\n\nIn [81]: df.groupby('A').agg([\"mean\", \"std\", \"min\", \"max\"])\nOut[81]: \n B \n mean       std min max\nA \n1  1.5  0.707107   1   2\n2  3.5  0.707107   3   4\n\n[2 rows x 4 columns] \n```", "```py\nIn [82]: np.random.seed(1234)\n\nIn [83]: df = pd.DataFrame(np.random.rand(100, 2),\n ....:                  columns=pd.Index(['A', 'B'], name='bar'),\n ....:                  index=pd.date_range('20160101',\n ....:                                      periods=100, freq='D', name='foo'))\n ....: \n\nIn [84]: df.tail()\nOut[84]: \nbar                A         B\nfoo \n2016-04-05  0.640880  0.126205\n2016-04-06  0.171465  0.737086\n2016-04-07  0.127029  0.369650\n2016-04-08  0.604334  0.103104\n2016-04-09  0.802374  0.945553\n\n[5 rows x 2 columns] \n```", "```py\nIn [2]: df.rolling(12).corr()\nOut[2]:\n<class 'pandas.core.panel.Panel'>\nDimensions: 100 (items) x 2 (major_axis) x 2 (minor_axis)\nItems axis: 2016-01-01 00:00:00 to 2016-04-09 00:00:00\nMajor_axis axis: A to B\nMinor_axis axis: A to B \n```", "```py\nIn [85]: res = df.rolling(12).corr()\n\nIn [86]: res.tail()\nOut[86]: \nbar                    A         B\nfoo        bar \n2016-04-07 B   -0.132090  1.000000\n2016-04-08 A    1.000000 -0.145775\n B   -0.145775  1.000000\n2016-04-09 A    1.000000  0.119645\n B    0.119645  1.000000\n\n[5 rows x 2 columns] \n```", "```py\nIn [87]: df.rolling(12).corr().loc['2016-04-07']\nOut[87]: \nbar        A        B\nbar \nA    1.00000 -0.13209\nB   -0.13209  1.00000\n\n[2 rows x 2 columns] \n```", "```py\nIn [88]: df = pd.DataFrame({'unparsed_date': ['2014-01-01', '2014-01-01']})\n\nIn [89]: df.to_hdf('store.h5', key='key', format='table', data_columns=True)\n\nIn [90]: df.dtypes\nOut[90]: \nunparsed_date    object\nLength: 1, dtype: object \n```", "```py\nIn [4]: pd.read_hdf('store.h5', 'key', where='unparsed_date > ts')\nFile \"<string>\", line 1\n (unparsed_date > 1970-01-01 00:00:01.388552400)\n ^\nSyntaxError: invalid token \n```", "```py\nIn [18]: ts = pd.Timestamp('2014-01-01')\n\nIn [19]: pd.read_hdf('store.h5', 'key', where='unparsed_date > ts')\nTypeError: Cannot compare 2014-01-01 00:00:00 of\ntype <class 'pandas.tslib.Timestamp'> to string column \n```", "```py\n    In [91]: left = pd.Index([2, 1, 0])\n\n    In [92]: left\n    Out[92]: Index([2, 1, 0], dtype='int64')\n\n    In [93]: right = pd.Index([1, 2, 3])\n\n    In [94]: right\n    Out[94]: Index([1, 2, 3], dtype='int64') \n    ```", "```py\n    In [4]: left.intersection(right)\n    Out[4]: Int64Index([1, 2], dtype='int64') \n    ```", "```py\n    In [95]: left.intersection(right)\n    Out[95]: Index([2, 1], dtype='int64') \n    ```", "```py\n    In [96]: left = pd.DataFrame({'a': [20, 10, 0]}, index=[2, 1, 0])\n\n    In [97]: left\n    Out[97]: \n     a\n    2  20\n    1  10\n    0   0\n\n    [3 rows x 1 columns]\n\n    In [98]: right = pd.DataFrame({'b': [100, 200, 300]}, index=[1, 2, 3])\n\n    In [99]: right\n    Out[99]: \n     b\n    1  100\n    2  200\n    3  300\n\n    [3 rows x 1 columns] \n    ```", "```py\n    In [4]: left.join(right, how='inner')\n    Out[4]:\n     a    b\n    1  10  100\n    2  20  200 \n    ```", "```py\n    In [100]: left.join(right, how='inner')\n    Out[100]: \n     a    b\n    2  20  200\n    1  10  100\n\n    [2 rows x 2 columns] \n    ```", "```py\nIn [101]: df = pd.DataFrame({'col1': [3, 4, 5],\n .....:                   'col2': ['C', 'D', 'E'],\n .....:                   'col3': [1, 3, 9]})\n .....: \n\nIn [102]: df\nOut[102]: \n col1 col2  col3\n0     3    C     1\n1     4    D     3\n2     5    E     9\n\n[3 rows x 3 columns] \n```", "```py\nIn [2]: df.pivot_table('col1', index=['col3', 'col2'], aggfunc=\"sum\")\nOut[2]:\ncol3  col2\n1     C       3\n3     D       4\n9     E       5\nName: col1, dtype: int64 \n```", "```py\nIn [103]: df.pivot_table('col1', index=['col3', 'col2'], aggfunc=\"sum\")\nOut[103]: \n col1\ncol3 col2 \n1    C        3\n3    D        4\n9    E        5\n\n[3 rows x 1 columns] \n```", "```py\nIn [2]: s = pd.TimeSeries([1, 2, 3], index=pd.date_range('20130101', periods=3))\n\nIn [3]: s\nOut[3]:\n2013-01-01    1\n2013-01-02    2\n2013-01-03    3\nFreq: D, dtype: int64\n\nIn [4]: type(s)\nOut[4]: pandas.core.series.TimeSeries\n\nIn [5]: s = pd.Series(s)\n\nIn [6]: s\nOut[6]:\n2013-01-01    1\n2013-01-02    2\n2013-01-03    3\nFreq: D, dtype: int64\n\nIn [7]: type(s)\nOut[7]: pandas.core.series.Series \n```", "```py\nIn [56]: idx = pd.Index([1, 2])\n\nIn [57]: idx\nOut[57]: Index([1, 2], dtype='int64')\n\nIn [58]: mi = pd.MultiIndex.from_tuples([(1, 2), (2, 4)])\n\nIn [59]: mi\nOut[59]: \nMultiIndex([(1, 2),\n (2, 4)],\n ) \n```", "```py\nIn [5]: idx.map(lambda x: x * 2)\nOut[5]: array([2, 4])\n\nIn [6]: idx.map(lambda x: (x, x * 2))\nOut[6]: array([(1, 2), (2, 4)], dtype=object)\n\nIn [7]: mi.map(lambda x: x)\nOut[7]: array([(1, 2), (2, 4)], dtype=object)\n\nIn [8]: mi.map(lambda x: x[0])\nOut[8]: array([1, 2]) \n```", "```py\nIn [60]: idx.map(lambda x: x * 2)\nOut[60]: Index([2, 4], dtype='int64')\n\nIn [61]: idx.map(lambda x: (x, x * 2))\nOut[61]: \nMultiIndex([(1, 2),\n (2, 4)],\n )\n\nIn [62]: mi.map(lambda x: x)\nOut[62]: \nMultiIndex([(1, 2),\n (2, 4)],\n )\n\nIn [63]: mi.map(lambda x: x[0])\nOut[63]: Index([1, 2], dtype='int64') \n```", "```py\nIn [64]: s = pd.Series(pd.date_range('2011-01-02T00:00', '2011-01-02T02:00', freq='H')\n ....:              .tz_localize('Asia/Tokyo'))\n ....:\n\nIn [65]: s\nOut[65]:\n0   2011-01-02 00:00:00+09:00\n1   2011-01-02 01:00:00+09:00\n2   2011-01-02 02:00:00+09:00\nLength: 3, dtype: datetime64[ns, Asia/Tokyo] \n```", "```py\nIn [9]: s.map(lambda x: x.hour)\nOut[9]:\n0    0\n1    1\n2    2\ndtype: int32 \n```", "```py\nIn [66]: s.map(lambda x: x.hour)\nOut[66]:\n0    0\n1    1\n2    2\nLength: 3, dtype: int64 \n```", "```py\nIn [1]: idx = pd.date_range(\"2015-01-01\", periods=5, freq='10H')\n\nIn [2]: idx.hour\nOut[2]: array([ 0, 10, 20,  6, 16], dtype=int32) \n```", "```py\nIn [67]: idx = pd.date_range(\"2015-01-01\", periods=5, freq='10H')\n\nIn [68]: idx.hour\nOut[68]: Index([0, 10, 20, 6, 16], dtype='int32') \n```", "```py\n    # Series\n    In [5]: pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n     ...:           pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n    Out[5]: array([Timestamp('2016-01-01 00:00:00-0500', tz='US/Eastern')], dtype=object)\n\n    In [6]: pd.unique(pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n     ...:                     pd.Timestamp('20160101', tz='US/Eastern')]))\n    Out[6]: array(['2016-01-01T05:00:00.000000000'], dtype='datetime64[ns]')\n\n    # Index\n    In [7]: pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n     ...:          pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n    Out[7]: DatetimeIndex(['2016-01-01 00:00:00-05:00'], dtype='datetime64[ns, US/Eastern]', freq=None)\n\n    In [8]: pd.unique([pd.Timestamp('20160101', tz='US/Eastern'),\n     ...:           pd.Timestamp('20160101', tz='US/Eastern')])\n    Out[8]: array(['2016-01-01T05:00:00.000000000'], dtype='datetime64[ns]') \n    ```", "```py\n    # Series, returns an array of Timestamp tz-aware\n    In [64]: pd.Series([pd.Timestamp(r'20160101', tz=r'US/Eastern'),\n     ....:           pd.Timestamp(r'20160101', tz=r'US/Eastern')]).unique()\n     ....: \n    Out[64]: \n    <DatetimeArray>\n    ['2016-01-01 00:00:00-05:00']\n    Length: 1, dtype: datetime64[ns, US/Eastern]\n\n    In [65]: pd.unique(pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),\n     ....:          pd.Timestamp('20160101', tz='US/Eastern')]))\n     ....: \n    Out[65]: \n    <DatetimeArray>\n    ['2016-01-01 00:00:00-05:00']\n    Length: 1, dtype: datetime64[ns, US/Eastern]\n\n    # Index, returns a DatetimeIndex\n    In [66]: pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n     ....:          pd.Timestamp('20160101', tz='US/Eastern')]).unique()\n     ....: \n    Out[66]: DatetimeIndex(['2016-01-01 00:00:00-05:00'], dtype='datetime64[ns, US/Eastern]', freq=None)\n\n    In [67]: pd.unique(pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),\n     ....:                    pd.Timestamp('20160101', tz='US/Eastern')]))\n     ....: \n    Out[67]: DatetimeIndex(['2016-01-01 00:00:00-05:00'], dtype='datetime64[ns, US/Eastern]', freq=None) \n    ```", "```py\n    In [1]: pd.Series(list('baabc'), dtype='category').unique()\n    Out[1]:\n    [b, a, c]\n    Categories (3, object): [b, a, c]\n\n    In [2]: pd.unique(pd.Series(list('baabc'), dtype='category'))\n    Out[2]: array(['b', 'a', 'c'], dtype=object) \n    ```", "```py\n    # returns a Categorical\n    In [68]: pd.Series(list('baabc'), dtype='category').unique()\n    Out[68]: \n    ['b', 'a', 'c']\n    Categories (3, object): ['a', 'b', 'c']\n\n    In [69]: pd.unique(pd.Series(list('baabc'), dtype='category'))\n    Out[69]: \n    ['b', 'a', 'c']\n    Categories (3, object): ['a', 'b', 'c'] \n    ```", "```py\nIn [70]: df = pd.DataFrame({'a': [1, 2, 3]}, pd.DatetimeIndex(['2011-12-31 23:59:59',\n ....:                                                      '2012-01-01 00:00:00',\n ....:                                                      '2012-01-01 00:00:01']))\n ....: \n```", "```py\nIn [4]: df['2011-12-31 23:59:59']\nOut[4]:\n a\n2011-12-31 23:59:59  1\n\nIn [5]: df['a']['2011-12-31 23:59:59']\nOut[5]:\n2011-12-31 23:59:59    1\nName: a, dtype: int64 \n```", "```py\nIn [4]: df['2011-12-31 23:59:59']\nKeyError: '2011-12-31 23:59:59'\n\nIn [5]: df['a']['2011-12-31 23:59:59']\nOut[5]: 1 \n```", "```py\nIn [71]: df1 = pd.DataFrame(np.array([1.0], dtype=np.float32, ndmin=2))\n\nIn [72]: df1.dtypes\nOut[72]: \n0    float32\nLength: 1, dtype: object\n\nIn [73]: df2 = pd.DataFrame(np.array([np.nan], dtype=np.float32, ndmin=2))\n\nIn [74]: df2.dtypes\nOut[74]: \n0    float32\nLength: 1, dtype: object \n```", "```py\nIn [7]: pd.concat([df1, df2]).dtypes\nOut[7]:\n0    float64\ndtype: object \n```", "```py\nIn [75]: pd.concat([df1, df2]).dtypes\nOut[75]: \n0    float32\nLength: 1, dtype: object \n```", "```py\nIn [8]: index = pd.Index(['foo', 'bar', 'baz'])\n\nIn [9]: index.memory_usage(deep=True)\nOut[9]: 180\n\nIn [10]: index.get_loc('foo')\nOut[10]: 0\n\nIn [11]: index.memory_usage(deep=True)\nOut[11]: 180 \n```", "```py\nIn [8]: index = pd.Index(['foo', 'bar', 'baz'])\n\nIn [9]: index.memory_usage(deep=True)\nOut[9]: 180\n\nIn [10]: index.get_loc('foo')\nOut[10]: 0\n\nIn [11]: index.memory_usage(deep=True)\nOut[11]: 260 \n```", "```py\nIn [81]: df = pd.DataFrame(np.arange(6), columns=['value'],\n   ....:                   index=pd.MultiIndex.from_product([list('BA'), range(3)]))\n   ....:\nIn [82]: df\n\nOut[82]:\n     value\nB 0      0\n  1      1\n  2      2\nA 0      3\n  1      4\n  2      5\n\n[6 rows x 1 columns] \n```", "```py\nIn [87]: df.index.is_lexsorted()\nOut[87]: False\n\nIn [88]: df.index.is_monotonic\nOut[88]: False \n```", "```py\nIn [76]: df.sort_index()\nOut[76]: \n a\n2011-12-31 23:59:59  1\n2012-01-01 00:00:00  2\n2012-01-01 00:00:01  3\n\n[3 rows x 1 columns] \n```", "```py\nIn [90]: df.sort_index().index.is_lexsorted()\nOut[90]: True\n\nIn [91]: df.sort_index().index.is_monotonic\nOut[91]: True \n```", "```py\nIn [77]: df = pd.DataFrame({'value': [1, 2, 3, 4]},\n ....:                  index=pd.MultiIndex([['a', 'b'], ['bb', 'aa']],\n ....:                                      [[0, 0, 1, 1], [0, 1, 0, 1]]))\n ....: \n\nIn [78]: df\nOut[78]: \n value\na bb      1\n aa      2\nb bb      3\n aa      4\n\n[4 rows x 1 columns] \n```", "```py\nIn [11]: df.sort_index()\nOut[11]:\n      value\na bb      1\n  aa      2\nb bb      3\n  aa      4\n\nIn [14]: df.sort_index().index.is_lexsorted()\nOut[14]: True\n\nIn [15]: df.sort_index().index.is_monotonic\nOut[15]: False \n```", "```py\nIn [94]: df.sort_index()\nOut[94]:\n      value\na aa      2\n  bb      1\nb aa      4\n  bb      3\n\n[4 rows x 1 columns]\n\nIn [95]: df.sort_index().index.is_lexsorted()\nOut[95]: True\n\nIn [96]: df.sort_index().index.is_monotonic\nOut[96]: True \n```", "```py\nIn [1]: df = pd.DataFrame({'A': [1, 1, 2, 2], 'B': [1, 2, 3, 4]})\n\nIn [2]: df.groupby('A').describe()\nOut[2]:\n B\nA\n1 count  2.000000\n mean   1.500000\n std    0.707107\n min    1.000000\n 25%    1.250000\n 50%    1.500000\n 75%    1.750000\n max    2.000000\n2 count  2.000000\n mean   3.500000\n std    0.707107\n min    3.000000\n 25%    3.250000\n 50%    3.500000\n 75%    3.750000\n max    4.000000\n\nIn [3]: df.groupby('A').agg([\"mean\", \"std\", \"min\", \"max\"])\nOut[3]:\n B\n mean       std amin amax\nA\n1  1.5  0.707107    1    2\n2  3.5  0.707107    3    4 \n```", "```py\nIn [79]: df = pd.DataFrame({'A': [1, 1, 2, 2], 'B': [1, 2, 3, 4]})\n\nIn [80]: df.groupby('A').describe()\nOut[80]: \n B \n count mean       std  min   25%  50%   75%  max\nA \n1   2.0  1.5  0.707107  1.0  1.25  1.5  1.75  2.0\n2   2.0  3.5  0.707107  3.0  3.25  3.5  3.75  4.0\n\n[2 rows x 8 columns]\n\nIn [81]: df.groupby('A').agg([\"mean\", \"std\", \"min\", \"max\"])\nOut[81]: \n B \n mean       std min max\nA \n1  1.5  0.707107   1   2\n2  3.5  0.707107   3   4\n\n[2 rows x 4 columns] \n```", "```py\nIn [82]: np.random.seed(1234)\n\nIn [83]: df = pd.DataFrame(np.random.rand(100, 2),\n ....:                  columns=pd.Index(['A', 'B'], name='bar'),\n ....:                  index=pd.date_range('20160101',\n ....:                                      periods=100, freq='D', name='foo'))\n ....: \n\nIn [84]: df.tail()\nOut[84]: \nbar                A         B\nfoo \n2016-04-05  0.640880  0.126205\n2016-04-06  0.171465  0.737086\n2016-04-07  0.127029  0.369650\n2016-04-08  0.604334  0.103104\n2016-04-09  0.802374  0.945553\n\n[5 rows x 2 columns] \n```", "```py\nIn [2]: df.rolling(12).corr()\nOut[2]:\n<class 'pandas.core.panel.Panel'>\nDimensions: 100 (items) x 2 (major_axis) x 2 (minor_axis)\nItems axis: 2016-01-01 00:00:00 to 2016-04-09 00:00:00\nMajor_axis axis: A to B\nMinor_axis axis: A to B \n```", "```py\nIn [85]: res = df.rolling(12).corr()\n\nIn [86]: res.tail()\nOut[86]: \nbar                    A         B\nfoo        bar \n2016-04-07 B   -0.132090  1.000000\n2016-04-08 A    1.000000 -0.145775\n B   -0.145775  1.000000\n2016-04-09 A    1.000000  0.119645\n B    0.119645  1.000000\n\n[5 rows x 2 columns] \n```", "```py\nIn [87]: df.rolling(12).corr().loc['2016-04-07']\nOut[87]: \nbar        A        B\nbar \nA    1.00000 -0.13209\nB   -0.13209  1.00000\n\n[2 rows x 2 columns] \n```", "```py\nIn [88]: df = pd.DataFrame({'unparsed_date': ['2014-01-01', '2014-01-01']})\n\nIn [89]: df.to_hdf('store.h5', key='key', format='table', data_columns=True)\n\nIn [90]: df.dtypes\nOut[90]: \nunparsed_date    object\nLength: 1, dtype: object \n```", "```py\nIn [4]: pd.read_hdf('store.h5', 'key', where='unparsed_date > ts')\nFile \"<string>\", line 1\n (unparsed_date > 1970-01-01 00:00:01.388552400)\n ^\nSyntaxError: invalid token \n```", "```py\nIn [18]: ts = pd.Timestamp('2014-01-01')\n\nIn [19]: pd.read_hdf('store.h5', 'key', where='unparsed_date > ts')\nTypeError: Cannot compare 2014-01-01 00:00:00 of\ntype <class 'pandas.tslib.Timestamp'> to string column \n```", "```py\n    In [91]: left = pd.Index([2, 1, 0])\n\n    In [92]: left\n    Out[92]: Index([2, 1, 0], dtype='int64')\n\n    In [93]: right = pd.Index([1, 2, 3])\n\n    In [94]: right\n    Out[94]: Index([1, 2, 3], dtype='int64') \n    ```", "```py\n    In [4]: left.intersection(right)\n    Out[4]: Int64Index([1, 2], dtype='int64') \n    ```", "```py\n    In [95]: left.intersection(right)\n    Out[95]: Index([2, 1], dtype='int64') \n    ```", "```py\n    In [96]: left = pd.DataFrame({'a': [20, 10, 0]}, index=[2, 1, 0])\n\n    In [97]: left\n    Out[97]: \n     a\n    2  20\n    1  10\n    0   0\n\n    [3 rows x 1 columns]\n\n    In [98]: right = pd.DataFrame({'b': [100, 200, 300]}, index=[1, 2, 3])\n\n    In [99]: right\n    Out[99]: \n     b\n    1  100\n    2  200\n    3  300\n\n    [3 rows x 1 columns] \n    ```", "```py\n    In [4]: left.join(right, how='inner')\n    Out[4]:\n     a    b\n    1  10  100\n    2  20  200 \n    ```", "```py\n    In [100]: left.join(right, how='inner')\n    Out[100]: \n     a    b\n    2  20  200\n    1  10  100\n\n    [2 rows x 2 columns] \n    ```", "```py\nIn [101]: df = pd.DataFrame({'col1': [3, 4, 5],\n .....:                   'col2': ['C', 'D', 'E'],\n .....:                   'col3': [1, 3, 9]})\n .....: \n\nIn [102]: df\nOut[102]: \n col1 col2  col3\n0     3    C     1\n1     4    D     3\n2     5    E     9\n\n[3 rows x 3 columns] \n```", "```py\nIn [2]: df.pivot_table('col1', index=['col3', 'col2'], aggfunc=\"sum\")\nOut[2]:\ncol3  col2\n1     C       3\n3     D       4\n9     E       5\nName: col1, dtype: int64 \n```", "```py\nIn [103]: df.pivot_table('col1', index=['col3', 'col2'], aggfunc=\"sum\")\nOut[103]: \n col1\ncol3 col2 \n1    C        3\n3    D        4\n9    E        5\n\n[3 rows x 1 columns] \n```", "```py\n['DtypeWarning',\n 'EmptyDataError',\n 'OutOfBoundsDatetime',\n 'ParserError',\n 'ParserWarning',\n 'PerformanceWarning',\n 'UnsortedIndexError',\n 'UnsupportedFunctionCall'] \n```", "```py\n['DtypeWarning',\n 'EmptyDataError',\n 'OutOfBoundsDatetime',\n 'ParserError',\n 'ParserWarning',\n 'PerformanceWarning',\n 'UnsortedIndexError',\n 'UnsupportedFunctionCall'] \n```", "```py\nIn [104]: df = pd.DataFrame({'A': [1, 2, 3],\n .....:                   'B': [4, 5, 6]},\n .....:                  index=list('abc'))\n .....: \n\nIn [105]: df\nOut[105]: \n A  B\na  1  4\nb  2  5\nc  3  6\n\n[3 rows x 2 columns] \n```", "```py\nIn [3]: df.ix[[0, 2], 'A']\nOut[3]:\na    1\nc    3\nName: A, dtype: int64 \n```", "```py\nIn [106]: df.loc[df.index[[0, 2]], 'A']\nOut[106]: \na    1\nc    3\nName: A, Length: 2, dtype: int64 \n```", "```py\nIn [107]: df.iloc[[0, 2], df.columns.get_loc('A')]\nOut[107]: \na    1\nc    3\nName: A, Length: 2, dtype: int64 \n```", "```py\nIn [133]: import pandas._testing as tm\n\nIn [134]: p = tm.makePanel()\n\nIn [135]: p\nOut[135]:\n<class 'pandas.core.panel.Panel'>\nDimensions: 3 (items) x 3 (major_axis) x 4 (minor_axis)\nItems axis: ItemA to ItemC\nMajor_axis axis: 2000-01-03 00:00:00 to 2000-01-05 00:00:00\nMinor_axis axis: A to D \n```", "```py\nIn [136]: p.to_frame()\nOut[136]:\n ItemA     ItemB     ItemC\nmajor      minor\n2000-01-03 A      0.628776 -1.409432  0.209395\n B      0.988138 -1.347533 -0.896581\n C     -0.938153  1.272395 -0.161137\n D     -0.223019 -0.591863 -1.051539\n2000-01-04 A      0.186494  1.422986 -0.592886\n B     -0.072608  0.363565  1.104352\n C     -1.239072 -1.449567  0.889157\n D      2.123692 -0.414505 -0.319561\n2000-01-05 A      0.952478 -2.147855 -1.473116\n B     -0.550603 -0.014752 -0.431550\n C      0.139683 -1.195524  0.288377\n D      0.122273 -1.425795 -0.619993\n\n[12 rows x 3 columns] \n```", "```py\nIn [137]: p.to_xarray()\nOut[137]:\n<xarray.DataArray (items: 3, major_axis: 3, minor_axis: 4)>\narray([[[ 0.628776,  0.988138, -0.938153, -0.223019],\n [ 0.186494, -0.072608, -1.239072,  2.123692],\n [ 0.952478, -0.550603,  0.139683,  0.122273]],\n\n [[-1.409432, -1.347533,  1.272395, -0.591863],\n [ 1.422986,  0.363565, -1.449567, -0.414505],\n [-2.147855, -0.014752, -1.195524, -1.425795]],\n\n [[ 0.209395, -0.896581, -0.161137, -1.051539],\n [-0.592886,  1.104352,  0.889157, -0.319561],\n [-1.473116, -0.43155 ,  0.288377, -0.619993]]])\nCoordinates:\n * items       (items) object 'ItemA' 'ItemB' 'ItemC'\n * major_axis  (major_axis) datetime64[ns] 2000-01-03 2000-01-04 2000-01-05\n * minor_axis  (minor_axis) object 'A' 'B' 'C' 'D' \n```", "```py\nIn [108]: df = pd.DataFrame({'A': [1, 1, 1, 2, 2],\n .....:                   'B': range(5),\n .....:                   'C': range(5)})\n .....: \n\nIn [109]: df\nOut[109]: \n A  B  C\n0  1  0  0\n1  1  1  1\n2  1  2  2\n3  2  3  3\n4  2  4  4\n\n[5 rows x 3 columns] \n```", "```py\nIn [110]: df.groupby('A').agg({'B': 'sum', 'C': 'min'})\nOut[110]: \n B  C\nA \n1  3  0\n2  7  3\n\n[2 rows x 2 columns] \n```", "```py\nIn [6]: df.groupby('A').B.agg({'foo': 'count'})\nFutureWarning: using a dict on a Series for aggregation\nis deprecated and will be removed in a future version\n\nOut[6]:\n foo\nA\n1    3\n2    2 \n```", "```py\nIn [111]: df.groupby('A').B.agg(['count']).rename(columns={'count': 'foo'})\nOut[111]: \n foo\nA \n1    3\n2    2\n\n[2 rows x 1 columns] \n```", "```py\nIn [23]: (df.groupby('A')\n    ...:    .agg({'B': {'foo': 'sum'}, 'C': {'bar': 'min'}})\n    ...:  )\nFutureWarning: using a dict with renaming is deprecated and\nwill be removed in a future version\n\nOut[23]:\n     B   C\n   foo bar\nA\n1   3   0\n2   7   3 \n```", "```py\nIn [112]: (df.groupby('A')\n .....:   .agg({'B': 'sum', 'C': 'min'})\n .....:   .rename(columns={'B': 'foo', 'C': 'bar'})\n .....: )\n .....: \nOut[112]: \n foo  bar\nA \n1    3    0\n2    7    3\n\n[2 rows x 2 columns] \n```", "```py\npd.tools.plotting.scatter_matrix(df)\npd.scatter_matrix(df) \n```", "```py\npd.plotting.scatter_matrix(df) \n```", "```py\nIn [104]: df = pd.DataFrame({'A': [1, 2, 3],\n .....:                   'B': [4, 5, 6]},\n .....:                  index=list('abc'))\n .....: \n\nIn [105]: df\nOut[105]: \n A  B\na  1  4\nb  2  5\nc  3  6\n\n[3 rows x 2 columns] \n```", "```py\nIn [3]: df.ix[[0, 2], 'A']\nOut[3]:\na    1\nc    3\nName: A, dtype: int64 \n```", "```py\nIn [106]: df.loc[df.index[[0, 2]], 'A']\nOut[106]: \na    1\nc    3\nName: A, Length: 2, dtype: int64 \n```", "```py\nIn [107]: df.iloc[[0, 2], df.columns.get_loc('A')]\nOut[107]: \na    1\nc    3\nName: A, Length: 2, dtype: int64 \n```", "```py\nIn [133]: import pandas._testing as tm\n\nIn [134]: p = tm.makePanel()\n\nIn [135]: p\nOut[135]:\n<class 'pandas.core.panel.Panel'>\nDimensions: 3 (items) x 3 (major_axis) x 4 (minor_axis)\nItems axis: ItemA to ItemC\nMajor_axis axis: 2000-01-03 00:00:00 to 2000-01-05 00:00:00\nMinor_axis axis: A to D \n```", "```py\nIn [136]: p.to_frame()\nOut[136]:\n ItemA     ItemB     ItemC\nmajor      minor\n2000-01-03 A      0.628776 -1.409432  0.209395\n B      0.988138 -1.347533 -0.896581\n C     -0.938153  1.272395 -0.161137\n D     -0.223019 -0.591863 -1.051539\n2000-01-04 A      0.186494  1.422986 -0.592886\n B     -0.072608  0.363565  1.104352\n C     -1.239072 -1.449567  0.889157\n D      2.123692 -0.414505 -0.319561\n2000-01-05 A      0.952478 -2.147855 -1.473116\n B     -0.550603 -0.014752 -0.431550\n C      0.139683 -1.195524  0.288377\n D      0.122273 -1.425795 -0.619993\n\n[12 rows x 3 columns] \n```", "```py\nIn [137]: p.to_xarray()\nOut[137]:\n<xarray.DataArray (items: 3, major_axis: 3, minor_axis: 4)>\narray([[[ 0.628776,  0.988138, -0.938153, -0.223019],\n [ 0.186494, -0.072608, -1.239072,  2.123692],\n [ 0.952478, -0.550603,  0.139683,  0.122273]],\n\n [[-1.409432, -1.347533,  1.272395, -0.591863],\n [ 1.422986,  0.363565, -1.449567, -0.414505],\n [-2.147855, -0.014752, -1.195524, -1.425795]],\n\n [[ 0.209395, -0.896581, -0.161137, -1.051539],\n [-0.592886,  1.104352,  0.889157, -0.319561],\n [-1.473116, -0.43155 ,  0.288377, -0.619993]]])\nCoordinates:\n * items       (items) object 'ItemA' 'ItemB' 'ItemC'\n * major_axis  (major_axis) datetime64[ns] 2000-01-03 2000-01-04 2000-01-05\n * minor_axis  (minor_axis) object 'A' 'B' 'C' 'D' \n```", "```py\nIn [108]: df = pd.DataFrame({'A': [1, 1, 1, 2, 2],\n .....:                   'B': range(5),\n .....:                   'C': range(5)})\n .....: \n\nIn [109]: df\nOut[109]: \n A  B  C\n0  1  0  0\n1  1  1  1\n2  1  2  2\n3  2  3  3\n4  2  4  4\n\n[5 rows x 3 columns] \n```", "```py\nIn [110]: df.groupby('A').agg({'B': 'sum', 'C': 'min'})\nOut[110]: \n B  C\nA \n1  3  0\n2  7  3\n\n[2 rows x 2 columns] \n```", "```py\nIn [6]: df.groupby('A').B.agg({'foo': 'count'})\nFutureWarning: using a dict on a Series for aggregation\nis deprecated and will be removed in a future version\n\nOut[6]:\n foo\nA\n1    3\n2    2 \n```", "```py\nIn [111]: df.groupby('A').B.agg(['count']).rename(columns={'count': 'foo'})\nOut[111]: \n foo\nA \n1    3\n2    2\n\n[2 rows x 1 columns] \n```", "```py\nIn [23]: (df.groupby('A')\n    ...:    .agg({'B': {'foo': 'sum'}, 'C': {'bar': 'min'}})\n    ...:  )\nFutureWarning: using a dict with renaming is deprecated and\nwill be removed in a future version\n\nOut[23]:\n     B   C\n   foo bar\nA\n1   3   0\n2   7   3 \n```", "```py\nIn [112]: (df.groupby('A')\n .....:   .agg({'B': 'sum', 'C': 'min'})\n .....:   .rename(columns={'B': 'foo', 'C': 'bar'})\n .....: )\n .....: \nOut[112]: \n foo  bar\nA \n1    3    0\n2    7    3\n\n[2 rows x 2 columns] \n```", "```py\npd.tools.plotting.scatter_matrix(df)\npd.scatter_matrix(df) \n```", "```py\npd.plotting.scatter_matrix(df) \n```"]