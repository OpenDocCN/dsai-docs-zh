["```py\nfrom pandas.io import data, wb \n```", "```py\nfrom pandas_datareader import data, wb \n```", "```py\nIn [1]: df = pd.DataFrame(\n ...:    {\n ...:        \"A\": pd.date_range(\"20130101\", periods=3),\n ...:        \"B\": pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\"),\n ...:        \"C\": pd.date_range(\"20130101\", periods=3, tz=\"CET\"),\n ...:    }\n ...: )\n ...: \n\nIn [2]: df\nOut[2]: \n A                         B                         C\n0 2013-01-01 2013-01-01 00:00:00-05:00 2013-01-01 00:00:00+01:00\n1 2013-01-02 2013-01-02 00:00:00-05:00 2013-01-02 00:00:00+01:00\n2 2013-01-03 2013-01-03 00:00:00-05:00 2013-01-03 00:00:00+01:00\n\n[3 rows x 3 columns]\n\nIn [3]: df.dtypes\nOut[3]: \nA                datetime64[ns]\nB    datetime64[ns, US/Eastern]\nC           datetime64[ns, CET]\nLength: 3, dtype: object \n```", "```py\nIn [4]: df.B\nOut[4]: \n0   2013-01-01 00:00:00-05:00\n1   2013-01-02 00:00:00-05:00\n2   2013-01-03 00:00:00-05:00\nName: B, Length: 3, dtype: datetime64[ns, US/Eastern]\n\nIn [5]: df.B.dt.tz_localize(None)\nOut[5]: \n0   2013-01-01\n1   2013-01-02\n2   2013-01-03\nName: B, Length: 3, dtype: datetime64[ns] \n```", "```py\nIn [6]: df[\"B\"].dtype\nOut[6]: datetime64[ns, US/Eastern]\n\nIn [7]: type(df[\"B\"].dtype)\nOut[7]: pandas.core.dtypes.dtypes.DatetimeTZDtype \n```", "```py\nIn [1]: pd.date_range('20130101', periods=3, tz='US/Eastern')\nOut[1]: DatetimeIndex(['2013-01-01 00:00:00-05:00', '2013-01-02 00:00:00-05:00',\n '2013-01-03 00:00:00-05:00'],\n dtype='datetime64[ns]', freq='D', tz='US/Eastern')\n\nIn [2]: pd.date_range('20130101', periods=3, tz='US/Eastern').dtype\nOut[2]: dtype('<M8[ns]') \n```", "```py\nIn [8]: pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\")\nOut[8]: \nDatetimeIndex(['2013-01-01 00:00:00-05:00', '2013-01-02 00:00:00-05:00',\n '2013-01-03 00:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq='D')\n\nIn [9]: pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\").dtype\nOut[9]: datetime64[ns, US/Eastern] \n```", "```py\nN = 1000000\nngroups = 10\ndf = DataFrame(\n    {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n)\ndf.groupby(\"key\")[\"data\"].sum() \n```", "```py\nIn [10]: df = pd.DataFrame(np.random.rand(10, 2), columns=['a', 'b'])\n\nIn [11]: df.plot.bar() \n```", "```py\nIn [12]: df.plot.<TAB>  # noqa: E225, E999\ndf.plot.area     df.plot.barh     df.plot.density  df.plot.hist     df.plot.line     df.plot.scatter\ndf.plot.bar      df.plot.box      df.plot.hexbin   df.plot.kde      df.plot.pie \n```", "```py\n# DatetimeIndex\nIn [13]: s = pd.Series(pd.date_range(\"20130101\", periods=4))\n\nIn [14]: s\nOut[14]: \n0   2013-01-01\n1   2013-01-02\n2   2013-01-03\n3   2013-01-04\nLength: 4, dtype: datetime64[ns]\n\nIn [15]: s.dt.strftime(\"%Y/%m/%d\")\nOut[15]: \n0    2013/01/01\n1    2013/01/02\n2    2013/01/03\n3    2013/01/04\nLength: 4, dtype: object \n```", "```py\n# PeriodIndex\nIn [16]: s = pd.Series(pd.period_range(\"20130101\", periods=4))\n\nIn [17]: s\nOut[17]: \n0    2013-01-01\n1    2013-01-02\n2    2013-01-03\n3    2013-01-04\nLength: 4, dtype: period[D]\n\nIn [18]: s.dt.strftime(\"%Y/%m/%d\")\nOut[18]: \n0    2013/01/01\n1    2013/01/02\n2    2013/01/03\n3    2013/01/04\nLength: 4, dtype: object \n```", "```py\n# TimedeltaIndex\nIn [19]: s = pd.Series(pd.timedelta_range(\"1 minutes\", periods=4))\n\nIn [20]: s\nOut[20]: \n0   0 days 00:01:00\n1   1 days 00:01:00\n2   2 days 00:01:00\n3   3 days 00:01:00\nLength: 4, dtype: timedelta64[ns]\n\nIn [21]: s.dt.total_seconds()\nOut[21]: \n0        60.0\n1     86460.0\n2    172860.0\n3    259260.0\nLength: 4, dtype: float64 \n```", "```py\nIn [22]: p = pd.Period(\"2015-08-01\", freq=\"3D\")\n\nIn [23]: p\nOut[23]: Period('2015-08-01', '3D')\n\nIn [24]: p + 1\nOut[24]: Period('2015-08-04', '3D')\n\nIn [25]: p - 2\nOut[25]: Period('2015-07-26', '3D')\n\nIn [26]: p.to_timestamp()\nOut[26]: Timestamp('2015-08-01 00:00:00')\n\nIn [27]: p.to_timestamp(how=\"E\")\nOut[27]: Timestamp('2015-08-03 23:59:59.999999999') \n```", "```py\nIn [28]: idx = pd.period_range(\"2015-08-01\", periods=4, freq=\"2D\")\n\nIn [29]: idx\nOut[29]: PeriodIndex(['2015-08-01', '2015-08-03', '2015-08-05', '2015-08-07'], dtype='period[2D]')\n\nIn [30]: idx + 1\nOut[30]: PeriodIndex(['2015-08-03', '2015-08-05', '2015-08-07', '2015-08-09'], dtype='period[2D]') \n```", "```py\ndf = pd.read_sas(\"sas_xport.xpt\") \n```", "```py\nfor df in pd.read_sas(\"sas_xport.xpt\", chunksize=10000):\n    do_something(df) \n```", "```py\ndf = pd.DataFrame({\"a\": np.random.randn(10)})\ndf.eval(\"b = sin(a)\") \n```", "```py\nIn [31]: df = pd.DataFrame(\n ....:    [[1, 2, 3, 4], [5, 6, 7, 8]],\n ....:    columns=pd.MultiIndex.from_product(\n ....:        [[\"foo\", \"bar\"], [\"a\", \"b\"]], names=[\"col1\", \"col2\"]\n ....:    ),\n ....:    index=pd.MultiIndex.from_product([[\"j\"], [\"l\", \"k\"]], names=[\"i1\", \"i2\"]),\n ....: )\n ....: \n\nIn [32]: df\nOut[32]: \ncol1  foo    bar \ncol2    a  b   a  b\ni1 i2 \nj  l    1  2   3  4\n k    5  6   7  8\n\n[2 rows x 4 columns]\n\nIn [33]: df.to_excel(\"test.xlsx\")\n\nIn [34]: df = pd.read_excel(\"test.xlsx\", header=[0, 1], index_col=[0, 1])\n\nIn [35]: df\nOut[35]: \ncol1  foo    bar \ncol2    a  b   a  b\ni1 i2 \nj  l    1  2   3  4\n k    5  6   7  8\n\n[2 rows x 4 columns] \n```", "```py\nIn [36]: df = pd.DataFrame({u\"\u56fd\u7c4d\": [\"UK\", u\"\u65e5\u672c\"], u\"\u540d\u524d\": [\"Alice\", u\"\u3057\u306e\u3076\"]})\n\nIn [37]: df\nOut[37]: \n \u56fd\u7c4d     \u540d\u524d\n0  UK  Alice\n1  \u65e5\u672c    \u3057\u306e\u3076\n\n[2 rows x 2 columns] \n```", "```py\nIn [38]: pd.set_option(\"display.unicode.east_asian_width\", True)\n\nIn [39]: df\nOut[39]: \n \u56fd\u7c4d    \u540d\u524d\n0    UK   Alice\n1  \u65e5\u672c  \u3057\u306e\u3076\n\n[2 rows x 2 columns] \n```", "```py\n    In [40]: df1 = pd.DataFrame({\"col1\": [0, 1], \"col_left\": [\"a\", \"b\"]})\n\n    In [41]: df2 = pd.DataFrame({\"col1\": [1, 2, 2], \"col_right\": [2, 2, 2]})\n\n    In [42]: pd.merge(df1, df2, on=\"col1\", how=\"outer\", indicator=True)\n    Out[42]: \n     col1 col_left  col_right      _merge\n    0     0        a        NaN   left_only\n    1     1        b        2.0        both\n    2     2      NaN        2.0  right_only\n    3     2      NaN        2.0  right_only\n\n    [4 rows x 4 columns] \n    ```", "```py\n    In [43]: foo = pd.Series([1, 2], name=\"foo\")\n\n    In [44]: bar = pd.Series([1, 2])\n\n    In [45]: baz = pd.Series([4, 5]) \n    ```", "```py\n    In [1]: pd.concat([foo, bar, baz], axis=1)\n    Out[1]:\n     0  1  2\n     0  1  1  4\n     1  2  2  5 \n    ```", "```py\n    In [46]: pd.concat([foo, bar, baz], axis=1)\n    Out[46]: \n     foo  0  1\n    0    1  1  4\n    1    2  2  5\n\n    [2 rows x 3 columns] \n    ```", "```py\n    In [47]: ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan, np.nan, 13])\n\n    In [48]: ser.interpolate(limit=1, limit_direction=\"both\")\n    Out[48]: \n    0     NaN\n    1     5.0\n    2     5.0\n    3     7.0\n    4     NaN\n    5    11.0\n    6    13.0\n    Length: 7, dtype: float64 \n    ```", "```py\n    In [49]: df = pd.DataFrame(\n     ....:    np.random.random([3, 3]),\n     ....:    columns=[\"A\", \"B\", \"C\"],\n     ....:    index=[\"first\", \"second\", \"third\"],\n     ....: )\n     ....: \n\n    In [50]: df\n    Out[50]: \n     A         B         C\n    first   0.126970  0.966718  0.260476\n    second  0.897237  0.376750  0.336222\n    third   0.451376  0.840255  0.123102\n\n    [3 rows x 3 columns]\n\n    In [51]: df.round(2)\n    Out[51]: \n     A     B     C\n    first   0.13  0.97  0.26\n    second  0.90  0.38  0.34\n    third   0.45  0.84  0.12\n\n    [3 rows x 3 columns]\n\n    In [52]: df.round({\"A\": 0, \"C\": 2})\n    Out[52]: \n     A         B     C\n    first   0.0  0.966718  0.26\n    second  1.0  0.376750  0.34\n    third   0.0  0.840255  0.12\n\n    [3 rows x 3 columns] \n    ```", "```py\n    In [53]: s = pd.Series([\"A\", \"B\", \"C\", \"A\", \"B\", \"D\"])\n\n    In [54]: s.drop_duplicates()\n    Out[54]: \n    0    A\n    1    B\n    2    C\n    5    D\n    Length: 4, dtype: object\n\n    In [55]: s.drop_duplicates(keep=\"last\")\n    Out[55]: \n    2    C\n    3    A\n    4    B\n    5    D\n    Length: 4, dtype: object\n\n    In [56]: s.drop_duplicates(keep=False)\n    Out[56]: \n    2    C\n    5    D\n    Length: 2, dtype: object \n    ```", "```py\n    In [57]: df = pd.DataFrame({\"x\": range(5), \"t\": pd.date_range(\"2000-01-01\", periods=5)})\n\n    In [58]: df.reindex([0.1, 1.9, 3.5], method=\"nearest\", tolerance=0.2)\n    Out[58]: \n     x          t\n    0.1  0.0 2000-01-01\n    1.9  2.0 2000-01-03\n    3.5  NaN        NaT\n\n    [3 rows x 2 columns] \n    ```", "```py\n    In [59]: df = df.set_index(\"t\")\n\n    In [60]: df.reindex(pd.to_datetime([\"1999-12-31\"]), method=\"nearest\", tolerance=\"1 day\")\n    Out[60]: \n     x\n    1999-12-31  0\n\n    [1 rows x 1 columns] \n    ```", "```py\nIn [2]: pd.to_datetime(['2009-07-31', 'asd'])\nOut[2]: array(['2009-07-31', 'asd'], dtype=object) \n```", "```py\nIn [3]: pd.to_datetime(['2009-07-31', 'asd'])\nValueError: Unknown string format \n```", "```py\nIn [61]: pd.to_datetime([\"2009-07-31\", \"asd\"], errors=\"coerce\")\nOut[61]: DatetimeIndex(['2009-07-31', 'NaT'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [4]: pd.to_datetime([\"2009-07-31\", \"asd\"], errors=\"ignore\")\nOut[4]: Index(['2009-07-31', 'asd'], dtype='object') \n```", "```py\nIn [1]: pd.Timestamp('2012Q2')\nTraceback\n ...\nValueError: Unable to parse 2012Q2\n\n# Results in today's date.\nIn [2]: pd.Timestamp('2014')\nOut [2]: 2014-08-12 00:00:00 \n```", "```py\nIn [62]: pd.Timestamp(\"2012Q2\")\nOut[62]: Timestamp('2012-04-01 00:00:00')\n\nIn [63]: pd.Timestamp(\"2014\")\nOut[63]: Timestamp('2014-01-01 00:00:00')\n\nIn [64]: pd.DatetimeIndex([\"2012Q2\", \"2014\"])\nOut[64]: DatetimeIndex(['2012-04-01', '2014-01-01'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [65]: import pandas.tseries.offsets as offsets\n\nIn [66]: pd.Timestamp.now()\nOut[66]: Timestamp('2024-04-10 17:55:56.541543')\n\nIn [67]: pd.Timestamp.now() + offsets.DateOffset(years=1)\nOut[67]: Timestamp('2025-04-10 17:55:56.542277') \n```", "```py\nIn [2]: pd.Index([1, 2, 3]) == pd.Index([1, 4, 5])\nOut[2]: array([ True, False, False], dtype=bool)\n\nIn [3]: pd.Index([1, 2, 3]) == pd.Index([2])\nOut[3]: array([False,  True, False], dtype=bool)\n\nIn [4]: pd.Index([1, 2, 3]) == pd.Index([1, 2])\nOut[4]: False \n```", "```py\nIn [8]: pd.Index([1, 2, 3]) == pd.Index([1, 4, 5])\nOut[8]: array([ True, False, False], dtype=bool)\n\nIn [9]: pd.Index([1, 2, 3]) == pd.Index([2])\nValueError: Lengths must match to compare\n\nIn [10]: pd.Index([1, 2, 3]) == pd.Index([1, 2])\nValueError: Lengths must match to compare \n```", "```py\nIn [68]: np.array([1, 2, 3]) == np.array([1])\nOut[68]: array([ True, False, False]) \n```", "```py\nIn [11]: np.array([1, 2, 3]) == np.array([1, 2])\nOut[11]: False \n```", "```py\nIn [69]: s = pd.Series(range(3), dtype=\"float\")\n\nIn [70]: s.iloc[1] = None\n\nIn [71]: s\nOut[71]: \n0    0.0\n1    NaN\n2    2.0\nLength: 3, dtype: float64 \n```", "```py\nIn [5]: s == None\nTypeError: Could not compare <type 'NoneType'> type with Series \n```", "```py\nIn [72]: s == None\nOut[72]: \n0    False\n1    False\n2    False\nLength: 3, dtype: bool \n```", "```py\nIn [73]: s.isnull()\nOut[73]: \n0    False\n1     True\n2    False\nLength: 3, dtype: bool \n```", "```py\nIn [74]: None == None\nOut[74]: True\n\nIn [75]: np.nan == np.nan\nOut[75]: False \n```", "```py\nIn [76]: df_with_missing = pd.DataFrame(\n ....:    {\"col1\": [0, np.nan, 2], \"col2\": [1, np.nan, np.nan]}\n ....: )\n ....: \n\nIn [77]: df_with_missing\nOut[77]: \n col1  col2\n0   0.0   1.0\n1   NaN   NaN\n2   2.0   NaN\n\n[3 rows x 2 columns] \n```", "```py\nIn [27]:\ndf_with_missing.to_hdf('file.h5',\n key='df_with_missing',\n format='table',\n mode='w')\n\nIn [28]: pd.read_hdf('file.h5', 'df_with_missing')\n\nOut [28]:\n col1  col2\n 0     0     1\n 2     2   NaN \n```", "```py\nIn [78]: df_with_missing.to_hdf(\"file.h5\", key=\"df_with_missing\", format=\"table\", mode=\"w\")\n\nIn [79]: pd.read_hdf(\"file.h5\", \"df_with_missing\")\nOut[79]: \n col1  col2\n0   0.0   1.0\n1   NaN   NaN\n2   2.0   NaN\n\n[3 rows x 2 columns] \n```", "```py\nIn [1]: pd.set_option('display.precision', 2)\n\nIn [2]: pd.DataFrame({'x': [123.456789]})\nOut[2]:\n x\n0  123.5 \n```", "```py\nIn [80]: pd.set_option(\"display.precision\", 2)\n\nIn [81]: pd.DataFrame({\"x\": [123.456789]})\nOut[81]: \n x\n0  123.46\n\n[1 rows x 1 columns] \n```", "```py\nIn [82]: cat = pd.Categorical([\"C\", \"A\", \"B\", \"C\"], categories=[\"A\", \"B\", \"C\"], ordered=True)\n\nIn [83]: cat\nOut[83]: \n['C', 'A', 'B', 'C']\nCategories (3, object): ['A' < 'B' < 'C']\n\nIn [84]: cat.unique()\nOut[84]: \n['C', 'A', 'B']\nCategories (3, object): ['A' < 'B' < 'C']\n\nIn [85]: cat = pd.Categorical([\"C\", \"A\", \"B\", \"C\"], categories=[\"A\", \"B\", \"C\"])\n\nIn [86]: cat\nOut[86]: \n['C', 'A', 'B', 'C']\nCategories (3, object): ['A', 'B', 'C']\n\nIn [87]: cat.unique()\nOut[87]: \n['C', 'A', 'B']\nCategories (3, object): ['A', 'B', 'C'] \n```", "```py\nIn [29]: df = pd.read_csv('data.csv', header=False)\nTypeError: Passing a bool to header is invalid. Use header=None for no header or\nheader=int or list-like of ints to specify the row(s) making up the column names \n```", "```py\n    In [88]: np.random.seed(1234)\n\n    In [89]: df = pd.DataFrame(\n     ....:    np.random.randn(5, 2),\n     ....:    columns=list(\"AB\"),\n     ....:    index=pd.date_range(\"2013-01-01\", periods=5),\n     ....: )\n     ....: \n\n    In [90]: df\n    Out[90]: \n     A         B\n    2013-01-01  0.471435 -1.190976\n    2013-01-02  1.432707 -0.312652\n    2013-01-03 -0.720589  0.887163\n    2013-01-04  0.859588 -0.636524\n    2013-01-05  0.015696 -2.242685\n\n    [5 rows x 2 columns] \n    ```", "```py\n    In [3]: df + df.A\n    FutureWarning: TimeSeries broadcasting along DataFrame index by default is deprecated.\n    Please use DataFrame.<op> to explicitly broadcast arithmetic operations along the index\n\n    Out[3]:\n     A         B\n    2013-01-01  0.942870 -0.719541\n    2013-01-02  2.865414  1.120055\n    2013-01-03 -1.441177  0.166574\n    2013-01-04  1.719177  0.223065\n    2013-01-05  0.031393 -2.226989 \n    ```", "```py\n    In [91]: df.add(df.A, axis=\"index\")\n    Out[91]: \n     A         B\n    2013-01-01  0.942870 -0.719541\n    2013-01-02  2.865414  1.120055\n    2013-01-03 -1.441177  0.166574\n    2013-01-04  1.719177  0.223065\n    2013-01-05  0.031393 -2.226989\n\n    [5 rows x 2 columns] \n    ```", "```py\nIn [1]: df = pd.DataFrame(\n ...:    {\n ...:        \"A\": pd.date_range(\"20130101\", periods=3),\n ...:        \"B\": pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\"),\n ...:        \"C\": pd.date_range(\"20130101\", periods=3, tz=\"CET\"),\n ...:    }\n ...: )\n ...: \n\nIn [2]: df\nOut[2]: \n A                         B                         C\n0 2013-01-01 2013-01-01 00:00:00-05:00 2013-01-01 00:00:00+01:00\n1 2013-01-02 2013-01-02 00:00:00-05:00 2013-01-02 00:00:00+01:00\n2 2013-01-03 2013-01-03 00:00:00-05:00 2013-01-03 00:00:00+01:00\n\n[3 rows x 3 columns]\n\nIn [3]: df.dtypes\nOut[3]: \nA                datetime64[ns]\nB    datetime64[ns, US/Eastern]\nC           datetime64[ns, CET]\nLength: 3, dtype: object \n```", "```py\nIn [4]: df.B\nOut[4]: \n0   2013-01-01 00:00:00-05:00\n1   2013-01-02 00:00:00-05:00\n2   2013-01-03 00:00:00-05:00\nName: B, Length: 3, dtype: datetime64[ns, US/Eastern]\n\nIn [5]: df.B.dt.tz_localize(None)\nOut[5]: \n0   2013-01-01\n1   2013-01-02\n2   2013-01-03\nName: B, Length: 3, dtype: datetime64[ns] \n```", "```py\nIn [6]: df[\"B\"].dtype\nOut[6]: datetime64[ns, US/Eastern]\n\nIn [7]: type(df[\"B\"].dtype)\nOut[7]: pandas.core.dtypes.dtypes.DatetimeTZDtype \n```", "```py\nIn [1]: pd.date_range('20130101', periods=3, tz='US/Eastern')\nOut[1]: DatetimeIndex(['2013-01-01 00:00:00-05:00', '2013-01-02 00:00:00-05:00',\n '2013-01-03 00:00:00-05:00'],\n dtype='datetime64[ns]', freq='D', tz='US/Eastern')\n\nIn [2]: pd.date_range('20130101', periods=3, tz='US/Eastern').dtype\nOut[2]: dtype('<M8[ns]') \n```", "```py\nIn [8]: pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\")\nOut[8]: \nDatetimeIndex(['2013-01-01 00:00:00-05:00', '2013-01-02 00:00:00-05:00',\n '2013-01-03 00:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq='D')\n\nIn [9]: pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\").dtype\nOut[9]: datetime64[ns, US/Eastern] \n```", "```py\nN = 1000000\nngroups = 10\ndf = DataFrame(\n    {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n)\ndf.groupby(\"key\")[\"data\"].sum() \n```", "```py\nIn [10]: df = pd.DataFrame(np.random.rand(10, 2), columns=['a', 'b'])\n\nIn [11]: df.plot.bar() \n```", "```py\nIn [12]: df.plot.<TAB>  # noqa: E225, E999\ndf.plot.area     df.plot.barh     df.plot.density  df.plot.hist     df.plot.line     df.plot.scatter\ndf.plot.bar      df.plot.box      df.plot.hexbin   df.plot.kde      df.plot.pie \n```", "```py\n# DatetimeIndex\nIn [13]: s = pd.Series(pd.date_range(\"20130101\", periods=4))\n\nIn [14]: s\nOut[14]: \n0   2013-01-01\n1   2013-01-02\n2   2013-01-03\n3   2013-01-04\nLength: 4, dtype: datetime64[ns]\n\nIn [15]: s.dt.strftime(\"%Y/%m/%d\")\nOut[15]: \n0    2013/01/01\n1    2013/01/02\n2    2013/01/03\n3    2013/01/04\nLength: 4, dtype: object \n```", "```py\n# PeriodIndex\nIn [16]: s = pd.Series(pd.period_range(\"20130101\", periods=4))\n\nIn [17]: s\nOut[17]: \n0    2013-01-01\n1    2013-01-02\n2    2013-01-03\n3    2013-01-04\nLength: 4, dtype: period[D]\n\nIn [18]: s.dt.strftime(\"%Y/%m/%d\")\nOut[18]: \n0    2013/01/01\n1    2013/01/02\n2    2013/01/03\n3    2013/01/04\nLength: 4, dtype: object \n```", "```py\n# TimedeltaIndex\nIn [19]: s = pd.Series(pd.timedelta_range(\"1 minutes\", periods=4))\n\nIn [20]: s\nOut[20]: \n0   0 days 00:01:00\n1   1 days 00:01:00\n2   2 days 00:01:00\n3   3 days 00:01:00\nLength: 4, dtype: timedelta64[ns]\n\nIn [21]: s.dt.total_seconds()\nOut[21]: \n0        60.0\n1     86460.0\n2    172860.0\n3    259260.0\nLength: 4, dtype: float64 \n```", "```py\nIn [22]: p = pd.Period(\"2015-08-01\", freq=\"3D\")\n\nIn [23]: p\nOut[23]: Period('2015-08-01', '3D')\n\nIn [24]: p + 1\nOut[24]: Period('2015-08-04', '3D')\n\nIn [25]: p - 2\nOut[25]: Period('2015-07-26', '3D')\n\nIn [26]: p.to_timestamp()\nOut[26]: Timestamp('2015-08-01 00:00:00')\n\nIn [27]: p.to_timestamp(how=\"E\")\nOut[27]: Timestamp('2015-08-03 23:59:59.999999999') \n```", "```py\nIn [28]: idx = pd.period_range(\"2015-08-01\", periods=4, freq=\"2D\")\n\nIn [29]: idx\nOut[29]: PeriodIndex(['2015-08-01', '2015-08-03', '2015-08-05', '2015-08-07'], dtype='period[2D]')\n\nIn [30]: idx + 1\nOut[30]: PeriodIndex(['2015-08-03', '2015-08-05', '2015-08-07', '2015-08-09'], dtype='period[2D]') \n```", "```py\ndf = pd.read_sas(\"sas_xport.xpt\") \n```", "```py\nfor df in pd.read_sas(\"sas_xport.xpt\", chunksize=10000):\n    do_something(df) \n```", "```py\ndf = pd.DataFrame({\"a\": np.random.randn(10)})\ndf.eval(\"b = sin(a)\") \n```", "```py\nIn [31]: df = pd.DataFrame(\n ....:    [[1, 2, 3, 4], [5, 6, 7, 8]],\n ....:    columns=pd.MultiIndex.from_product(\n ....:        [[\"foo\", \"bar\"], [\"a\", \"b\"]], names=[\"col1\", \"col2\"]\n ....:    ),\n ....:    index=pd.MultiIndex.from_product([[\"j\"], [\"l\", \"k\"]], names=[\"i1\", \"i2\"]),\n ....: )\n ....: \n\nIn [32]: df\nOut[32]: \ncol1  foo    bar \ncol2    a  b   a  b\ni1 i2 \nj  l    1  2   3  4\n k    5  6   7  8\n\n[2 rows x 4 columns]\n\nIn [33]: df.to_excel(\"test.xlsx\")\n\nIn [34]: df = pd.read_excel(\"test.xlsx\", header=[0, 1], index_col=[0, 1])\n\nIn [35]: df\nOut[35]: \ncol1  foo    bar \ncol2    a  b   a  b\ni1 i2 \nj  l    1  2   3  4\n k    5  6   7  8\n\n[2 rows x 4 columns] \n```", "```py\nIn [36]: df = pd.DataFrame({u\"\u56fd\u7c4d\": [\"UK\", u\"\u65e5\u672c\"], u\"\u540d\u524d\": [\"Alice\", u\"\u3057\u306e\u3076\"]})\n\nIn [37]: df\nOut[37]: \n \u56fd\u7c4d     \u540d\u524d\n0  UK  Alice\n1  \u65e5\u672c    \u3057\u306e\u3076\n\n[2 rows x 2 columns] \n```", "```py\nIn [38]: pd.set_option(\"display.unicode.east_asian_width\", True)\n\nIn [39]: df\nOut[39]: \n \u56fd\u7c4d    \u540d\u524d\n0    UK   Alice\n1  \u65e5\u672c  \u3057\u306e\u3076\n\n[2 rows x 2 columns] \n```", "```py\n    In [40]: df1 = pd.DataFrame({\"col1\": [0, 1], \"col_left\": [\"a\", \"b\"]})\n\n    In [41]: df2 = pd.DataFrame({\"col1\": [1, 2, 2], \"col_right\": [2, 2, 2]})\n\n    In [42]: pd.merge(df1, df2, on=\"col1\", how=\"outer\", indicator=True)\n    Out[42]: \n     col1 col_left  col_right      _merge\n    0     0        a        NaN   left_only\n    1     1        b        2.0        both\n    2     2      NaN        2.0  right_only\n    3     2      NaN        2.0  right_only\n\n    [4 rows x 4 columns] \n    ```", "```py\n    In [43]: foo = pd.Series([1, 2], name=\"foo\")\n\n    In [44]: bar = pd.Series([1, 2])\n\n    In [45]: baz = pd.Series([4, 5]) \n    ```", "```py\n    In [1]: pd.concat([foo, bar, baz], axis=1)\n    Out[1]:\n     0  1  2\n     0  1  1  4\n     1  2  2  5 \n    ```", "```py\n    In [46]: pd.concat([foo, bar, baz], axis=1)\n    Out[46]: \n     foo  0  1\n    0    1  1  4\n    1    2  2  5\n\n    [2 rows x 3 columns] \n    ```", "```py\n    In [47]: ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan, np.nan, 13])\n\n    In [48]: ser.interpolate(limit=1, limit_direction=\"both\")\n    Out[48]: \n    0     NaN\n    1     5.0\n    2     5.0\n    3     7.0\n    4     NaN\n    5    11.0\n    6    13.0\n    Length: 7, dtype: float64 \n    ```", "```py\n    In [49]: df = pd.DataFrame(\n     ....:    np.random.random([3, 3]),\n     ....:    columns=[\"A\", \"B\", \"C\"],\n     ....:    index=[\"first\", \"second\", \"third\"],\n     ....: )\n     ....: \n\n    In [50]: df\n    Out[50]: \n     A         B         C\n    first   0.126970  0.966718  0.260476\n    second  0.897237  0.376750  0.336222\n    third   0.451376  0.840255  0.123102\n\n    [3 rows x 3 columns]\n\n    In [51]: df.round(2)\n    Out[51]: \n     A     B     C\n    first   0.13  0.97  0.26\n    second  0.90  0.38  0.34\n    third   0.45  0.84  0.12\n\n    [3 rows x 3 columns]\n\n    In [52]: df.round({\"A\": 0, \"C\": 2})\n    Out[52]: \n     A         B     C\n    first   0.0  0.966718  0.26\n    second  1.0  0.376750  0.34\n    third   0.0  0.840255  0.12\n\n    [3 rows x 3 columns] \n    ```", "```py\n    In [53]: s = pd.Series([\"A\", \"B\", \"C\", \"A\", \"B\", \"D\"])\n\n    In [54]: s.drop_duplicates()\n    Out[54]: \n    0    A\n    1    B\n    2    C\n    5    D\n    Length: 4, dtype: object\n\n    In [55]: s.drop_duplicates(keep=\"last\")\n    Out[55]: \n    2    C\n    3    A\n    4    B\n    5    D\n    Length: 4, dtype: object\n\n    In [56]: s.drop_duplicates(keep=False)\n    Out[56]: \n    2    C\n    5    D\n    Length: 2, dtype: object \n    ```", "```py\n    In [57]: df = pd.DataFrame({\"x\": range(5), \"t\": pd.date_range(\"2000-01-01\", periods=5)})\n\n    In [58]: df.reindex([0.1, 1.9, 3.5], method=\"nearest\", tolerance=0.2)\n    Out[58]: \n     x          t\n    0.1  0.0 2000-01-01\n    1.9  2.0 2000-01-03\n    3.5  NaN        NaT\n\n    [3 rows x 2 columns] \n    ```", "```py\n    In [59]: df = df.set_index(\"t\")\n\n    In [60]: df.reindex(pd.to_datetime([\"1999-12-31\"]), method=\"nearest\", tolerance=\"1 day\")\n    Out[60]: \n     x\n    1999-12-31  0\n\n    [1 rows x 1 columns] \n    ```", "```py\nIn [1]: df = pd.DataFrame(\n ...:    {\n ...:        \"A\": pd.date_range(\"20130101\", periods=3),\n ...:        \"B\": pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\"),\n ...:        \"C\": pd.date_range(\"20130101\", periods=3, tz=\"CET\"),\n ...:    }\n ...: )\n ...: \n\nIn [2]: df\nOut[2]: \n A                         B                         C\n0 2013-01-01 2013-01-01 00:00:00-05:00 2013-01-01 00:00:00+01:00\n1 2013-01-02 2013-01-02 00:00:00-05:00 2013-01-02 00:00:00+01:00\n2 2013-01-03 2013-01-03 00:00:00-05:00 2013-01-03 00:00:00+01:00\n\n[3 rows x 3 columns]\n\nIn [3]: df.dtypes\nOut[3]: \nA                datetime64[ns]\nB    datetime64[ns, US/Eastern]\nC           datetime64[ns, CET]\nLength: 3, dtype: object \n```", "```py\nIn [4]: df.B\nOut[4]: \n0   2013-01-01 00:00:00-05:00\n1   2013-01-02 00:00:00-05:00\n2   2013-01-03 00:00:00-05:00\nName: B, Length: 3, dtype: datetime64[ns, US/Eastern]\n\nIn [5]: df.B.dt.tz_localize(None)\nOut[5]: \n0   2013-01-01\n1   2013-01-02\n2   2013-01-03\nName: B, Length: 3, dtype: datetime64[ns] \n```", "```py\nIn [6]: df[\"B\"].dtype\nOut[6]: datetime64[ns, US/Eastern]\n\nIn [7]: type(df[\"B\"].dtype)\nOut[7]: pandas.core.dtypes.dtypes.DatetimeTZDtype \n```", "```py\nIn [1]: pd.date_range('20130101', periods=3, tz='US/Eastern')\nOut[1]: DatetimeIndex(['2013-01-01 00:00:00-05:00', '2013-01-02 00:00:00-05:00',\n '2013-01-03 00:00:00-05:00'],\n dtype='datetime64[ns]', freq='D', tz='US/Eastern')\n\nIn [2]: pd.date_range('20130101', periods=3, tz='US/Eastern').dtype\nOut[2]: dtype('<M8[ns]') \n```", "```py\nIn [8]: pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\")\nOut[8]: \nDatetimeIndex(['2013-01-01 00:00:00-05:00', '2013-01-02 00:00:00-05:00',\n '2013-01-03 00:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq='D')\n\nIn [9]: pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\").dtype\nOut[9]: datetime64[ns, US/Eastern] \n```", "```py\nN = 1000000\nngroups = 10\ndf = DataFrame(\n    {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n)\ndf.groupby(\"key\")[\"data\"].sum() \n```", "```py\nIn [10]: df = pd.DataFrame(np.random.rand(10, 2), columns=['a', 'b'])\n\nIn [11]: df.plot.bar() \n```", "```py\nIn [12]: df.plot.<TAB>  # noqa: E225, E999\ndf.plot.area     df.plot.barh     df.plot.density  df.plot.hist     df.plot.line     df.plot.scatter\ndf.plot.bar      df.plot.box      df.plot.hexbin   df.plot.kde      df.plot.pie \n```", "```py\n# DatetimeIndex\nIn [13]: s = pd.Series(pd.date_range(\"20130101\", periods=4))\n\nIn [14]: s\nOut[14]: \n0   2013-01-01\n1   2013-01-02\n2   2013-01-03\n3   2013-01-04\nLength: 4, dtype: datetime64[ns]\n\nIn [15]: s.dt.strftime(\"%Y/%m/%d\")\nOut[15]: \n0    2013/01/01\n1    2013/01/02\n2    2013/01/03\n3    2013/01/04\nLength: 4, dtype: object \n```", "```py\n# PeriodIndex\nIn [16]: s = pd.Series(pd.period_range(\"20130101\", periods=4))\n\nIn [17]: s\nOut[17]: \n0    2013-01-01\n1    2013-01-02\n2    2013-01-03\n3    2013-01-04\nLength: 4, dtype: period[D]\n\nIn [18]: s.dt.strftime(\"%Y/%m/%d\")\nOut[18]: \n0    2013/01/01\n1    2013/01/02\n2    2013/01/03\n3    2013/01/04\nLength: 4, dtype: object \n```", "```py\n# TimedeltaIndex\nIn [19]: s = pd.Series(pd.timedelta_range(\"1 minutes\", periods=4))\n\nIn [20]: s\nOut[20]: \n0   0 days 00:01:00\n1   1 days 00:01:00\n2   2 days 00:01:00\n3   3 days 00:01:00\nLength: 4, dtype: timedelta64[ns]\n\nIn [21]: s.dt.total_seconds()\nOut[21]: \n0        60.0\n1     86460.0\n2    172860.0\n3    259260.0\nLength: 4, dtype: float64 \n```", "```py\n# DatetimeIndex\nIn [13]: s = pd.Series(pd.date_range(\"20130101\", periods=4))\n\nIn [14]: s\nOut[14]: \n0   2013-01-01\n1   2013-01-02\n2   2013-01-03\n3   2013-01-04\nLength: 4, dtype: datetime64[ns]\n\nIn [15]: s.dt.strftime(\"%Y/%m/%d\")\nOut[15]: \n0    2013/01/01\n1    2013/01/02\n2    2013/01/03\n3    2013/01/04\nLength: 4, dtype: object \n```", "```py\n# PeriodIndex\nIn [16]: s = pd.Series(pd.period_range(\"20130101\", periods=4))\n\nIn [17]: s\nOut[17]: \n0    2013-01-01\n1    2013-01-02\n2    2013-01-03\n3    2013-01-04\nLength: 4, dtype: period[D]\n\nIn [18]: s.dt.strftime(\"%Y/%m/%d\")\nOut[18]: \n0    2013/01/01\n1    2013/01/02\n2    2013/01/03\n3    2013/01/04\nLength: 4, dtype: object \n```", "```py\n# TimedeltaIndex\nIn [19]: s = pd.Series(pd.timedelta_range(\"1 minutes\", periods=4))\n\nIn [20]: s\nOut[20]: \n0   0 days 00:01:00\n1   1 days 00:01:00\n2   2 days 00:01:00\n3   3 days 00:01:00\nLength: 4, dtype: timedelta64[ns]\n\nIn [21]: s.dt.total_seconds()\nOut[21]: \n0        60.0\n1     86460.0\n2    172860.0\n3    259260.0\nLength: 4, dtype: float64 \n```", "```py\nIn [22]: p = pd.Period(\"2015-08-01\", freq=\"3D\")\n\nIn [23]: p\nOut[23]: Period('2015-08-01', '3D')\n\nIn [24]: p + 1\nOut[24]: Period('2015-08-04', '3D')\n\nIn [25]: p - 2\nOut[25]: Period('2015-07-26', '3D')\n\nIn [26]: p.to_timestamp()\nOut[26]: Timestamp('2015-08-01 00:00:00')\n\nIn [27]: p.to_timestamp(how=\"E\")\nOut[27]: Timestamp('2015-08-03 23:59:59.999999999') \n```", "```py\nIn [28]: idx = pd.period_range(\"2015-08-01\", periods=4, freq=\"2D\")\n\nIn [29]: idx\nOut[29]: PeriodIndex(['2015-08-01', '2015-08-03', '2015-08-05', '2015-08-07'], dtype='period[2D]')\n\nIn [30]: idx + 1\nOut[30]: PeriodIndex(['2015-08-03', '2015-08-05', '2015-08-07', '2015-08-09'], dtype='period[2D]') \n```", "```py\ndf = pd.read_sas(\"sas_xport.xpt\") \n```", "```py\nfor df in pd.read_sas(\"sas_xport.xpt\", chunksize=10000):\n    do_something(df) \n```", "```py\ndf = pd.DataFrame({\"a\": np.random.randn(10)})\ndf.eval(\"b = sin(a)\") \n```", "```py\nIn [31]: df = pd.DataFrame(\n ....:    [[1, 2, 3, 4], [5, 6, 7, 8]],\n ....:    columns=pd.MultiIndex.from_product(\n ....:        [[\"foo\", \"bar\"], [\"a\", \"b\"]], names=[\"col1\", \"col2\"]\n ....:    ),\n ....:    index=pd.MultiIndex.from_product([[\"j\"], [\"l\", \"k\"]], names=[\"i1\", \"i2\"]),\n ....: )\n ....: \n\nIn [32]: df\nOut[32]: \ncol1  foo    bar \ncol2    a  b   a  b\ni1 i2 \nj  l    1  2   3  4\n k    5  6   7  8\n\n[2 rows x 4 columns]\n\nIn [33]: df.to_excel(\"test.xlsx\")\n\nIn [34]: df = pd.read_excel(\"test.xlsx\", header=[0, 1], index_col=[0, 1])\n\nIn [35]: df\nOut[35]: \ncol1  foo    bar \ncol2    a  b   a  b\ni1 i2 \nj  l    1  2   3  4\n k    5  6   7  8\n\n[2 rows x 4 columns] \n```", "```py\nIn [36]: df = pd.DataFrame({u\"\u56fd\u7c4d\": [\"UK\", u\"\u65e5\u672c\"], u\"\u540d\u524d\": [\"Alice\", u\"\u3057\u306e\u3076\"]})\n\nIn [37]: df\nOut[37]: \n \u56fd\u7c4d     \u540d\u524d\n0  UK  Alice\n1  \u65e5\u672c    \u3057\u306e\u3076\n\n[2 rows x 2 columns] \n```", "```py\nIn [38]: pd.set_option(\"display.unicode.east_asian_width\", True)\n\nIn [39]: df\nOut[39]: \n \u56fd\u7c4d    \u540d\u524d\n0    UK   Alice\n1  \u65e5\u672c  \u3057\u306e\u3076\n\n[2 rows x 2 columns] \n```", "```py\n    In [40]: df1 = pd.DataFrame({\"col1\": [0, 1], \"col_left\": [\"a\", \"b\"]})\n\n    In [41]: df2 = pd.DataFrame({\"col1\": [1, 2, 2], \"col_right\": [2, 2, 2]})\n\n    In [42]: pd.merge(df1, df2, on=\"col1\", how=\"outer\", indicator=True)\n    Out[42]: \n     col1 col_left  col_right      _merge\n    0     0        a        NaN   left_only\n    1     1        b        2.0        both\n    2     2      NaN        2.0  right_only\n    3     2      NaN        2.0  right_only\n\n    [4 rows x 4 columns] \n    ```", "```py\n    In [43]: foo = pd.Series([1, 2], name=\"foo\")\n\n    In [44]: bar = pd.Series([1, 2])\n\n    In [45]: baz = pd.Series([4, 5]) \n    ```", "```py\n    In [1]: pd.concat([foo, bar, baz], axis=1)\n    Out[1]:\n     0  1  2\n     0  1  1  4\n     1  2  2  5 \n    ```", "```py\n    In [46]: pd.concat([foo, bar, baz], axis=1)\n    Out[46]: \n     foo  0  1\n    0    1  1  4\n    1    2  2  5\n\n    [2 rows x 3 columns] \n    ```", "```py\n    In [47]: ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan, np.nan, 13])\n\n    In [48]: ser.interpolate(limit=1, limit_direction=\"both\")\n    Out[48]: \n    0     NaN\n    1     5.0\n    2     5.0\n    3     7.0\n    4     NaN\n    5    11.0\n    6    13.0\n    Length: 7, dtype: float64 \n    ```", "```py\n    In [49]: df = pd.DataFrame(\n     ....:    np.random.random([3, 3]),\n     ....:    columns=[\"A\", \"B\", \"C\"],\n     ....:    index=[\"first\", \"second\", \"third\"],\n     ....: )\n     ....: \n\n    In [50]: df\n    Out[50]: \n     A         B         C\n    first   0.126970  0.966718  0.260476\n    second  0.897237  0.376750  0.336222\n    third   0.451376  0.840255  0.123102\n\n    [3 rows x 3 columns]\n\n    In [51]: df.round(2)\n    Out[51]: \n     A     B     C\n    first   0.13  0.97  0.26\n    second  0.90  0.38  0.34\n    third   0.45  0.84  0.12\n\n    [3 rows x 3 columns]\n\n    In [52]: df.round({\"A\": 0, \"C\": 2})\n    Out[52]: \n     A         B     C\n    first   0.0  0.966718  0.26\n    second  1.0  0.376750  0.34\n    third   0.0  0.840255  0.12\n\n    [3 rows x 3 columns] \n    ```", "```py\n    In [53]: s = pd.Series([\"A\", \"B\", \"C\", \"A\", \"B\", \"D\"])\n\n    In [54]: s.drop_duplicates()\n    Out[54]: \n    0    A\n    1    B\n    2    C\n    5    D\n    Length: 4, dtype: object\n\n    In [55]: s.drop_duplicates(keep=\"last\")\n    Out[55]: \n    2    C\n    3    A\n    4    B\n    5    D\n    Length: 4, dtype: object\n\n    In [56]: s.drop_duplicates(keep=False)\n    Out[56]: \n    2    C\n    5    D\n    Length: 2, dtype: object \n    ```", "```py\n    In [57]: df = pd.DataFrame({\"x\": range(5), \"t\": pd.date_range(\"2000-01-01\", periods=5)})\n\n    In [58]: df.reindex([0.1, 1.9, 3.5], method=\"nearest\", tolerance=0.2)\n    Out[58]: \n     x          t\n    0.1  0.0 2000-01-01\n    1.9  2.0 2000-01-03\n    3.5  NaN        NaT\n\n    [3 rows x 2 columns] \n    ```", "```py\n    In [59]: df = df.set_index(\"t\")\n\n    In [60]: df.reindex(pd.to_datetime([\"1999-12-31\"]), method=\"nearest\", tolerance=\"1 day\")\n    Out[60]: \n     x\n    1999-12-31  0\n\n    [1 rows x 1 columns] \n    ```", "```py\nIn [2]: pd.to_datetime(['2009-07-31', 'asd'])\nOut[2]: array(['2009-07-31', 'asd'], dtype=object) \n```", "```py\nIn [3]: pd.to_datetime(['2009-07-31', 'asd'])\nValueError: Unknown string format \n```", "```py\nIn [61]: pd.to_datetime([\"2009-07-31\", \"asd\"], errors=\"coerce\")\nOut[61]: DatetimeIndex(['2009-07-31', 'NaT'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [4]: pd.to_datetime([\"2009-07-31\", \"asd\"], errors=\"ignore\")\nOut[4]: Index(['2009-07-31', 'asd'], dtype='object') \n```", "```py\nIn [1]: pd.Timestamp('2012Q2')\nTraceback\n ...\nValueError: Unable to parse 2012Q2\n\n# Results in today's date.\nIn [2]: pd.Timestamp('2014')\nOut [2]: 2014-08-12 00:00:00 \n```", "```py\nIn [62]: pd.Timestamp(\"2012Q2\")\nOut[62]: Timestamp('2012-04-01 00:00:00')\n\nIn [63]: pd.Timestamp(\"2014\")\nOut[63]: Timestamp('2014-01-01 00:00:00')\n\nIn [64]: pd.DatetimeIndex([\"2012Q2\", \"2014\"])\nOut[64]: DatetimeIndex(['2012-04-01', '2014-01-01'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [65]: import pandas.tseries.offsets as offsets\n\nIn [66]: pd.Timestamp.now()\nOut[66]: Timestamp('2024-04-10 17:55:56.541543')\n\nIn [67]: pd.Timestamp.now() + offsets.DateOffset(years=1)\nOut[67]: Timestamp('2025-04-10 17:55:56.542277') \n```", "```py\nIn [2]: pd.Index([1, 2, 3]) == pd.Index([1, 4, 5])\nOut[2]: array([ True, False, False], dtype=bool)\n\nIn [3]: pd.Index([1, 2, 3]) == pd.Index([2])\nOut[3]: array([False,  True, False], dtype=bool)\n\nIn [4]: pd.Index([1, 2, 3]) == pd.Index([1, 2])\nOut[4]: False \n```", "```py\nIn [8]: pd.Index([1, 2, 3]) == pd.Index([1, 4, 5])\nOut[8]: array([ True, False, False], dtype=bool)\n\nIn [9]: pd.Index([1, 2, 3]) == pd.Index([2])\nValueError: Lengths must match to compare\n\nIn [10]: pd.Index([1, 2, 3]) == pd.Index([1, 2])\nValueError: Lengths must match to compare \n```", "```py\nIn [68]: np.array([1, 2, 3]) == np.array([1])\nOut[68]: array([ True, False, False]) \n```", "```py\nIn [11]: np.array([1, 2, 3]) == np.array([1, 2])\nOut[11]: False \n```", "```py\nIn [69]: s = pd.Series(range(3), dtype=\"float\")\n\nIn [70]: s.iloc[1] = None\n\nIn [71]: s\nOut[71]: \n0    0.0\n1    NaN\n2    2.0\nLength: 3, dtype: float64 \n```", "```py\nIn [5]: s == None\nTypeError: Could not compare <type 'NoneType'> type with Series \n```", "```py\nIn [72]: s == None\nOut[72]: \n0    False\n1    False\n2    False\nLength: 3, dtype: bool \n```", "```py\nIn [73]: s.isnull()\nOut[73]: \n0    False\n1     True\n2    False\nLength: 3, dtype: bool \n```", "```py\nIn [74]: None == None\nOut[74]: True\n\nIn [75]: np.nan == np.nan\nOut[75]: False \n```", "```py\nIn [76]: df_with_missing = pd.DataFrame(\n ....:    {\"col1\": [0, np.nan, 2], \"col2\": [1, np.nan, np.nan]}\n ....: )\n ....: \n\nIn [77]: df_with_missing\nOut[77]: \n col1  col2\n0   0.0   1.0\n1   NaN   NaN\n2   2.0   NaN\n\n[3 rows x 2 columns] \n```", "```py\nIn [27]:\ndf_with_missing.to_hdf('file.h5',\n key='df_with_missing',\n format='table',\n mode='w')\n\nIn [28]: pd.read_hdf('file.h5', 'df_with_missing')\n\nOut [28]:\n col1  col2\n 0     0     1\n 2     2   NaN \n```", "```py\nIn [78]: df_with_missing.to_hdf(\"file.h5\", key=\"df_with_missing\", format=\"table\", mode=\"w\")\n\nIn [79]: pd.read_hdf(\"file.h5\", \"df_with_missing\")\nOut[79]: \n col1  col2\n0   0.0   1.0\n1   NaN   NaN\n2   2.0   NaN\n\n[3 rows x 2 columns] \n```", "```py\nIn [1]: pd.set_option('display.precision', 2)\n\nIn [2]: pd.DataFrame({'x': [123.456789]})\nOut[2]:\n x\n0  123.5 \n```", "```py\nIn [80]: pd.set_option(\"display.precision\", 2)\n\nIn [81]: pd.DataFrame({\"x\": [123.456789]})\nOut[81]: \n x\n0  123.46\n\n[1 rows x 1 columns] \n```", "```py\nIn [82]: cat = pd.Categorical([\"C\", \"A\", \"B\", \"C\"], categories=[\"A\", \"B\", \"C\"], ordered=True)\n\nIn [83]: cat\nOut[83]: \n['C', 'A', 'B', 'C']\nCategories (3, object): ['A' < 'B' < 'C']\n\nIn [84]: cat.unique()\nOut[84]: \n['C', 'A', 'B']\nCategories (3, object): ['A' < 'B' < 'C']\n\nIn [85]: cat = pd.Categorical([\"C\", \"A\", \"B\", \"C\"], categories=[\"A\", \"B\", \"C\"])\n\nIn [86]: cat\nOut[86]: \n['C', 'A', 'B', 'C']\nCategories (3, object): ['A', 'B', 'C']\n\nIn [87]: cat.unique()\nOut[87]: \n['C', 'A', 'B']\nCategories (3, object): ['A', 'B', 'C'] \n```", "```py\nIn [29]: df = pd.read_csv('data.csv', header=False)\nTypeError: Passing a bool to header is invalid. Use header=None for no header or\nheader=int or list-like of ints to specify the row(s) making up the column names \n```", "```py\n    In [88]: np.random.seed(1234)\n\n    In [89]: df = pd.DataFrame(\n     ....:    np.random.randn(5, 2),\n     ....:    columns=list(\"AB\"),\n     ....:    index=pd.date_range(\"2013-01-01\", periods=5),\n     ....: )\n     ....: \n\n    In [90]: df\n    Out[90]: \n     A         B\n    2013-01-01  0.471435 -1.190976\n    2013-01-02  1.432707 -0.312652\n    2013-01-03 -0.720589  0.887163\n    2013-01-04  0.859588 -0.636524\n    2013-01-05  0.015696 -2.242685\n\n    [5 rows x 2 columns] \n    ```", "```py\n    In [3]: df + df.A\n    FutureWarning: TimeSeries broadcasting along DataFrame index by default is deprecated.\n    Please use DataFrame.<op> to explicitly broadcast arithmetic operations along the index\n\n    Out[3]:\n     A         B\n    2013-01-01  0.942870 -0.719541\n    2013-01-02  2.865414  1.120055\n    2013-01-03 -1.441177  0.166574\n    2013-01-04  1.719177  0.223065\n    2013-01-05  0.031393 -2.226989 \n    ```", "```py\n    In [91]: df.add(df.A, axis=\"index\")\n    Out[91]: \n     A         B\n    2013-01-01  0.942870 -0.719541\n    2013-01-02  2.865414  1.120055\n    2013-01-03 -1.441177  0.166574\n    2013-01-04  1.719177  0.223065\n    2013-01-05  0.031393 -2.226989\n\n    [5 rows x 2 columns] \n    ```", "```py\nIn [2]: pd.to_datetime(['2009-07-31', 'asd'])\nOut[2]: array(['2009-07-31', 'asd'], dtype=object) \n```", "```py\nIn [3]: pd.to_datetime(['2009-07-31', 'asd'])\nValueError: Unknown string format \n```", "```py\nIn [61]: pd.to_datetime([\"2009-07-31\", \"asd\"], errors=\"coerce\")\nOut[61]: DatetimeIndex(['2009-07-31', 'NaT'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [4]: pd.to_datetime([\"2009-07-31\", \"asd\"], errors=\"ignore\")\nOut[4]: Index(['2009-07-31', 'asd'], dtype='object') \n```", "```py\nIn [1]: pd.Timestamp('2012Q2')\nTraceback\n ...\nValueError: Unable to parse 2012Q2\n\n# Results in today's date.\nIn [2]: pd.Timestamp('2014')\nOut [2]: 2014-08-12 00:00:00 \n```", "```py\nIn [62]: pd.Timestamp(\"2012Q2\")\nOut[62]: Timestamp('2012-04-01 00:00:00')\n\nIn [63]: pd.Timestamp(\"2014\")\nOut[63]: Timestamp('2014-01-01 00:00:00')\n\nIn [64]: pd.DatetimeIndex([\"2012Q2\", \"2014\"])\nOut[64]: DatetimeIndex(['2012-04-01', '2014-01-01'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [65]: import pandas.tseries.offsets as offsets\n\nIn [66]: pd.Timestamp.now()\nOut[66]: Timestamp('2024-04-10 17:55:56.541543')\n\nIn [67]: pd.Timestamp.now() + offsets.DateOffset(years=1)\nOut[67]: Timestamp('2025-04-10 17:55:56.542277') \n```", "```py\nIn [2]: pd.to_datetime(['2009-07-31', 'asd'])\nOut[2]: array(['2009-07-31', 'asd'], dtype=object) \n```", "```py\nIn [3]: pd.to_datetime(['2009-07-31', 'asd'])\nValueError: Unknown string format \n```", "```py\nIn [61]: pd.to_datetime([\"2009-07-31\", \"asd\"], errors=\"coerce\")\nOut[61]: DatetimeIndex(['2009-07-31', 'NaT'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [4]: pd.to_datetime([\"2009-07-31\", \"asd\"], errors=\"ignore\")\nOut[4]: Index(['2009-07-31', 'asd'], dtype='object') \n```", "```py\nIn [1]: pd.Timestamp('2012Q2')\nTraceback\n ...\nValueError: Unable to parse 2012Q2\n\n# Results in today's date.\nIn [2]: pd.Timestamp('2014')\nOut [2]: 2014-08-12 00:00:00 \n```", "```py\nIn [62]: pd.Timestamp(\"2012Q2\")\nOut[62]: Timestamp('2012-04-01 00:00:00')\n\nIn [63]: pd.Timestamp(\"2014\")\nOut[63]: Timestamp('2014-01-01 00:00:00')\n\nIn [64]: pd.DatetimeIndex([\"2012Q2\", \"2014\"])\nOut[64]: DatetimeIndex(['2012-04-01', '2014-01-01'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [65]: import pandas.tseries.offsets as offsets\n\nIn [66]: pd.Timestamp.now()\nOut[66]: Timestamp('2024-04-10 17:55:56.541543')\n\nIn [67]: pd.Timestamp.now() + offsets.DateOffset(years=1)\nOut[67]: Timestamp('2025-04-10 17:55:56.542277') \n```", "```py\nIn [2]: pd.Index([1, 2, 3]) == pd.Index([1, 4, 5])\nOut[2]: array([ True, False, False], dtype=bool)\n\nIn [3]: pd.Index([1, 2, 3]) == pd.Index([2])\nOut[3]: array([False,  True, False], dtype=bool)\n\nIn [4]: pd.Index([1, 2, 3]) == pd.Index([1, 2])\nOut[4]: False \n```", "```py\nIn [8]: pd.Index([1, 2, 3]) == pd.Index([1, 4, 5])\nOut[8]: array([ True, False, False], dtype=bool)\n\nIn [9]: pd.Index([1, 2, 3]) == pd.Index([2])\nValueError: Lengths must match to compare\n\nIn [10]: pd.Index([1, 2, 3]) == pd.Index([1, 2])\nValueError: Lengths must match to compare \n```", "```py\nIn [68]: np.array([1, 2, 3]) == np.array([1])\nOut[68]: array([ True, False, False]) \n```", "```py\nIn [11]: np.array([1, 2, 3]) == np.array([1, 2])\nOut[11]: False \n```", "```py\nIn [69]: s = pd.Series(range(3), dtype=\"float\")\n\nIn [70]: s.iloc[1] = None\n\nIn [71]: s\nOut[71]: \n0    0.0\n1    NaN\n2    2.0\nLength: 3, dtype: float64 \n```", "```py\nIn [5]: s == None\nTypeError: Could not compare <type 'NoneType'> type with Series \n```", "```py\nIn [72]: s == None\nOut[72]: \n0    False\n1    False\n2    False\nLength: 3, dtype: bool \n```", "```py\nIn [73]: s.isnull()\nOut[73]: \n0    False\n1     True\n2    False\nLength: 3, dtype: bool \n```", "```py\nIn [74]: None == None\nOut[74]: True\n\nIn [75]: np.nan == np.nan\nOut[75]: False \n```", "```py\nIn [76]: df_with_missing = pd.DataFrame(\n ....:    {\"col1\": [0, np.nan, 2], \"col2\": [1, np.nan, np.nan]}\n ....: )\n ....: \n\nIn [77]: df_with_missing\nOut[77]: \n col1  col2\n0   0.0   1.0\n1   NaN   NaN\n2   2.0   NaN\n\n[3 rows x 2 columns] \n```", "```py\nIn [27]:\ndf_with_missing.to_hdf('file.h5',\n key='df_with_missing',\n format='table',\n mode='w')\n\nIn [28]: pd.read_hdf('file.h5', 'df_with_missing')\n\nOut [28]:\n col1  col2\n 0     0     1\n 2     2   NaN \n```", "```py\nIn [78]: df_with_missing.to_hdf(\"file.h5\", key=\"df_with_missing\", format=\"table\", mode=\"w\")\n\nIn [79]: pd.read_hdf(\"file.h5\", \"df_with_missing\")\nOut[79]: \n col1  col2\n0   0.0   1.0\n1   NaN   NaN\n2   2.0   NaN\n\n[3 rows x 2 columns] \n```", "```py\nIn [1]: pd.set_option('display.precision', 2)\n\nIn [2]: pd.DataFrame({'x': [123.456789]})\nOut[2]:\n x\n0  123.5 \n```", "```py\nIn [80]: pd.set_option(\"display.precision\", 2)\n\nIn [81]: pd.DataFrame({\"x\": [123.456789]})\nOut[81]: \n x\n0  123.46\n\n[1 rows x 1 columns] \n```", "```py\nIn [82]: cat = pd.Categorical([\"C\", \"A\", \"B\", \"C\"], categories=[\"A\", \"B\", \"C\"], ordered=True)\n\nIn [83]: cat\nOut[83]: \n['C', 'A', 'B', 'C']\nCategories (3, object): ['A' < 'B' < 'C']\n\nIn [84]: cat.unique()\nOut[84]: \n['C', 'A', 'B']\nCategories (3, object): ['A' < 'B' < 'C']\n\nIn [85]: cat = pd.Categorical([\"C\", \"A\", \"B\", \"C\"], categories=[\"A\", \"B\", \"C\"])\n\nIn [86]: cat\nOut[86]: \n['C', 'A', 'B', 'C']\nCategories (3, object): ['A', 'B', 'C']\n\nIn [87]: cat.unique()\nOut[87]: \n['C', 'A', 'B']\nCategories (3, object): ['A', 'B', 'C'] \n```", "```py\nIn [29]: df = pd.read_csv('data.csv', header=False)\nTypeError: Passing a bool to header is invalid. Use header=None for no header or\nheader=int or list-like of ints to specify the row(s) making up the column names \n```", "```py\n    In [88]: np.random.seed(1234)\n\n    In [89]: df = pd.DataFrame(\n     ....:    np.random.randn(5, 2),\n     ....:    columns=list(\"AB\"),\n     ....:    index=pd.date_range(\"2013-01-01\", periods=5),\n     ....: )\n     ....: \n\n    In [90]: df\n    Out[90]: \n     A         B\n    2013-01-01  0.471435 -1.190976\n    2013-01-02  1.432707 -0.312652\n    2013-01-03 -0.720589  0.887163\n    2013-01-04  0.859588 -0.636524\n    2013-01-05  0.015696 -2.242685\n\n    [5 rows x 2 columns] \n    ```", "```py\n    In [3]: df + df.A\n    FutureWarning: TimeSeries broadcasting along DataFrame index by default is deprecated.\n    Please use DataFrame.<op> to explicitly broadcast arithmetic operations along the index\n\n    Out[3]:\n     A         B\n    2013-01-01  0.942870 -0.719541\n    2013-01-02  2.865414  1.120055\n    2013-01-03 -1.441177  0.166574\n    2013-01-04  1.719177  0.223065\n    2013-01-05  0.031393 -2.226989 \n    ```", "```py\n    In [91]: df.add(df.A, axis=\"index\")\n    Out[91]: \n     A         B\n    2013-01-01  0.942870 -0.719541\n    2013-01-02  2.865414  1.120055\n    2013-01-03 -1.441177  0.166574\n    2013-01-04  1.719177  0.223065\n    2013-01-05  0.031393 -2.226989\n\n    [5 rows x 2 columns] \n    ```"]