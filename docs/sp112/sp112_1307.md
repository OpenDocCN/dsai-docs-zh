# `scipy.stats.pearsonr`

> 原文链接：[`docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.stats.pearsonr.html#scipy.stats.pearsonr`](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.stats.pearsonr.html#scipy.stats.pearsonr)

```py
scipy.stats.pearsonr(x, y, *, alternative='two-sided', method=None)
```

用于测试非相关性的 Pearson 相关系数和 p 值。

Pearson 相关系数 [[1]](#r8c6348c62346-1) 用于衡量两个数据集之间的线性关系。与其他相关系数一样，此系数在 -1 到 +1 之间变化，0 表示无相关性。相关系数为 -1 或 +1 表示精确的线性关系。正相关表示随着 x 的增加，y 也增加。负相关表示随着 x 的增加，y 减少。

此函数还执行零假设测试，即样本所代表的分布是不相关和正态分布的。（有关输入非正态对相关系数分布影响的讨论，请参见 Kowalski [[3]](#r8c6348c62346-3)。）p 值大致指示不相关系统生成具有至少与这些数据集计算的 Pearson 相关性一样极端的数据集的概率。

参数：

**x**(N,) array_like

输入数组。

**y**(N,) array_like

输入数组。

**alternative**{‘two-sided’, ‘greater’, ‘less’}，可选

定义备择假设。默认为 ‘two-sided’。可用的选项包括：

+   ‘two-sided’: 相关性非零

+   ‘less’: 相关性为负（小于零）

+   ‘greater’: 相关性为正（大于零）

自版本 1.9.0 新增。

**method**ResamplingMethod，可选

定义了计算 p 值的方法。如果 *method* 是 `PermutationMethod`/`MonteCarloMethod` 的实例，则使用提供的配置选项和其他适当的设置使用 `scipy.stats.permutation_test`/`scipy.stats.monte_carlo_test` 计算 p 值。否则，按照说明文档计算 p 值。

自版本 1.11.0 新增。

返回：

**result**`PearsonRResult`

一个具有以下属性的对象：

statisticfloat

Pearson 乘积矩相关系数。

pvaluefloat

与选择的备择假设相关的 p 值。

该对象具有以下方法：

confidence_interval(confidence_level, method)

此函数计算给定置信水平的相关系数*统计量*的置信区间。置信区间以`namedtuple`的形式返回，字段为*low*和*high*。如果未提供*method*，则使用 Fisher 变换计算置信区间[[1]](#r8c6348c62346-1)。如果*method*是`BootstrapMethod`的一个实例，则使用`scipy.stats.bootstrap`根据提供的配置选项和其他适当的设置计算置信区间。在某些情况下，由于重采样退化，置信限可能为 NaN，这在非常小的样本（~6 个观测值）中很典型。

警告：

`ConstantInputWarning`

如果输入为常量数组，则引发警告。在这种情况下，相关系数未定义，因此返回`np.nan`。

`NearConstantInputWarning`

如果输入“几乎”是常量，则引发警告。如果`x`数组被认为几乎是常量，则`norm(x - mean(x)) < 1e-13 * abs(mean(x))`。在这种情况下，计算中`x - mean(x)`的数值误差可能导致 r 的不准确计算。

另见：

`spearmanr`

Spearman 秩相关系数。

`kendalltau`

Kendall's tau，用于有序数据的相关度量。

注：

相关系数计算方法如下：

\[r = \frac{\sum (x - m_x) (y - m_y)} {\sqrt{\sum (x - m_x)² \sum (y - m_y)²}}\]

其中\(m_x\)为向量 x 的均值，\(m_y\)为向量 y 的均值。

在假设 x 和 y 来自独立正态分布（因此总体相关系数为 0）的条件下，样本相关系数 r 的概率密度函数为([[1]](#r8c6348c62346-1), [[2]](#r8c6348c62346-2))：

\[f(r) = \frac{{(1-r²)}^{n/2-2}}{\mathrm{B}(\frac{1}{2},\frac{n}{2}-1)}\]

其中 n 为样本数，B 为 Beta 函数。有时称为 r 的确切分布。当*method*参数保持默认值（None）时，这是用于计算 p 值的分布，例如`pearsonr`。r 的分布是在区间[-1, 1]上的 Beta 分布，具有相等的形状参数 a = b = n/2 - 1。在 SciPy 的 Beta 分布实现中，r 的分布如下：

```py
dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2) 
```

`pearsonr`返回的默认 p 值是双侧 p 值。对于给定相关系数 r 的样本，p 值是随机抽样 x'和 y'来自零相关总体时 abs(r')大于或等于 abs(r)的概率。根据上述`dist`对象，给定 r 和长度 n 的 p 值可以计算为：

```py
p = 2*dist.cdf(-abs(r)) 
```

当 n 为 2 时，上述连续分布未定义。可以将 beta 分布在形状参数 a 和 b 接近 a = b = 0 时解释为具有 r = 1 和 r = -1 的离散分布。更直接地，可以观察到，鉴于数据 x = [x1, x2]和 y = [y1, y2]，假设 x1 != x2 和 y1 != y2，则 r 的唯一可能值为 1 和-1。因为对于长度为 2 的任意样本 x'和 y'，abs(r')始终为 1，所以长度为 2 的样本的双侧 p 值始终为 1。

为了向后兼容，返回的对象也像长度为二的元组，其中保存统计量和 p 值。

参考文献

[1] (1,2,3)

“皮尔逊相关系数”，维基百科，[`en.wikipedia.org/wiki/Pearson_correlation_coefficient`](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)

[2]

Student，“相关系数的可能误差”，生物统计学，第 6 卷，第 2-3 期，1908 年 9 月 1 日，第 302-310 页。

[3]

C. J. Kowalski，“关于非正态对样本积矩相关系数分布的影响” 皇家统计学会杂志。C 系列（应用统计学），第 21 卷，第 1 期（1972 年），第 1-12 页。

例如

```py
>>> import numpy as np
>>> from scipy import stats
>>> x, y = [1, 2, 3, 4, 5, 6, 7], [10, 9, 2.5, 6, 4, 3, 2]
>>> res = stats.pearsonr(x, y)
>>> res
PearsonRResult(statistic=-0.828503883588428, pvalue=0.021280260007523286) 
```

执行测试的精确排列版本：  

```py
>>> rng = np.random.default_rng()
>>> method = stats.PermutationMethod(n_resamples=np.inf, random_state=rng)
>>> stats.pearsonr(x, y, method=method)
PearsonRResult(statistic=-0.828503883588428, pvalue=0.028174603174603175) 
```

在空假设下执行检验，即数据来自*均匀*分布：

```py
>>> method = stats.MonteCarloMethod(rvs=(rng.uniform, rng.uniform))
>>> stats.pearsonr(x, y, method=method)
PearsonRResult(statistic=-0.828503883588428, pvalue=0.0188) 
```

生成渐近 90%置信区间：

```py
>>> res.confidence_interval(confidence_level=0.9)
ConfidenceInterval(low=-0.9644331982722841, high=-0.3460237473272273) 
```

而对于自举置信区间：

```py
>>> method = stats.BootstrapMethod(method='BCa', random_state=rng)
>>> res.confidence_interval(confidence_level=0.9, method=method)
ConfidenceInterval(low=-0.9983163756488651, high=-0.22771001702132443)  # may vary 
```

如果 y = a + b*x + e，其中 a，b 是常数，e 是随机误差项，假设与 x 独立。为简单起见，假设 x 是标准正态分布，a=0，b=1，让 e 遵循均值为零，标准差为 s>0 的正态分布。

```py
>>> rng = np.random.default_rng()
>>> s = 0.5
>>> x = stats.norm.rvs(size=500, random_state=rng)
>>> e = stats.norm.rvs(scale=s, size=500, random_state=rng)
>>> y = x + e
>>> stats.pearsonr(x, y).statistic
0.9001942438244763 
```

这应该接近所给出的确切值。

```py
>>> 1/np.sqrt(1 + s**2)
0.8944271909999159 
```

对于 s=0.5，我们观察到高度相关性。通常，噪声的大方差会降低相关性，而误差方差接近零时，相关性接近于 1。

需要记住，没有相关性并不意味着独立，除非（x，y）是联合正态的。即使在存在非常简单的依赖结构时，相关性也可能为零：如果 X 服从标准正态分布，则令 y = abs(x)。注意，x 和 y 之间的相关性为零。确实，由于 x 的期望为零，cov(x，y) = E[x*y]。根据定义，这等于 E[x*abs(x)]，由于对称性，这是零。以下代码行说明了这一观察：

```py
>>> y = np.abs(x)
>>> stats.pearsonr(x, y)
PearsonRResult(statistic=-0.05444919272687482, pvalue=0.22422294836207743) 
```

非零相关系数可能具有误导性。例如，如果 X 符合标准正态分布，定义 y = x 如果 x < 0，否则 y = 0。简单的计算显示 corr(x, y) = sqrt(2/Pi) = 0.797…，表明高度相关：

```py
>>> y = np.where(x < 0, x, 0)
>>> stats.pearsonr(x, y)
PearsonRResult(statistic=0.861985781588, pvalue=4.813432002751103e-149) 
```

这是不直观的，因为如果我们对 x 和 y 进行抽样，当 x 大于零时，x 和 y 之间没有依赖关系，在大约一半的情况下会发生这种情况。
