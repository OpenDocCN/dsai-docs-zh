["```py\n/usr/share/dict\n/var/lib/dict \n```", "```py\n>>> word_list = open('/usr/share/dict/words').readlines()\n>>> word_list = map(str.strip, word_list) \n```", "```py\n>>> word_list = [word for word in word_list if len(word) == 3]\n>>> word_list = [word for word in word_list if word[0].islower()]\n>>> word_list = [word for word in word_list if word.isalpha()]\n>>> word_list = list(map(str.lower, word_list))\n>>> len(word_list)\n586    # may vary \n```", "```py\n>>> import numpy as np\n>>> word_list = np.asarray(word_list)\n>>> word_list.dtype   # these are unicode characters in Python 3\ndtype('<U3')\n>>> word_list.sort()  # sort for quick searching later \n```", "```py\n>>> word_bytes = np.ndarray((word_list.size, word_list.itemsize),\n...                         dtype='uint8',\n...                         buffer=word_list.data)\n>>> # each unicode character is four bytes long. We only need first byte\n>>> # we know that there are three characters in each word\n>>> word_bytes = word_bytes[:, ::word_list.itemsize//3]\n>>> word_bytes.shape\n(586, 3)    # may vary \n```", "```py\n>>> from scipy.spatial.distance import pdist, squareform\n>>> from scipy.sparse import csr_matrix\n>>> hamming_dist = pdist(word_bytes, metric='hamming')\n>>> # there are three characters in each word\n>>> graph = csr_matrix(squareform(hamming_dist < 1.5 / 3)) \n```", "```py\n>>> i1 = word_list.searchsorted('ape')\n>>> i2 = word_list.searchsorted('man')\n>>> word_list[i1]\n'ape'\n>>> word_list[i2]\n'man' \n```", "```py\n>>> from scipy.sparse.csgraph import dijkstra\n>>> distances, predecessors = dijkstra(graph, indices=i1,\n...                                    return_predecessors=True)\n>>> print(distances[i2])\n5.0    # may vary \n```", "```py\n>>> path = []\n>>> i = i2\n>>> while i != i1:\n...     path.append(word_list[i])\n...     i = predecessors[i]\n>>> path.append(word_list[i1])\n>>> print(path[::-1])\n['ape', 'apt', 'opt', 'oat', 'mat', 'man']    # may vary \n```", "```py\n>>> from scipy.sparse.csgraph import connected_components\n>>> N_components, component_list = connected_components(graph)\n>>> print(N_components)\n15    # may vary \n```", "```py\n>>> [np.sum(component_list == i) for i in range(N_components)]\n[571, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]    # may vary \n```", "```py\n>>> [list(word_list[np.nonzero(component_list == i)]) for i in range(1, N_components)]\n[['aha'],    # may vary\n ['chi'],\n ['ebb'],\n ['ems', 'emu'],\n ['gnu'],\n ['ism'],\n ['khz'],\n ['nth'],\n ['ova'],\n ['qua'],\n ['ugh'],\n ['ups'],\n ['urn'],\n ['use']] \n```", "```py\n>>> distances, predecessors = dijkstra(graph, return_predecessors=True)\n>>> max_distance = np.max(distances[~np.isinf(distances)])\n>>> print(max_distance)\n13.0    # may vary \n```", "```py\n>>> i1, i2 = np.nonzero(distances == max_distance)\n>>> list(zip(word_list[i1], word_list[i2]))\n[('imp', 'ohm'),    # may vary\n ('imp', 'ohs'),\n ('ohm', 'imp'),\n ('ohm', 'ump'),\n ('ohs', 'imp'),\n ('ohs', 'ump'),\n ('ump', 'ohm'),\n ('ump', 'ohs')] \n```", "```py\n>>> path = []\n>>> i = i2[0]\n>>> while i != i1[0]:\n...     path.append(word_list[i])\n...     i = predecessors[i1[0], i]\n>>> path.append(word_list[i1[0]])\n>>> print(path[::-1])\n['imp', 'amp', 'asp', 'ass', 'ads', 'add', 'aid', 'mid', 'mod', 'moo', 'too', 'tho', 'oho', 'ohm']    # may vary \n```"]