- en: Mobile Segment Anything (MobileSAM)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 移动端任意分割（MobileSAM）
- en: 原文：[`docs.ultralytics.com/models/mobile-sam/`](https://docs.ultralytics.com/models/mobile-sam/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/models/mobile-sam/`](https://docs.ultralytics.com/models/mobile-sam/)
- en: '![MobileSAM Logo](img/453c729475acdee37d7f0db7d4748c60.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![MobileSAM Logo](img/453c729475acdee37d7f0db7d4748c60.png)'
- en: The MobileSAM paper is now available on [arXiv](https://arxiv.org/pdf/2306.14289.pdf).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: MobileSAM的论文现已在[arXiv](https://arxiv.org/pdf/2306.14289.pdf)上发布。
- en: A demonstration of MobileSAM running on a CPU can be accessed at this [demo
    link](https://huggingface.co/spaces/dhkim2810/MobileSAM). The performance on a
    Mac i5 CPU takes approximately 3 seconds. On the Hugging Face demo, the interface
    and lower-performance CPUs contribute to a slower response, but it continues to
    function effectively.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过此[演示链接](https://huggingface.co/spaces/dhkim2810/MobileSAM)访问MobileSAM在CPU上运行的演示。在Mac
    i5 CPU上，每张图片大约需要3秒。在Hugging Face的演示中，界面和性能较低的CPU导致响应速度较慢，但功能仍然有效。
- en: MobileSAM is implemented in various projects including [Grounding-SAM](https://github.com/IDEA-Research/Grounded-Segment-Anything),
    [AnyLabeling](https://github.com/vietanhdev/anylabeling), and [Segment Anything
    in 3D](https://github.com/Jumpat/SegmentAnythingin3D).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: MobileSAM已在多个项目中实施，包括[Grounding-SAM](https://github.com/IDEA-Research/Grounded-Segment-Anything)，[AnyLabeling](https://github.com/vietanhdev/anylabeling)，以及[3D中的任意分割](https://github.com/Jumpat/SegmentAnythingin3D)。
- en: MobileSAM is trained on a single GPU with a 100k dataset (1% of the original
    images) in less than a day. The code for this training will be made available
    in the future.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: MobileSAM在单个GPU上训练，使用了100k数据集（原始图像的1%）不到一天时间。该训练的代码将在未来公布。
- en: Available Models, Supported Tasks, and Operating Modes
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可用模型、支持的任务和操作模式
- en: This table presents the available models with their specific pre-trained weights,
    the tasks they support, and their compatibility with different operating modes
    like Inference, Validation, Training, and Export, indicated by ✅ emojis for supported
    modes and ❌ emojis for unsupported modes.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 此表显示了可用模型及其特定的预训练权重，它们支持的任务以及它们与不同操作模式（支持的模式用✅标示，不支持的模式用❌标示）的兼容性。
- en: '| Model Type | Pre-trained Weights | Tasks Supported | Inference | Validation
    | Training | Export |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 模型类型 | 预训练权重 | 支持的任务 | 推理 | 验证 | 训练 | 导出 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| MobileSAM | [mobile_sam.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/mobile_sam.pt)
    | Instance Segmentation | ✅ | ❌ | ❌ | ❌ |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| MobileSAM | [mobile_sam.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/mobile_sam.pt)
    | 实例分割 | ✅ | ❌ | ❌ | ❌ |'
- en: Adapting from SAM to MobileSAM
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从SAM适配到MobileSAM
- en: Since MobileSAM retains the same pipeline as the original SAM, we have incorporated
    the original's pre-processing, post-processing, and all other interfaces. Consequently,
    those currently using the original SAM can transition to MobileSAM with minimal
    effort.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 由于MobileSAM保留了与原始SAM相同的管道，我们已经整合了原始的预处理、后处理和所有其他接口。因此，当前使用原始SAM的用户可以以最小的努力过渡到MobileSAM。
- en: 'MobileSAM performs comparably to the original SAM and retains the same pipeline
    except for a change in the image encoder. Specifically, we replace the original
    heavyweight ViT-H encoder (632M) with a smaller Tiny-ViT (5M). On a single GPU,
    MobileSAM operates at about 12ms per image: 8ms on the image encoder and 4ms on
    the mask decoder.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: MobileSAM在执行方面与原始SAM相媲美，并且保留了相同的管道，只是更改了图像编码器。具体来说，我们用更小的Tiny-ViT（5M）替换了原始的重型ViT-H编码器（632M）。在单个GPU上，MobileSAM每张图片的操作时间约为12ms：图像编码器为8ms，蒙版解码器为4ms。
- en: 'The following table provides a comparison of ViT-based image encoders:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 下表提供了基于ViT的图像编码器的比较：
- en: '| Image Encoder | Original SAM | MobileSAM |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 图像编码器 | 原始SAM | MobileSAM |'
- en: '| --- | --- | --- |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Parameters | 611M | 5M |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 611M | 5M |'
- en: '| Speed | 452ms | 8ms |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 速度 | 452ms | 8ms |'
- en: 'Both the original SAM and MobileSAM utilize the same prompt-guided mask decoder:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 原始SAM和MobileSAM都利用相同的提示引导蒙版解码器：
- en: '| Mask Decoder | Original SAM | MobileSAM |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 蒙版解码器 | 原始SAM | MobileSAM |'
- en: '| --- | --- | --- |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Parameters | 3.876M | 3.876M |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 3.876M | 3.876M |'
- en: '| Speed | 4ms | 4ms |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 速度 | 4ms | 4ms |'
- en: 'Here is the comparison of the whole pipeline:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是整体管道的比较：
- en: '| Whole Pipeline (Enc+Dec) | Original SAM | MobileSAM |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 整体管道（Enc+Dec） | 原始SAM | MobileSAM |'
- en: '| --- | --- | --- |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Parameters | 615M | 9.66M |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 615M | 9.66M |'
- en: '| Speed | 456ms | 12ms |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 速度 | 456ms | 12ms |'
- en: The performance of MobileSAM and the original SAM are demonstrated using both
    a point and a box as prompts.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: MobileSAM和原始SAM的性能通过点和框提示进行演示。
- en: '![Image with Point as Prompt](img/f2294f007c6c2f0e63d2508720eae89f.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![使用点作为提示的图像](img/f2294f007c6c2f0e63d2508720eae89f.png)'
- en: '![Image with Box as Prompt](img/f2294f007c6c2f0e63d2508720eae89f.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![使用框作为提示的图像](img/f2294f007c6c2f0e63d2508720eae89f.png)'
- en: With its superior performance, MobileSAM is approximately 5 times smaller and
    7 times faster than the current FastSAM. More details are available at the [MobileSAM
    project page](https://github.com/ChaoningZhang/MobileSAM).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 凭借其卓越的性能，MobileSAM 比当前的 FastSAM 大约小了 5 倍，速度快了 7 倍。更多细节请参阅 [MobileSAM 项目页面](https://github.com/ChaoningZhang/MobileSAM)。
- en: Testing MobileSAM in Ultralytics
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Ultralytics 中测试 MobileSAM
- en: Just like the original SAM, we offer a straightforward testing method in Ultralytics,
    including modes for both Point and Box prompts.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 就像原始的 SAM 一样，我们在 Ultralytics 中提供了一种简单直接的测试方法，包括点和框提示的模式。
- en: Model Download
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型下载
- en: You can download the model [here](https://github.com/ChaoningZhang/MobileSAM/blob/master/weights/mobile_sam.pt).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [这里](https://github.com/ChaoningZhang/MobileSAM/blob/master/weights/mobile_sam.pt)
    下载该模型。
- en: Point Prompt
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 点提示
- en: Example
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Box Prompt
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 框提示
- en: Example
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We have implemented `MobileSAM` and `SAM` using the same API. For more usage
    information, please see the SAM page.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用相同的 API 实现了 `MobileSAM` 和 `SAM`。有关更多使用信息，请参阅 SAM 页面。
- en: Citations and Acknowledgements
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引用和致谢
- en: 'If you find MobileSAM useful in your research or development work, please consider
    citing our paper:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在研究或开发工作中发现 MobileSAM 有用，请考虑引用我们的论文：
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: FAQ
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题
- en: What is MobileSAM and how does it differ from the original SAM model?
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MobileSAM 是什么，它与原始 SAM 模型有什么不同？
- en: MobileSAM is a lightweight, fast image segmentation model designed for mobile
    applications. It retains the same pipeline as the original SAM but replaces the
    heavyweight ViT-H encoder (632M parameters) with a smaller Tiny-ViT encoder (5M
    parameters). This change results in MobileSAM being approximately 5 times smaller
    and 7 times faster than the original SAM. For instance, MobileSAM operates at
    about 12ms per image, compared to the original SAM's 456ms. You can learn more
    about the MobileSAM implementation in various projects [here](https://github.com/ChaoningZhang/MobileSAM).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: MobileSAM 是一种专为移动应用设计的轻量级快速图像分割模型。它保留了与原始 SAM 相同的管道，但将笨重的 ViT-H 编码器（632M 参数）替换为较小的
    Tiny-ViT 编码器（5M 参数）。这一改变使 MobileSAM 大约小了 5 倍，速度快了 7 倍。例如，MobileSAM 每张图像的操作速度约为
    12 毫秒，而原始 SAM 则为 456 毫秒。您可以在各种项目中了解更多关于 MobileSAM 实现的信息 [这里](https://github.com/ChaoningZhang/MobileSAM)。
- en: How can I test MobileSAM using Ultralytics?
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何使用 Ultralytics 测试 MobileSAM？
- en: 'Testing MobileSAM in Ultralytics can be accomplished through straightforward
    methods. You can use Point and Box prompts to predict segments. Here''s an example
    using a Point prompt:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 通过简单的方法即可完成在 Ultralytics 中测试 MobileSAM。您可以使用点和框提示来预测段。以下是使用点提示的示例：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can also refer to the Testing MobileSAM section for more details.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以参考《测试 MobileSAM》部分获取更多详细信息。
- en: Why should I use MobileSAM for my mobile application?
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么我应该在我的移动应用中使用 MobileSAM？
- en: MobileSAM is ideal for mobile applications due to its lightweight architecture
    and fast inference speed. Compared to the original SAM, MobileSAM is approximately
    5 times smaller and 7 times faster, making it suitable for environments where
    computational resources are limited. This efficiency ensures that mobile devices
    can perform real-time image segmentation without significant latency. Additionally,
    MobileSAM's models, such as Inference, are optimized for mobile performance.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其轻量级架构和快速推理速度，MobileSAM 非常适合移动应用。与原始的 SAM 相比，MobileSAM 大约小了 5 倍，速度快了 7 倍，适合计算资源有限的环境。这种效率确保了移动设备可以在没有显著延迟的情况下进行实时图像分割。此外，MobileSAM
    的模型（如推理模型）已经优化，以提升移动性能。
- en: How was MobileSAM trained, and is the training code available?
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MobileSAM 是如何训练的，训练代码是否可用？
- en: MobileSAM was trained on a single GPU with a 100k dataset, which is 1% of the
    original images, in less than a day. While the training code will be made available
    in the future, you can currently explore other aspects of MobileSAM in the [MobileSAM
    GitHub repository](https://github.com/ultralytics/assets/releases/download/v8.2.0/mobile_sam.pt).
    This repository includes pre-trained weights and implementation details for various
    applications.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: MobileSAM 在少于一天的时间内使用单个 GPU 训练了一个包含 10 万张数据集的模型，这相当于原始图像的 1%。虽然训练代码将来会公开，但目前您可以在
    [MobileSAM GitHub 仓库](https://github.com/ultralytics/assets/releases/download/v8.2.0/mobile_sam.pt)
    中了解 MobileSAM 的其他方面。该仓库包括预训练权重和各种应用的实现细节。
- en: What are the primary use cases for MobileSAM?
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MobileSAM 的主要用例是什么？
- en: 'MobileSAM is designed for fast and efficient image segmentation in mobile environments.
    Primary use cases include:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: MobileSAM旨在移动环境中实现快速高效的图像分割。主要用例包括：
- en: '**Real-time object detection and segmentation** for mobile applications.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**移动应用的实时目标检测和分割**。'
- en: '**Low-latency image processing** in devices with limited computational resources.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低延迟图像处理**，适用于计算资源有限的设备。'
- en: '**Integration in AI-driven mobile apps** for tasks such as augmented reality
    (AR) and real-time analytics.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工智能驱动的移动应用中的集成**，用于增强现实（AR）和实时分析等任务。'
- en: For more detailed use cases and performance comparisons, see the section on
    Adapting from SAM to MobileSAM.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更详细的用例和性能比较，请参见从SAM到MobileSAM的适应部分。
