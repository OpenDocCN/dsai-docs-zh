- en: Train Custom Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è®­ç»ƒè‡ªå®šä¹‰æ•°æ®
- en: åŸæ–‡ï¼š[`docs.ultralytics.com/yolov5/tutorials/train_custom_data/`](https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[`docs.ultralytics.com/yolov5/tutorials/train_custom_data/`](https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/)
- en: ğŸ“š This guide explains how to train your own **custom dataset** with [YOLOv5](https://github.com/ultralytics/yolov5)
    ğŸš€.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ“š æœ¬æŒ‡å—è§£é‡Šäº†å¦‚ä½•ä½¿ç”¨[YOLOv5](https://github.com/ultralytics/yolov5)è®­ç»ƒæ‚¨è‡ªå·±çš„**è‡ªå®šä¹‰æ•°æ®é›†**
    ğŸš€ã€‚
- en: Before You Start
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨å¼€å§‹ä¹‹å‰
- en: Clone repo and install [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt)
    in a [**Python>=3.8.0**](https://www.python.org/) environment, including [**PyTorch>=1.8**](https://pytorch.org/get-started/locally/).
    [Models](https://github.com/ultralytics/yolov5/tree/master/models) and [datasets](https://github.com/ultralytics/yolov5/tree/master/data)
    download automatically from the latest YOLOv5 [release](https://github.com/ultralytics/yolov5/releases).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: å…‹éš†å­˜å‚¨åº“å¹¶åœ¨[**Python>=3.8.0**](https://www.python.org/)ç¯å¢ƒä¸­å®‰è£…[requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt)ï¼ŒåŒ…æ‹¬[**PyTorch>=1.8**](https://pytorch.org/get-started/locally/)ã€‚ä»æœ€æ–°çš„
    YOLOv5 [ç‰ˆæœ¬](https://github.com/ultralytics/yolov5/releases)è‡ªåŠ¨ä¸‹è½½[æ¨¡å‹](https://github.com/ultralytics/yolov5/tree/master/models)å’Œ[æ•°æ®é›†](https://github.com/ultralytics/yolov5/tree/master/data)ã€‚
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Train On Custom Data
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªå®šä¹‰æ•°æ®è®­ç»ƒ
- en: '![Ultralytics active learning](https://ultralytics.com/hub)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![Ultralytics ä¸»åŠ¨å­¦ä¹ ](https://ultralytics.com/hub)'
- en: Creating a custom model to detect your objects is an iterative process of collecting
    and organizing images, labeling your objects of interest, training a model, deploying
    it into the wild to make predictions, and then using that deployed model to collect
    examples of edge cases to repeat and improve.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰æ¨¡å‹æ¥æ£€æµ‹æ‚¨çš„å¯¹è±¡æ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ”¶é›†å’Œç»„ç»‡å›¾åƒï¼Œæ ‡è®°æ‚¨æ„Ÿå…´è¶£çš„å¯¹è±¡ï¼Œè®­ç»ƒæ¨¡å‹ï¼Œéƒ¨ç½²åˆ°å®é™…ç¯å¢ƒè¿›è¡Œé¢„æµ‹ï¼Œç„¶åä½¿ç”¨éƒ¨ç½²æ¨¡å‹æ”¶é›†è¾¹ç•Œæƒ…å†µç¤ºä¾‹ï¼Œä»¥é‡å¤å’Œæ”¹è¿›ã€‚
- en: Licensing
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¯åè®®
- en: 'Ultralytics offers two licensing options:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics æä¾›ä¸¤ç§è®¸å¯é€‰é¡¹ï¼š
- en: The [AGPL-3.0 License](https://github.com/ultralytics/ultralytics/blob/main/LICENSE),
    an [OSI-approved](https://opensource.org/licenses/) open-source license ideal
    for students and enthusiasts.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AGPL-3.0 è®¸å¯è¯](https://github.com/ultralytics/ultralytics/blob/main/LICENSE)ï¼Œè¿™æ˜¯ä¸€ä¸ª[OSI
    æ‰¹å‡†çš„](https://opensource.org/licenses/)å¼€æºè®¸å¯è¯ï¼Œéå¸¸é€‚åˆå­¦ç”Ÿå’Œçˆ±å¥½è€…ã€‚'
- en: The [Enterprise License](https://ultralytics.com/license) for businesses seeking
    to incorporate our AI models into their products and services.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¼ä¸šè®¸å¯è¯ä¸ºå¯»æ±‚å°†æˆ‘ä»¬çš„ AI æ¨¡å‹æ•´åˆåˆ°å…¶äº§å“å’ŒæœåŠ¡ä¸­çš„ä¼ä¸šæä¾›æ”¯æŒï¼Œè¯¦è§[ä¼ä¸šè®¸å¯è¯](https://ultralytics.com/license)ã€‚
- en: For more details see [Ultralytics Licensing](https://ultralytics.com/license).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ¬²äº†è§£æ›´å¤šè¯¦æƒ…ï¼Œè¯·å‚é˜…[Ultralytics è®¸å¯åè®®](https://ultralytics.com/license)ã€‚
- en: 'YOLOv5 models must be trained on labelled data in order to learn classes of
    objects in that data. There are two options for creating your dataset before you
    start training:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv5 æ¨¡å‹å¿…é¡»åœ¨æ ‡è®°æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»¥å­¦ä¹ è¯¥æ•°æ®ä¸­çš„å¯¹è±¡ç±»åˆ«ã€‚åœ¨å¼€å§‹è®­ç»ƒä¹‹å‰ï¼Œæœ‰ä¸¤ç§åˆ›å»ºæ•°æ®é›†çš„é€‰é¡¹ï¼š
- en: 'Option 1: Create a [Roboflow](https://roboflow.com/?ref=ultralytics) Dataset'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é€‰é¡¹ 1ï¼šåˆ›å»ºä¸€ä¸ª[Roboflow æ•°æ®é›†](https://roboflow.com/?ref=ultralytics)
- en: 1.1 Collect Images
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 æ”¶é›†å›¾åƒ
- en: Your model will learn by example. Training on images similar to the ones it
    will see in the wild is of the utmost importance. Ideally, you will collect a
    wide variety of images from the same configuration (camera, angle, lighting, etc.)
    as you will ultimately deploy your project.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨çš„æ¨¡å‹å°†é€šè¿‡ç¤ºä¾‹å­¦ä¹ ã€‚åœ¨é‡å¤–åœºæ™¯è®­ç»ƒæ¨¡å‹çš„å›¾åƒéå¸¸é‡è¦ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œæ‚¨å°†æ”¶é›†ä¸€ç³»åˆ—ä¸æœ€ç»ˆéƒ¨ç½²é¡¹ç›®ç›¸åŒé…ç½®çš„å›¾åƒï¼ˆç›¸æœºã€è§’åº¦ã€å…‰çº¿ç­‰ï¼‰ã€‚
- en: If this is not possible, you can start from [a public dataset](https://universe.roboflow.com/?ref=ultralytics)
    to train your initial model and then [sample images from the wild during inference](https://blog.roboflow.com/computer-vision-active-learning-tips/?ref=ultralytics)
    to improve your dataset and model iteratively.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœè¿™ä¸å¯è¡Œï¼Œæ‚¨å¯ä»¥ä»[å…¬å…±æ•°æ®é›†](https://universe.roboflow.com/?ref=ultralytics)å¼€å§‹è®­ç»ƒåˆå§‹æ¨¡å‹ï¼Œç„¶ååœ¨æ¨æ–­æœŸé—´ä»å®é™…åœºæ™¯ä¸­[é‡‡æ ·å›¾åƒ](https://blog.roboflow.com/computer-vision-active-learning-tips/?ref=ultralytics)æ¥è¿­ä»£æ”¹è¿›æ‚¨çš„æ•°æ®é›†å’Œæ¨¡å‹ã€‚
- en: 1.2 Create Labels
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2 åˆ›å»ºæ ‡ç­¾
- en: Once you have collected images, you will need to annotate the objects of interest
    to create a ground truth for your model to learn from.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ”¶é›†äº†å›¾åƒï¼Œæ‚¨éœ€è¦æ³¨é‡Šæ„Ÿå…´è¶£çš„å¯¹è±¡ï¼Œä»¥åˆ›å»ºæ¨¡å‹çš„çœŸå®æ€§æ•°æ®ã€‚
- en: '![YOLOv5 accuracies](https://app.roboflow.com/?model=yolov5&ref=ultralytics
    "Create a Free Roboflow Account")'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![YOLOv5 å‡†ç¡®æ€§](https://app.roboflow.com/?model=yolov5&ref=ultralytics "åˆ›å»ºå…è´¹
    Roboflow å¸æˆ·")'
- en: '[Roboflow Annotate](https://roboflow.com/annotate?ref=ultralytics) is a simple
    web-based tool for managing and labeling your images with your team and exporting
    them in [YOLOv5''s annotation format](https://roboflow.com/formats/yolov5-pytorch-txt?ref=ultralytics).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[Roboflowæ ‡æ³¨](https://roboflow.com/annotate?ref=ultralytics)æ˜¯ä¸€ä¸ªç®€å•çš„åŸºäºWebçš„å·¥å…·ï¼Œç”¨äºç®¡ç†å’Œæ ‡è®°æ‚¨çš„å›¾åƒåŠä¸æ‚¨çš„å›¢é˜Ÿåˆä½œï¼Œå¹¶ä»¥[YOLOv5çš„æ ‡æ³¨æ ¼å¼](https://roboflow.com/formats/yolov5-pytorch-txt?ref=ultralytics)å¯¼å‡ºå®ƒä»¬ã€‚'
- en: 1.3 Prepare Dataset for YOLOv5
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3 ä¸ºYOLOv5å‡†å¤‡æ•°æ®é›†
- en: Whether you [label your images with Roboflow](https://roboflow.com/annotate?ref=ultralytics)
    or not, you can use it to convert your dataset into YOLO format, create a YOLOv5
    YAML configuration file, and host it for importing into your training script.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºæ‚¨æ˜¯å¦ä½¿ç”¨[Roboflowæ ‡æ³¨æ‚¨çš„å›¾åƒ](https://roboflow.com/annotate?ref=ultralytics)ï¼Œæ‚¨éƒ½å¯ä»¥ä½¿ç”¨å®ƒå°†æ‚¨çš„æ•°æ®é›†è½¬æ¢ä¸ºYOLOæ ¼å¼ï¼Œåˆ›å»ºä¸€ä¸ªYOLOv5
    YAMLé…ç½®æ–‡ä»¶ï¼Œå¹¶å°†å…¶æ‰˜ç®¡ä»¥ä¾›å¯¼å…¥åˆ°æ‚¨çš„è®­ç»ƒè„šæœ¬ä¸­ã€‚
- en: '[Create a free Roboflow account](https://app.roboflow.com/?model=yolov5&ref=ultralytics)
    and upload your dataset to a `Public` workspace, label any unannotated images,
    then generate and export a version of your dataset in `YOLOv5 Pytorch` format.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[åˆ›å»ºä¸€ä¸ªå…è´¹çš„Roboflowè´¦æˆ·](https://app.roboflow.com/?model=yolov5&ref=ultralytics)å¹¶å°†æ‚¨çš„æ•°æ®é›†ä¸Šä¼ åˆ°`Public`å·¥ä½œåŒºï¼Œåœ¨æœªæ ‡æ³¨çš„å›¾åƒä¸Šæ ‡æ³¨ï¼Œç„¶åç”Ÿæˆå¹¶å¯¼å‡ºä¸€ä¸ªYOLOv5
    Pytorchæ ¼å¼çš„æ•°æ®é›†ç‰ˆæœ¬ã€‚'
- en: 'Note: YOLOv5 does online augmentation during training, so we do not recommend
    applying any augmentation steps in Roboflow for training with YOLOv5\. But we
    recommend applying the following preprocessing steps:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼šYOLOv5åœ¨è®­ç»ƒæœŸé—´è¿›è¡Œåœ¨çº¿å¢å¼ºï¼Œå› æ­¤æˆ‘ä»¬ä¸å»ºè®®åœ¨Roboflowä¸­åº”ç”¨ä»»ä½•å¢å¼ºæ­¥éª¤ç”¨äºYOLOv5çš„è®­ç»ƒã€‚ä½†æˆ‘ä»¬å»ºè®®åº”ç”¨ä»¥ä¸‹é¢„å¤„ç†æ­¥éª¤ï¼š
- en: '![Recommended Preprocessing Steps](img/ac7ffe631fd9af9f8bd369fc99a6cebc.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![æ¨èçš„é¢„å¤„ç†æ­¥éª¤](img/ac7ffe631fd9af9f8bd369fc99a6cebc.png)'
- en: '**Auto-Orient** - to strip EXIF orientation from your images.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è‡ªåŠ¨æ–¹å‘** - ä»å›¾åƒä¸­å»é™¤EXIFæ–¹å‘ä¿¡æ¯ã€‚'
- en: '**Resize (Stretch)** - to the square input size of your model (640x640 is the
    YOLOv5 default).'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è°ƒæ•´å¤§å°ï¼ˆæ‹‰ä¼¸ï¼‰** - åˆ°æ‚¨æ¨¡å‹çš„æ–¹å½¢è¾“å…¥å¤§å°ï¼ˆ640x640æ˜¯YOLOv5çš„é»˜è®¤è®¾ç½®ï¼‰ã€‚'
- en: Generating a version will give you a snapshot of your dataset, so you can always
    go back and compare your future model training runs against it, even if you add
    more images or change its configuration later.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆä¸€ä¸ªç‰ˆæœ¬å°†ä¸ºæ‚¨çš„æ•°æ®é›†æä¾›ä¸€ä¸ªå¿«ç…§ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥éšæ—¶å›é¡¾å¹¶æ¯”è¾ƒå°†æ¥æ¨¡å‹è®­ç»ƒè¿è¡Œçš„ç»“æœï¼Œå³ä½¿æ‚¨æ·»åŠ äº†æ›´å¤šå›¾åƒæˆ–ç¨åæ›´æ”¹äº†å…¶é…ç½®ã€‚
- en: '![Export in YOLOv5 Format](img/03af3625a1a6398c1d83acf98936d9d8.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![ä»¥YOLOv5æ ¼å¼å¯¼å‡º](img/03af3625a1a6398c1d83acf98936d9d8.png)'
- en: Export in `YOLOv5 Pytorch` format, then copy the snippet into your training
    script or notebook to download your dataset.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥`YOLOv5 Pytorch`æ ¼å¼å¯¼å‡ºï¼Œç„¶åå°†ç‰‡æ®µå¤åˆ¶åˆ°æ‚¨çš„è®­ç»ƒè„šæœ¬æˆ–ç¬”è®°æœ¬ä¸­ä»¥ä¸‹è½½æ‚¨çš„æ•°æ®é›†ã€‚
- en: '![Roboflow dataset download snippet](img/12be70e035123de5f9e65767cf1199ef.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![Roboflowæ•°æ®é›†ä¸‹è½½ç‰‡æ®µ](img/12be70e035123de5f9e65767cf1199ef.png)'
- en: 'Option 2: Create a Manual Dataset'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é€‰é¡¹2ï¼šåˆ›å»ºä¸€ä¸ªæ‰‹åŠ¨æ•°æ®é›†
- en: 2.1 Create `dataset.yaml`
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 åˆ›å»º`dataset.yaml`
- en: '[COCO128](https://www.kaggle.com/ultralytics/coco128) is an example small tutorial
    dataset composed of the first 128 images in [COCO](https://cocodataset.org/) train2017\.
    These same 128 images are used for both training and validation to verify our
    training pipeline is capable of overfitting. [data/coco128.yaml](https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml),
    shown below, is the dataset config file that defines 1) the dataset root directory
    `path` and relative paths to `train` / `val` / `test` image directories (or `*.txt`
    files with image paths) and 2) a class `names` dictionary:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[COCO128](https://www.kaggle.com/ultralytics/coco128)æ˜¯ä¸€ä¸ªå°å‹æ•™ç¨‹æ•°æ®é›†çš„ç¤ºä¾‹ï¼Œç”±[COCO](https://cocodataset.org/)
    train2017çš„å‰128å¼ å›¾åƒç»„æˆã€‚è¿™äº›ç›¸åŒçš„128å¼ å›¾åƒç”¨äºè®­ç»ƒå’ŒéªŒè¯ï¼Œä»¥éªŒè¯æˆ‘ä»¬çš„è®­ç»ƒæµæ°´çº¿èƒ½å¤Ÿè¿‡æ‹Ÿåˆã€‚ä¸‹é¢æ˜¾ç¤ºçš„[data/coco128.yaml](https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml)æ˜¯æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼Œå®šä¹‰äº†1ï¼‰æ•°æ®é›†æ ¹ç›®å½•`path`å’Œ`train`/`val`/`test`å›¾åƒç›®å½•ï¼ˆæˆ–å¸¦å›¾åƒè·¯å¾„çš„`*.txt`æ–‡ä»¶ï¼‰çš„ç›¸å¯¹è·¯å¾„ï¼Œä»¥åŠ2ï¼‰ç±»åˆ«`names`å­—å…¸ï¼š'
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 2.2 Create Labels
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 åˆ›å»ºæ ‡ç­¾
- en: 'After using an annotation tool to label your images, export your labels to
    **YOLO format**, with one `*.txt` file per image (if no objects in image, no `*.txt`
    file is required). The `*.txt` file specifications are:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ ‡æ³¨å·¥å…·ä¸ºæ‚¨çš„å›¾åƒæ·»åŠ æ ‡ç­¾åï¼Œå°†æ ‡ç­¾å¯¼å‡ºä¸º**YOLOæ ¼å¼**ï¼Œæ¯å¼ å›¾åƒç”Ÿæˆä¸€ä¸ª`*.txt`æ–‡ä»¶ï¼ˆå¦‚æœå›¾åƒä¸­æ²¡æœ‰å¯¹è±¡ï¼Œåˆ™ä¸éœ€è¦`*.txt`æ–‡ä»¶ï¼‰ã€‚`*.txt`æ–‡ä»¶çš„è§„èŒƒå¦‚ä¸‹ï¼š
- en: One row per object
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯ä¸ªå¯¹è±¡ä¸€è¡Œ
- en: Each row is `class x_center y_center width height` format.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯è¡Œæ˜¯`class x_center y_center width height`æ ¼å¼ã€‚
- en: Box coordinates must be in **normalized xywh** format (from 0 to 1). If your
    boxes are in pixels, divide `x_center` and `width` by image width, and `y_center`
    and `height` by image height.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›’å­åæ ‡å¿…é¡»ä»¥**å½’ä¸€åŒ–çš„xywhæ ¼å¼**è¡¨ç¤ºï¼ˆä»0åˆ°1ï¼‰ã€‚å¦‚æœæ‚¨çš„æ¡†æ˜¯ä»¥åƒç´ ä¸ºå•ä½çš„ï¼Œè¯·å°†`x_center`å’Œ`width`é™¤ä»¥å›¾åƒå®½åº¦ï¼Œå°†`y_center`å’Œ`height`é™¤ä»¥å›¾åƒé«˜åº¦ã€‚
- en: Class numbers are zero-indexed (start from 0).
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç±»åˆ«ç¼–å·æ˜¯ä»é›¶å¼€å§‹çš„ã€‚
- en: '![Roboflow annotations](img/7862b814c7eb88586c58cc415aac0ee0.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![Roboflowæ ‡æ³¨](img/7862b814c7eb88586c58cc415aac0ee0.png)'
- en: 'The label file corresponding to the above image contains 2 persons (class `0`)
    and a tie (class `27`):'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ä¸Šè¿°å›¾åƒå¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶åŒ…å«2ä¸ªäººï¼ˆç±»`0`ï¼‰å’Œä¸€æ¡é¢†å¸¦ï¼ˆç±»`27`ï¼‰ï¼š
- en: '![Roboflow dataset preprocessing](img/95161ff593802e8e1a7aee55e61c2d5a.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![Roboflow æ•°æ®é›†é¢„å¤„ç†](img/95161ff593802e8e1a7aee55e61c2d5a.png)'
- en: 2.3 Organize Directories
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 ç»„ç»‡ç›®å½•
- en: 'Organize your train and val images and labels according to the example below.
    YOLOv5 assumes `/coco128` is inside a `/datasets` directory **next to** the `/yolov5`
    directory. **YOLOv5 locates labels automatically for each image** by replacing
    the last instance of `/images/` in each image path with `/labels/`. For example:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®ä»¥ä¸‹ç¤ºä¾‹ç»„ç»‡æ‚¨çš„è®­ç»ƒå’ŒéªŒè¯å›¾åƒåŠæ ‡ç­¾ã€‚YOLOv5 å‡å®š`/coco128`ç›®å½•åœ¨ä¸`/yolov5`ç›®å½•**ç›¸é‚»**çš„`/datasets`ç›®å½•å†…ã€‚**YOLOv5ä¼šè‡ªåŠ¨å®šä½æ¯ä¸ªå›¾åƒè·¯å¾„ä¸­`/images/`çš„æœ€åä¸€ä¸ªå®ä¾‹ï¼Œä»¥è·å–ç›¸åº”çš„æ ‡ç­¾**ã€‚ä¾‹å¦‚ï¼š
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![YOLOv5 dataset structure](img/af465e2a88df7a85a7bbf7dc4588995b.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![YOLOv5 æ•°æ®é›†ç»“æ„](img/af465e2a88df7a85a7bbf7dc4588995b.png)'
- en: 3\. Select a Model
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. é€‰æ‹©æ¨¡å‹
- en: Select a pretrained model to start training from. Here we select [YOLOv5s](https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml),
    the second-smallest and fastest model available. See our README [table](https://github.com/ultralytics/yolov5#pretrained-checkpoints)
    for a full comparison of all models.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: é€‰æ‹©ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹å¼€å§‹è®­ç»ƒã€‚è¿™é‡Œæˆ‘ä»¬é€‰æ‹©äº†[YOLOv5s](https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml)ï¼Œè¿™æ˜¯å¯ç”¨çš„ç¬¬äºŒå°å’Œæœ€å¿«çš„æ¨¡å‹ã€‚è¯·æŸ¥çœ‹æˆ‘ä»¬çš„
    README [è¡¨æ ¼](https://github.com/ultralytics/yolov5#pretrained-checkpoints)ä»¥è·å–æ‰€æœ‰æ¨¡å‹çš„è¯¦ç»†æ¯”è¾ƒã€‚
- en: '![YOLOv5 models](img/ffa2ff00ee071ea0f899ac622121cf9f.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![YOLOv5 æ¨¡å‹](img/ffa2ff00ee071ea0f899ac622121cf9f.png)'
- en: 4\. Train
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. è®­ç»ƒ
- en: Train a YOLOv5s model on COCO128 by specifying dataset, batch-size, image size
    and either pretrained `--weights yolov5s.pt` (recommended), or randomly initialized
    `--weights '' --cfg yolov5s.yaml` (not recommended). Pretrained weights are auto-downloaded
    from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æŒ‡å®šæ•°æ®é›†ã€æ‰¹å¤§å°ã€å›¾åƒå¤§å°ä»¥åŠé¢„è®­ç»ƒæ¨¡å‹`--weights yolov5s.pt`ï¼ˆæ¨èï¼‰æˆ–éšæœºåˆå§‹åŒ–æ¨¡å‹`--weights '' --cfg
    yolov5s.yaml`ï¼ˆä¸æ¨èï¼‰ï¼Œåœ¨ COCO128 æ•°æ®é›†ä¸Šè®­ç»ƒ YOLOv5s æ¨¡å‹ã€‚é¢„è®­ç»ƒæƒé‡ä¼šè‡ªåŠ¨ä»[æœ€æ–°çš„ YOLOv5 å‘å¸ƒ](https://github.com/ultralytics/yolov5/releases)ä¸­ä¸‹è½½ã€‚
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Tip
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤º
- en: ğŸ’¡ Add `--cache ram` or `--cache disk` to speed up training (requires significant
    RAM/disk resources).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡ æ·»åŠ `--cache ram`æˆ–`--cache disk`ä»¥åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼ˆéœ€è¦å¤§é‡ RAM/ç£ç›˜èµ„æºï¼‰ã€‚
- en: Tip
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤º
- en: ğŸ’¡ Always train from a local dataset. Mounted or network drives like Google Drive
    will be very slow.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡ å§‹ç»ˆä»æœ¬åœ°æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚åƒ Google Drive è¿™æ ·çš„æŒ‚è½½æˆ–ç½‘ç»œé©±åŠ¨å™¨ä¼šéå¸¸æ…¢ã€‚
- en: All training results are saved to `runs/train/` with incrementing run directories,
    i.e. `runs/train/exp2`, `runs/train/exp3` etc. For more details see the Training
    section of our tutorial notebook. ![Open In Colab](https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb)
    ![Open In Kaggle](https://www.kaggle.com/ultralytics/yolov5)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰è®­ç»ƒç»“æœéƒ½ä¿å­˜åœ¨`runs/train/`ç›®å½•ä¸‹ï¼Œæ¯ä¸ªè¿è¡Œç”Ÿæˆä¸€ä¸ªé€’å¢çš„è¿è¡Œç›®å½•ï¼Œä¾‹å¦‚`runs/train/exp2`ï¼Œ`runs/train/exp3`ç­‰ã€‚æ›´å¤šç»†èŠ‚è¯·æŸ¥çœ‹æˆ‘ä»¬æ•™ç¨‹ç¬”è®°æœ¬çš„è®­ç»ƒéƒ¨åˆ†ã€‚![åœ¨
    Colab ä¸­æ‰“å¼€](https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb)
    ![åœ¨ Kaggle ä¸­æ‰“å¼€](https://www.kaggle.com/ultralytics/yolov5)
- en: 5\. Visualize
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. å¯è§†åŒ–
- en: Comet Logging and Visualization ğŸŒŸ NEW
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Comet æ—¥å¿—è®°å½•å’Œå¯è§†åŒ– ğŸŒŸ NEW
- en: '[Comet](https://bit.ly/yolov5-readme-comet) is now fully integrated with YOLOv5\.
    Track and visualize model metrics in real time, save your hyperparameters, datasets,
    and model checkpoints, and visualize your model predictions with [Comet Custom
    Panels](https://bit.ly/yolov5-colab-comet-panels)! Comet makes sure you never
    lose track of your work and makes it easy to share results and collaborate across
    teams of all sizes!'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[Comet](https://bit.ly/yolov5-readme-comet)ç°åœ¨å·²å®Œå…¨é›†æˆåˆ°YOLOv5ä¸­ã€‚å®æ—¶è·Ÿè¸ªå’Œå¯è§†åŒ–æ¨¡å‹æŒ‡æ ‡ï¼Œä¿å­˜è¶…å‚æ•°ã€æ•°æ®é›†å’Œæ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œå¹¶ä½¿ç”¨[Comet
    è‡ªå®šä¹‰é¢æ¿](https://bit.ly/yolov5-colab-comet-panels)å¯è§†åŒ–æ¨¡å‹é¢„æµ‹ï¼Comet ç¡®ä¿æ‚¨å§‹ç»ˆæŒæ¡å·¥ä½œè¿›å±•ï¼Œå¹¶è½»æ¾åˆ†äº«ç»“æœï¼Œä¿ƒè¿›å„ç§è§„æ¨¡å›¢é˜Ÿçš„åä½œï¼'
- en: 'Getting started is easy:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å¼€å§‹å¾ˆç®€å•ï¼š
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To learn more about all the supported Comet features for this integration,
    check out the Comet Tutorial. If you''d like to learn more about Comet, head over
    to our [documentation](https://bit.ly/yolov5-colab-comet-docs). Get started by
    trying out the Comet Colab Notebook: ![Open In Colab](https://colab.research.google.com/drive/1RG0WOQyxlDlo5Km8GogJpIEJlg_5lyYO?usp=sharing)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è¦äº†è§£æœ‰å…³æ­¤é›†æˆæ”¯æŒçš„æ‰€æœ‰ Comet åŠŸèƒ½çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ Comet æ•™ç¨‹ã€‚å¦‚æœæ‚¨æƒ³äº†è§£æ›´å¤šå…³äº Comet çš„ä¿¡æ¯ï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„[æ–‡æ¡£](https://bit.ly/yolov5-colab-comet-docs)ã€‚é€šè¿‡å°è¯•
    Comet Colab ç¬”è®°æœ¬æ¥å¼€å§‹å§ï¼š![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/drive/1RG0WOQyxlDlo5Km8GogJpIEJlg_5lyYO?usp=sharing)
- en: '![YOLO UI](img/ff37b378e0fc9906a44a9196515ec1f9.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![YOLO UI](img/ff37b378e0fc9906a44a9196515ec1f9.png)'
- en: ClearML Logging and Automation ğŸŒŸ NEW
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ClearML æ—¥å¿—è®°å½•å’Œè‡ªåŠ¨åŒ– ğŸŒŸ NEW
- en: '[ClearML](https://clear.ml/) is completely integrated into YOLOv5 to track
    your experimentation, manage dataset versions and even remotely execute training
    runs. To enable ClearML:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[ClearML](https://clear.ml/) å®Œå…¨é›†æˆåˆ° YOLOv5 ä¸­ï¼Œç”¨äºè·Ÿè¸ªæ‚¨çš„å®éªŒã€ç®¡ç†æ•°æ®é›†ç‰ˆæœ¬ï¼Œç”šè‡³è¿œç¨‹æ‰§è¡Œè®­ç»ƒè¿è¡Œã€‚è¦å¯ç”¨
    ClearMLï¼š'
- en: '`pip install clearml`'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip install clearml`'
- en: run `clearml-init` to connect to a ClearML server
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿è¡Œ`clearml-init`ä»¥è¿æ¥åˆ° ClearML æœåŠ¡å™¨
- en: 'You''ll get all the great expected features from an experiment manager: live
    updates, model upload, experiment comparison etc. but ClearML also tracks uncommitted
    changes and installed packages for example. Thanks to that ClearML Tasks (which
    is what we call experiments) are also reproducible on different machines! With
    only 1 extra line, we can schedule a YOLOv5 training task on a queue to be executed
    by any number of ClearML Agents (workers).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å°†è·å¾—å®éªŒç®¡ç†å™¨çš„æ‰€æœ‰é¢„æœŸåŠŸèƒ½ï¼šå®æ—¶æ›´æ–°ã€æ¨¡å‹ä¸Šä¼ ã€å®éªŒæ¯”è¾ƒç­‰ç­‰ã€‚ä½†æ˜¯ ClearML è¿˜ä¼šè·Ÿè¸ªæœªæäº¤çš„æ›´æ”¹å’Œå®‰è£…çš„è½¯ä»¶åŒ…ç­‰ã€‚ç”±äºè¿™ä¸€ç‚¹ï¼ŒClearML
    ä»»åŠ¡ï¼ˆæˆ‘ä»¬ç§°ä¹‹ä¸ºå®éªŒï¼‰åœ¨ä¸åŒçš„æœºå™¨ä¸Šä¹Ÿæ˜¯å¯é‡ç°çš„ï¼åªéœ€é¢å¤–çš„ 1 è¡Œä»£ç ï¼Œæˆ‘ä»¬å°±å¯ä»¥åœ¨é˜Ÿåˆ—ä¸Šå®‰æ’ä¸€ä¸ª YOLOv5 è®­ç»ƒä»»åŠ¡ï¼Œå¹¶ç”±ä»»æ„æ•°é‡çš„ ClearML
    ä»£ç†ï¼ˆå·¥ä½œèŠ‚ç‚¹ï¼‰æ‰§è¡Œã€‚
- en: You can use ClearML Data to version your dataset and then pass it to YOLOv5
    simply using its unique ID. This will help you keep track of your data without
    adding extra hassle. Explore the ClearML Tutorial for details!
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥ä½¿ç”¨ ClearML Data ç‰ˆæœ¬åŒ–æ‚¨çš„æ•°æ®é›†ï¼Œç„¶åé€šè¿‡å…¶å”¯ä¸€ ID ç®€å•åœ°ä¼ é€’ç»™ YOLOv5ã€‚è¿™å°†å¸®åŠ©æ‚¨åœ¨ä¸å¢åŠ é¢å¤–éº»çƒ¦çš„æƒ…å†µä¸‹è·Ÿè¸ªæ‚¨çš„æ•°æ®ã€‚æŸ¥çœ‹
    ClearML æ•™ç¨‹ä»¥è·å–è¯¦ç»†ä¿¡æ¯ï¼
- en: '![ClearML Experiment Management UI](https://clear.ml/)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![ClearML å®éªŒç®¡ç† UI](https://clear.ml/)'
- en: Local Logging
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æœ¬åœ°æ—¥å¿—è®°å½•
- en: Training results are automatically logged with [Tensorboard](https://www.tensorflow.org/tensorboard)
    and [CSV](https://github.com/ultralytics/yolov5/pull/4148) loggers to `runs/train`,
    with a new experiment directory created for each new training as `runs/train/exp2`,
    `runs/train/exp3`, etc.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒç»“æœä¼šè‡ªåŠ¨ä½¿ç”¨[Tensorboard](https://www.tensorflow.org/tensorboard)å’Œ[CSV](https://github.com/ultralytics/yolov5/pull/4148)è®°å½•å™¨è®°å½•åˆ°`runs/train`ï¼Œæ¯æ¬¡æ–°çš„è®­ç»ƒéƒ½ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„å®éªŒç›®å½•ï¼Œå¦‚`runs/train/exp2`ï¼Œ`runs/train/exp3`ç­‰ã€‚
- en: This directory contains train and val statistics, mosaics, labels, predictions
    and augmented mosaics, as well as metrics and charts including precision-recall
    (PR) curves and confusion matrices.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤ç›®å½•åŒ…å«è®­ç»ƒå’ŒéªŒè¯ç»Ÿè®¡æ•°æ®ã€é©¬èµ›å…‹ã€æ ‡ç­¾ã€é¢„æµ‹å’Œå¢å¼ºé©¬èµ›å…‹ï¼Œä»¥åŠåŒ…æ‹¬ç²¾ç¡®ç‡-å¬å›ç‡ (PR) æ›²çº¿å’Œæ··æ·†çŸ©é˜µåœ¨å†…çš„æŒ‡æ ‡å’Œå›¾è¡¨ã€‚
- en: '![Local logging results](img/3a55f7a591b526105186a450060fcee7.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![æœ¬åœ°æ—¥å¿—ç»“æœ](img/3a55f7a591b526105186a450060fcee7.png)'
- en: 'Results file `results.csv` is updated after each epoch, and then plotted as
    `results.png` (below) after training completes. You can also plot any `results.csv`
    file manually:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå®Œæˆåï¼Œç»“æœæ–‡ä»¶`results.csv`ä¼šåœ¨æ¯ä¸ªæ—¶æœŸåæ›´æ–°ï¼Œå¹¶åœ¨è®­ç»ƒå®Œæˆåç»˜åˆ¶ä¸º`results.png`ï¼ˆä¸‹å›¾ï¼‰ã€‚æ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨ç»˜åˆ¶ä»»ä½•`results.csv`æ–‡ä»¶ï¼š
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![results.png](img/35b4c06846d28420289c7aa59df324f8.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![results.png](img/35b4c06846d28420289c7aa59df324f8.png)'
- en: Next Steps
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€æ­¥
- en: 'Once your model is trained you can use your best checkpoint `best.pt` to:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨çš„æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æœ€ä½³æ£€æŸ¥ç‚¹`best.pt`ï¼š
- en: Run [CLI](https://github.com/ultralytics/yolov5#quick-start-examples) or Python
    inference on new images and videos
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ–°å›¾åƒå’Œè§†é¢‘ä¸Šè¿è¡Œ[CLI](https://github.com/ultralytics/yolov5#quick-start-examples)æˆ–Pythonæ¨ç†
- en: '[Validate](https://github.com/ultralytics/yolov5/blob/master/val.py) accuracy
    on train, val and test splits'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†ä¸Š[éªŒè¯](https://github.com/ultralytics/yolov5/blob/master/val.py)ç²¾åº¦
- en: Export to TensorFlow, Keras, ONNX, TFlite, TF.js, CoreML and TensorRT formats
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¼å‡ºåˆ° TensorFlowã€Kerasã€ONNXã€TFliteã€TF.jsã€CoreML å’Œ TensorRT æ ¼å¼
- en: Evolve hyperparameters to improve performance
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è°ƒæ•´è¶…å‚æ•°ä»¥æé«˜æ€§èƒ½
- en: '[Improve](https://docs.roboflow.com/adding-data/upload-api?ref=ultralytics)
    your model by sampling real-world images and adding them to your dataset'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ”¹è¿›](https://docs.roboflow.com/adding-data/upload-api?ref=ultralytics)æ‚¨çš„æ¨¡å‹ï¼Œé€šè¿‡é‡‡æ ·çœŸå®ä¸–ç•Œå›¾åƒå¹¶å°†å…¶æ·»åŠ åˆ°æ•°æ®é›†ä¸­'
- en: Supported Environments
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ”¯æŒçš„ç¯å¢ƒ
- en: Ultralytics provides a range of ready-to-use environments, each pre-installed
    with essential dependencies such as [CUDA](https://developer.nvidia.com/cuda),
    [CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/),
    and [PyTorch](https://pytorch.org/), to kickstart your projects.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics æä¾›ä¸€ç³»åˆ—é¢„å®‰è£…äº†å…³é”®ä¾èµ–é¡¹å¦‚[CUDA](https://developer.nvidia.com/cuda)ã€[CUDNN](https://developer.nvidia.com/cudnn)ã€[Python](https://www.python.org/)å’Œ[PyTorch](https://pytorch.org/)çš„å³ç”¨ç¯å¢ƒï¼Œä¸ºæ‚¨çš„é¡¹ç›®å¯åŠ¨æä¾›å¸®åŠ©ã€‚
- en: '**Free GPU Notebooks**: ![Run on Gradient](https://bit.ly/yolov5-paperspace-notebook)
    ![Open In Colab](https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb)
    ![Open In Kaggle](https://www.kaggle.com/ultralytics/yolov5)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å…è´¹ GPU ç¬”è®°æœ¬**: ![åœ¨ Gradient ä¸Šè¿è¡Œ](https://bit.ly/yolov5-paperspace-notebook)
    ![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb)
    ![åœ¨ Kaggle ä¸­æ‰“å¼€](https://www.kaggle.com/ultralytics/yolov5)'
- en: '**Google Cloud**: GCP Quickstart Guide'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Cloud**: GCP å¿«é€Ÿå…¥é—¨æŒ‡å—'
- en: '**Amazon**: AWS Quickstart Guide'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon**ï¼šAWS å¿«é€Ÿå…¥é—¨æŒ‡å—'
- en: '**Azure**: AzureML Quickstart Guide'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure**ï¼šAzureML å¿«é€Ÿå…¥é—¨æŒ‡å—'
- en: '**Docker**: Docker Quickstart Guide ![Docker Pulls](https://hub.docker.com/r/ultralytics/yolov5)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker**ï¼šDocker å¿«é€Ÿå…¥é—¨æŒ‡å— ![Docker Pulls](https://hub.docker.com/r/ultralytics/yolov5)'
- en: Project Status
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é¡¹ç›®çŠ¶æ€
- en: '![YOLOv5 CI](https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![YOLOv5 CI](https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml)'
- en: 'This badge indicates that all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions)
    Continuous Integration (CI) tests are successfully passing. These CI tests rigorously
    check the functionality and performance of YOLOv5 across various key aspects:
    [training](https://github.com/ultralytics/yolov5/blob/master/train.py), [validation](https://github.com/ultralytics/yolov5/blob/master/val.py),
    [inference](https://github.com/ultralytics/yolov5/blob/master/detect.py), [export](https://github.com/ultralytics/yolov5/blob/master/export.py),
    and [benchmarks](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py).
    They ensure consistent and reliable operation on macOS, Windows, and Ubuntu, with
    tests conducted every 24 hours and upon each new commit.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¾½ç« è¡¨ç¤ºæ‰€æœ‰ [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions)
    æŒç»­é›†æˆï¼ˆCIï¼‰æµ‹è¯•éƒ½å·²æˆåŠŸé€šè¿‡ã€‚è¿™äº› CI æµ‹è¯•ä¸¥æ ¼æ£€æŸ¥ YOLOv5 åœ¨å„ä¸ªå…³é”®æ–¹é¢çš„åŠŸèƒ½å’Œæ€§èƒ½ï¼š[è®­ç»ƒ](https://github.com/ultralytics/yolov5/blob/master/train.py)ï¼Œ[éªŒè¯](https://github.com/ultralytics/yolov5/blob/master/val.py)ï¼Œ[æ¨æ–­](https://github.com/ultralytics/yolov5/blob/master/detect.py)ï¼Œ[å¯¼å‡º](https://github.com/ultralytics/yolov5/blob/master/export.py)
    å’Œ [åŸºå‡†æµ‹è¯•](https://github.com/ultralytics/yolov5/blob/master/benchmarks.py)ã€‚å®ƒä»¬ç¡®ä¿åœ¨
    macOSã€Windows å’Œ Ubuntu ä¸Šçš„ä¸€è‡´å’Œå¯é æ“ä½œï¼Œæ¯ 24 å°æ—¶å’Œæ¯æ¬¡æ–°æäº¤åéƒ½è¿›è¡Œæµ‹è¯•ã€‚
- en: FAQ
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¸¸è§é—®é¢˜è§£ç­”
- en: How do I train YOLOv5 on my custom dataset?
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æˆ‘å¦‚ä½•åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šè®­ç»ƒ YOLOv5ï¼Ÿ
- en: 'Training YOLOv5 on a custom dataset involves several steps:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒè‡ªå®šä¹‰æ•°æ®é›†çš„ YOLOv5 æ¶‰åŠä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š
- en: '**Prepare Your Dataset**: Collect and label images. Use tools like [Roboflow](https://roboflow.com/?ref=ultralytics)
    to organize data and export in [YOLOv5 format](https://roboflow.com/formats/yolov5-pytorch-txt?ref=ultralytics).'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å‡†å¤‡æ•°æ®é›†**ï¼šæ”¶é›†å’Œæ ‡è®°å›¾åƒã€‚ä½¿ç”¨åƒ [Roboflow](https://roboflow.com/?ref=ultralytics) è¿™æ ·çš„å·¥å…·æ¥ç»„ç»‡æ•°æ®å¹¶ä»¥
    [YOLOv5 æ ¼å¼](https://roboflow.com/formats/yolov5-pytorch-txt?ref=ultralytics) å¯¼å‡ºã€‚'
- en: '**Setup Environment**: Clone the YOLOv5 repo and install dependencies:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è®¾ç½®ç¯å¢ƒ**ï¼šå…‹éš† YOLOv5 ä»“åº“å¹¶å®‰è£…ä¾èµ–é¡¹ï¼š'
- en: '[PRE6]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Create Dataset Configuration**: Write a `dataset.yaml` file defining train/val
    paths and class names.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åˆ›å»ºæ•°æ®é›†é…ç½®**ï¼šç¼–å†™ `dataset.yaml` æ–‡ä»¶å®šä¹‰è®­ç»ƒ/éªŒè¯è·¯å¾„å’Œç±»åã€‚'
- en: '**Train the Model**:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è®­ç»ƒæ¨¡å‹**ï¼š'
- en: '[PRE7]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: What tools can I use to annotate my YOLOv5 dataset?
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æˆ‘å¯ä»¥ä½¿ç”¨ä»€ä¹ˆå·¥å…·æ¥æ³¨é‡Šæˆ‘çš„ YOLOv5 æ•°æ®é›†ï¼Ÿ
- en: You can use [Roboflow Annotate](https://roboflow.com/annotate?ref=ultralytics),
    an intuitive web-based tool for labeling images. It supports team collaboration
    and exports in YOLOv5 format. After collecting images, use Roboflow to create
    and manage annotations efficiently. Other options include tools like LabelImg
    and CVAT for local annotations.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥ä½¿ç”¨ [Roboflow Annotate](https://roboflow.com/annotate?ref=ultralytics)ï¼Œè¿™æ˜¯ä¸€ä¸ªç›´è§‚çš„åŸºäº
    Web çš„å›¾åƒæ ‡æ³¨å·¥å…·ã€‚æ”¯æŒå›¢é˜Ÿåä½œï¼Œå¹¶æ”¯æŒ YOLOv5 æ ¼å¼çš„å¯¼å‡ºã€‚æ”¶é›†å›¾åƒåï¼Œä½¿ç”¨ Roboflow å¯ä»¥é«˜æ•ˆåœ°åˆ›å»ºå’Œç®¡ç†æ³¨é‡Šã€‚å…¶ä»–é€‰é¡¹åŒ…æ‹¬åƒ LabelImg
    å’Œ CVAT è¿™æ ·çš„æœ¬åœ°æ ‡æ³¨å·¥å…·ã€‚
- en: Why should I use Ultralytics HUB for training my YOLO models?
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆåº”è¯¥ä½¿ç”¨ Ultralytics HUB è®­ç»ƒæˆ‘çš„ YOLO æ¨¡å‹ï¼Ÿ
- en: 'Ultralytics HUB offers an end-to-end platform for training, deploying, and
    managing YOLO models without needing extensive coding skills. Benefits of using
    Ultralytics HUB include:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics HUB æä¾›äº†ä¸€ä¸ªç«¯åˆ°ç«¯å¹³å°ï¼Œç”¨äºè®­ç»ƒã€éƒ¨ç½²å’Œç®¡ç† YOLO æ¨¡å‹ï¼Œæ— éœ€æ·±å…¥çš„ç¼–ç æŠ€èƒ½ã€‚ä½¿ç”¨ Ultralytics HUB çš„å¥½å¤„åŒ…æ‹¬ï¼š
- en: '**Easy Model Training**: Simplifies the training process with preconfigured
    environments.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç®€æ˜“æ¨¡å‹è®­ç»ƒ**ï¼šé€šè¿‡é¢„é…ç½®ç¯å¢ƒç®€åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚'
- en: '**Data Management**: Effortlessly manage datasets and version control.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ•°æ®ç®¡ç†**ï¼šè½»æ¾ç®¡ç†æ•°æ®é›†å’Œç‰ˆæœ¬æ§åˆ¶ã€‚'
- en: '**Real-time Monitoring**: Integrates tools like [Comet](https://bit.ly/yolov5-readme-comet)
    for real-time metrics tracking and visualization.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å®æ—¶ç›‘æ§**ï¼šé›†æˆåƒ [Comet](https://bit.ly/yolov5-readme-comet) è¿™æ ·çš„å·¥å…·è¿›è¡Œå®æ—¶åº¦é‡è·Ÿè¸ªå’Œå¯è§†åŒ–ã€‚'
- en: '**Collaboration**: Ideal for team projects with shared resources and easy management.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åä½œ**ï¼šéå¸¸é€‚åˆå…±äº«èµ„æºå’Œè½»æ¾ç®¡ç†çš„å›¢é˜Ÿé¡¹ç›®ã€‚'
- en: How do I convert my annotated data to YOLOv5 format?
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¦‚ä½•å°†æˆ‘çš„æ ‡æ³¨æ•°æ®è½¬æ¢ä¸º YOLOv5 æ ¼å¼ï¼Ÿ
- en: 'To convert annotated data to YOLOv5 format using Roboflow:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Roboflow å°†æ ‡æ³¨æ•°æ®è½¬æ¢ä¸º YOLOv5 æ ¼å¼çš„æ­¥éª¤ï¼š
- en: '**Upload Your Dataset** to a Roboflow workspace.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä¸Šä¼ æ‚¨çš„æ•°æ®é›†**ï¼ˆUpload Your Datasetï¼‰è‡³ Roboflow å·¥ä½œç©ºé—´ã€‚'
- en: '**Label Images** if not already labeled.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ ‡è®°å›¾åƒ**ï¼ˆLabel Imagesï¼‰å¦‚æœå°šæœªæ ‡è®°ã€‚'
- en: '**Generate and Export** the dataset in `YOLOv5 Pytorch` format. Ensure preprocessing
    steps like Auto-Orient and Resize (Stretch) to the square input size (e.g., 640x640)
    are applied.'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¹¶å¯¼å‡ºä»¥ `YOLOv5 Pytorch` æ ¼å¼çš„æ•°æ®é›†ã€‚ç¡®ä¿åº”ç”¨åƒè‡ªåŠ¨å®šå‘å’Œè°ƒæ•´å¤§å°ï¼ˆæ‹‰ä¼¸ï¼‰åˆ°æ–¹å½¢è¾“å…¥å°ºå¯¸ï¼ˆä¾‹å¦‚ 640x640ï¼‰çš„é¢„å¤„ç†æ­¥éª¤ã€‚
- en: '**Download the Dataset** and integrate it into your YOLOv5 training script.'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä¸‹è½½æ•°æ®é›†** å¹¶å°†å…¶é›†æˆåˆ°æ‚¨çš„ YOLOv5 è®­ç»ƒè„šæœ¬ä¸­ã€‚'
- en: What are the licensing options for using YOLOv5 in commercial applications?
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœ¨å•†ä¸šåº”ç”¨ä¸­ä½¿ç”¨ YOLOv5 çš„è®¸å¯é€‰é¡¹æ˜¯ä»€ä¹ˆï¼Ÿ
- en: 'Ultralytics offers two licensing options:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics æä¾›ä¸¤ç§è®¸å¯é€‰é¡¹ï¼š
- en: '**AGPL-3.0 License**: An open-source license suitable for non-commercial use,
    ideal for students and enthusiasts.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AGPL-3.0 è®¸å¯è¯**ï¼šé€‚ç”¨äºéå•†ä¸šç”¨é€”çš„å¼€æºè®¸å¯ï¼Œéå¸¸é€‚åˆå­¦ç”Ÿå’Œçˆ±å¥½è€…ã€‚'
- en: '**Enterprise License**: Tailored for businesses seeking to integrate YOLOv5
    into commercial products and services. For detailed information, visit our [Licensing
    page](https://ultralytics.com/license).'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¼ä¸šè®¸å¯è¯**ï¼šä¸“ä¸ºå¸Œæœ›å°† YOLOv5 é›†æˆåˆ°å•†ä¸šäº§å“å’ŒæœåŠ¡ä¸­çš„ä¼ä¸šé‡èº«å®šåˆ¶ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„ [è®¸å¯é¡µé¢](https://ultralytics.com/license)ã€‚'
- en: For more details, refer to our guide on [Ultralytics Licensing](https://ultralytics.com/license).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥é˜…æˆ‘ä»¬çš„æŒ‡å— [Ultralytics è®¸å¯](https://ultralytics.com/license) è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
