- en: scipy.special.log_softmax
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.special.log_softmax.html#scipy.special.log_softmax](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.special.log_softmax.html#scipy.special.log_softmax)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Compute the logarithm of the softmax function.
  prefs: []
  type: TYPE_NORMAL
- en: 'In principle:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: but using a more accurate implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**x**array_like'
  prefs: []
  type: TYPE_NORMAL
- en: Input array.
  prefs: []
  type: TYPE_NORMAL
- en: '**axis**int or tuple of ints, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Axis to compute values along. Default is None and softmax will be computed over
    the entire array *x*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: '**s**ndarray or scalar'
  prefs: []
  type: TYPE_NORMAL
- en: An array with the same shape as *x*. Exponential of the result will sum to 1
    along the specified axis. If *x* is a scalar, a scalar is returned.
  prefs: []
  type: TYPE_NORMAL
- en: Notes
  prefs: []
  type: TYPE_NORMAL
- en: '[`log_softmax`](#scipy.special.log_softmax "scipy.special.log_softmax") is
    more accurate than `np.log(softmax(x))` with inputs that make [`softmax`](scipy.special.softmax.html#scipy.special.softmax
    "scipy.special.softmax") saturate (see examples below).'
  prefs: []
  type: TYPE_NORMAL
- en: New in version 1.5.0.
  prefs: []
  type: TYPE_NORMAL
- en: Examples
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
