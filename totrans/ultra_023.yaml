- en: 'YOLOv9: A Leap Forward in Object Detection Technology'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/models/yolov9/`](https://docs.ultralytics.com/models/yolov9/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: YOLOv9 marks a significant advancement in real-time object detection, introducing
    groundbreaking techniques such as Programmable Gradient Information (PGI) and
    the Generalized Efficient Layer Aggregation Network (GELAN). This model demonstrates
    remarkable improvements in efficiency, accuracy, and adaptability, setting new
    benchmarks on the MS COCO dataset. The YOLOv9 project, while developed by a separate
    open-source team, builds upon the robust codebase provided by [Ultralytics](https://ultralytics.com)
    YOLOv5, showcasing the collaborative spirit of the AI research community.
  prefs: []
  type: TYPE_NORMAL
- en: '[`www.youtube.com/embed/ZF7EAodHn1U`](https://www.youtube.com/embed/ZF7EAodHn1U)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch:** YOLOv9 Training on Custom Data using Ultralytics | Industrial Package
    Dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '![YOLOv9 performance comparison](img/58159486ad379b1c4e02ad9e75e3ac24.png)'
  prefs: []
  type: TYPE_IMG
- en: Introduction to YOLOv9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the quest for optimal real-time object detection, YOLOv9 stands out with
    its innovative approach to overcoming information loss challenges inherent in
    deep neural networks. By integrating PGI and the versatile GELAN architecture,
    YOLOv9 not only enhances the model's learning capacity but also ensures the retention
    of crucial information throughout the detection process, thereby achieving exceptional
    accuracy and performance.
  prefs: []
  type: TYPE_NORMAL
- en: Core Innovations of YOLOv9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: YOLOv9's advancements are deeply rooted in addressing the challenges posed by
    information loss in deep neural networks. The Information Bottleneck Principle
    and the innovative use of Reversible Functions are central to its design, ensuring
    YOLOv9 maintains high efficiency and accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Information Bottleneck Principle
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Information Bottleneck Principle reveals a fundamental challenge in deep
    learning: as data passes through successive layers of a network, the potential
    for information loss increases. This phenomenon is mathematically represented
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: where `I` denotes mutual information, and `f` and `g` represent transformation
    functions with parameters `theta` and `phi`, respectively. YOLOv9 counters this
    challenge by implementing Programmable Gradient Information (PGI), which aids
    in preserving essential data across the network's depth, ensuring more reliable
    gradient generation and, consequently, better model convergence and performance.
  prefs: []
  type: TYPE_NORMAL
- en: Reversible Functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The concept of Reversible Functions is another cornerstone of YOLOv9''s design.
    A function is deemed reversible if it can be inverted without any loss of information,
    as expressed by:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: with `psi` and `zeta` as parameters for the reversible and its inverse function,
    respectively. This property is crucial for deep learning architectures, as it
    allows the network to retain a complete information flow, thereby enabling more
    accurate updates to the model's parameters. YOLOv9 incorporates reversible functions
    within its architecture to mitigate the risk of information degradation, especially
    in deeper layers, ensuring the preservation of critical data for object detection
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Impact on Lightweight Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Addressing information loss is particularly vital for lightweight models, which
    are often under-parameterized and prone to losing significant information during
    the feedforward process. YOLOv9's architecture, through the use of PGI and reversible
    functions, ensures that even with a streamlined model, the essential information
    required for accurate object detection is retained and effectively utilized.
  prefs: []
  type: TYPE_NORMAL
- en: Programmable Gradient Information (PGI)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: PGI is a novel concept introduced in YOLOv9 to combat the information bottleneck
    problem, ensuring the preservation of essential data across deep network layers.
    This allows for the generation of reliable gradients, facilitating accurate model
    updates and improving the overall detection performance.
  prefs: []
  type: TYPE_NORMAL
- en: Generalized Efficient Layer Aggregation Network (GELAN)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GELAN represents a strategic architectural advancement, enabling YOLOv9 to achieve
    superior parameter utilization and computational efficiency. Its design allows
    for flexible integration of various computational blocks, making YOLOv9 adaptable
    to a wide range of applications without sacrificing speed or accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '![YOLOv9 architecture comparison](img/3a4ffbfbce4fe4b8b735a7d8375094eb.png)'
  prefs: []
  type: TYPE_IMG
- en: YOLOv9 Benchmarks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Benchmarking in YOLOv9 using [Ultralytics](https://docs.ultralytics.com/modes/benchmark/)
    involves evaluating the performance of your trained and validated model in real-world
    scenarios. This process includes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Performance Evaluation:** Assessing the model''s speed and accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Export Formats:** Testing the model across different export formats to ensure
    it meets the necessary standards and performs well in various environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Framework Support:** Providing a comprehensive framework within Ultralytics
    YOLOv8 to facilitate these assessments and ensure consistent and reliable results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By benchmarking, you can ensure that your model not only performs well in controlled
    testing environments but also maintains high performance in practical, real-world
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: '[`www.youtube.com/embed/ziJR01lKnio`](https://www.youtube.com/embed/ziJR01lKnio)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch:** How to Benchmark the YOLOv9 Model Using the Ultralytics Python Package'
  prefs: []
  type: TYPE_NORMAL
- en: Performance on MS COCO Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The performance of YOLOv9 on the COCO dataset exemplifies its significant advancements
    in real-time object detection, setting new benchmarks across various model sizes.
    Table 1 presents a comprehensive comparison of state-of-the-art real-time object
    detectors, illustrating YOLOv9's superior efficiency and accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 1\. Comparison of State-of-the-Art Real-Time Object Detectors**'
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | mAP^(val 50) | params ^((M))
    | FLOPs ^((B)) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv9t](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9t.pt)
    | 640 | 38.3 | 53.1 | 2.0 | 7.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv9s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9s.pt)
    | 640 | 46.8 | 63.4 | 7.2 | 26.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv9m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9m.pt)
    | 640 | 51.4 | 68.1 | 20.1 | 76.8 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv9c](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9c.pt)
    | 640 | 53.0 | 70.2 | 25.5 | 102.8 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv9e](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9e.pt)
    | 640 | 55.6 | 72.8 | 58.1 | 192.5 |'
  prefs: []
  type: TYPE_TB
- en: '| Model | size ^((pixels)) | mAP^(box 50-95) | mAP^(mask 50-95) | params ^((M))
    | FLOPs ^((B)) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv9c-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9c-seg.pt)
    | 640 | 52.4 | 42.2 | 27.9 | 159.4 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv9e-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9e-seg.pt)
    | 640 | 55.1 | 44.3 | 60.5 | 248.4 |'
  prefs: []
  type: TYPE_TB
- en: YOLOv9's iterations, ranging from the tiny `t` variant to the extensive `e`
    model, demonstrate improvements not only in accuracy (mAP metrics) but also in
    efficiency with a reduced number of parameters and computational needs (FLOPs).
    This table underscores YOLOv9's ability to deliver high precision while maintaining
    or reducing the computational overhead compared to prior versions and competing
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Comparatively, YOLOv9 exhibits remarkable gains:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lightweight Models**: YOLOv9s surpasses the YOLO MS-S in parameter efficiency
    and computational load while achieving an improvement of 0.4∼0.6% in AP.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Medium to Large Models**: YOLOv9m and YOLOv9e show notable advancements in
    balancing the trade-off between model complexity and detection performance, offering
    significant reductions in parameters and computations against the backdrop of
    improved accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The YOLOv9c model, in particular, highlights the effectiveness of the architecture's
    optimizations. It operates with 42% fewer parameters and 21% less computational
    demand than YOLOv7 AF, yet it achieves comparable accuracy, demonstrating YOLOv9's
    significant efficiency improvements. Furthermore, the YOLOv9e model sets a new
    standard for large models, with 15% fewer parameters and 25% less computational
    need than YOLOv8x, alongside an incremental 1.7% improvement in AP.
  prefs: []
  type: TYPE_NORMAL
- en: These results showcase YOLOv9's strategic advancements in model design, emphasizing
    its enhanced efficiency without compromising on the precision essential for real-time
    object detection tasks. The model not only pushes the boundaries of performance
    metrics but also emphasizes the importance of computational efficiency, making
    it a pivotal development in the field of computer vision.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: YOLOv9 represents a pivotal development in real-time object detection, offering
    significant improvements in terms of efficiency, accuracy, and adaptability. By
    addressing critical challenges through innovative solutions like PGI and GELAN,
    YOLOv9 sets a new precedent for future research and application in the field.
    As the AI community continues to evolve, YOLOv9 stands as a testament to the power
    of collaboration and innovation in driving technological progress.
  prefs: []
  type: TYPE_NORMAL
- en: Usage Examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This example provides simple YOLOv9 training and inference examples. For full
    documentation on these and other modes see the Predict, Train, Val and Export
    docs pages.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: 'PyTorch pretrained `*.pt` models as well as configuration `*.yaml` files can
    be passed to the `YOLO()` class to create a model instance in python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'CLI commands are available to directly run the models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Supported Tasks and Modes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The YOLOv9 series offers a range of models, each optimized for high-performance
    Object Detection. These models cater to varying computational needs and accuracy
    requirements, making them versatile for a wide array of applications.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Filenames | Tasks | Inference | Validation | Training | Export |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv9 | `yolov9t` `yolov9s` `yolov9m` `yolov9c.pt` `yolov9e.pt` | Object
    Detection | ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv9-seg | `yolov9c-seg.pt` `yolov9e-seg.pt` | Instance Segmentation |
    ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: This table provides a detailed overview of the YOLOv9 model variants, highlighting
    their capabilities in object detection tasks and their compatibility with various
    operational modes such as Inference, Validation, Training, and Export. This comprehensive
    support ensures that users can fully leverage the capabilities of YOLOv9 models
    in a broad range of object detection scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Training YOLOv9 models will require *more* resources **and** take longer than
    the equivalent sized YOLOv8 model.
  prefs: []
  type: TYPE_NORMAL
- en: Citations and Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We would like to acknowledge the YOLOv9 authors for their significant contributions
    in the field of real-time object detection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The original YOLOv9 paper can be found on [arXiv](https://arxiv.org/pdf/2402.13616.pdf).
    The authors have made their work publicly available, and the codebase can be accessed
    on [GitHub](https://github.com/WongKinYiu/yolov9). We appreciate their efforts
    in advancing the field and making their work accessible to the broader community.
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What innovations does YOLOv9 introduce for real-time object detection?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv9 introduces groundbreaking techniques such as Programmable Gradient Information
    (PGI) and the Generalized Efficient Layer Aggregation Network (GELAN). These innovations
    address information loss challenges in deep neural networks, ensuring high efficiency,
    accuracy, and adaptability. PGI preserves essential data across network layers,
    while GELAN optimizes parameter utilization and computational efficiency. Learn
    more about YOLOv9's core innovations that set new benchmarks on the MS COCO dataset.
  prefs: []
  type: TYPE_NORMAL
- en: How does YOLOv9 perform on the MS COCO dataset compared to other models?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv9 outperforms state-of-the-art real-time object detectors by achieving
    higher accuracy and efficiency. On the COCO dataset, YOLOv9 models exhibit superior
    mAP scores across various sizes while maintaining or reducing computational overhead.
    For instance, YOLOv9c achieves comparable accuracy with 42% fewer parameters and
    21% less computational demand than YOLOv7 AF. Explore performance comparisons
    for detailed metrics.
  prefs: []
  type: TYPE_NORMAL
- en: How can I train a YOLOv9 model using Python and CLI?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can train a YOLOv9 model using both Python and CLI commands. For Python,
    instantiate a model using the `YOLO` class and call the `train` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'For CLI training, execute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Learn more about usage examples for training and inference.
  prefs: []
  type: TYPE_NORMAL
- en: What are the advantages of using Ultralytics YOLOv9 for lightweight models?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv9 is designed to mitigate information loss, which is particularly important
    for lightweight models often prone to losing significant information. By integrating
    Programmable Gradient Information (PGI) and reversible functions, YOLOv9 ensures
    essential data retention, enhancing the model's accuracy and efficiency. This
    makes it highly suitable for applications requiring compact models with high performance.
    For more details, explore the section on YOLOv9's impact on lightweight models.
  prefs: []
  type: TYPE_NORMAL
- en: What tasks and modes does YOLOv9 support?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv9 supports various tasks including object detection and instance segmentation.
    It is compatible with multiple operational modes such as inference, validation,
    training, and export. This versatility makes YOLOv9 adaptable to diverse real-time
    computer vision applications. Refer to the supported tasks and modes section for
    more information.
  prefs: []
  type: TYPE_NORMAL
