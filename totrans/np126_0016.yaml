- en: Interoperability with NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://numpy.org/doc/1.26/user/basics.interoperability.html](https://numpy.org/doc/1.26/user/basics.interoperability.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: NumPy’s ndarray objects provide both a high-level API for operations on array-structured
    data and a concrete implementation of the API based on [strided in-RAM storage](../reference/arrays.html#arrays).
    While this API is powerful and fairly general, its concrete implementation has
    limitations. As datasets grow and NumPy becomes used in a variety of new environments
    and architectures, there are cases where the strided in-RAM storage strategy is
    inappropriate, which has caused different libraries to reimplement this API for
    their own uses. This includes GPU arrays ([CuPy](https://cupy.dev/)), Sparse arrays
    ([`scipy.sparse`](https://docs.scipy.org/doc/scipy/reference/sparse.html#module-scipy.sparse
    "(in SciPy v1.11.2)"), [PyData/Sparse](https://sparse.pydata.org/)) and parallel
    arrays ([Dask](https://docs.dask.org/) arrays) as well as various NumPy-like implementations
    in deep learning frameworks, like [TensorFlow](https://www.tensorflow.org/) and
    [PyTorch](https://pytorch.org/). Similarly, there are many projects that build
    on top of the NumPy API for labeled and indexed arrays ([XArray](http://xarray.pydata.org/)),
    automatic differentiation ([JAX](https://jax.readthedocs.io/)), masked arrays
    ([`numpy.ma`](../reference/maskedarray.generic.html#module-numpy.ma "numpy.ma")),
    physical units ([astropy.units](https://docs.astropy.org/en/stable/units/), [pint](https://pint.readthedocs.io/),
    [unyt](https://unyt.readthedocs.io/)), among others that add additional functionality
    on top of the NumPy API.
  prefs: []
  type: TYPE_NORMAL
- en: Yet, users still want to work with these arrays using the familiar NumPy API
    and re-use existing code with minimal (ideally zero) porting overhead. With this
    goal in mind, various protocols are defined for implementations of multi-dimensional
    arrays with high-level APIs matching NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Broadly speaking, there are three groups of features used for interoperability
    with NumPy:'
  prefs: []
  type: TYPE_NORMAL
- en: Methods of turning a foreign object into an ndarray;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Methods of deferring execution from a NumPy function to another array library;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Methods that use NumPy functions and return an instance of a foreign object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We describe these features below.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Using arbitrary objects in NumPy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first set of interoperability features from the NumPy API allows foreign
    objects to be treated as NumPy arrays whenever possible. When NumPy functions
    encounter a foreign object, they will try (in order):'
  prefs: []
  type: TYPE_NORMAL
- en: The buffer protocol, described [in the Python C-API documentation](https://docs.python.org/3/c-api/buffer.html
    "(in Python v3.11)").
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `__array_interface__` protocol, described [in this page](../reference/arrays.interface.html#arrays-interface).
    A precursor to Python’s buffer protocol, it defines a way to access the contents
    of a NumPy array from other C extensions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `__array__()` method, which asks an arbitrary object to convert itself into
    an array.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For both the buffer and the `__array_interface__` protocols, the object describes
    its memory layout and NumPy does everything else (zero-copy if possible). If that’s
    not possible, the object itself is responsible for returning a `ndarray` from
    `__array__()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[DLPack](https://dmlc.github.io/dlpack/latest/index.html "(in DLPack)") is
    yet another protocol to convert foreign objects to NumPy arrays in a language
    and device agnostic manner. NumPy doesn’t implicitly convert objects to ndarrays
    using DLPack. It provides the function [`numpy.from_dlpack`](../reference/generated/numpy.from_dlpack.html#numpy.from_dlpack
    "numpy.from_dlpack") that accepts any object implementing the `__dlpack__` method
    and outputs a NumPy ndarray (which is generally a view of the input object’s data
    buffer). The [Python Specification for DLPack](https://dmlc.github.io/dlpack/latest/python_spec.html#python-spec
    "(in DLPack)") page explains the `__dlpack__` protocol in detail.'
  prefs: []
  type: TYPE_NORMAL
- en: The array interface protocol
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The [array interface protocol](../reference/arrays.interface.html#arrays-interface)
    defines a way for array-like objects to re-use each other’s data buffers. Its
    implementation relies on the existence of the following attributes or methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`__array_interface__`: a Python dictionary containing the shape, the element
    type, and optionally, the data buffer address and the strides of an array-like
    object;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__array__()`: a method returning the NumPy ndarray view of an array-like object;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `__array_interface__` attribute can be inspected directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `__array_interface__` attribute can also be used to manipulate the object
    data in place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check that `arr` and `new_arr` share the same data buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `__array__()` method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `__array__()` method ensures that any NumPy-like object (an array, any object
    exposing the array interface, an object whose `__array__()` method returns an
    array or any nested sequence) that implements it can be used as a NumPy array.
    If possible, this will mean using `__array__()` to create a NumPy ndarray view
    of the array-like object. Otherwise, this copies the data into a new ndarray object.
    This is not optimal, as coercing arrays into ndarrays may cause performance problems
    or create the need for copies and loss of metadata, as the original object and
    any attributes/behavior it may have had, is lost.
  prefs: []
  type: TYPE_NORMAL
- en: To see an example of a custom array implementation including the use of `__array__()`,
    see [Writing custom array containers](basics.dispatch.html#basics-dispatch).
  prefs: []
  type: TYPE_NORMAL
- en: The DLPack Protocol
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The [DLPack](https://dmlc.github.io/dlpack/latest/index.html "(in DLPack)")
    protocol defines a memory-layout of strided n-dimensional array objects. It offers
    the following syntax for data exchange:'
  prefs: []
  type: TYPE_NORMAL
- en: A [`numpy.from_dlpack`](../reference/generated/numpy.from_dlpack.html#numpy.from_dlpack
    "numpy.from_dlpack") function, which accepts (array) objects with a `__dlpack__`
    method and uses that method to construct a new array containing the data from
    `x`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`__dlpack__(self, stream=None)` and `__dlpack_device__` methods on the array
    object, which will be called from within `from_dlpack`, to query what device the
    array is on (may be needed to pass in the correct stream, e.g. in the case of
    multiple GPUs) and to access the data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Unlike the buffer protocol, DLPack allows exchanging arrays containing data
    on devices other than the CPU (e.g. Vulkan or GPU). Since NumPy only supports
    CPU, it can only convert objects whose data exists on the CPU. But other libraries,
    like [PyTorch](https://pytorch.org/) and [CuPy](https://cupy.dev/), may exchange
    data on GPU using this protocol.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Operating on foreign objects without converting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A second set of methods defined by the NumPy API allows us to defer the execution
    from a NumPy function to another array library.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the following function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that [`np.exp`](../reference/generated/numpy.exp.html#numpy.exp "numpy.exp")
    is a [ufunc](basics.ufuncs.html#ufuncs-basics), which means that it operates on
    ndarrays in an element-by-element fashion. On the other hand, [`np.mean`](../reference/generated/numpy.mean.html#numpy.mean
    "numpy.mean") operates along one of the array’s axes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can apply `f` to a NumPy ndarray object directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We would like this function to work equally well with any NumPy-like array object.
  prefs: []
  type: TYPE_NORMAL
- en: 'NumPy allows a class to indicate that it would like to handle computations
    in a custom-defined way through the following interfaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '`__array_ufunc__`: allows third-party objects to support and override [ufuncs](basics.ufuncs.html#ufuncs-basics).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__array_function__`: a catch-all for NumPy functionality that is not covered
    by the `__array_ufunc__` protocol for universal functions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As long as foreign objects implement the `__array_ufunc__` or `__array_function__`
    protocols, it is possible to operate on them without the need for explicit conversion.
  prefs: []
  type: TYPE_NORMAL
- en: The `__array_ufunc__` protocol
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A [universal function (or ufunc for short)](basics.ufuncs.html#ufuncs-basics)
    is a “vectorized” wrapper for a function that takes a fixed number of specific
    inputs and produces a fixed number of specific outputs. The output of the ufunc
    (and its methods) is not necessarily a ndarray, if not all input arguments are
    ndarrays. Indeed, if any input defines an `__array_ufunc__` method, control will
    be passed completely to that function, i.e., the ufunc is overridden. The `__array_ufunc__`
    method defined on that (non-ndarray) object has access to the NumPy ufunc. Because
    ufuncs have a well-defined structure, the foreign `__array_ufunc__` method may
    rely on ufunc attributes like `.at()`, `.reduce()`, and others.
  prefs: []
  type: TYPE_NORMAL
- en: A subclass can override what happens when executing NumPy ufuncs on it by overriding
    the default `ndarray.__array_ufunc__` method. This method is executed instead
    of the ufunc and should return either the result of the operation, or `NotImplemented`
    if the operation requested is not implemented.
  prefs: []
  type: TYPE_NORMAL
- en: The `__array_function__` protocol
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To achieve enough coverage of the NumPy API to support downstream projects,
    there is a need to go beyond `__array_ufunc__` and implement a protocol that allows
    arguments of a NumPy function to take control and divert execution to another
    function (for example, a GPU or parallel implementation) in a way that is safe
    and consistent across projects.
  prefs: []
  type: TYPE_NORMAL
- en: The semantics of `__array_function__` are very similar to `__array_ufunc__`,
    except the operation is specified by an arbitrary callable object rather than
    a ufunc instance and method. For more details, see [NEP 18 — A dispatch mechanism
    for NumPy’s high level array functions](https://numpy.org/neps/nep-0018-array-function-protocol.html#nep18
    "(in NumPy Enhancement Proposals)").
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Returning foreign objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A third type of feature set is meant to use the NumPy function implementation
    and then convert the return value back into an instance of the foreign object.
    The `__array_finalize__` and `__array_wrap__` methods act behind the scenes to
    ensure that the return type of a NumPy function can be specified as needed.
  prefs: []
  type: TYPE_NORMAL
- en: The `__array_finalize__` method is the mechanism that NumPy provides to allow
    subclasses to handle the various ways that new instances get created. This method
    is called whenever the system internally allocates a new array from an object
    which is a subclass (subtype) of the ndarray. It can be used to change attributes
    after construction, or to update meta-information from the “parent.”
  prefs: []
  type: TYPE_NORMAL
- en: The `__array_wrap__` method “wraps up the action” in the sense of allowing any
    object (such as user-defined functions) to set the type of its return value and
    update attributes and metadata. This can be seen as the opposite of the `__array__`
    method. At the end of every object that implements `__array_wrap__`, this method
    is called on the input object with the highest *array priority*, or the output
    object if one was specified. The `__array_priority__` attribute is used to determine
    what type of object to return in situations where there is more than one possibility
    for the Python type of the returned object. For example, subclasses may opt to
    use this method to transform the output array into an instance of the subclass
    and update metadata before returning the array to the user.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on these methods, see [Subclassing ndarray](basics.subclassing.html#basics-subclassing)
    and [Specific features of ndarray sub-typing](c-info.beyond-basics.html#specific-array-subtyping).
  prefs: []
  type: TYPE_NORMAL
- en: Interoperability examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Example: Pandas `Series` objects'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, `ser` is **not** a ndarray, but because it [implements the __array_ufunc__
    protocol](https://pandas.pydata.org/docs/user_guide/dsintro.html#dataframe-interoperability-with-numpy-functions),
    we can apply ufuncs to it as if it were a ndarray:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We can even do operations with other ndarrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Example: PyTorch tensors'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PyTorch](https://pytorch.org/) is an optimized tensor library for deep learning
    using GPUs and CPUs. PyTorch arrays are commonly called *tensors*. Tensors are
    similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware
    accelerators. In fact, tensors and NumPy arrays can often share the same underlying
    memory, eliminating the need to copy data.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `x_np` and `x_tensor` are different kinds of objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'However, we can treat PyTorch tensors as NumPy arrays without the need for
    explicit conversion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Also, note that the return type of this function is compatible with the initial
    data type.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs: []
  type: TYPE_NORMAL
- en: While this mixing of ndarrays and tensors may be convenient, it is not recommended.
    It will not work for non-CPU tensors, and will have unexpected behavior in corner
    cases. Users should prefer explicitly converting the ndarray to a tensor.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch does not implement `__array_function__` or `__array_ufunc__`. Under
    the hood, the `Tensor.__array__()` method returns a NumPy ndarray as a view of
    the tensor data buffer. See [this issue](https://github.com/pytorch/pytorch/issues/24015)
    and the [__torch_function__ implementation](https://github.com/pytorch/pytorch/blob/master/torch/overrides.py)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note also that we can see `__array_wrap__` in action here, even though `torch.Tensor`
    is not a subclass of ndarray:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: PyTorch implements `__array_wrap__` to be able to get tensors back from NumPy
    functions, and we can modify it directly to control which type of objects are
    returned from these functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: CuPy arrays'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CuPy is a NumPy/SciPy-compatible array library for GPU-accelerated computing
    with Python. CuPy implements a subset of the NumPy interface by implementing `cupy.ndarray`,
    [a counterpart to NumPy ndarrays](https://docs.cupy.dev/en/stable/reference/ndarray.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The `cupy.ndarray` object implements the `__array_ufunc__` interface. This
    enables NumPy ufuncs to be applied to CuPy arrays (this will defer operation to
    the matching CuPy CUDA/ROCm implementation of the ufunc):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the return type of these operations is still consistent with the
    initial type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: See [this page in the CuPy documentation for details](https://docs.cupy.dev/en/stable/reference/ufunc.html).
  prefs: []
  type: TYPE_NORMAL
- en: '`cupy.ndarray` also implements the `__array_function__` interface, meaning
    it is possible to do operations such as'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: CuPy implements many NumPy functions on `cupy.ndarray` objects, but not all.
    See [the CuPy documentation](https://docs.cupy.dev/en/stable/user_guide/difference.html)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Dask arrays'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dask is a flexible library for parallel computing in Python. Dask Array implements
    a subset of the NumPy ndarray interface using blocked algorithms, cutting up the
    large array into many small arrays. This allows computations on larger-than-memory
    arrays using multiple cores.
  prefs: []
  type: TYPE_NORMAL
- en: Dask supports `__array__()` and `__array_ufunc__`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Dask is lazily evaluated, and the result from a computation isn’t computed until
    you ask for it by invoking `compute()`.
  prefs: []
  type: TYPE_NORMAL
- en: See [the Dask array documentation](https://docs.dask.org/en/stable/array.html)
    and the [scope of Dask arrays interoperability with NumPy arrays](https://docs.dask.org/en/stable/array.html#scope)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: DLPack'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Several Python data science libraries implement the `__dlpack__` protocol. Among
    them are [PyTorch](https://pytorch.org/) and [CuPy](https://cupy.dev/). A full
    list of libraries that implement this protocol can be found on [this page of DLPack
    documentation](https://dmlc.github.io/dlpack/latest/index.html "(in DLPack)").
  prefs: []
  type: TYPE_NORMAL
- en: 'Convert a PyTorch CPU tensor to NumPy array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The imported arrays are read-only so writing or operating in-place will fail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'A copy must be created in order to operate on the imported arrays in-place,
    but will mean duplicating the memory. Do not do this for very large arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that GPU tensors can’t be converted to NumPy arrays since NumPy doesn’t
    support GPU devices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'But, if both libraries support the device the data buffer is on, it is possible
    to use the `__dlpack__` protocol (e.g. [PyTorch](https://pytorch.org/) and [CuPy](https://cupy.dev/)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, a NumPy array can be converted to a PyTorch tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Read-only arrays cannot be exported:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Further reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[The array interface protocol](../reference/arrays.interface.html#arrays-interface)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Writing custom array containers](basics.dispatch.html#basics-dispatch)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Special attributes and methods](../reference/arrays.classes.html#special-attributes-and-methods)
    (details on the `__array_ufunc__` and `__array_function__` protocols)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Subclassing ndarray](basics.subclassing.html#basics-subclassing) (details
    on the `__array_wrap__` and `__array_finalize__` methods)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Specific features of ndarray sub-typing](c-info.beyond-basics.html#specific-array-subtyping)
    (more details on the implementation of `__array_finalize__`, `__array_wrap__`
    and `__array_priority__`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NumPy roadmap: interoperability](https://numpy.org/neps/roadmap.html "(in
    NumPy Enhancement Proposals)")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PyTorch documentation on the Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1\. Using arbitrary objects in NumPy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first set of interoperability features from the NumPy API allows foreign
    objects to be treated as NumPy arrays whenever possible. When NumPy functions
    encounter a foreign object, they will try (in order):'
  prefs: []
  type: TYPE_NORMAL
- en: The buffer protocol, described [in the Python C-API documentation](https://docs.python.org/3/c-api/buffer.html
    "(in Python v3.11)").
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `__array_interface__` protocol, described [in this page](../reference/arrays.interface.html#arrays-interface).
    A precursor to Python’s buffer protocol, it defines a way to access the contents
    of a NumPy array from other C extensions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `__array__()` method, which asks an arbitrary object to convert itself into
    an array.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For both the buffer and the `__array_interface__` protocols, the object describes
    its memory layout and NumPy does everything else (zero-copy if possible). If that’s
    not possible, the object itself is responsible for returning a `ndarray` from
    `__array__()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[DLPack](https://dmlc.github.io/dlpack/latest/index.html "(in DLPack)") is
    yet another protocol to convert foreign objects to NumPy arrays in a language
    and device agnostic manner. NumPy doesn’t implicitly convert objects to ndarrays
    using DLPack. It provides the function [`numpy.from_dlpack`](../reference/generated/numpy.from_dlpack.html#numpy.from_dlpack
    "numpy.from_dlpack") that accepts any object implementing the `__dlpack__` method
    and outputs a NumPy ndarray (which is generally a view of the input object’s data
    buffer). The [Python Specification for DLPack](https://dmlc.github.io/dlpack/latest/python_spec.html#python-spec
    "(in DLPack)") page explains the `__dlpack__` protocol in detail.'
  prefs: []
  type: TYPE_NORMAL
- en: The array interface protocol
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The [array interface protocol](../reference/arrays.interface.html#arrays-interface)
    defines a way for array-like objects to re-use each other’s data buffers. Its
    implementation relies on the existence of the following attributes or methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`__array_interface__`: a Python dictionary containing the shape, the element
    type, and optionally, the data buffer address and the strides of an array-like
    object;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__array__()`: a method returning the NumPy ndarray view of an array-like object;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `__array_interface__` attribute can be inspected directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The `__array_interface__` attribute can also be used to manipulate the object
    data in place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check that `arr` and `new_arr` share the same data buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The `__array__()` method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `__array__()` method ensures that any NumPy-like object (an array, any object
    exposing the array interface, an object whose `__array__()` method returns an
    array or any nested sequence) that implements it can be used as a NumPy array.
    If possible, this will mean using `__array__()` to create a NumPy ndarray view
    of the array-like object. Otherwise, this copies the data into a new ndarray object.
    This is not optimal, as coercing arrays into ndarrays may cause performance problems
    or create the need for copies and loss of metadata, as the original object and
    any attributes/behavior it may have had, is lost.
  prefs: []
  type: TYPE_NORMAL
- en: To see an example of a custom array implementation including the use of `__array__()`,
    see [Writing custom array containers](basics.dispatch.html#basics-dispatch).
  prefs: []
  type: TYPE_NORMAL
- en: The DLPack Protocol
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The [DLPack](https://dmlc.github.io/dlpack/latest/index.html "(in DLPack)")
    protocol defines a memory-layout of strided n-dimensional array objects. It offers
    the following syntax for data exchange:'
  prefs: []
  type: TYPE_NORMAL
- en: A [`numpy.from_dlpack`](../reference/generated/numpy.from_dlpack.html#numpy.from_dlpack
    "numpy.from_dlpack") function, which accepts (array) objects with a `__dlpack__`
    method and uses that method to construct a new array containing the data from
    `x`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`__dlpack__(self, stream=None)` and `__dlpack_device__` methods on the array
    object, which will be called from within `from_dlpack`, to query what device the
    array is on (may be needed to pass in the correct stream, e.g. in the case of
    multiple GPUs) and to access the data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Unlike the buffer protocol, DLPack allows exchanging arrays containing data
    on devices other than the CPU (e.g. Vulkan or GPU). Since NumPy only supports
    CPU, it can only convert objects whose data exists on the CPU. But other libraries,
    like [PyTorch](https://pytorch.org/) and [CuPy](https://cupy.dev/), may exchange
    data on GPU using this protocol.
  prefs: []
  type: TYPE_NORMAL
- en: The array interface protocol
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The [array interface protocol](../reference/arrays.interface.html#arrays-interface)
    defines a way for array-like objects to re-use each other’s data buffers. Its
    implementation relies on the existence of the following attributes or methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`__array_interface__`: a Python dictionary containing the shape, the element
    type, and optionally, the data buffer address and the strides of an array-like
    object;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__array__()`: a method returning the NumPy ndarray view of an array-like object;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `__array_interface__` attribute can be inspected directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The `__array_interface__` attribute can also be used to manipulate the object
    data in place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check that `arr` and `new_arr` share the same data buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The `__array__()` method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `__array__()` method ensures that any NumPy-like object (an array, any object
    exposing the array interface, an object whose `__array__()` method returns an
    array or any nested sequence) that implements it can be used as a NumPy array.
    If possible, this will mean using `__array__()` to create a NumPy ndarray view
    of the array-like object. Otherwise, this copies the data into a new ndarray object.
    This is not optimal, as coercing arrays into ndarrays may cause performance problems
    or create the need for copies and loss of metadata, as the original object and
    any attributes/behavior it may have had, is lost.
  prefs: []
  type: TYPE_NORMAL
- en: To see an example of a custom array implementation including the use of `__array__()`,
    see [Writing custom array containers](basics.dispatch.html#basics-dispatch).
  prefs: []
  type: TYPE_NORMAL
- en: The DLPack Protocol
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The [DLPack](https://dmlc.github.io/dlpack/latest/index.html "(in DLPack)")
    protocol defines a memory-layout of strided n-dimensional array objects. It offers
    the following syntax for data exchange:'
  prefs: []
  type: TYPE_NORMAL
- en: A [`numpy.from_dlpack`](../reference/generated/numpy.from_dlpack.html#numpy.from_dlpack
    "numpy.from_dlpack") function, which accepts (array) objects with a `__dlpack__`
    method and uses that method to construct a new array containing the data from
    `x`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`__dlpack__(self, stream=None)` and `__dlpack_device__` methods on the array
    object, which will be called from within `from_dlpack`, to query what device the
    array is on (may be needed to pass in the correct stream, e.g. in the case of
    multiple GPUs) and to access the data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Unlike the buffer protocol, DLPack allows exchanging arrays containing data
    on devices other than the CPU (e.g. Vulkan or GPU). Since NumPy only supports
    CPU, it can only convert objects whose data exists on the CPU. But other libraries,
    like [PyTorch](https://pytorch.org/) and [CuPy](https://cupy.dev/), may exchange
    data on GPU using this protocol.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Operating on foreign objects without converting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A second set of methods defined by the NumPy API allows us to defer the execution
    from a NumPy function to another array library.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the following function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Note that [`np.exp`](../reference/generated/numpy.exp.html#numpy.exp "numpy.exp")
    is a [ufunc](basics.ufuncs.html#ufuncs-basics), which means that it operates on
    ndarrays in an element-by-element fashion. On the other hand, [`np.mean`](../reference/generated/numpy.mean.html#numpy.mean
    "numpy.mean") operates along one of the array’s axes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can apply `f` to a NumPy ndarray object directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: We would like this function to work equally well with any NumPy-like array object.
  prefs: []
  type: TYPE_NORMAL
- en: 'NumPy allows a class to indicate that it would like to handle computations
    in a custom-defined way through the following interfaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '`__array_ufunc__`: allows third-party objects to support and override [ufuncs](basics.ufuncs.html#ufuncs-basics).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__array_function__`: a catch-all for NumPy functionality that is not covered
    by the `__array_ufunc__` protocol for universal functions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As long as foreign objects implement the `__array_ufunc__` or `__array_function__`
    protocols, it is possible to operate on them without the need for explicit conversion.
  prefs: []
  type: TYPE_NORMAL
- en: The `__array_ufunc__` protocol
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A [universal function (or ufunc for short)](basics.ufuncs.html#ufuncs-basics)
    is a “vectorized” wrapper for a function that takes a fixed number of specific
    inputs and produces a fixed number of specific outputs. The output of the ufunc
    (and its methods) is not necessarily a ndarray, if not all input arguments are
    ndarrays. Indeed, if any input defines an `__array_ufunc__` method, control will
    be passed completely to that function, i.e., the ufunc is overridden. The `__array_ufunc__`
    method defined on that (non-ndarray) object has access to the NumPy ufunc. Because
    ufuncs have a well-defined structure, the foreign `__array_ufunc__` method may
    rely on ufunc attributes like `.at()`, `.reduce()`, and others.
  prefs: []
  type: TYPE_NORMAL
- en: A subclass can override what happens when executing NumPy ufuncs on it by overriding
    the default `ndarray.__array_ufunc__` method. This method is executed instead
    of the ufunc and should return either the result of the operation, or `NotImplemented`
    if the operation requested is not implemented.
  prefs: []
  type: TYPE_NORMAL
- en: The `__array_function__` protocol
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To achieve enough coverage of the NumPy API to support downstream projects,
    there is a need to go beyond `__array_ufunc__` and implement a protocol that allows
    arguments of a NumPy function to take control and divert execution to another
    function (for example, a GPU or parallel implementation) in a way that is safe
    and consistent across projects.
  prefs: []
  type: TYPE_NORMAL
- en: The semantics of `__array_function__` are very similar to `__array_ufunc__`,
    except the operation is specified by an arbitrary callable object rather than
    a ufunc instance and method. For more details, see [NEP 18 — A dispatch mechanism
    for NumPy’s high level array functions](https://numpy.org/neps/nep-0018-array-function-protocol.html#nep18
    "(in NumPy Enhancement Proposals)").
  prefs: []
  type: TYPE_NORMAL
- en: The `__array_ufunc__` protocol
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A [universal function (or ufunc for short)](basics.ufuncs.html#ufuncs-basics)
    is a “vectorized” wrapper for a function that takes a fixed number of specific
    inputs and produces a fixed number of specific outputs. The output of the ufunc
    (and its methods) is not necessarily a ndarray, if not all input arguments are
    ndarrays. Indeed, if any input defines an `__array_ufunc__` method, control will
    be passed completely to that function, i.e., the ufunc is overridden. The `__array_ufunc__`
    method defined on that (non-ndarray) object has access to the NumPy ufunc. Because
    ufuncs have a well-defined structure, the foreign `__array_ufunc__` method may
    rely on ufunc attributes like `.at()`, `.reduce()`, and others.
  prefs: []
  type: TYPE_NORMAL
- en: A subclass can override what happens when executing NumPy ufuncs on it by overriding
    the default `ndarray.__array_ufunc__` method. This method is executed instead
    of the ufunc and should return either the result of the operation, or `NotImplemented`
    if the operation requested is not implemented.
  prefs: []
  type: TYPE_NORMAL
- en: The `__array_function__` protocol
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To achieve enough coverage of the NumPy API to support downstream projects,
    there is a need to go beyond `__array_ufunc__` and implement a protocol that allows
    arguments of a NumPy function to take control and divert execution to another
    function (for example, a GPU or parallel implementation) in a way that is safe
    and consistent across projects.
  prefs: []
  type: TYPE_NORMAL
- en: The semantics of `__array_function__` are very similar to `__array_ufunc__`,
    except the operation is specified by an arbitrary callable object rather than
    a ufunc instance and method. For more details, see [NEP 18 — A dispatch mechanism
    for NumPy’s high level array functions](https://numpy.org/neps/nep-0018-array-function-protocol.html#nep18
    "(in NumPy Enhancement Proposals)").
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Returning foreign objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A third type of feature set is meant to use the NumPy function implementation
    and then convert the return value back into an instance of the foreign object.
    The `__array_finalize__` and `__array_wrap__` methods act behind the scenes to
    ensure that the return type of a NumPy function can be specified as needed.
  prefs: []
  type: TYPE_NORMAL
- en: The `__array_finalize__` method is the mechanism that NumPy provides to allow
    subclasses to handle the various ways that new instances get created. This method
    is called whenever the system internally allocates a new array from an object
    which is a subclass (subtype) of the ndarray. It can be used to change attributes
    after construction, or to update meta-information from the “parent.”
  prefs: []
  type: TYPE_NORMAL
- en: The `__array_wrap__` method “wraps up the action” in the sense of allowing any
    object (such as user-defined functions) to set the type of its return value and
    update attributes and metadata. This can be seen as the opposite of the `__array__`
    method. At the end of every object that implements `__array_wrap__`, this method
    is called on the input object with the highest *array priority*, or the output
    object if one was specified. The `__array_priority__` attribute is used to determine
    what type of object to return in situations where there is more than one possibility
    for the Python type of the returned object. For example, subclasses may opt to
    use this method to transform the output array into an instance of the subclass
    and update metadata before returning the array to the user.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on these methods, see [Subclassing ndarray](basics.subclassing.html#basics-subclassing)
    and [Specific features of ndarray sub-typing](c-info.beyond-basics.html#specific-array-subtyping).
  prefs: []
  type: TYPE_NORMAL
- en: Interoperability examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Example: Pandas `Series` objects'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, `ser` is **not** a ndarray, but because it [implements the __array_ufunc__
    protocol](https://pandas.pydata.org/docs/user_guide/dsintro.html#dataframe-interoperability-with-numpy-functions),
    we can apply ufuncs to it as if it were a ndarray:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We can even do operations with other ndarrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Example: PyTorch tensors'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PyTorch](https://pytorch.org/) is an optimized tensor library for deep learning
    using GPUs and CPUs. PyTorch arrays are commonly called *tensors*. Tensors are
    similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware
    accelerators. In fact, tensors and NumPy arrays can often share the same underlying
    memory, eliminating the need to copy data.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `x_np` and `x_tensor` are different kinds of objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'However, we can treat PyTorch tensors as NumPy arrays without the need for
    explicit conversion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Also, note that the return type of this function is compatible with the initial
    data type.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs: []
  type: TYPE_NORMAL
- en: While this mixing of ndarrays and tensors may be convenient, it is not recommended.
    It will not work for non-CPU tensors, and will have unexpected behavior in corner
    cases. Users should prefer explicitly converting the ndarray to a tensor.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch does not implement `__array_function__` or `__array_ufunc__`. Under
    the hood, the `Tensor.__array__()` method returns a NumPy ndarray as a view of
    the tensor data buffer. See [this issue](https://github.com/pytorch/pytorch/issues/24015)
    and the [__torch_function__ implementation](https://github.com/pytorch/pytorch/blob/master/torch/overrides.py)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note also that we can see `__array_wrap__` in action here, even though `torch.Tensor`
    is not a subclass of ndarray:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: PyTorch implements `__array_wrap__` to be able to get tensors back from NumPy
    functions, and we can modify it directly to control which type of objects are
    returned from these functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: CuPy arrays'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CuPy is a NumPy/SciPy-compatible array library for GPU-accelerated computing
    with Python. CuPy implements a subset of the NumPy interface by implementing `cupy.ndarray`,
    [a counterpart to NumPy ndarrays](https://docs.cupy.dev/en/stable/reference/ndarray.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The `cupy.ndarray` object implements the `__array_ufunc__` interface. This
    enables NumPy ufuncs to be applied to CuPy arrays (this will defer operation to
    the matching CuPy CUDA/ROCm implementation of the ufunc):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the return type of these operations is still consistent with the
    initial type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: See [this page in the CuPy documentation for details](https://docs.cupy.dev/en/stable/reference/ufunc.html).
  prefs: []
  type: TYPE_NORMAL
- en: '`cupy.ndarray` also implements the `__array_function__` interface, meaning
    it is possible to do operations such as'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: CuPy implements many NumPy functions on `cupy.ndarray` objects, but not all.
    See [the CuPy documentation](https://docs.cupy.dev/en/stable/user_guide/difference.html)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Dask arrays'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dask is a flexible library for parallel computing in Python. Dask Array implements
    a subset of the NumPy ndarray interface using blocked algorithms, cutting up the
    large array into many small arrays. This allows computations on larger-than-memory
    arrays using multiple cores.
  prefs: []
  type: TYPE_NORMAL
- en: Dask supports `__array__()` and `__array_ufunc__`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Dask is lazily evaluated, and the result from a computation isn’t computed until
    you ask for it by invoking `compute()`.
  prefs: []
  type: TYPE_NORMAL
- en: See [the Dask array documentation](https://docs.dask.org/en/stable/array.html)
    and the [scope of Dask arrays interoperability with NumPy arrays](https://docs.dask.org/en/stable/array.html#scope)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: DLPack'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Several Python data science libraries implement the `__dlpack__` protocol. Among
    them are [PyTorch](https://pytorch.org/) and [CuPy](https://cupy.dev/). A full
    list of libraries that implement this protocol can be found on [this page of DLPack
    documentation](https://dmlc.github.io/dlpack/latest/index.html "(in DLPack)").
  prefs: []
  type: TYPE_NORMAL
- en: 'Convert a PyTorch CPU tensor to NumPy array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The imported arrays are read-only so writing or operating in-place will fail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'A copy must be created in order to operate on the imported arrays in-place,
    but will mean duplicating the memory. Do not do this for very large arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that GPU tensors can’t be converted to NumPy arrays since NumPy doesn’t
    support GPU devices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'But, if both libraries support the device the data buffer is on, it is possible
    to use the `__dlpack__` protocol (e.g. [PyTorch](https://pytorch.org/) and [CuPy](https://cupy.dev/)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, a NumPy array can be converted to a PyTorch tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Read-only arrays cannot be exported:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Example: Pandas `Series` objects'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, `ser` is **not** a ndarray, but because it [implements the __array_ufunc__
    protocol](https://pandas.pydata.org/docs/user_guide/dsintro.html#dataframe-interoperability-with-numpy-functions),
    we can apply ufuncs to it as if it were a ndarray:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'We can even do operations with other ndarrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Example: PyTorch tensors'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PyTorch](https://pytorch.org/) is an optimized tensor library for deep learning
    using GPUs and CPUs. PyTorch arrays are commonly called *tensors*. Tensors are
    similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware
    accelerators. In fact, tensors and NumPy arrays can often share the same underlying
    memory, eliminating the need to copy data.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `x_np` and `x_tensor` are different kinds of objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'However, we can treat PyTorch tensors as NumPy arrays without the need for
    explicit conversion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Also, note that the return type of this function is compatible with the initial
    data type.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs: []
  type: TYPE_NORMAL
- en: While this mixing of ndarrays and tensors may be convenient, it is not recommended.
    It will not work for non-CPU tensors, and will have unexpected behavior in corner
    cases. Users should prefer explicitly converting the ndarray to a tensor.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch does not implement `__array_function__` or `__array_ufunc__`. Under
    the hood, the `Tensor.__array__()` method returns a NumPy ndarray as a view of
    the tensor data buffer. See [this issue](https://github.com/pytorch/pytorch/issues/24015)
    and the [__torch_function__ implementation](https://github.com/pytorch/pytorch/blob/master/torch/overrides.py)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note also that we can see `__array_wrap__` in action here, even though `torch.Tensor`
    is not a subclass of ndarray:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: PyTorch implements `__array_wrap__` to be able to get tensors back from NumPy
    functions, and we can modify it directly to control which type of objects are
    returned from these functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: CuPy arrays'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CuPy is a NumPy/SciPy-compatible array library for GPU-accelerated computing
    with Python. CuPy implements a subset of the NumPy interface by implementing `cupy.ndarray`,
    [a counterpart to NumPy ndarrays](https://docs.cupy.dev/en/stable/reference/ndarray.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The `cupy.ndarray` object implements the `__array_ufunc__` interface. This
    enables NumPy ufuncs to be applied to CuPy arrays (this will defer operation to
    the matching CuPy CUDA/ROCm implementation of the ufunc):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the return type of these operations is still consistent with the
    initial type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: See [this page in the CuPy documentation for details](https://docs.cupy.dev/en/stable/reference/ufunc.html).
  prefs: []
  type: TYPE_NORMAL
- en: '`cupy.ndarray` also implements the `__array_function__` interface, meaning
    it is possible to do operations such as'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: CuPy implements many NumPy functions on `cupy.ndarray` objects, but not all.
    See [the CuPy documentation](https://docs.cupy.dev/en/stable/user_guide/difference.html)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Dask arrays'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dask is a flexible library for parallel computing in Python. Dask Array implements
    a subset of the NumPy ndarray interface using blocked algorithms, cutting up the
    large array into many small arrays. This allows computations on larger-than-memory
    arrays using multiple cores.
  prefs: []
  type: TYPE_NORMAL
- en: Dask supports `__array__()` and `__array_ufunc__`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Dask is lazily evaluated, and the result from a computation isn’t computed until
    you ask for it by invoking `compute()`.
  prefs: []
  type: TYPE_NORMAL
- en: See [the Dask array documentation](https://docs.dask.org/en/stable/array.html)
    and the [scope of Dask arrays interoperability with NumPy arrays](https://docs.dask.org/en/stable/array.html#scope)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: DLPack'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Several Python data science libraries implement the `__dlpack__` protocol. Among
    them are [PyTorch](https://pytorch.org/) and [CuPy](https://cupy.dev/). A full
    list of libraries that implement this protocol can be found on [this page of DLPack
    documentation](https://dmlc.github.io/dlpack/latest/index.html "(in DLPack)").
  prefs: []
  type: TYPE_NORMAL
- en: 'Convert a PyTorch CPU tensor to NumPy array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The imported arrays are read-only so writing or operating in-place will fail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'A copy must be created in order to operate on the imported arrays in-place,
    but will mean duplicating the memory. Do not do this for very large arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that GPU tensors can’t be converted to NumPy arrays since NumPy doesn’t
    support GPU devices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'But, if both libraries support the device the data buffer is on, it is possible
    to use the `__dlpack__` protocol (e.g. [PyTorch](https://pytorch.org/) and [CuPy](https://cupy.dev/)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, a NumPy array can be converted to a PyTorch tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Read-only arrays cannot be exported:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Further reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[The array interface protocol](../reference/arrays.interface.html#arrays-interface)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Writing custom array containers](basics.dispatch.html#basics-dispatch)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Special attributes and methods](../reference/arrays.classes.html#special-attributes-and-methods)
    (details on the `__array_ufunc__` and `__array_function__` protocols)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Subclassing ndarray](basics.subclassing.html#basics-subclassing) (details
    on the `__array_wrap__` and `__array_finalize__` methods)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Specific features of ndarray sub-typing](c-info.beyond-basics.html#specific-array-subtyping)
    (more details on the implementation of `__array_finalize__`, `__array_wrap__`
    and `__array_priority__`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NumPy roadmap: interoperability](https://numpy.org/neps/roadmap.html "(in
    NumPy Enhancement Proposals)")'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PyTorch documentation on the Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
