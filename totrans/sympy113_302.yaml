- en: Writing Tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://docs.sympy.org/latest/contributing/new-contributors-guide/writing-tests.html](https://docs.sympy.org/latest/contributing/new-contributors-guide/writing-tests.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The most important thing for a mathematical library like SymPy is correctness.
    Functions should never return mathematically incorrect results. Correctness is
    always the top concern, even if it comes at the cost of things like performance
    or modularity.
  prefs: []
  type: TYPE_NORMAL
- en: Consequently, all functionality in SymPy is tested extensively. This guide goes
    over how tests in SymPy are written.
  prefs: []
  type: TYPE_NORMAL
- en: Testing Policies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to ensure the high standard of correctness, SymPy has the following
    rules that apply to all pull requests:'
  prefs: []
  type: TYPE_NORMAL
- en: All new functionality must be tested. Tests should aim to cover all possible
    cases to best ensure correctness. This means not only maximizing code coverage,
    but also covering all possible corner cases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Every pull request must pass all tests before it can be merged. The tests are
    automatically run by the GitHub Actions CI on every pull request. If any tests
    fail, the CI will fail with a red ❌. These failures must be addressed before the
    pull request can be merged.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bug fixes should be accompanied by a [regression test](#writing-tests-regression-tests).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '## Basics for Writing Tests'
  prefs: []
  type: TYPE_NORMAL
- en: Tests are located alongside the code in `tests/` directories, in files named
    `test_<thing>.py`. In most cases, if you modified `sympy/<submodule>/<file>.py`
    then the test for the functionality will go in `sympy/<submodule>/tests/test_<file>.py`.
    For example, the tests for the functions in `sympy/simplify/sqrtdenest.py` are
    in `sympy/simplify/tests/test_sqrtdenest.py`. There are some exceptions to this
    rule, so in general try to find where the existing tests are for a function and
    add your tests alongside them. If you are adding tests for a new function, follow
    the general pattern of tests in the module you are adding to.
  prefs: []
  type: TYPE_NORMAL
- en: Tests follow a simple pattern, which should be apparent from reading the existing
    test files. Tests are in functions that start with `test_` and contain lines like
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: New test cases can be added to an existing test function if it is relevant,
    or you can create a new test function.
  prefs: []
  type: TYPE_NORMAL
- en: Running Tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The basic way to run the tests is to use
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: to run the tests, and
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: to run the doctests. Note that the full test suite can take some time to run,
    so typically you should just run a subset of the tests, e.g., corresponding to
    the module you modified. You can do this by passing the name of the submodules
    or tests files to the test command. For example,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: will run only the tests for the solvers.
  prefs: []
  type: TYPE_NORMAL
- en: If you want, you can also use `pytest` to run the tests instead of the `./bin/test`
    tool, for example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Another option is to just push your code up to GitHub and let the tests run
    on the CI. The GitHub Actions CI will run all the tests. However, it can take
    some time to finish, so it is usually advisable to run at least the basic tests
    before committing to avoid having to wait.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging Test Failures on GitHub Actions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When you see a test failure on CI, like
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The bit in between `_________________` is the name of the test. You can reproduce
    the test locally by copying and pasting this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: or
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The test also shows the file and line number (in this example, 317 in `sympy/printing/pretty/tests/test_pretty.py`)
    of the assertion that fails, so you can look it up to see what the test is testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes when you do this, you will not be able to reproduce the test failure
    locally. Some common causes of this are:'
  prefs: []
  type: TYPE_NORMAL
- en: You may need to merge the latest `master` into your branch to reproduce the
    failure (GitHub Actions will always merge your branch with the latest `master`
    before running the tests).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Something about the CI testing environment may be different from yours (this
    is especially likely for tests that depend on [optional dependencies](../dependencies.html#optional-dependencies).
    Check which versions of relevant packages are installed at the top of the CI log.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s possible that some other test that ran prior to yours may have somehow
    influenced your test. SymPy is not supposed to have global state, but sometimes
    some state can sneak in on accident. The only way to check this is to run the
    exact same test command that was run on CI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A test may fail sporadically. Try rerunning the test multiple times. The beginning
    of the test log on CI prints the random seed, which can be passed to `./bin/test
    --seed`, and the `PYTHONHASHSEED` environment variable, which may be helpful for
    reproducing such failures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is also sometimes possible that a failure on CI may be unrelated to your
    branch. We only merge branches that have passing CI, so that master always ideally
    has passing tests. But sometimes a failure can slip in. Typically this is either
    because the failure is sporadic (see the previous bullet), and it wasn’t noticed,
    or because some [optional dependency](../dependencies.html#optional-dependencies)
    was updated which broken an optional dependency test. If a test failure seems
    like it is unrelated to your change, check if the [CI builds for master](https://github.com/sympy/sympy/actions?query=branch%3Amaster)
    and if CI builds on other recent PRs have the same failure. If they do, this is
    likely the case. If they don’t, you should check more carefully if your change
    is causing the failure, even if it seems unrelated.
  prefs: []
  type: TYPE_NORMAL
- en: When there is a CI failure in the master branch, be aware that your pull request
    cannot be merged until it is fixed. This is not required, but if you know how
    to fix it, please do this to help everyone (if you do this, do it in a separate
    pull request so that it can be merged expeditiously).
  prefs: []
  type: TYPE_NORMAL
- en: '## Regression Tests'
  prefs: []
  type: TYPE_NORMAL
- en: Regression tests are tests that would fail before a bug fix but now pass. Often
    you can use a code example from an issue as a test case, although it is also OK
    to simplify such examples or to write your own, so long as it tests the issue
    in question.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider [issue #21177](https://github.com/sympy/sympy/issues/21177),
    which identified the following wrong result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here the first expression was correct but the second was not. In the issue,
    the cause of the issue was identified in the `as_leading_term` method, and several
    other related issues were also found.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the corresponding pull request ([#21253](https://github.com/sympy/sympy/pull/21253/files)),
    several regression tests were added. For example (from that PR):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This example shows some important aspects of regression tests:'
  prefs: []
  type: TYPE_NORMAL
- en: Tests should be added for the underlying fix, not just the originally reported
    issue. The originally reported issue in this example was with the `residue()`
    function but the underlying issue was with the `as_leading_term()` method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the same time, it can also be beneficial to add a test for the high-level
    issue as reported. This ensures that `residue` itself won’t break in the future,
    even if the implementation details of it change so that it no longer uses the
    same code path that was fixed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This example does not show it, but in some cases it may be prudent to simplify
    the originally reported issue for the test case. For example, sometimes users
    will include unnecessary details in the report that don’t actually matter for
    the reproduction of the issue (like unnecessary assumptions on symbols), or make
    the input expression too large or have too many unnecessary constant symbols.
    This is especially important to do if the code from the originally stated issue
    is slow to compute. If the same thing can be tested with a test that runs more
    quickly, this should be preferred.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression tests should also be added for additional bugs that are identified
    in the issue. In this example, the second test (the test added to `test_as_leading_term()`)
    was identified as a related problem in a [comment on the issue](https://github.com/sympy/sympy/issues/21177#issuecomment-812816346).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is useful to cross-reference the issue number in a regression test, either
    using a comment or in the test name. A comment is preferred if the test is being
    added to an existing test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression tests aren’t just for bug fixes. They should also be used for new
    features, to make sure the newly implemented functionality remains implemented
    and correct.
  prefs: []
  type: TYPE_NORMAL
- en: Special Types of Tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most tests will be of the form `assert function(input) == output`. However,
    there are other types of things that you might want to test that should be tested
    in certain ways.
  prefs: []
  type: TYPE_NORMAL
- en: Testing Exceptions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To test that a function raises a given exception, use `sympy.testing.pytest.raises`.
    `raises()` takes an exception class and a lambda. For example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Remember to include the `lambda`. Otherwise, the code will be executed immediately
    and will raise the exception, causing the test to fail.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '`raises` can also be used as a context manager, like'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: However, be careful using this form, as it can only check one expression at
    a time. If the code under context manager raises multiple exceptions, only the
    first one will actually be tested
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The `lambda` form is generally better because it avoids this problem, although
    if you are testing something that cannot be represented in a `lambda` you will
    need to use the context manager form.
  prefs: []
  type: TYPE_NORMAL
- en: '### Testing Warnings'
  prefs: []
  type: TYPE_NORMAL
- en: '[Warnings](https://docs.python.org/3/library/warnings.html) can be tested with
    the [`sympy.testing.pytest.warns()`](../../modules/testing/pytest.html#sympy.testing.pytest.warns
    "sympy.testing.pytest.warns") context manager. Note that `SymPyDeprecationWarning`
    is special and should be tested with `warns_deprecated_sympy()` instead (see [below](#writing-tests-test-deprecated-functionality)).'
  prefs: []
  type: TYPE_NORMAL
- en: The context manager should take a warning class (`warnings.warn()` uses `UserWarning`
    by default), and, optionally, a regular expression that the warning message should
    match as the `match` keyword argument.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '**Any test functionality that emits a warning should use `warns()`.** That
    way, no warnings are actually emitted during the tests themselves. This includes
    warnings coming from external libraries.'
  prefs: []
  type: TYPE_NORMAL
- en: Warnings within SymPy itself should be used very sparingly. Aside from [deprecation
    warnings](../deprecations.html#deprecation-policy), warnings are generally not
    used in SymPy, as they may be too annoying for users, especially those who use
    SymPy as a library, to be warranted.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you do use them, you must set the `stacklevel` parameter in the warning
    so that it shows the user code that called the function that emitted the warning.
    If the `stacklevel` parameter is impossible to set correctly, use `warns(test_stacklevel=False)`
    to disable the check in `warns` that `stacklevel` is used properly. `warns(SymPyDeprecationWarning,
    test_stacklevel=False)` must be used in place of `warns_deprecated_sympy()` if
    this applies to a `SymPyDeprecationWarning`  ### Test Deprecated Functionality'
  prefs: []
  type: TYPE_NORMAL
- en: Deprecated functionality should be tested with the [`sympy.testing.pytest.warns_deprecated_sympy()`](../../modules/testing/pytest.html#sympy.testing.pytest.warns_deprecated_sympy
    "sympy.testing.pytest.warns_deprecated_sympy") context manager.
  prefs: []
  type: TYPE_NORMAL
- en: The only purpose of this context manager is to test that the deprecation warning
    itself is functioning correctly. This should be the only place in the test suite
    where deprecated functionality is called. All other tests should use non-deprecated
    functionality. If it is impossible to avoid deprecated functionality, this may
    be a sign that the functionality should not actually be deprecated.
  prefs: []
  type: TYPE_NORMAL
- en: The [deprecation policy](../deprecations.html#deprecation-policy) page goes
    into detail about how to add a deprecation to a function.
  prefs: []
  type: TYPE_NORMAL
- en: For example,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: If code is using deprecated functionality from another library, this code should
    be updated. Until then, the normal [`warns()`](#writing-tests-testing-warnings)
    context manager should be used in the corresponding tests to prevent the warning
    from being emitted.
  prefs: []
  type: TYPE_NORMAL
- en: Testing that Something is Unchanged
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The normal test style of
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'works for most types of tests. However, it doesn’t work in the case where a
    SymPy object should remain unchanged. Consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The first two tests here are fine. The test that `sin` returns the corresponding
    special value for the inputs `pi` and `pi/2`. However, the last test nominally
    checks that `sin(1)` doesn’t return anything. But upon closer inspection, we see
    that it doesn’t do that at all. `sin(1)` could in fact return anything. It could
    return complete nonsense or even a wrong answer like `0`. The test would still
    pass, because all it is doing is checking that the result of `sin(1)` equals the
    result of `sin(1)`, which it always will so long as it always returns the same
    thing.
  prefs: []
  type: TYPE_NORMAL
- en: We really want to check that `sin(1)` remains unevaluated. The `sympy.core.expr.unchanged`
    helper will do this.
  prefs: []
  type: TYPE_NORMAL
- en: Use it like
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This test now actually checks the correct thing. If `sin(1)` were made to return
    some value, the test would fail.
  prefs: []
  type: TYPE_NORMAL
- en: Testing Expressions with [`Dummy`](../../modules/core.html#sympy.core.symbol.Dummy
    "sympy.core.symbol.Dummy")
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Expressions that return [`Dummy`](../../modules/core.html#sympy.core.symbol.Dummy
    "sympy.core.symbol.Dummy") cannot be tested with `==` directly, due to the nature
    of `Dummy`. In such cases, use the [`dummy_eq()`](../../modules/core.html#sympy.core.basic.Basic.dummy_eq
    "sympy.core.basic.Basic.dummy_eq") method. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Consistency Checks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Checking a set of known inputs and outputs can only get you so far. A test like
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: will check that `function(input)` returns `expression`, but it doesn’t check
    that `expression` itself is actually mathematically correct.
  prefs: []
  type: TYPE_NORMAL
- en: However, depending on what `function` is, sometimes a consistency check can
    be done to check that `expression` itself is correct. This typically boils down
    to “computing `expression` in two different ways”. If both ways agree, there is
    a pretty high chance it is correct, as it is unlikely that two completely different
    methods will produce the same wrong answer.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the inverse of indefinite integration is differentiation. The
    tests for integrals can be checked for consistency by seeing if the derivative
    of the result produces the original integrand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The implementation for `diff` is very simple compared to `integrate`, and it
    is tested separately, so this confirms the answer is correct.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, one could also just confirm the answer by hand, and this is what
    most tests in SymPy do. But a consistency check does not hurt, especially when
    it is easy to do.
  prefs: []
  type: TYPE_NORMAL
- en: The use of consistency checks in the SymPy test suite is not, itself, consistent.
    Some modules make heavy use of them, e.g., every test in the ODE module checks
    itself using [`checkodesol()`](../../modules/solvers/ode.html#sympy.solvers.ode.checkodesol
    "sympy.solvers.ode.checkodesol"), for instance. Other modules do not use consistency
    checks in their tests at all, although some of these could be updated to do so.
    In some cases, there are no reasonable consistency checks and other sources of
    truth must be used to verify the test outputs.
  prefs: []
  type: TYPE_NORMAL
- en: When making heavy use of consistency checks, it’s often a good idea to factor
    out the logic into a helper function in the test file to avoid duplication. Helper
    functions should start with an underscore so they aren’t mistaken for test functions
    by the test runner.
  prefs: []
  type: TYPE_NORMAL
- en: Random Tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another way that tests can check themselves for consistency is to check the
    expressions on random numerical inputs. The helper functions in `sympy.core.random`
    can be used for this. See the tests in `sympy/functions/special/` which make heavy
    use of this functionality.
  prefs: []
  type: TYPE_NORMAL
- en: If you add a random test, be sure to run the test multiple times to ensure that
    it always passes. Random tests can be reproduced by using the random seed printed
    at the top of the tests. For example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Here the random seed is `7357232`. It can be reproduced with
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: In general you may need to use the same Python version and architecture as shown
    in the test header to reproduce a random test failure. You may also in some situations,
    need to run the tests using the exact same input arguments (i.e., running the
    full test suite or running only a subset) in order to reproduce a test that fails
    randomly.
  prefs: []
  type: TYPE_NORMAL
- en: '### Skipping Tests'
  prefs: []
  type: TYPE_NORMAL
- en: Tests can be skipped using the `sympy.testing.pytest.SKIP` decorator or using
    the `sympy.testing.pytest.skip()` function. Note that tests that are skipped because
    they are expected to fail should use the `@XFAIL` decorator instead (see [below](#writing-tests-xfail)).
    Test that are skipped because they are too slow should use the [`@slow` decorator
    instead](#writing-tests-slow).
  prefs: []
  type: TYPE_NORMAL
- en: Tests that are skipped unconditionally should be avoided. Such a test is almost
    completely useless, as it will never be actually run. The only reason to skip
    a test unconditionally is if it would otherwise be `@XFAIL` or `@slow` but cannot
    use one of those decorators for some reason.
  prefs: []
  type: TYPE_NORMAL
- en: Both `@SKIP()` and `skip()` should include a message that explains why the test
    is being skipped, like `skip('numpy not installed')`.
  prefs: []
  type: TYPE_NORMAL
- en: The typical usage of skipping a test is when a test depends on an [optional
    dependency](../dependencies.html#optional-dependencies).
  prefs: []
  type: TYPE_NORMAL
- en: Such tests are generally written like
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'When the test is written in this way, the test will not fail when NumPy is
    not installed, which is important since NumPy is not a hard dependency of SymPy.
    See also [Writing Tests with External Dependencies](#writing-tests-external-dependencies)
    below.  ### Marking Tests as Expected to Fail'
  prefs: []
  type: TYPE_NORMAL
- en: Some tests in SymPy are expected to fail. They are written so that when the
    functionality the check is finally implemented, a test is already written for
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Tests that are expected to fail are called XFAIL tests. They show up as `f`
    in the test runner when they fail as expected and `X` when they pass (or “XPASS”).
    A test that XPASSes should have its `@XFAIL` decorator removed so that it becomes
    a normal test.
  prefs: []
  type: TYPE_NORMAL
- en: To XFAIL a test, add the `sympy.testing.pytest.XFAIL` decorator to it
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Care should be taken when writing an XFAIL test so that it actually passes when
    the functionality starts working. If you mistype the output, for example, the
    test may never pass. For example, the integral in the above test might start working,
    but return a result in a slightly different form than the one being checked. A
    more robust test would be
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This will cause the test to XPASS once the integral starts working, at which
    time the test can be updated with the actual output of `integrate()` (which can
    be compared against the expected output).  ### Marking Tests as Slow'
  prefs: []
  type: TYPE_NORMAL
- en: A test that is slow to run should be marked with the `@slow` decorator from
    `sympy.testing.pytest.slow`. The `@slow` decorator should be used for tests that
    take more than a minute to run. Tests that hang should use `@SKIP` instead of
    `@slow`. The slow tests will be run automatically in a separate CI job, but are
    skipped by default. You can manually run the slow tests with
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]  ### Writing Tests with External Dependencies'
  prefs: []
  type: TYPE_NORMAL
- en: When writing a test for a function that uses one of SymPy’s [optional dependencies](../dependencies.html#optional-dependencies),
    the test should be written in a way that makes it so that the test does not fail
    when the module is not installed.
  prefs: []
  type: TYPE_NORMAL
- en: The way to do this is to use `sympy.external.import_module()`. This will import
    the module if it is installed and return `None` otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: '`sympy.testing.pytest.skip` should be used to skip tests when the module in
    question is not installed (see [Skipping Tests](#writing-tests-skip) above). This
    can be done at the module level if the entire test file should be skippped, or
    in each individual function.'
  prefs: []
  type: TYPE_NORMAL
- en: You should also make sure the test is run in the “Optional Dependencies” CI
    run. To do this, edit `bin/test_optional_dependencies.py` and make sure the test
    is included (most SymPy submodules that test optional dependencies are already
    included automatically).
  prefs: []
  type: TYPE_NORMAL
- en: If the optional dependency is new, add it to the list of packages that are installed
    in the optional dependencies build in `.github/workflows/runtests.yml`, and add
    it to the optional dependencies document at `doc/src/contributing/dependencies.md`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that it is not necessary to do any of this when using `mpmath`, as it
    is already a [hard dependency](../dependencies.html#hard-dependencies) of SymPy
    and will always be installed.  ## Doctests'
  prefs: []
  type: TYPE_NORMAL
- en: Every public function should have a docstring, and every docstring should have
    a examples. Code examples are all tested, which is why they are also sometimes
    called *doctests*. The [docstring style guide](../docstring.html#style-guide-docstring-examples-section)
    has more details on how to format examples in docstrings.
  prefs: []
  type: TYPE_NORMAL
- en: To run the doctests, use the
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: command. This command can also take arguments to test a specific file or submodule,
    similar to `bin/test`.
  prefs: []
  type: TYPE_NORMAL
- en: Doctests should be written in a self-contained manner, with each doctest acting
    like a fresh Python session. This means that each doctest must manually import
    each function used in the doctest and define the symbols used. This may seem verbose,
    but it is helpful to users who are new to SymPy or even to Python who may not
    know where different functions come from. It also makes it easy for a user to
    copy and paste an example into a Python session of their own (the HTML documentation
    includes a button in the top right of every code example that copies the whole
    example to the clipboard).
  prefs: []
  type: TYPE_NORMAL
- en: For example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The doctest output should look exactly as it would in a `python` session, with
    `>>>` before the inputs and the outputs after. The doctester tests that the output
    string matches, unlike normal tests which typically check that the Python objects
    are the same with `==`. Consequently, the output needs to look *exactly* the same
    as it does in a Python session.
  prefs: []
  type: TYPE_NORMAL
- en: Like tests, all doctests must pass for a change to be accepted. However, when
    writing doctests, it is important to remember that **doctests should not be thought
    of as tests. Rather, they are examples that happen to be tested.**
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, you should always think about what will make a good, readable example
    when writing doctests. Doctests do not need to extensively cover all possible
    inputs, and should not include corner or extreme cases unless they are important
    for users to be aware of.
  prefs: []
  type: TYPE_NORMAL
- en: Everything that is tested in a doctest should also be tested in a [normal test](#writing-tests-basics).
    You should always be free to remove or change a doctest example at any time if
    it improves the documentation (to contrast, a normal test should never be changed
    or removed, except in [certain exceptional situations](#writing-tests-updating-existing-tests)).
  prefs: []
  type: TYPE_NORMAL
- en: This also means that doctests should be written first and foremost in a way
    that makes them understandable by someone reading the documentation. It can sometimes
    be tempting to write a doctest in some indirect way to please the doctester, but
    this should be avoided if it makes the example harder to understand. For example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This passes the doctest, and something along these lines would be fine a normal
    test. But in a docstring example, it is much clearer to just show the actual output
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Of course, in some situations, the full output is unwieldy and showing it would
    make the example harder to read, so this sort of thing may be appropriate. Use
    your best judgment, keeping in mind that the understandability of the doctest
    as a *documentation example* is the most important thing. In some extreme instances,
    it may be preferable to just skip testing an example (see [below](#writing-tests-doctest-skip))
    rather than writing it in a convoluted way that is difficult to read just to please
    the doctester.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some additional tips for writing doctests:'
  prefs: []
  type: TYPE_NORMAL
- en: Long input lines can be broken into multiple lines by using `...` as a continuation
    prompt, as in the example above. The doctest runner also allows long outputs to
    be line wrapped (it ignores newlines in the output).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common symbol names can be imported from `sympy.abc`. Uncommon symbol names
    or symbols that use assumptions should be defined using `symbols`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If a test shows a traceback, everything between `Traceback (most recent call
    last):` and the last line with the exception message should be replaced with `...`,
    like
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`...` is special in that whenever it appears in the output of an example, the
    doctester will allow it to replace any amount of text. It should also be used
    in instances where the exact output differs between runs, like'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here the actual output is something like `<function simplify at 0x10e997790>`
    but the `0x10e997790` is a memory address which will differ with every Python
    session.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`...` in outputs should be used sparingly, as it prevents the doctest from
    actually checking that part of the output. It also may not be clear to the reader
    of the documentation what it is meant. Note that it’s fine if the output of a
    doctest is updated to something else in the future. `...` should not be used in
    an attempt to “future-proof” doctest output. Also note that the doctester already
    automatically handles things like whitespace-only differences in the output and
    floating-point values.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can line break output lines. The doctester automatically ignores whitespace-only
    differences in the output, which includes newlines. Long lines should be broken
    so that they do not extend beyond the page in the HTML documentation (and so that
    the source code does not have lines longer than 80 characters). For example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Another option if a doctest cannot pass is to skip it, by adding `# doctest:+SKIP`
    to the end of the input line, like
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `# doctest:+SKIP` part will be automatically hidden in the HTML documentation.
    When skipping a doctest, always be sure to test the output manually, as the doctester
    will not check it for you.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`# doctest:+SKIP` should be used sparingly. Ideally a doctest should only be
    skipped when it is impossible to run it. A doctest that is skipped will never
    be tested, meaning it may become outdated (i.e., incorrect), which will be confusing
    to users.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Doctests that require a dependency to run should not be skipped with `# doctest:
    +SKIP`. Instead, use the [`@doctest_depends_on`](../../modules/utilities/decorator.html#sympy.utilities.decorator.doctest_depends_on
    "sympy.utilities.decorator.doctest_depends_on") decorator on the function to indicate
    which libraries should be installed for the doctest to run.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the test output includes a blank line, use `<BLANKLINE>` in place of the
    blank line. Otherwise the doctester will think that the output ends at the blank
    line. `<BLANKLINE>` will be automatically hidden in the HTML documentation. This
    is not common as most SymPy objects do not print with blank lines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid using `pprint()` in doctest examples. If you need to show an expression
    in an easier to read way, you can include it inline as LaTeX math using dollar
    signs. If you absolutely must use `pprint()`, always use `pprint(use_unicode=False)`
    as the Unicode characters used for pretty printing do not always render correctly
    in the HTML documentation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to show that something returns `None` use `print`, like
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can add short comments to doctests, either at the end of a line or by themselves
    after `>>>`. However, these should typically be only a few words long. Detailed
    explanations of what is happening in the doctest should go in the surrounding
    text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dictionaries and sets are automatically sorted by the doctester, and any expressions
    are automatically sorted so that the order of terms is always printed in the same
    way. Usually you can just include the output that the doctester “expects” it and
    it will always pass subsequently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE42]  ## Updating Existing Tests'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Sometimes when you change something or fix a bug, some existing tests will fail.
    If this happens, you should check the test to see why it is failing. In many cases,
    the test will be checking for something you didn’t consider, or your change has
    an unexpected side effect that broke something else. When this happens, you may
    need to revisit your change. If you are unsure what to do, you should discuss
    it on the issue or pull request.
  prefs: []
  type: TYPE_NORMAL
- en: If the test that fails is a [code quality test](#code-quality-checks), that
    usually means you just need to fix your code so that it satisfies the code quality
    check (e.g., remove trailing whitespace).
  prefs: []
  type: TYPE_NORMAL
- en: Occasionally, however, it can happen that the test fails but there is nothing
    wrong. In this case, the test should be updated. The most common instance of this
    is a test that checks for a specific expression, but the function now returns
    a different, but mathematically equivalent expression. This is especially common
    with [doctests](#writing-tests-doctests), since they check not just the output
    expression but the way it is printed.
  prefs: []
  type: TYPE_NORMAL
- en: 'If a function output is mathematically equivalent, the existing test can be
    updated with the new output. However, even when doing this, you should be careful:'
  prefs: []
  type: TYPE_NORMAL
- en: Carefully check that the new output is indeed the same. Manually check something
    like if the difference of old and new expressions simplifies to 0. Sometimes,
    two expressions are equivalent for some assumptions but not for all, so check
    that the two expressions are really the same for all complex numbers. This can
    particularly happen with expressions involving square roots or other radicals.
    You can check random numbers, or use the `equals()` method to do this.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the new output is considerably more complicated than the old output, then
    it may not be a good idea to update the test, even if they are mathematically
    equivalent. Instead, you may need to adjust the change so that the function still
    returns the simpler result.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s not common, but it can happen that an existing test is itself incorrect.
    If a test is plain wrong, it should just be deleted, and updated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In any case, when updating an existing test, you should always explain the rationale
    for doing so in a commit message or in a pull request comment. Do not explain
    the change in a code comment or documentation. Code comments and documentation
    should only refer to the code as it is. Discussion of changes belongs in the commit
    messages or issue tracker. Code comments that talk about how the code used to
    be will only become confusing and won’t actually be relevant anymore once the
    change is made.
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, the default should be to not change existing tests. The tests exist
    for a reason, and changing them defeats the purpose of having them in the first
    place. The exception to this rule is doctests, which are allowed to change or
    be removed if they improve the documentation, as the primary purpose of doctests
    is to serve as examples for users.  ## Code Quality Checks'
  prefs: []
  type: TYPE_NORMAL
- en: SymPy has several code quality checks that must pass. The first job that is
    run on the CI on a pull request is the code quality checks. If this job fails,
    none of the other tests are run. Your PR may be ignored by reviewers until they
    are fixed.
  prefs: []
  type: TYPE_NORMAL
- en: The code quality checks are all straightforward to fix. You can run the checks
    locally using
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: This second command requires you to install `flake8`. Make sure you have the
    latest version of flake8 and its dependencies `pycodestyle` and `pyflakes` installed.
    Sometimes newer versions of these packages will add new checks and if you have
    an older version installed you won’t see the checks for them.
  prefs: []
  type: TYPE_NORMAL
- en: The `./bin/test quality` check tests for very basic code quality things. The
    most common of these that will cause the test to fail is trailing whitespace.
    Trailing whitespace is when a line of code has spaces at the end of it. These
    spaces do nothing, and they only cause the code diff to be polluted. The best
    way to handle trailing whitespace is to configure your text editor to automatically
    strip trailing whitespace when you save. You can also use the `./bin/strip_whitepace`
    command in the SymPy repo.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `flake8` command will check the code for basic code errors like undefined
    variables. These are restricted by the configuration in `setup.cfg` to only check
    for things that are logical errors. The usual flake8 checks for cosmetic style
    errors are disabled. In rare situations, a flake8 warning will be a false positive.
    If this happens, add a `# noqa: <CODE>` comment to the corresponding line, where
    `<CODE>` is the code for the error from [https://flake8.pycqa.org/en/latest/user/error-codes.html](https://flake8.pycqa.org/en/latest/user/error-codes.html).
    For example, code that uses `multipledispatch` will need to use'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: to avoid warnings about redefining the same function multiple times.
  prefs: []
  type: TYPE_NORMAL
- en: Tests Style Guide
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In most cases, tests should be written in a way that matches the surrounding
    tests in the same test file.
  prefs: []
  type: TYPE_NORMAL
- en: 'A few important stylistic points should be followed when writing tests:'
  prefs: []
  type: TYPE_NORMAL
- en: Test functions should start with `test_`. If they do not, the test runner will
    not test them. Any helper functions which are not test functions should not start
    with `test_`. Usually it is best to start test helper functions with an underscore.
    If you find yourself reusing the same helper function for many test files, consider
    whether it should be moved to somewhere like `sympy.testing`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Format expressions using the same whitespace that would be produced by `str()`
    (e.g., spaces around binary `+` and `-`, no spaces around `*` and `**`, space
    after comma, no redundant parentheses, etc.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid the use of Float values in test cases. Unless the test is explicitly testing
    the result of a function on floating-point inputs, test expressions should use
    exact values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In particular, avoid using integer division like `1/2` that will create a float
    value (see [the gotchas section of the tutorial](../../tutorials/intro-tutorial/gotchas.html#tutorial-gotchas-final-notes)).
    For example:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you do actually intend to explicitly test an expression with a floating-point
    value, use a float (like `0.5` instead of `1/2`) so that it is clear this is intentional
    and not accidental.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Symbols may be defined at the top of the test file or within each test function.
    Symbols with assumptions that are defined at the top of the test file should be
    named in a way that makes it clear they have an assumption (e.g., `xp = Symbol('x',
    positive=True)`). It is often best to define symbols that have assumptions inside
    each test function so that they are not accidentally reused in another test that
    doesn’t expect them to have the assumption defined (which can often change the
    behavior of the test).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test files are typically named corresponding to the code file they test (e.g.,
    `sympy/core/tests/test_symbol.py` has the tests for `sympy/core/symbol.py`). However,
    this rule can be broken if there are tests that don’t exactly correspond to a
    specific code file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid using string forms of expressions in tests (obviously strings should be
    used in the printing tests; this rule applies to other types of tests). This makes
    the test depend on the exact printing output, rather than just the expression
    output. This makes the test harder to read, and if the printer is ever changed
    in some way, the test would have be updated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Similarly, do not parse the string form of an expression for input (unless the
    test is explicitly testing parsing strings). Just create the expression directly.
    Even if this requires creating many symbols or extensive use of `S()` to wrap
    rationals, this is still cleaner.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Use `is True`, `is False` and `is None` when testing assumptions. Don’t rely
    on truthiness, as it’s easy to forget that `None` is considered false by Python.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Test Coverage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To generate a test coverage report, first install [coverage.py](https://coverage.readthedocs.io/en/latest/)
    (e.g., with `pip install coverage`). Then run
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: This will run the test suite and analyze which lines of the codebase are covered
    by at least one test. Note that this will take longer than running the tests normally
    with `./bin/test` because the coverage tooling makes Python run a little bit slower.
    You can also run a subset of the tests, e.g., `./bin/coverage_report.py sympy/solvers`.
  prefs: []
  type: TYPE_NORMAL
- en: Once the tests are done, the coverage report will be in `covhtml`, which you
    can view by opening `covhtml/index.html`. Each file will show which lines were
    covered by a test (in green) and which were not covered by any test (in red).
  prefs: []
  type: TYPE_NORMAL
- en: Lines that are not covered by any test should have a test added for them, if
    possible. Note that 100% coverage is generally impossible. There may be a line
    of defensive code that checks if something has gone wrong, but which would only
    be triggered if there is a bug. Or there may be some functionality that is simply
    too hard to test (e.g., some code that interfaces with [external dependencies](../dependencies.html#optional-dependencies)),
    or that is only triggered when a given optional dependency is installed. However,
    if a line of code can be tested, it should be. And, for instance, the test files
    themselves should have 100% coverage. If a line in a test file is not covered,
    that generally indicates a mistake (see [https://nedbatchelder.com/blog/202008/you_should_include_your_tests_in_coverage.html](https://nedbatchelder.com/blog/202008/you_should_include_your_tests_in_coverage.html)).
  prefs: []
  type: TYPE_NORMAL
- en: Also be aware that coverage is not the end of the story. While a line of code
    that is not tested has no guarantees of being correct, a line of code that is
    covered is not guaranteed to be correct either. Maybe it is only tested for general
    inputs, but not for corner cases. Sometimes code may have a conditional, like
    `if a or b`, and `a` is always true in every test, so that the `b` condition is
    never tested. And of course, just because a line of code is executed, doesn’t
    mean that is correct. The test needs to actually check that the output of the
    function is what it is supposed to be. Test coverage is just one part of ensuring
    the correctness of a codebase. See [https://nedbatchelder.com/blog/200710/flaws_in_coverage_measurement.html](https://nedbatchelder.com/blog/200710/flaws_in_coverage_measurement.html).
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Property based tests can now be created using the [Hypothesis](https://hypothesis.readthedocs.io/en/latest/quickstart.html)
    library. Tests should be added to the `test_hypothesis.py` file in the respective
    `tests` subdirectory. If the file does not exist, create one. Below is an example
    of hypothesis test for modular arithmetic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
