# xView æ•°æ®é›†

> åŸæ–‡ï¼š[`docs.ultralytics.com/datasets/detect/xview/`](https://docs.ultralytics.com/datasets/detect/xview/)

[xView](http://xviewdataset.org/)æ•°æ®é›†æ˜¯æœ€å¤§çš„å…¬å…±å¯ç”¨é«˜ç©ºå›¾åƒæ•°æ®é›†ä¹‹ä¸€ï¼ŒåŒ…å«æ¥è‡ªä¸–ç•Œå„åœ°å¤æ‚åœºæ™¯çš„å›¾åƒï¼Œå¹¶ä½¿ç”¨è¾¹ç•Œæ¡†è¿›è¡Œæ³¨é‡Šã€‚xView æ•°æ®é›†çš„ç›®æ ‡æ˜¯åŠ é€Ÿå››ä¸ªè®¡ç®—æœºè§†è§‰å‰æ²¿é¢†åŸŸçš„è¿›å±•ï¼š

1.  é™ä½æ£€æµ‹çš„æœ€å°åˆ†è¾¨ç‡ã€‚

1.  æé«˜å­¦ä¹ æ•ˆç‡ã€‚

1.  ä½¿å‘ç°æ›´å¤šç‰©ä½“ç±»åˆ«æˆä¸ºå¯èƒ½ã€‚

1.  æ”¹å–„å¯¹ç»†ç²’åº¦ç±»åˆ«çš„æ£€æµ‹ã€‚

xView å»ºç«‹åœ¨åƒâ€œä¸Šä¸‹æ–‡ä¸­çš„å¸¸è§ç‰©ä½“â€ï¼ˆCOCOï¼‰è¿™æ ·çš„æŒ‘æˆ˜æˆåŠŸä¹‹ä¸Šï¼Œæ—¨åœ¨åˆ©ç”¨è®¡ç®—æœºè§†è§‰åˆ†ææ¥è‡ªå¤ªç©ºçš„æ—¥ç›Šå¢é•¿çš„å¯ç”¨å›¾åƒï¼Œä»¥ä¾¿ä»¥æ–°çš„æ–¹å¼ç†è§£è§†è§‰ä¸–ç•Œå¹¶è§£å†³ä¸€ç³»åˆ—é‡è¦åº”ç”¨ã€‚

## å…³é”®ç‰¹æ€§

+   xView åŒ…å«è¶…è¿‡ 100 ä¸‡ä¸ªç‰©ä½“å®ä¾‹ï¼Œè·¨è¶Š 60 ä¸ªç±»åˆ«ã€‚

+   è¯¥æ•°æ®é›†çš„åˆ†è¾¨ç‡ä¸º 0.3 ç±³ï¼Œæä¾›æ¯”å¤§å¤šæ•°å…¬å…±å«æ˜Ÿå½±åƒæ•°æ®é›†æ›´é«˜åˆ†è¾¨ç‡çš„å›¾åƒã€‚

+   xView å…·æœ‰å¤šæ ·åŒ–çš„å°å‹ã€ç¨€æœ‰ã€ç»†ç²’åº¦å’Œå¤šç±»å‹ç‰©ä½“çš„è¾¹ç•Œæ¡†æ³¨é‡Šé›†åˆã€‚

+   é™„å¸¦ä¸€ä¸ªä½¿ç”¨ TensorFlow ç‰©ä½“æ£€æµ‹ API çš„é¢„è®­ç»ƒåŸºçº¿æ¨¡å‹å’Œä¸€ä¸ª PyTorch ç¤ºä¾‹ã€‚

## æ•°æ®é›†ç»“æ„

xView æ•°æ®é›†ç”±ä» WorldView-3 å«æ˜Ÿæ”¶é›†çš„å«æ˜Ÿå›¾åƒç»„æˆï¼Œå…·æœ‰ 0.3 ç±³çš„åœ°é¢é‡‡æ ·è·ç¦»ã€‚å®ƒåŒ…å«è¶…è¿‡ 100 ä¸‡ä¸ªç‰©ä½“ï¼Œè·¨è¶Š 60 ä¸ªç±»åˆ«ï¼Œè¦†ç›–è¶…è¿‡ 1,400 å¹³æ–¹å…¬é‡Œçš„å›¾åƒã€‚

## åº”ç”¨

xView æ•°æ®é›†å¹¿æ³›ç”¨äºè®­ç»ƒå’Œè¯„ä¼°ç”¨äºé«˜ç©ºå›¾åƒç‰©ä½“æ£€æµ‹çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ•°æ®é›†å¤šæ ·çš„ç‰©ä½“ç±»åˆ«å’Œé«˜åˆ†è¾¨ç‡å›¾åƒä½¿å…¶æˆä¸ºè®¡ç®—æœºè§†è§‰é¢†åŸŸç ”ç©¶äººå‘˜å’Œä»ä¸šè€…çš„å®è´µèµ„æºï¼Œç‰¹åˆ«æ˜¯åœ¨å«æ˜Ÿå›¾åƒåˆ†ææ–¹é¢ã€‚

## æ•°æ®é›† YAML

YAMLï¼ˆYet Another Markup Languageï¼‰æ–‡ä»¶ç”¨äºå®šä¹‰æ•°æ®é›†é…ç½®ã€‚å®ƒåŒ…å«æœ‰å…³æ•°æ®é›†è·¯å¾„ã€ç±»åˆ«å’Œå…¶ä»–ç›¸å…³ä¿¡æ¯çš„ä¿¡æ¯ã€‚åœ¨ xView æ•°æ®é›†ä¸­ï¼Œ`xView.yaml`æ–‡ä»¶ç»´æŠ¤åœ¨[`github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/xView.yaml`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/xView.yaml)ã€‚

ultralytics/cfg/datasets/xView.yaml

```py
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# DIUx xView 2018 Challenge https://challenge.xviewdataset.org by U.S. National Geospatial-Intelligence Agency (NGA)
# --------  DOWNLOAD DATA MANUALLY and jar xf val_images.zip to 'datasets/xView' before running train command!  --------
# Documentation: https://docs.ultralytics.com/datasets/detect/xview/
# Example usage: yolo train data=xView.yaml
# parent
# â”œâ”€â”€ ultralytics
# â””â”€â”€ datasets
#     â””â”€â”€ xView  â† downloads here (20.7 GB)

# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path:  ../datasets/xView  # dataset root dir
train:  images/autosplit_train.txt  # train images (relative to 'path') 90% of 847 train images
val:  images/autosplit_val.txt  # train images (relative to 'path') 10% of 847 train images

# Classes
names:
  0:  Fixed-wing Aircraft
  1:  Small Aircraft
  2:  Cargo Plane
  3:  Helicopter
  4:  Passenger Vehicle
  5:  Small Car
  6:  Bus
  7:  Pickup Truck
  8:  Utility Truck
  9:  Truck
  10:  Cargo Truck
  11:  Truck w/Box
  12:  Truck Tractor
  13:  Trailer
  14:  Truck w/Flatbed
  15:  Truck w/Liquid
  16:  Crane Truck
  17:  Railway Vehicle
  18:  Passenger Car
  19:  Cargo Car
  20:  Flat Car
  21:  Tank car
  22:  Locomotive
  23:  Maritime Vessel
  24:  Motorboat
  25:  Sailboat
  26:  Tugboat
  27:  Barge
  28:  Fishing Vessel
  29:  Ferry
  30:  Yacht
  31:  Container Ship
  32:  Oil Tanker
  33:  Engineering Vehicle
  34:  Tower crane
  35:  Container Crane
  36:  Reach Stacker
  37:  Straddle Carrier
  38:  Mobile Crane
  39:  Dump Truck
  40:  Haul Truck
  41:  Scraper/Tractor
  42:  Front loader/Bulldozer
  43:  Excavator
  44:  Cement Mixer
  45:  Ground Grader
  46:  Hut/Tent
  47:  Shed
  48:  Building
  49:  Aircraft Hangar
  50:  Damaged Building
  51:  Facility
  52:  Construction Site
  53:  Vehicle Lot
  54:  Helipad
  55:  Storage Tank
  56:  Shipping container lot
  57:  Shipping Container
  58:  Pylon
  59:  Tower

# Download script/URL (optional) ---------------------------------------------------------------------------------------
download:  |
  import json
  import os
  from pathlib import Path

  import numpy as np
  from PIL import Image
  from tqdm import tqdm

  from ultralytics.data.utils import autosplit
  from ultralytics.utils.ops import xyxy2xywhn

  def convert_labels(fname=Path('xView/xView_train.geojson')):
  # Convert xView geoJSON labels to YOLO format
  path = fname.parent
  with open(fname) as f:
  print(f'Loading {fname}...')
  data = json.load(f)

  # Make dirs
  labels = Path(path / 'labels' / 'train')
  os.system(f'rm -rf {labels}')
  labels.mkdir(parents=True, exist_ok=True)

  # xView classes 11-94 to 0-59
  xview_class2index = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, 2, -1, 3, -1, 4, 5, 6, 7, 8, -1, 9, 10, 11,
  12, 13, 14, 15, -1, -1, 16, 17, 18, 19, 20, 21, 22, -1, 23, 24, 25, -1, 26, 27, -1, 28, -1,
  29, 30, 31, 32, 33, 34, 35, 36, 37, -1, 38, 39, 40, 41, 42, 43, 44, 45, -1, -1, -1, -1, 46,
  47, 48, 49, -1, 50, 51, -1, 52, -1, -1, -1, 53, 54, -1, 55, -1, -1, 56, -1, 57, -1, 58, 59]

  shapes = {}
  for feature in tqdm(data['features'], desc=f'Converting {fname}'):
  p = feature['properties']
  if p['bounds_imcoords']:
  id = p['image_id']
  file = path / 'train_images' / id
  if file.exists():  # 1395.tif missing
  try:
  box = np.array([int(num) for num in p['bounds_imcoords'].split(",")])
  assert box.shape[0] == 4, f'incorrect box shape {box.shape[0]}'
  cls = p['type_id']
  cls = xview_class2index[int(cls)]  # xView class to 0-60
  assert 59 >= cls >= 0, f'incorrect class index {cls}'

  # Write YOLO label
  if id not in shapes:
  shapes[id] = Image.open(file).size
  box = xyxy2xywhn(box[None].astype(np.float), w=shapes[id][0], h=shapes[id][1], clip=True)
  with open((labels / id).with_suffix('.txt'), 'a') as f:
  f.write(f"{cls} {' '.join(f'{x:.6f}' for x in box[0])}\n")  # write label.txt
  except Exception as e:
  print(f'WARNING: skipping one label for {file}: {e}')

  # Download manually from https://challenge.xviewdataset.org
  dir = Path(yaml['path'])  # dataset root dir
  # urls = ['https://d307kc0mrhucc3.cloudfront.net/train_labels.zip',  # train labels
  #         'https://d307kc0mrhucc3.cloudfront.net/train_images.zip',  # 15G, 847 train images
  #         'https://d307kc0mrhucc3.cloudfront.net/val_images.zip']  # 5G, 282 val images (no labels)
  # download(urls, dir=dir)

  # Convert labels
  convert_labels(dir / 'xView_train.geojson')

  # Move images
  images = Path(dir / 'images')
  images.mkdir(parents=True, exist_ok=True)
  Path(dir / 'train_images').rename(dir / 'images' / 'train')
  Path(dir / 'val_images').rename(dir / 'images' / 'val')

  # Split
  autosplit(dir / 'images' / 'train') 
```

## ä½¿ç”¨

è¦åœ¨ xView æ•°æ®é›†ä¸Šè®­ç»ƒä¸€ä¸ªæ¨¡å‹ 100 ä¸ªå‘¨æœŸï¼Œå›¾åƒå¤§å°ä¸º 640ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç ç‰‡æ®µã€‚æœ‰å…³å¯ç”¨å‚æ•°çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·å‚é˜…æ¨¡å‹è®­ç»ƒé¡µé¢ã€‚

è®­ç»ƒç¤ºä¾‹

```py
from ultralytics import YOLO

# Load a model
model = YOLO("yolov8n.pt")  # load a pretrained model (recommended for training)

# Train the model
results = model.train(data="xView.yaml", epochs=100, imgsz=640) 
```

```py
# Start training from a pretrained *.pt model
yolo  detect  train  data=xView.yaml  model=yolov8n.pt  epochs=100  imgsz=640 
```

## ç¤ºä¾‹æ•°æ®å’Œæ³¨é‡Š

xView æ•°æ®é›†åŒ…å«é«˜åˆ†è¾¨ç‡å«æ˜Ÿå›¾åƒï¼Œå…·æœ‰å¤šæ ·åŒ–çš„ç‰©ä½“ï¼Œä½¿ç”¨è¾¹ç•Œæ¡†è¿›è¡Œæ³¨é‡Šã€‚ä»¥ä¸‹æ˜¯æ¥è‡ªè¯¥æ•°æ®é›†çš„ä¸€äº›æ•°æ®ç¤ºä¾‹åŠå…¶ç›¸åº”çš„æ³¨é‡Šï¼š

![æ•°æ®é›†ç¤ºä¾‹å›¾åƒ](img/d56ebaba62a20076c132b6e59ef92255.png)

+   **èˆªæ‹å›¾åƒ**ï¼šè¿™å¹…å›¾åƒå±•ç¤ºäº†èˆªæ‹å›¾åƒä¸­å¯¹è±¡æ£€æµ‹çš„ç¤ºä¾‹ï¼Œå…¶ä¸­å¯¹è±¡ç”¨è¾¹ç•Œæ¡†è¿›è¡Œäº†æ³¨é‡Šã€‚è¯¥æ•°æ®é›†æä¾›é«˜åˆ†è¾¨ç‡å«æ˜Ÿå›¾åƒï¼Œä»¥ä¾¿ä¸ºè¯¥ä»»åŠ¡å¼€å‘æ¨¡å‹ã€‚

æ­¤ç¤ºä¾‹å±•ç¤ºäº† xView æ•°æ®é›†ä¸­æ•°æ®çš„å¤šæ ·æ€§å’Œå¤æ‚æ€§ï¼Œå¹¶çªæ˜¾äº†é«˜è´¨é‡å«æ˜Ÿå›¾åƒå¯¹å¯¹è±¡æ£€æµ‹ä»»åŠ¡çš„é‡è¦æ€§ã€‚

## å¼•ç”¨å’Œè‡´è°¢

å¦‚æœæ‚¨åœ¨ç ”ç©¶æˆ–å¼€å‘å·¥ä½œä¸­ä½¿ç”¨ xView æ•°æ®é›†ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

```py
@misc{lam2018xview,
  title={xView: Objects in Context in Overhead Imagery},
  author={Darius Lam and Richard Kuzma and Kevin McGee and Samuel Dooley and Michael Laielli and Matthew Klaric and Yaroslav Bulatov and Brendan McCord},
  year={2018},
  eprint={1802.07856},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
} 
```

æˆ‘ä»¬è¦æ„Ÿè°¢[å›½é˜²åˆ›æ–°å•ä½](https://www.diu.mil/)ï¼ˆDIUï¼‰å’Œ xView æ•°æ®é›†çš„åˆ›å»ºè€…ï¼Œæ„Ÿè°¢ä»–ä»¬ä¸ºè®¡ç®—æœºè§†è§‰ç ”ç©¶ç¤¾åŒºåšå‡ºçš„å®è´µè´¡çŒ®ã€‚æœ‰å…³ xView æ•°æ®é›†åŠå…¶åˆ›å»ºè€…çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·è®¿é—®[xView æ•°æ®é›†ç½‘ç«™](http://xviewdataset.org/)ã€‚

## å¸¸è§é—®é¢˜è§£ç­”

### xView æ•°æ®é›†æ˜¯ä»€ä¹ˆï¼Œä»¥åŠå®ƒå¦‚ä½•ä¿ƒè¿›è®¡ç®—æœºè§†è§‰ç ”ç©¶ï¼Ÿ

[xView](http://xviewdataset.org/)æ•°æ®é›†æ˜¯æœ€å¤§çš„å…¬å¼€é«˜åˆ†è¾¨ç‡èˆªæ‹å›¾åƒé›†åˆä¹‹ä¸€ï¼ŒåŒ…å« 60 ä¸ªç±»åˆ«çš„è¶…è¿‡ 100 ä¸‡ä¸ªå¯¹è±¡å®ä¾‹ã€‚å®ƒæ—¨åœ¨å¢å¼ºè®¡ç®—æœºè§†è§‰ç ”ç©¶çš„å„ä¸ªæ–¹é¢ï¼Œå¦‚é™ä½æ£€æµ‹çš„æœ€å°åˆ†è¾¨ç‡ã€æé«˜å­¦ä¹ æ•ˆç‡ã€å‘ç°æ›´å¤šå¯¹è±¡ç±»åˆ«ä»¥åŠæ¨è¿›ç»†ç²’åº¦å¯¹è±¡æ£€æµ‹ã€‚

### å¦‚ä½•ä½¿ç”¨ Ultralytics YOLO åœ¨ xView æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Ÿ

ä½¿ç”¨ Ultralytics YOLO åœ¨ xView æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š

è®­ç»ƒç¤ºä¾‹

```py
from ultralytics import YOLO

# Load a model
model = YOLO("yolov8n.pt")  # load a pretrained model (recommended for training)

# Train the model
results = model.train(data="xView.yaml", epochs=100, imgsz=640) 
```

```py
# Start training from a pretrained *.pt model
yolo  detect  train  data=xView.yaml  model=yolov8n.pt  epochs=100  imgsz=640 
```

æœ‰å…³è¯¦ç»†çš„å‚æ•°å’Œè®¾ç½®ï¼Œè¯·å‚é˜…æ¨¡å‹è®­ç»ƒé¡µé¢ã€‚

### xView æ•°æ®é›†çš„å…³é”®ç‰¹æ€§æ˜¯ä»€ä¹ˆï¼Ÿ

xView æ•°æ®é›†ä»¥å…¶å…¨é¢çš„ç‰¹æ€§è„±é¢–è€Œå‡ºï¼š- è¶…è¿‡ 100 ä¸‡ä¸ª 60 ä¸ªä¸åŒç±»åˆ«çš„å¯¹è±¡å®ä¾‹ã€‚- åœ°é¢åˆ†è¾¨ç‡ä¸º 0.3 ç±³çš„é«˜åˆ†è¾¨ç‡å½±åƒã€‚- åŒ…æ‹¬å°å‹ã€ç¨€æœ‰å’Œç»†ç²’åº¦å¯¹è±¡ç±»å‹ï¼Œæ‰€æœ‰è¿™äº›éƒ½ç”¨è¾¹ç•Œæ¡†è¿›è¡Œäº†æ³¨é‡Šã€‚- æä¾›äº†ä¸€ä¸ªé¢„è®­ç»ƒçš„åŸºçº¿æ¨¡å‹å’Œ TensorFlow å’Œ PyTorch çš„ç¤ºä¾‹ã€‚

### xView æ•°æ®é›†çš„æ•°æ®ç»“æ„åŠå…¶å¦‚ä½•æ ‡æ³¨ï¼Ÿ

xView æ•°æ®é›†ç”± WorldView-3 å«æ˜Ÿæ”¶é›†çš„é«˜åˆ†è¾¨ç‡å«æ˜Ÿå›¾åƒç»„æˆï¼Œåœ°é¢é‡‡æ ·è·ç¦»ä¸º 0.3 ç±³ã€‚å®ƒåŒ…å«çº¦ 1400 å¹³æ–¹å…¬é‡Œçš„å½±åƒä¸­è¶…è¿‡ 100 ä¸‡ä¸ªå¯¹è±¡ï¼Œæ¶µç›– 60 ä¸ªç±»åˆ«ã€‚æ•°æ®é›†ä¸­çš„æ¯ä¸ªå¯¹è±¡éƒ½ç”¨è¾¹ç•Œæ¡†è¿›è¡Œäº†æ³¨é‡Šï¼Œéå¸¸é€‚åˆç”¨äºè®­ç»ƒå’Œè¯„ä¼°ç”¨äºèˆªæ‹å›¾åƒä¸­å¯¹è±¡æ£€æµ‹çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚æœ‰å…³è¯¦ç»†æ¦‚è¿°ï¼Œè¯·å‚é˜…æ­¤å¤„çš„æ•°æ®é›†ç»“æ„éƒ¨åˆ†ã€‚

### å¦‚ä½•åœ¨æˆ‘çš„ç ”ç©¶ä¸­å¼•ç”¨ xView æ•°æ®é›†ï¼Ÿ

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨ xView æ•°æ®é›†ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

BibTeX

```py
@misc{lam2018xview,
  title={xView: Objects in Context in Overhead Imagery},
  author={Darius Lam and Richard Kuzma and Kevin McGee and Samuel Dooley and Michael Laielli and Matthew Klaric and Yaroslav Bulatov and Brendan McCord},
  year={2018},
  eprint={1802.07856},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
} 
```

å…³äº xView æ•°æ®é›†çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·è®¿é—®å®˜æ–¹[xView æ•°æ®é›†ç½‘ç«™](http://xviewdataset.org/)ã€‚
