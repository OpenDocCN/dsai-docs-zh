- en: scipy.optimize.isotonic_regression
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: scipy.optimize.isotonic_regression
- en: Original text：[https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.isotonic_regression.html#scipy.optimize.isotonic_regression](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.isotonic_regression.html#scipy.optimize.isotonic_regression)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文链接：[https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.isotonic_regression.html#scipy.optimize.isotonic_regression](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.isotonic_regression.html#scipy.optimize.isotonic_regression)
- en: '[PRE0]'
  id: totrans-2
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Nonparametric isotonic regression.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 非参数等温回归。
- en: A (not strictly) monotonically increasing array *x* with the same length as
    *y* is calculated by the pool adjacent violators algorithm (PAVA), see [[1]](#rddcb72c1ad4d-1).
    See the Notes section for more details.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 通过池相邻违反者算法（PAVA）计算出与*y*长度相同的（不严格）单调递增数组*x*，参见[[1]](#rddcb72c1ad4d-1)。更多细节请参见注释部分。
- en: 'Parameters:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**y**(N,) array_like'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**y**(N,) array_like'
- en: Response variable.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 响应变量。
- en: '**weights**(N,) array_like or None'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**weights**(N,) array_like or None'
- en: Case weights.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 案例权重。
- en: '**increasing**bool'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**increasing**bool'
- en: If True, fit monotonic increasing, i.e. isotonic, regression. If False, fit
    a monotonic decreasing, i.e. antitonic, regression. Default is True.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果为True，则拟合单调递增，即等温，回归。如果为False，则拟合单调递减，即反等温，回归。默认为True。
- en: 'Returns:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 返回：
- en: '**res**OptimizeResult'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**res**OptimizeResult'
- en: 'The optimization result represented as a `OptimizeResult` object. Important
    attributes are:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 优化结果表示为`OptimizeResult`对象。重要属性包括：
- en: '`x`: The isotonic regression solution, i.e. an increasing (or decreasing) array
    of the same length than y, with elements in the range from min(y) to max(y).'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：等温回归解，即与y长度相同的递增（或递减）数组，元素范围从min(y)到max(y)。'
- en: '`weights` : Array with the sum of case weights for each block (or pool) B.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weights`：每个块（或池）B的案例权重总和的数组。'
- en: '`blocks`: Array of length B+1 with the indices of the start positions of each
    block (or pool) B. The j-th block is given by `x[blocks[j]:blocks[j+1]]` for which
    all values are the same.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`blocks`：长度为B+1的数组，其中包含每个块（或池）B的起始位置的索引。第j个块由`x[blocks[j]:blocks[j+1]]`给出，其中所有值都相同。'
- en: Notes
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 注释
- en: 'Given data \(y\) and case weights \(w\), the isotonic regression solves the
    following optimization problem:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 给定数据\(y\)和案例权重\(w\)，等温回归解决了以下优化问题：
- en: \[\operatorname{argmin}_{x_i} \sum_i w_i (y_i - x_i)^2 \quad \text{subject to
    } x_i \leq x_j \text{ whenever } i \leq j \,.\]
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: \[\operatorname{argmin}_{x_i} \sum_i w_i (y_i - x_i)^2 \quad \text{subject to
    } x_i \leq x_j \text{ whenever } i \leq j \,.\]
- en: For every input value \(y_i\), it generates a value \(x_i\) such that \(x\)
    is increasing (but not strictly), i.e. \(x_i \leq x_{i+1}\). This is accomplished
    by the PAVA. The solution consists of pools or blocks, i.e. neighboring elements
    of \(x\), e.g. \(x_i\) and \(x_{i+1}\), that all have the same value.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个输入值\(y_i\)，它生成一个值\(x_i\)，使得\(x\)是递增的（但不是严格的），即\(x_i \leq x_{i+1}\)。这是通过PAVA完成的。解决方案由池或块组成，即\(x\)的相邻元素，例如\(x_i\)和\(x_{i+1}\)，它们都具有相同的值。
- en: Most interestingly, the solution stays the same if the squared loss is replaced
    by the wide class of Bregman functions which are the unique class of strictly
    consistent scoring functions for the mean, see [[2]](#rddcb72c1ad4d-2) and references
    therein.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最有趣的是，如果将平方损失替换为广泛的Bregman函数类，那么解决方案将保持不变，这些函数是均值的唯一一类严格一致的评分函数，参见[[2]](#rddcb72c1ad4d-2)及其中的参考文献。
- en: The implemented version of PAVA according to [[1]](#rddcb72c1ad4d-1) has a computational
    complexity of O(N) with input size N.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[[1]](#rddcb72c1ad4d-1)实现的PAVA版本，其计算复杂度为O(N)，其中N为输入大小。
- en: References
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] ([1](#id1),[2](#id3))'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] ([1](#id1),[2](#id3))'
- en: 'Busing, F. M. T. A. (2022). Monotone Regression: A Simple and Fast O(n) PAVA
    Implementation. Journal of Statistical Software, Code Snippets, 102(1), 1-25.
    [DOI:10.18637/jss.v102.c01](https://doi.org/10.18637/jss.v102.c01)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Busing, F. M. T. A. (2022). 单调回归：简单快速的O(n) PAVA实现。《统计软件杂志》，代码片段，102(1)，1-25。[DOI:10.18637/jss.v102.c01](https://doi.org/10.18637/jss.v102.c01)
- en: '[[2](#id2)]'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[[2](#id2)]'
- en: Jordan, A.I., Mühlemann, A. & Ziegel, J.F. Characterizing the optimal solutions
    to the isotonic regression problem for identifiable functionals. Ann Inst Stat
    Math 74, 489-514 (2022). [DOI:10.1007/s10463-021-00808-0](https://doi.org/10.1007/s10463-021-00808-0)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Jordan, A.I., Mühlemann, A. & Ziegel, J.F. 表征可识别函数的等温回归问题的最优解。《统计数学研究所通报》74，489-514
    (2022)。[DOI:10.1007/s10463-021-00808-0](https://doi.org/10.1007/s10463-021-00808-0)
- en: Examples
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: This example demonstrates that `isotonic_regression` really solves a constrained
    optimization problem.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例演示了`isotonic_regression`确实解决了一个受限制的优化问题。
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The big advantage of `isotonic_regression` compared to calling `minimize` is
    that it is more user friendly, i.e. one does not need to define objective and
    constraint functions, and that it is orders of magnitudes faster. On commodity
    hardware (in 2023), for normal distributed input y of length 1000, the minimizer
    takes about 4 seconds, while `isotonic_regression` takes about 200 microseconds.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 相对于调用`minimize`，`isotonic_regression`的一个巨大优势在于它更加用户友好，即无需定义目标和约束函数，并且速度快上几个数量级。在普通硬件（2023年）上，对长度为1000的正态分布输入y进行优化，最小化器大约需要4秒，而`isotonic_regression`只需大约200微秒。
