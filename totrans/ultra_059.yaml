- en: COCO-Pose Dataset
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/datasets/pose/coco/`](https://docs.ultralytics.com/datasets/pose/coco/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The [COCO-Pose](https://cocodataset.org/#keypoints-2017) dataset is a specialized
    version of the COCO (Common Objects in Context) dataset, designed for pose estimation
    tasks. It leverages the COCO Keypoints 2017 images and labels to enable the training
    of models like YOLO for pose estimation tasks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '![Pose sample image](img/d0a8a254d8baabd83cc50ff9b841b8ca.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
- en: COCO-Pose Pretrained Models
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(pose 50-95) | mAP^(pose 50) | Speed ^(CPU
    ONNX'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-pose.pt)
    | 640 | 50.4 | 80.1 | 131.8 | 1.18 | 3.3 | 9.2 |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-pose.pt)
    | 640 | 60.0 | 86.2 | 233.2 | 1.42 | 11.6 | 30.2 |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-pose.pt)
    | 640 | 65.0 | 88.8 | 456.3 | 2.00 | 26.4 | 81.0 |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-pose.pt)
    | 640 | 67.6 | 90.0 | 784.5 | 2.59 | 44.4 | 168.6 |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-pose.pt)
    | 640 | 69.2 | 90.2 | 1607.1 | 3.73 | 69.4 | 263.2 |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-pose-p6](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-pose-p6.pt)
    | 1280 | 71.6 | 91.2 | 4088.7 | 10.04 | 99.1 | 1066.4 |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
- en: Key Features
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: COCO-Pose builds upon the COCO Keypoints 2017 dataset which contains 200K images
    labeled with keypoints for pose estimation tasks.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dataset supports 17 keypoints for human figures, facilitating detailed pose
    estimation.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Like COCO, it provides standardized evaluation metrics, including Object Keypoint
    Similarity (OKS) for pose estimation tasks, making it suitable for comparing model
    performance.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset Structure
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The COCO-Pose dataset is split into three subsets:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '**Train2017**: This subset contains a portion of the 118K images from the COCO
    dataset, annotated for training pose estimation models.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Val2017**: This subset has a selection of images used for validation purposes
    during model training.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Test2017**: This subset consists of images used for testing and benchmarking
    the trained models. Ground truth annotations for this subset are not publicly
    available, and the results are submitted to the [COCO evaluation server](https://codalab.lisn.upsaclay.fr/competitions/7384)
    for performance evaluation.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Applications
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The COCO-Pose dataset is specifically used for training and evaluating deep
    learning models in keypoint detection and pose estimation tasks, such as OpenPose.
    The dataset's large number of annotated images and standardized evaluation metrics
    make it an essential resource for computer vision researchers and practitioners
    focused on pose estimation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Dataset YAML
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**数据集YAML**'
- en: A YAML (Yet Another Markup Language) file is used to define the dataset configuration.
    It contains information about the dataset's paths, classes, and other relevant
    information. In the case of the COCO-Pose dataset, the `coco-pose.yaml` file is
    maintained at [`github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco-pose.yaml`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco-pose.yaml).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用YAML（Yet Another Markup Language）文件来定义数据集配置。它包含关于数据集路径、类别和其他相关信息。在COCO-Pose数据集的情况下，`coco-pose.yaml`文件维护在[`github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco-pose.yaml`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco-pose.yaml)。
- en: ultralytics/cfg/datasets/coco-pose.yaml
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ultralytics/cfg/datasets/coco-pose.yaml
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Usage
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**用法**'
- en: To train a YOLOv8n-pose model on the COCO-Pose dataset for 100 epochs with an
    image size of 640, you can use the following code snippets. For a comprehensive
    list of available arguments, refer to the model Training page.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要在COCO-Pose数据集上训练YOLOv8n-pose模型，进行100个epochs并设置图像大小为640，您可以使用以下代码片段。要获取可用参数的全面列表，请参阅模型训练页面。
- en: Train Example
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练示例**'
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Sample Images and Annotations
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**样本图像和注释**'
- en: 'The COCO-Pose dataset contains a diverse set of images with human figures annotated
    with keypoints. Here are some examples of images from the dataset, along with
    their corresponding annotations:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: COCO-Pose数据集包含一组多样的图像，其中的人物用关键点进行注释。以下是数据集中一些图像的示例及其相应的注释：
- en: '![Dataset sample image](img/6defdfd1871ea1affb9f24d277d684b7.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![数据集示例图像](img/6defdfd1871ea1affb9f24d277d684b7.png)'
- en: '**Mosaiced Image**: This image demonstrates a training batch composed of mosaiced
    dataset images. Mosaicing is a technique used during training that combines multiple
    images into a single image to increase the variety of objects and scenes within
    each training batch. This helps improve the model''s ability to generalize to
    different object sizes, aspect ratios, and contexts.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**马赛克图像**：这幅图展示了由马赛克数据集图像组成的训练批次。在训练过程中，马赛克是一种技术，将多个图像合并成单个图像，以增加每个训练批次中对象和场景的多样性。这有助于提高模型对不同对象大小、长宽比和背景环境的泛化能力。'
- en: The example showcases the variety and complexity of the images in the COCO-Pose
    dataset and the benefits of using mosaicing during the training process.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例展示了COCO-Pose数据集中图像的多样性和复杂性，以及在训练过程中使用马赛克的好处。
- en: Citations and Acknowledgments
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**引用和致谢**'
- en: 'If you use the COCO-Pose dataset in your research or development work, please
    cite the following paper:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在研究或开发工作中使用COCO-Pose数据集，请引用以下论文：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We would like to acknowledge the COCO Consortium for creating and maintaining
    this valuable resource for the computer vision community. For more information
    about the COCO-Pose dataset and its creators, visit the [COCO dataset website](https://cocodataset.org/#home).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '我们要感谢COCO联盟为计算机视觉社区创建和维护这一宝贵资源。有关COCO-Pose数据集及其创建者的更多信息，请访问[COCO数据集网站](https://cocodataset.org/#home)。 '
- en: FAQ
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**常见问题解答**'
- en: What is the COCO-Pose dataset and how is it used with Ultralytics YOLO for pose
    estimation?
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: COCO-Pose数据集是什么，如何与Ultralytics YOLO用于姿态估计？
- en: The [COCO-Pose](https://cocodataset.org/#keypoints-2017) dataset is a specialized
    version of the COCO (Common Objects in Context) dataset designed for pose estimation
    tasks. It builds upon the COCO Keypoints 2017 images and annotations, allowing
    for the training of models like Ultralytics YOLO for detailed pose estimation.
    For instance, you can use the COCO-Pose dataset to train a YOLOv8n-pose model
    by loading a pretrained model and training it with a YAML configuration. For training
    examples, refer to the Training documentation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[COCO-Pose](https://cocodataset.org/#keypoints-2017) 数据集是专门用于姿态估计任务的COCO（通用物体上下文）数据集的一个特殊版本。它基于COCO
    Keypoints 2017图像和注释，允许像Ultralytics YOLO这样的模型进行详细的姿态估计训练。例如，您可以使用COCO-Pose数据集通过加载预训练模型并使用YAML配置来训练YOLOv8n-pose模型。有关训练示例，请参阅训练文档。'
- en: How can I train a YOLOv8 model on the COCO-Pose dataset?
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何在COCO-Pose数据集上训练YOLOv8模型？
- en: 'Training a YOLOv8 model on the COCO-Pose dataset can be accomplished using
    either Python or CLI commands. For example, to train a YOLOv8n-pose model for
    100 epochs with an image size of 640, you can follow the steps below:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python或CLI命令可以在COCO-Pose数据集上训练YOLOv8模型。例如，要在图像大小为640的情况下训练100个epochs的YOLOv8n-pose模型，可以按照以下步骤进行：
- en: Train Example
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练示例**'
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: For more details on the training process and available arguments, check the
    training page.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多关于训练过程和可用参数的详细信息，请查看训练页面。
- en: What are the different metrics provided by the COCO-Pose dataset for evaluating
    model performance?
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: COCO-Pose数据集提供了哪些用于评估模型性能的不同指标？
- en: The COCO-Pose dataset provides several standardized evaluation metrics for pose
    estimation tasks, similar to the original COCO dataset. Key metrics include the
    Object Keypoint Similarity (OKS), which evaluates the accuracy of predicted keypoints
    against ground truth annotations. These metrics allow for thorough performance
    comparisons between different models. For instance, the COCO-Pose pretrained models
    such as YOLOv8n-pose, YOLOv8s-pose, and others have specific performance metrics
    listed in the documentation, like mAP^(pose)50-95 and mAP^(pose)50.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: COCO-Pose数据集为姿态估计任务提供了几个标准化评估指标，类似于原始的COCO数据集。关键指标包括对象关键点相似性（OKS），评估预测关键点与地面实况注释的准确性。这些指标允许对不同模型进行彻底的性能比较。例如，COCO-Pose预训练模型如YOLOv8n-pose、YOLOv8s-pose等在文档中列出了特定的性能指标，如mAP^(pose)50-95和mAP^(pose)50。
- en: How is the dataset structured and split for the COCO-Pose dataset?
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: COCO-Pose数据集的结构和拆分如何？
- en: 'The COCO-Pose dataset is split into three subsets:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: COCO-Pose数据集分为三个子集：
- en: '**Train2017**: Contains a portion of the 118K COCO images, annotated for training
    pose estimation models.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Train2017**: 包含118K COCO图像的一部分，用于训练姿态估计模型的注释。'
- en: '**Val2017**: Selected images for validation purposes during model training.'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Val2017**: 用于模型训练过程中验证目的的选定图像。'
- en: '**Test2017**: Images used for testing and benchmarking trained models. Ground
    truth annotations for this subset are not publicly available; results are submitted
    to the [COCO evaluation server](https://codalab.lisn.upsaclay.fr/competitions/7384)
    for performance evaluation.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Test2017**: 用于测试和基准测试训练模型的图像。此子集的地面实况注释不公开；结果将提交至[COCO评估服务器](https://codalab.lisn.upsaclay.fr/competitions/7384)进行性能评估。'
- en: These subsets help organize the training, validation, and testing phases effectively.
    For configuration details, explore the `coco-pose.yaml` file available on [GitHub](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco-pose.yaml).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这些子集有助于有效组织培训、验证和测试阶段。有关配置详细信息，请查看GitHub上的`coco-pose.yaml`文件，网址为[GitHub](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco-pose.yaml)。
- en: What are the key features and applications of the COCO-Pose dataset?
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: COCO-Pose数据集的关键特性和应用是什么？
- en: The COCO-Pose dataset extends the COCO Keypoints 2017 annotations to include
    17 keypoints for human figures, enabling detailed pose estimation. Standardized
    evaluation metrics (e.g., OKS) facilitate comparisons across different models.
    Applications of the COCO-Pose dataset span various domains, such as sports analytics,
    healthcare, and human-computer interaction, wherever detailed pose estimation
    of human figures is required. For practical use, leveraging pretrained models
    like those provided in the documentation (e.g., YOLOv8n-pose) can significantly
    streamline the process (Key Features).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: COCO-Pose数据集将COCO Keypoints 2017注释扩展到包括人物图像的17个关键点，实现了详细的姿态估计。标准化评估指标（例如OKS）有助于跨不同模型进行比较。COCO-Pose数据集的应用涵盖各种领域，如体育分析、医疗保健和人机交互，无论何处需要对人物图像进行详细的姿态估计。对于实际应用，利用文档中提供的预训练模型（例如YOLOv8n-pose）可以显著简化流程（关键特性）。
- en: If you use the COCO-Pose dataset in your research or development work, please
    cite the paper with the following BibTeX entry.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在研究或开发工作中使用COCO-Pose数据集，请引用以下BibTeX条目中的论文。
