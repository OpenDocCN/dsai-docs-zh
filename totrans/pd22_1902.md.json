["```py\npip  install  \"pandas[performance, aws]>=2.0.0\" \n```", "```py\nIn [1]: pd.Index([1, 2, 3], dtype=np.int8)\nOut[1]: Int64Index([1, 2, 3], dtype=\"int64\")\nIn [2]: pd.Index([1, 2, 3], dtype=np.uint16)\nOut[2]: UInt64Index([1, 2, 3], dtype=\"uint64\")\nIn [3]: pd.Index([1, 2, 3], dtype=np.float32)\nOut[3]: Float64Index([1.0, 2.0, 3.0], dtype=\"float64\") \n```", "```py\nIn [1]: pd.Index([1, 2, 3], dtype=np.int8)\nOut[1]: Index([1, 2, 3], dtype='int8')\n\nIn [2]: pd.Index([1, 2, 3], dtype=np.uint16)\nOut[2]: Index([1, 2, 3], dtype='uint16')\n\nIn [3]: pd.Index([1, 2, 3], dtype=np.float32)\nOut[3]: Index([1.0, 2.0, 3.0], dtype='float32') \n```", "```py\n    In [4]: idx = pd.date_range(start='1/1/2018', periods=3, freq='ME')\n\n    In [5]: idx.array.year\n    Out[5]: array([2018, 2018, 2018], dtype=int32)\n\n    In [6]: idx.year\n    Out[6]: Index([2018, 2018, 2018], dtype='int32') \n    ```", "```py\n    In [7]: from scipy import sparse\n\n    In [8]: A = sparse.coo_matrix(\n     ...:    ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(3, 4)\n     ...: )\n     ...: \n\n    In [9]: ser = pd.Series.sparse.from_coo(A)\n\n    In [10]: ser.index.dtypes\n    Out[10]: \n    level_0    int32\n    level_1    int32\n    dtype: object \n    ```", "```py\n    In [11]: pd.Index([1, 2, 3], dtype=np.float16)\n    ---------------------------------------------------------------------------\n    NotImplementedError  Traceback (most recent call last)\n    Cell In[11], line 1\n    ----> 1 pd.Index([1, 2, 3], dtype=np.float16)\n\n    File ~/work/pandas/pandas/pandas/core/indexes/base.py:576, in Index.__new__(cls, data, dtype, copy, name, tupleize_cols)\n      572 arr = ensure_wrapped_if_datetimelike(arr)\n      574 klass = cls._dtype_to_subclass(arr.dtype)\n    --> 576 arr = klass._ensure_array(arr, arr.dtype, copy=False)\n      577 result = klass._simple_new(arr, name, refs=refs)\n      578 if dtype is None and is_pandas_object and data_dtype == np.object_:\n\n    File ~/work/pandas/pandas/pandas/core/indexes/base.py:601, in Index._ensure_array(cls, data, dtype, copy)\n      598     raise ValueError(\"Index data must be 1-dimensional\")\n      599 elif dtype == np.float16:\n      600     # float16 not supported (no indexing engine)\n    --> 601     raise NotImplementedError(\"float16 indexes are not supported\")\n      603 if copy:\n      604     # asarray_tuplesafe does not always copy underlying data,\n      605     #  so need to make sure that this happens\n      606     data = data.copy()\n\n    NotImplementedError: float16 indexes are not supported \n    ```", "```py\nIn [12]: import io\n\nIn [13]: data = io.StringIO(\"\"\"a,b,c,d,e,f,g,h,i\n ....:    1,2.5,True,a,,,,,\n ....:    3,4.5,False,b,6,7.5,True,a,\n ....: \"\"\")\n ....: \n\nIn [14]: df = pd.read_csv(data, dtype_backend=\"pyarrow\")\n\nIn [15]: df.dtypes\nOut[15]: \na     int64[pyarrow]\nb    double[pyarrow]\nc      bool[pyarrow]\nd    string[pyarrow]\ne     int64[pyarrow]\nf    double[pyarrow]\ng      bool[pyarrow]\nh    string[pyarrow]\ni      null[pyarrow]\ndtype: object\n\nIn [16]: data.seek(0)\nOut[16]: 0\n\nIn [17]: df_pyarrow = pd.read_csv(data, dtype_backend=\"pyarrow\", engine=\"pyarrow\")\n\nIn [18]: df_pyarrow.dtypes\nOut[18]: \na     int64[pyarrow]\nb    double[pyarrow]\nc      bool[pyarrow]\nd    string[pyarrow]\ne     int64[pyarrow]\nf    double[pyarrow]\ng      bool[pyarrow]\nh    string[pyarrow]\ni      null[pyarrow]\ndtype: object \n```", "```py\npd.set_option(\"mode.copy_on_write\", True) \n```", "```py\npd.options.mode.copy_on_write = True \n```", "```py\nwith pd.option_context(\"mode.copy_on_write\", True):\n    ... \n```", "```py\nIn [1]: df = pd.DataFrame({\"key\": [\"b\"] * 7, \"value\": 625})\nIn [2]: df.groupby(\"key\")[\"value\"].cumprod()[5]\nOut[2]: 5.960464477539062e+16 \n```", "```py\nIn [19]: df = pd.DataFrame({\"key\": [\"b\"] * 7, \"value\": 625})\n\nIn [20]: df.groupby(\"key\")[\"value\"].cumprod()\nOut[20]: \n0                   625\n1                390625\n2             244140625\n3          152587890625\n4        95367431640625\n5     59604644775390625\n6    359414837200037393\nName: value, dtype: int64 \n```", "```py\nIn [21]: df = pd.DataFrame({\"a\": [1, 1, 2, 1, 2], \"b\": [np.nan, 2.0, 3.0, 4.0, 5.0]})\n\nIn [22]: gb = df.groupby(\"a\") \n```", "```py\nIn [5]: gb.nth(n=1)\nOut[5]:\n A    B\n1  1  2.0\n4  2  5.0 \n```", "```py\nIn [23]: gb.nth(n=1)\nOut[23]: \n a    b\n1  1  2.0\n4  2  5.0 \n```", "```py\nIn [5]: gb.nth(n=3, dropna=\"any\")\nOut[5]:\n B\nA\n1 NaN\n2 NaN \n```", "```py\nIn [24]: gb.nth(n=3, dropna=\"any\")\nOut[24]: \nEmpty DataFrame\nColumns: [a, b]\nIndex: [] \n```", "```py\nIn [5]: pd.Series([\"2016-01-01\"], dtype=\"datetime64[s]\")\nOut[5]:\n0   2016-01-01\ndtype: datetime64[ns]\n\nIn [6] pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\nOut[6]:\n0   2016-01-01\ndtype: datetime64[ns] \n```", "```py\nIn [25]: pd.Series([\"2016-01-01\"], dtype=\"datetime64[s]\")\nOut[25]: \n0   2016-01-01\ndtype: datetime64[s] \n```", "```py\nIn [26]: pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\n---------------------------------------------------------------------------\nTypeError  Traceback (most recent call last)\nCell In[26], line 1\n----> 1 pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\n\nFile ~/work/pandas/pandas/pandas/core/series.py:584, in Series.__init__(self, data, index, dtype, name, copy, fastpath)\n  582         data = data.copy()\n  583 else:\n--> 584     data = sanitize_array(data, index, dtype, copy)\n  586     manager = _get_option(\"mode.data_manager\", silent=True)\n  587     if manager == \"block\":\n\nFile ~/work/pandas/pandas/pandas/core/construction.py:651, in sanitize_array(data, index, dtype, copy, allow_2d)\n  648     subarr = np.array([], dtype=np.float64)\n  650 elif dtype is not None:\n--> 651     subarr = _try_cast(data, dtype, copy)\n  653 else:\n  654     subarr = maybe_convert_platform(data)\n\nFile ~/work/pandas/pandas/pandas/core/construction.py:811, in _try_cast(arr, dtype, copy)\n  806     return lib.ensure_string_array(arr, convert_na_value=False, copy=copy).reshape(\n  807         shape\n  808     )\n  810 elif dtype.kind in \"mM\":\n--> 811     return maybe_cast_to_datetime(arr, dtype)\n  813 # GH#15832: Check if we are requesting a numeric dtype and\n  814 # that we can convert the data to the requested dtype.\n  815 elif dtype.kind in \"iu\":\n  816     # this will raise if we have e.g. floats\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/cast.py:1219, in maybe_cast_to_datetime(value, dtype)\n  1215     raise TypeError(\"value must be listlike\")\n  1217 # TODO: _from_sequence would raise ValueError in cases where\n  1218 #  _ensure_nanosecond_dtype raises TypeError\n-> 1219 _ensure_nanosecond_dtype(dtype)\n  1221 if lib.is_np_dtype(dtype, \"m\"):\n  1222     res = TimedeltaArray._from_sequence(value, dtype=dtype)\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/cast.py:1276, in _ensure_nanosecond_dtype(dtype)\n  1273     raise ValueError(msg)\n  1274 # TODO: ValueError or TypeError? existing test\n  1275 #  test_constructor_generic_timestamp_bad_frequency expects TypeError\n-> 1276 raise TypeError(\n  1277     f\"dtype={dtype} is not supported. Supported resolutions are 's', \"\n  1278     \"'ms', 'us', and 'ns'\"\n  1279 )\n\nTypeError: dtype=datetime64[D] is not supported. Supported resolutions are 's', 'ms', 'us', and 'ns' \n```", "```py\nIn [8]: pd.Series(['quetzal', 'quetzal', 'elk'], name='animal').value_counts()\n\nOut[2]:\nquetzal    2\nelk        1\nName: animal, dtype: int64 \n```", "```py\nIn [27]: pd.Series(['quetzal', 'quetzal', 'elk'], name='animal').value_counts()\nOut[27]: \nanimal\nquetzal    2\nelk        1\nName: count, dtype: int64 \n```", "```py\nIn [28]: idx = pd.date_range(\"2016-01-01\", periods=3)\n\nIn [29]: ser = pd.Series(idx) \n```", "```py\nIn [4]: ser.astype(\"datetime64[s]\")\nOut[4]:\n0   2016-01-01\n1   2016-01-02\n2   2016-01-03\ndtype: datetime64[ns] \n```", "```py\nIn [30]: ser.astype(\"datetime64[s]\")\nOut[30]: \n0   2016-01-01\n1   2016-01-02\n2   2016-01-03\ndtype: datetime64[s] \n```", "```py\nIn [31]: ser.astype(\"datetime64[D]\")\n---------------------------------------------------------------------------\nTypeError  Traceback (most recent call last)\nCell In[31], line 1\n----> 1 ser.astype(\"datetime64[D]\")\n\nFile ~/work/pandas/pandas/pandas/core/generic.py:6643, in NDFrame.astype(self, dtype, copy, errors)\n  6637     results = [\n 6638         ser.astype(dtype, copy=copy, errors=errors) for _, ser in self.items()\n  6639     ]\n  6641 else:\n  6642     # else, only a single dtype is given\n-> 6643     new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n  6644     res = self._constructor_from_mgr(new_data, axes=new_data.axes)\n  6645     return res.__finalize__(self, method=\"astype\")\n\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:430, in BaseBlockManager.astype(self, dtype, copy, errors)\n  427 elif using_copy_on_write():\n  428     copy = False\n--> 430 return self.apply(\n  431     \"astype\",\n  432     dtype=dtype,\n  433     copy=copy,\n  434     errors=errors,\n  435     using_cow=using_copy_on_write(),\n  436 )\n\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:363, in BaseBlockManager.apply(self, f, align_keys, **kwargs)\n  361         applied = b.apply(f, **kwargs)\n  362     else:\n--> 363         applied = getattr(b, f)(**kwargs)\n  364     result_blocks = extend_blocks(applied, result_blocks)\n  366 out = type(self).from_blocks(result_blocks, self.axes)\n\nFile ~/work/pandas/pandas/pandas/core/internals/blocks.py:758, in Block.astype(self, dtype, copy, errors, using_cow, squeeze)\n  755         raise ValueError(\"Can not squeeze with more than one column.\")\n  756     values = values[0, :]  # type: ignore[call-overload]\n--> 758 new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n  760 new_values = maybe_coerce_values(new_values)\n  762 refs = None\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:237, in astype_array_safe(values, dtype, copy, errors)\n  234     dtype = dtype.numpy_dtype\n  236 try:\n--> 237     new_values = astype_array(values, dtype, copy=copy)\n  238 except (ValueError, TypeError):\n  239     # e.g. _astype_nansafe can fail on object-dtype of strings\n  240     #  trying to convert to float\n  241     if errors == \"ignore\":\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:179, in astype_array(values, dtype, copy)\n  175     return values\n  177 if not isinstance(values, np.ndarray):\n  178     # i.e. ExtensionArray\n--> 179     values = values.astype(dtype, copy=copy)\n  181 else:\n  182     values = _astype_nansafe(values, dtype, copy=copy)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimes.py:739, in DatetimeArray.astype(self, dtype, copy)\n  737 elif isinstance(dtype, PeriodDtype):\n  738     return self.to_period(freq=dtype.freq)\n--> 739 return dtl.DatetimeLikeArrayMixin.astype(self, dtype, copy)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimelike.py:494, in DatetimeLikeArrayMixin.astype(self, dtype, copy)\n  490 elif (dtype.kind in \"mM\" and self.dtype != dtype) or dtype.kind == \"f\":\n  491     # disallow conversion between datetime/timedelta,\n  492     # and conversions for any datetimelike to float\n  493     msg = f\"Cannot cast {type(self).__name__} to dtype {dtype}\"\n--> 494     raise TypeError(msg)\n  495 else:\n  496     return np.asarray(self, dtype=dtype)\n\nTypeError: Cannot cast DatetimeArray to dtype datetime64[D] \n```", "```py\nIn [32]: idx = pd.timedelta_range(\"1 Day\", periods=3)\n\nIn [33]: ser = pd.Series(idx) \n```", "```py\nIn [7]: ser.astype(\"timedelta64[s]\")\nOut[7]:\n0     86400.0\n1    172800.0\n2    259200.0\ndtype: float64\n\nIn [8]: ser.astype(\"timedelta64[D]\")\nOut[8]:\n0    1.0\n1    2.0\n2    3.0\ndtype: float64 \n```", "```py\nIn [34]: ser.astype(\"timedelta64[s]\")\nOut[34]: \n0   1 days\n1   2 days\n2   3 days\ndtype: timedelta64[s]\n\nIn [35]: ser.astype(\"timedelta64[D]\")\n---------------------------------------------------------------------------\nValueError  Traceback (most recent call last)\nCell In[35], line 1\n----> 1 ser.astype(\"timedelta64[D]\")\n\nFile ~/work/pandas/pandas/pandas/core/generic.py:6643, in NDFrame.astype(self, dtype, copy, errors)\n  6637     results = [\n 6638         ser.astype(dtype, copy=copy, errors=errors) for _, ser in self.items()\n  6639     ]\n  6641 else:\n  6642     # else, only a single dtype is given\n-> 6643     new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n  6644     res = self._constructor_from_mgr(new_data, axes=new_data.axes)\n  6645     return res.__finalize__(self, method=\"astype\")\n\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:430, in BaseBlockManager.astype(self, dtype, copy, errors)\n  427 elif using_copy_on_write():\n  428     copy = False\n--> 430 return self.apply(\n  431     \"astype\",\n  432     dtype=dtype,\n  433     copy=copy,\n  434     errors=errors,\n  435     using_cow=using_copy_on_write(),\n  436 )\n\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:363, in BaseBlockManager.apply(self, f, align_keys, **kwargs)\n  361         applied = b.apply(f, **kwargs)\n  362     else:\n--> 363         applied = getattr(b, f)(**kwargs)\n  364     result_blocks = extend_blocks(applied, result_blocks)\n  366 out = type(self).from_blocks(result_blocks, self.axes)\n\nFile ~/work/pandas/pandas/pandas/core/internals/blocks.py:758, in Block.astype(self, dtype, copy, errors, using_cow, squeeze)\n  755         raise ValueError(\"Can not squeeze with more than one column.\")\n  756     values = values[0, :]  # type: ignore[call-overload]\n--> 758 new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n  760 new_values = maybe_coerce_values(new_values)\n  762 refs = None\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:237, in astype_array_safe(values, dtype, copy, errors)\n  234     dtype = dtype.numpy_dtype\n  236 try:\n--> 237     new_values = astype_array(values, dtype, copy=copy)\n  238 except (ValueError, TypeError):\n  239     # e.g. _astype_nansafe can fail on object-dtype of strings\n  240     #  trying to convert to float\n  241     if errors == \"ignore\":\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:179, in astype_array(values, dtype, copy)\n  175     return values\n  177 if not isinstance(values, np.ndarray):\n  178     # i.e. ExtensionArray\n--> 179     values = values.astype(dtype, copy=copy)\n  181 else:\n  182     values = _astype_nansafe(values, dtype, copy=copy)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/timedeltas.py:358, in TimedeltaArray.astype(self, dtype, copy)\n  354         return type(self)._simple_new(\n  355             res_values, dtype=res_values.dtype, freq=self.freq\n  356         )\n  357     else:\n--> 358         raise ValueError(\n  359             f\"Cannot convert from {self.dtype} to {dtype}. \"\n  360             \"Supported resolutions are 's', 'ms', 'us', 'ns'\"\n  361         )\n  363 return dtl.DatetimeLikeArrayMixin.astype(self, dtype, copy=copy)\n\nValueError: Cannot convert from timedelta64[ns] to timedelta64[D]. Supported resolutions are 's', 'ms', 'us', 'ns' \n```", "```py\nIn [2]: ts = pd.Timestamp(\"2016-01-01\", tz=\"UTC\")\nIn [3]: type(ts.tzinfo)\nOut[3]: pytz.UTC\n\nIn [4]: ts2 = pd.Timestamp(\"2016-01-01 04:05:06-07:00\")\nIn [3]: type(ts2.tzinfo)\nOut[5]: pytz._FixedOffset \n```", "```py\nIn [36]: ts = pd.Timestamp(\"2016-01-01\", tz=\"UTC\")\n\nIn [37]: type(ts.tzinfo)\nOut[37]: datetime.timezone\n\nIn [38]: ts2 = pd.Timestamp(\"2016-01-01 04:05:06-07:00\")\n\nIn [39]: type(ts2.tzinfo)\nOut[39]: datetime.timezone \n```", "```py\nIn [8]: pd.Series().index\nOut[8]:\nIndex([], dtype='object')\n\nIn [9] pd.DataFrame().axes\nOut[9]:\n[Index([], dtype='object'), Index([], dtype='object')] \n```", "```py\nIn [40]: pd.Series().index\nOut[40]: RangeIndex(start=0, stop=0, step=1)\n\nIn [41]: pd.DataFrame().axes\nOut[41]: [RangeIndex(start=0, stop=0, step=1), RangeIndex(start=0, stop=0, step=1)] \n```", "```py\nIn [1]: ser = pd.Series(['13-01-2000', '12-01-2000'])\nIn [2]: pd.to_datetime(ser)\nOut[2]:\n0   2000-01-13\n1   2000-12-01\ndtype: datetime64[ns] \n```", "```py\nIn [42]: ser = pd.Series(['13-01-2000', '12-01-2000'])\n\nIn [43]: pd.to_datetime(ser)\nOut[43]: \n0   2000-01-13\n1   2000-01-12\ndtype: datetime64[ns] \n```", "```py\nser = pd.Series(['13-01-2000', '12 January 2000'])\npd.to_datetime(ser, format='mixed', dayfirst=True) \n```", "```py\nser = pd.Series(['2020-01-01', '2020-01-01 03:00'])\npd.to_datetime(ser, format='ISO8601') \n```", "```py\npip  install  \"pandas[performance, aws]>=2.0.0\" \n```", "```py\nIn [1]: pd.Index([1, 2, 3], dtype=np.int8)\nOut[1]: Int64Index([1, 2, 3], dtype=\"int64\")\nIn [2]: pd.Index([1, 2, 3], dtype=np.uint16)\nOut[2]: UInt64Index([1, 2, 3], dtype=\"uint64\")\nIn [3]: pd.Index([1, 2, 3], dtype=np.float32)\nOut[3]: Float64Index([1.0, 2.0, 3.0], dtype=\"float64\") \n```", "```py\nIn [1]: pd.Index([1, 2, 3], dtype=np.int8)\nOut[1]: Index([1, 2, 3], dtype='int8')\n\nIn [2]: pd.Index([1, 2, 3], dtype=np.uint16)\nOut[2]: Index([1, 2, 3], dtype='uint16')\n\nIn [3]: pd.Index([1, 2, 3], dtype=np.float32)\nOut[3]: Index([1.0, 2.0, 3.0], dtype='float32') \n```", "```py\n    In [4]: idx = pd.date_range(start='1/1/2018', periods=3, freq='ME')\n\n    In [5]: idx.array.year\n    Out[5]: array([2018, 2018, 2018], dtype=int32)\n\n    In [6]: idx.year\n    Out[6]: Index([2018, 2018, 2018], dtype='int32') \n    ```", "```py\n    In [7]: from scipy import sparse\n\n    In [8]: A = sparse.coo_matrix(\n     ...:    ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(3, 4)\n     ...: )\n     ...: \n\n    In [9]: ser = pd.Series.sparse.from_coo(A)\n\n    In [10]: ser.index.dtypes\n    Out[10]: \n    level_0    int32\n    level_1    int32\n    dtype: object \n    ```", "```py\n    In [11]: pd.Index([1, 2, 3], dtype=np.float16)\n    ---------------------------------------------------------------------------\n    NotImplementedError  Traceback (most recent call last)\n    Cell In[11], line 1\n    ----> 1 pd.Index([1, 2, 3], dtype=np.float16)\n\n    File ~/work/pandas/pandas/pandas/core/indexes/base.py:576, in Index.__new__(cls, data, dtype, copy, name, tupleize_cols)\n      572 arr = ensure_wrapped_if_datetimelike(arr)\n      574 klass = cls._dtype_to_subclass(arr.dtype)\n    --> 576 arr = klass._ensure_array(arr, arr.dtype, copy=False)\n      577 result = klass._simple_new(arr, name, refs=refs)\n      578 if dtype is None and is_pandas_object and data_dtype == np.object_:\n\n    File ~/work/pandas/pandas/pandas/core/indexes/base.py:601, in Index._ensure_array(cls, data, dtype, copy)\n      598     raise ValueError(\"Index data must be 1-dimensional\")\n      599 elif dtype == np.float16:\n      600     # float16 not supported (no indexing engine)\n    --> 601     raise NotImplementedError(\"float16 indexes are not supported\")\n      603 if copy:\n      604     # asarray_tuplesafe does not always copy underlying data,\n      605     #  so need to make sure that this happens\n      606     data = data.copy()\n\n    NotImplementedError: float16 indexes are not supported \n    ```", "```py\nIn [12]: import io\n\nIn [13]: data = io.StringIO(\"\"\"a,b,c,d,e,f,g,h,i\n ....:    1,2.5,True,a,,,,,\n ....:    3,4.5,False,b,6,7.5,True,a,\n ....: \"\"\")\n ....: \n\nIn [14]: df = pd.read_csv(data, dtype_backend=\"pyarrow\")\n\nIn [15]: df.dtypes\nOut[15]: \na     int64[pyarrow]\nb    double[pyarrow]\nc      bool[pyarrow]\nd    string[pyarrow]\ne     int64[pyarrow]\nf    double[pyarrow]\ng      bool[pyarrow]\nh    string[pyarrow]\ni      null[pyarrow]\ndtype: object\n\nIn [16]: data.seek(0)\nOut[16]: 0\n\nIn [17]: df_pyarrow = pd.read_csv(data, dtype_backend=\"pyarrow\", engine=\"pyarrow\")\n\nIn [18]: df_pyarrow.dtypes\nOut[18]: \na     int64[pyarrow]\nb    double[pyarrow]\nc      bool[pyarrow]\nd    string[pyarrow]\ne     int64[pyarrow]\nf    double[pyarrow]\ng      bool[pyarrow]\nh    string[pyarrow]\ni      null[pyarrow]\ndtype: object \n```", "```py\npd.set_option(\"mode.copy_on_write\", True) \n```", "```py\npd.options.mode.copy_on_write = True \n```", "```py\nwith pd.option_context(\"mode.copy_on_write\", True):\n    ... \n```", "```py\npip  install  \"pandas[performance, aws]>=2.0.0\" \n```", "```py\nIn [1]: pd.Index([1, 2, 3], dtype=np.int8)\nOut[1]: Int64Index([1, 2, 3], dtype=\"int64\")\nIn [2]: pd.Index([1, 2, 3], dtype=np.uint16)\nOut[2]: UInt64Index([1, 2, 3], dtype=\"uint64\")\nIn [3]: pd.Index([1, 2, 3], dtype=np.float32)\nOut[3]: Float64Index([1.0, 2.0, 3.0], dtype=\"float64\") \n```", "```py\nIn [1]: pd.Index([1, 2, 3], dtype=np.int8)\nOut[1]: Index([1, 2, 3], dtype='int8')\n\nIn [2]: pd.Index([1, 2, 3], dtype=np.uint16)\nOut[2]: Index([1, 2, 3], dtype='uint16')\n\nIn [3]: pd.Index([1, 2, 3], dtype=np.float32)\nOut[3]: Index([1.0, 2.0, 3.0], dtype='float32') \n```", "```py\n    In [4]: idx = pd.date_range(start='1/1/2018', periods=3, freq='ME')\n\n    In [5]: idx.array.year\n    Out[5]: array([2018, 2018, 2018], dtype=int32)\n\n    In [6]: idx.year\n    Out[6]: Index([2018, 2018, 2018], dtype='int32') \n    ```", "```py\n    In [7]: from scipy import sparse\n\n    In [8]: A = sparse.coo_matrix(\n     ...:    ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(3, 4)\n     ...: )\n     ...: \n\n    In [9]: ser = pd.Series.sparse.from_coo(A)\n\n    In [10]: ser.index.dtypes\n    Out[10]: \n    level_0    int32\n    level_1    int32\n    dtype: object \n    ```", "```py\n    In [11]: pd.Index([1, 2, 3], dtype=np.float16)\n    ---------------------------------------------------------------------------\n    NotImplementedError  Traceback (most recent call last)\n    Cell In[11], line 1\n    ----> 1 pd.Index([1, 2, 3], dtype=np.float16)\n\n    File ~/work/pandas/pandas/pandas/core/indexes/base.py:576, in Index.__new__(cls, data, dtype, copy, name, tupleize_cols)\n      572 arr = ensure_wrapped_if_datetimelike(arr)\n      574 klass = cls._dtype_to_subclass(arr.dtype)\n    --> 576 arr = klass._ensure_array(arr, arr.dtype, copy=False)\n      577 result = klass._simple_new(arr, name, refs=refs)\n      578 if dtype is None and is_pandas_object and data_dtype == np.object_:\n\n    File ~/work/pandas/pandas/pandas/core/indexes/base.py:601, in Index._ensure_array(cls, data, dtype, copy)\n      598     raise ValueError(\"Index data must be 1-dimensional\")\n      599 elif dtype == np.float16:\n      600     # float16 not supported (no indexing engine)\n    --> 601     raise NotImplementedError(\"float16 indexes are not supported\")\n      603 if copy:\n      604     # asarray_tuplesafe does not always copy underlying data,\n      605     #  so need to make sure that this happens\n      606     data = data.copy()\n\n    NotImplementedError: float16 indexes are not supported \n    ```", "```py\nIn [12]: import io\n\nIn [13]: data = io.StringIO(\"\"\"a,b,c,d,e,f,g,h,i\n ....:    1,2.5,True,a,,,,,\n ....:    3,4.5,False,b,6,7.5,True,a,\n ....: \"\"\")\n ....: \n\nIn [14]: df = pd.read_csv(data, dtype_backend=\"pyarrow\")\n\nIn [15]: df.dtypes\nOut[15]: \na     int64[pyarrow]\nb    double[pyarrow]\nc      bool[pyarrow]\nd    string[pyarrow]\ne     int64[pyarrow]\nf    double[pyarrow]\ng      bool[pyarrow]\nh    string[pyarrow]\ni      null[pyarrow]\ndtype: object\n\nIn [16]: data.seek(0)\nOut[16]: 0\n\nIn [17]: df_pyarrow = pd.read_csv(data, dtype_backend=\"pyarrow\", engine=\"pyarrow\")\n\nIn [18]: df_pyarrow.dtypes\nOut[18]: \na     int64[pyarrow]\nb    double[pyarrow]\nc      bool[pyarrow]\nd    string[pyarrow]\ne     int64[pyarrow]\nf    double[pyarrow]\ng      bool[pyarrow]\nh    string[pyarrow]\ni      null[pyarrow]\ndtype: object \n```", "```py\npd.set_option(\"mode.copy_on_write\", True) \n```", "```py\npd.options.mode.copy_on_write = True \n```", "```py\nwith pd.option_context(\"mode.copy_on_write\", True):\n    ... \n```", "```py\nIn [1]: df = pd.DataFrame({\"key\": [\"b\"] * 7, \"value\": 625})\nIn [2]: df.groupby(\"key\")[\"value\"].cumprod()[5]\nOut[2]: 5.960464477539062e+16 \n```", "```py\nIn [19]: df = pd.DataFrame({\"key\": [\"b\"] * 7, \"value\": 625})\n\nIn [20]: df.groupby(\"key\")[\"value\"].cumprod()\nOut[20]: \n0                   625\n1                390625\n2             244140625\n3          152587890625\n4        95367431640625\n5     59604644775390625\n6    359414837200037393\nName: value, dtype: int64 \n```", "```py\nIn [21]: df = pd.DataFrame({\"a\": [1, 1, 2, 1, 2], \"b\": [np.nan, 2.0, 3.0, 4.0, 5.0]})\n\nIn [22]: gb = df.groupby(\"a\") \n```", "```py\nIn [5]: gb.nth(n=1)\nOut[5]:\n A    B\n1  1  2.0\n4  2  5.0 \n```", "```py\nIn [23]: gb.nth(n=1)\nOut[23]: \n a    b\n1  1  2.0\n4  2  5.0 \n```", "```py\nIn [5]: gb.nth(n=3, dropna=\"any\")\nOut[5]:\n B\nA\n1 NaN\n2 NaN \n```", "```py\nIn [24]: gb.nth(n=3, dropna=\"any\")\nOut[24]: \nEmpty DataFrame\nColumns: [a, b]\nIndex: [] \n```", "```py\nIn [1]: df = pd.DataFrame({\"key\": [\"b\"] * 7, \"value\": 625})\nIn [2]: df.groupby(\"key\")[\"value\"].cumprod()[5]\nOut[2]: 5.960464477539062e+16 \n```", "```py\nIn [19]: df = pd.DataFrame({\"key\": [\"b\"] * 7, \"value\": 625})\n\nIn [20]: df.groupby(\"key\")[\"value\"].cumprod()\nOut[20]: \n0                   625\n1                390625\n2             244140625\n3          152587890625\n4        95367431640625\n5     59604644775390625\n6    359414837200037393\nName: value, dtype: int64 \n```", "```py\nIn [21]: df = pd.DataFrame({\"a\": [1, 1, 2, 1, 2], \"b\": [np.nan, 2.0, 3.0, 4.0, 5.0]})\n\nIn [22]: gb = df.groupby(\"a\") \n```", "```py\nIn [5]: gb.nth(n=1)\nOut[5]:\n A    B\n1  1  2.0\n4  2  5.0 \n```", "```py\nIn [23]: gb.nth(n=1)\nOut[23]: \n a    b\n1  1  2.0\n4  2  5.0 \n```", "```py\nIn [5]: gb.nth(n=3, dropna=\"any\")\nOut[5]:\n B\nA\n1 NaN\n2 NaN \n```", "```py\nIn [24]: gb.nth(n=3, dropna=\"any\")\nOut[24]: \nEmpty DataFrame\nColumns: [a, b]\nIndex: [] \n```", "```py\nIn [5]: pd.Series([\"2016-01-01\"], dtype=\"datetime64[s]\")\nOut[5]:\n0   2016-01-01\ndtype: datetime64[ns]\n\nIn [6] pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\nOut[6]:\n0   2016-01-01\ndtype: datetime64[ns] \n```", "```py\nIn [25]: pd.Series([\"2016-01-01\"], dtype=\"datetime64[s]\")\nOut[25]: \n0   2016-01-01\ndtype: datetime64[s] \n```", "```py\nIn [26]: pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\n---------------------------------------------------------------------------\nTypeError  Traceback (most recent call last)\nCell In[26], line 1\n----> 1 pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\n\nFile ~/work/pandas/pandas/pandas/core/series.py:584, in Series.__init__(self, data, index, dtype, name, copy, fastpath)\n  582         data = data.copy()\n  583 else:\n--> 584     data = sanitize_array(data, index, dtype, copy)\n  586     manager = _get_option(\"mode.data_manager\", silent=True)\n  587     if manager == \"block\":\n\nFile ~/work/pandas/pandas/pandas/core/construction.py:651, in sanitize_array(data, index, dtype, copy, allow_2d)\n  648     subarr = np.array([], dtype=np.float64)\n  650 elif dtype is not None:\n--> 651     subarr = _try_cast(data, dtype, copy)\n  653 else:\n  654     subarr = maybe_convert_platform(data)\n\nFile ~/work/pandas/pandas/pandas/core/construction.py:811, in _try_cast(arr, dtype, copy)\n  806     return lib.ensure_string_array(arr, convert_na_value=False, copy=copy).reshape(\n  807         shape\n  808     )\n  810 elif dtype.kind in \"mM\":\n--> 811     return maybe_cast_to_datetime(arr, dtype)\n  813 # GH#15832: Check if we are requesting a numeric dtype and\n  814 # that we can convert the data to the requested dtype.\n  815 elif dtype.kind in \"iu\":\n  816     # this will raise if we have e.g. floats\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/cast.py:1219, in maybe_cast_to_datetime(value, dtype)\n  1215     raise TypeError(\"value must be listlike\")\n  1217 # TODO: _from_sequence would raise ValueError in cases where\n  1218 #  _ensure_nanosecond_dtype raises TypeError\n-> 1219 _ensure_nanosecond_dtype(dtype)\n  1221 if lib.is_np_dtype(dtype, \"m\"):\n  1222     res = TimedeltaArray._from_sequence(value, dtype=dtype)\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/cast.py:1276, in _ensure_nanosecond_dtype(dtype)\n  1273     raise ValueError(msg)\n  1274 # TODO: ValueError or TypeError? existing test\n  1275 #  test_constructor_generic_timestamp_bad_frequency expects TypeError\n-> 1276 raise TypeError(\n  1277     f\"dtype={dtype} is not supported. Supported resolutions are 's', \"\n  1278     \"'ms', 'us', and 'ns'\"\n  1279 )\n\nTypeError: dtype=datetime64[D] is not supported. Supported resolutions are 's', 'ms', 'us', and 'ns' \n```", "```py\nIn [8]: pd.Series(['quetzal', 'quetzal', 'elk'], name='animal').value_counts()\n\nOut[2]:\nquetzal    2\nelk        1\nName: animal, dtype: int64 \n```", "```py\nIn [27]: pd.Series(['quetzal', 'quetzal', 'elk'], name='animal').value_counts()\nOut[27]: \nanimal\nquetzal    2\nelk        1\nName: count, dtype: int64 \n```", "```py\nIn [28]: idx = pd.date_range(\"2016-01-01\", periods=3)\n\nIn [29]: ser = pd.Series(idx) \n```", "```py\nIn [4]: ser.astype(\"datetime64[s]\")\nOut[4]:\n0   2016-01-01\n1   2016-01-02\n2   2016-01-03\ndtype: datetime64[ns] \n```", "```py\nIn [30]: ser.astype(\"datetime64[s]\")\nOut[30]: \n0   2016-01-01\n1   2016-01-02\n2   2016-01-03\ndtype: datetime64[s] \n```", "```py\nIn [31]: ser.astype(\"datetime64[D]\")\n---------------------------------------------------------------------------\nTypeError  Traceback (most recent call last)\nCell In[31], line 1\n----> 1 ser.astype(\"datetime64[D]\")\n\nFile ~/work/pandas/pandas/pandas/core/generic.py:6643, in NDFrame.astype(self, dtype, copy, errors)\n  6637     results = [\n 6638         ser.astype(dtype, copy=copy, errors=errors) for _, ser in self.items()\n  6639     ]\n  6641 else:\n  6642     # else, only a single dtype is given\n-> 6643     new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n  6644     res = self._constructor_from_mgr(new_data, axes=new_data.axes)\n  6645     return res.__finalize__(self, method=\"astype\")\n\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:430, in BaseBlockManager.astype(self, dtype, copy, errors)\n  427 elif using_copy_on_write():\n  428     copy = False\n--> 430 return self.apply(\n  431     \"astype\",\n  432     dtype=dtype,\n  433     copy=copy,\n  434     errors=errors,\n  435     using_cow=using_copy_on_write(),\n  436 )\n\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:363, in BaseBlockManager.apply(self, f, align_keys, **kwargs)\n  361         applied = b.apply(f, **kwargs)\n  362     else:\n--> 363         applied = getattr(b, f)(**kwargs)\n  364     result_blocks = extend_blocks(applied, result_blocks)\n  366 out = type(self).from_blocks(result_blocks, self.axes)\n\nFile ~/work/pandas/pandas/pandas/core/internals/blocks.py:758, in Block.astype(self, dtype, copy, errors, using_cow, squeeze)\n  755         raise ValueError(\"Can not squeeze with more than one column.\")\n  756     values = values[0, :]  # type: ignore[call-overload]\n--> 758 new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n  760 new_values = maybe_coerce_values(new_values)\n  762 refs = None\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:237, in astype_array_safe(values, dtype, copy, errors)\n  234     dtype = dtype.numpy_dtype\n  236 try:\n--> 237     new_values = astype_array(values, dtype, copy=copy)\n  238 except (ValueError, TypeError):\n  239     # e.g. _astype_nansafe can fail on object-dtype of strings\n  240     #  trying to convert to float\n  241     if errors == \"ignore\":\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:179, in astype_array(values, dtype, copy)\n  175     return values\n  177 if not isinstance(values, np.ndarray):\n  178     # i.e. ExtensionArray\n--> 179     values = values.astype(dtype, copy=copy)\n  181 else:\n  182     values = _astype_nansafe(values, dtype, copy=copy)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimes.py:739, in DatetimeArray.astype(self, dtype, copy)\n  737 elif isinstance(dtype, PeriodDtype):\n  738     return self.to_period(freq=dtype.freq)\n--> 739 return dtl.DatetimeLikeArrayMixin.astype(self, dtype, copy)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimelike.py:494, in DatetimeLikeArrayMixin.astype(self, dtype, copy)\n  490 elif (dtype.kind in \"mM\" and self.dtype != dtype) or dtype.kind == \"f\":\n  491     # disallow conversion between datetime/timedelta,\n  492     # and conversions for any datetimelike to float\n  493     msg = f\"Cannot cast {type(self).__name__} to dtype {dtype}\"\n--> 494     raise TypeError(msg)\n  495 else:\n  496     return np.asarray(self, dtype=dtype)\n\nTypeError: Cannot cast DatetimeArray to dtype datetime64[D] \n```", "```py\nIn [32]: idx = pd.timedelta_range(\"1 Day\", periods=3)\n\nIn [33]: ser = pd.Series(idx) \n```", "```py\nIn [7]: ser.astype(\"timedelta64[s]\")\nOut[7]:\n0     86400.0\n1    172800.0\n2    259200.0\ndtype: float64\n\nIn [8]: ser.astype(\"timedelta64[D]\")\nOut[8]:\n0    1.0\n1    2.0\n2    3.0\ndtype: float64 \n```", "```py\nIn [34]: ser.astype(\"timedelta64[s]\")\nOut[34]: \n0   1 days\n1   2 days\n2   3 days\ndtype: timedelta64[s]\n\nIn [35]: ser.astype(\"timedelta64[D]\")\n---------------------------------------------------------------------------\nValueError  Traceback (most recent call last)\nCell In[35], line 1\n----> 1 ser.astype(\"timedelta64[D]\")\n\nFile ~/work/pandas/pandas/pandas/core/generic.py:6643, in NDFrame.astype(self, dtype, copy, errors)\n  6637     results = [\n 6638         ser.astype(dtype, copy=copy, errors=errors) for _, ser in self.items()\n  6639     ]\n  6641 else:\n  6642     # else, only a single dtype is given\n-> 6643     new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n  6644     res = self._constructor_from_mgr(new_data, axes=new_data.axes)\n  6645     return res.__finalize__(self, method=\"astype\")\n\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:430, in BaseBlockManager.astype(self, dtype, copy, errors)\n  427 elif using_copy_on_write():\n  428     copy = False\n--> 430 return self.apply(\n  431     \"astype\",\n  432     dtype=dtype,\n  433     copy=copy,\n  434     errors=errors,\n  435     using_cow=using_copy_on_write(),\n  436 )\n\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:363, in BaseBlockManager.apply(self, f, align_keys, **kwargs)\n  361         applied = b.apply(f, **kwargs)\n  362     else:\n--> 363         applied = getattr(b, f)(**kwargs)\n  364     result_blocks = extend_blocks(applied, result_blocks)\n  366 out = type(self).from_blocks(result_blocks, self.axes)\n\nFile ~/work/pandas/pandas/pandas/core/internals/blocks.py:758, in Block.astype(self, dtype, copy, errors, using_cow, squeeze)\n  755         raise ValueError(\"Can not squeeze with more than one column.\")\n  756     values = values[0, :]  # type: ignore[call-overload]\n--> 758 new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n  760 new_values = maybe_coerce_values(new_values)\n  762 refs = None\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:237, in astype_array_safe(values, dtype, copy, errors)\n  234     dtype = dtype.numpy_dtype\n  236 try:\n--> 237     new_values = astype_array(values, dtype, copy=copy)\n  238 except (ValueError, TypeError):\n  239     # e.g. _astype_nansafe can fail on object-dtype of strings\n  240     #  trying to convert to float\n  241     if errors == \"ignore\":\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:179, in astype_array(values, dtype, copy)\n  175     return values\n  177 if not isinstance(values, np.ndarray):\n  178     # i.e. ExtensionArray\n--> 179     values = values.astype(dtype, copy=copy)\n  181 else:\n  182     values = _astype_nansafe(values, dtype, copy=copy)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/timedeltas.py:358, in TimedeltaArray.astype(self, dtype, copy)\n  354         return type(self)._simple_new(\n  355             res_values, dtype=res_values.dtype, freq=self.freq\n  356         )\n  357     else:\n--> 358         raise ValueError(\n  359             f\"Cannot convert from {self.dtype} to {dtype}. \"\n  360             \"Supported resolutions are 's', 'ms', 'us', 'ns'\"\n  361         )\n  363 return dtl.DatetimeLikeArrayMixin.astype(self, dtype, copy=copy)\n\nValueError: Cannot convert from timedelta64[ns] to timedelta64[D]. Supported resolutions are 's', 'ms', 'us', 'ns' \n```", "```py\nIn [2]: ts = pd.Timestamp(\"2016-01-01\", tz=\"UTC\")\nIn [3]: type(ts.tzinfo)\nOut[3]: pytz.UTC\n\nIn [4]: ts2 = pd.Timestamp(\"2016-01-01 04:05:06-07:00\")\nIn [3]: type(ts2.tzinfo)\nOut[5]: pytz._FixedOffset \n```", "```py\nIn [36]: ts = pd.Timestamp(\"2016-01-01\", tz=\"UTC\")\n\nIn [37]: type(ts.tzinfo)\nOut[37]: datetime.timezone\n\nIn [38]: ts2 = pd.Timestamp(\"2016-01-01 04:05:06-07:00\")\n\nIn [39]: type(ts2.tzinfo)\nOut[39]: datetime.timezone \n```", "```py\nIn [8]: pd.Series().index\nOut[8]:\nIndex([], dtype='object')\n\nIn [9] pd.DataFrame().axes\nOut[9]:\n[Index([], dtype='object'), Index([], dtype='object')] \n```", "```py\nIn [40]: pd.Series().index\nOut[40]: RangeIndex(start=0, stop=0, step=1)\n\nIn [41]: pd.DataFrame().axes\nOut[41]: [RangeIndex(start=0, stop=0, step=1), RangeIndex(start=0, stop=0, step=1)] \n```", "```py\nIn [1]: ser = pd.Series(['13-01-2000', '12-01-2000'])\nIn [2]: pd.to_datetime(ser)\nOut[2]:\n0   2000-01-13\n1   2000-12-01\ndtype: datetime64[ns] \n```", "```py\nIn [42]: ser = pd.Series(['13-01-2000', '12-01-2000'])\n\nIn [43]: pd.to_datetime(ser)\nOut[43]: \n0   2000-01-13\n1   2000-01-12\ndtype: datetime64[ns] \n```", "```py\nser = pd.Series(['13-01-2000', '12 January 2000'])\npd.to_datetime(ser, format='mixed', dayfirst=True) \n```", "```py\nser = pd.Series(['2020-01-01', '2020-01-01 03:00'])\npd.to_datetime(ser, format='ISO8601') \n```", "```py\nIn [5]: pd.Series([\"2016-01-01\"], dtype=\"datetime64[s]\")\nOut[5]:\n0   2016-01-01\ndtype: datetime64[ns]\n\nIn [6] pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\nOut[6]:\n0   2016-01-01\ndtype: datetime64[ns] \n```", "```py\nIn [25]: pd.Series([\"2016-01-01\"], dtype=\"datetime64[s]\")\nOut[25]: \n0   2016-01-01\ndtype: datetime64[s] \n```", "```py\nIn [26]: pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\n---------------------------------------------------------------------------\nTypeError  Traceback (most recent call last)\nCell In[26], line 1\n----> 1 pd.Series([\"2016-01-01\"], dtype=\"datetime64[D]\")\n\nFile ~/work/pandas/pandas/pandas/core/series.py:584, in Series.__init__(self, data, index, dtype, name, copy, fastpath)\n  582         data = data.copy()\n  583 else:\n--> 584     data = sanitize_array(data, index, dtype, copy)\n  586     manager = _get_option(\"mode.data_manager\", silent=True)\n  587     if manager == \"block\":\n\nFile ~/work/pandas/pandas/pandas/core/construction.py:651, in sanitize_array(data, index, dtype, copy, allow_2d)\n  648     subarr = np.array([], dtype=np.float64)\n  650 elif dtype is not None:\n--> 651     subarr = _try_cast(data, dtype, copy)\n  653 else:\n  654     subarr = maybe_convert_platform(data)\n\nFile ~/work/pandas/pandas/pandas/core/construction.py:811, in _try_cast(arr, dtype, copy)\n  806     return lib.ensure_string_array(arr, convert_na_value=False, copy=copy).reshape(\n  807         shape\n  808     )\n  810 elif dtype.kind in \"mM\":\n--> 811     return maybe_cast_to_datetime(arr, dtype)\n  813 # GH#15832: Check if we are requesting a numeric dtype and\n  814 # that we can convert the data to the requested dtype.\n  815 elif dtype.kind in \"iu\":\n  816     # this will raise if we have e.g. floats\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/cast.py:1219, in maybe_cast_to_datetime(value, dtype)\n  1215     raise TypeError(\"value must be listlike\")\n  1217 # TODO: _from_sequence would raise ValueError in cases where\n  1218 #  _ensure_nanosecond_dtype raises TypeError\n-> 1219 _ensure_nanosecond_dtype(dtype)\n  1221 if lib.is_np_dtype(dtype, \"m\"):\n  1222     res = TimedeltaArray._from_sequence(value, dtype=dtype)\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/cast.py:1276, in _ensure_nanosecond_dtype(dtype)\n  1273     raise ValueError(msg)\n  1274 # TODO: ValueError or TypeError? existing test\n  1275 #  test_constructor_generic_timestamp_bad_frequency expects TypeError\n-> 1276 raise TypeError(\n  1277     f\"dtype={dtype} is not supported. Supported resolutions are 's', \"\n  1278     \"'ms', 'us', and 'ns'\"\n  1279 )\n\nTypeError: dtype=datetime64[D] is not supported. Supported resolutions are 's', 'ms', 'us', and 'ns' \n```", "```py\nIn [8]: pd.Series(['quetzal', 'quetzal', 'elk'], name='animal').value_counts()\n\nOut[2]:\nquetzal    2\nelk        1\nName: animal, dtype: int64 \n```", "```py\nIn [27]: pd.Series(['quetzal', 'quetzal', 'elk'], name='animal').value_counts()\nOut[27]: \nanimal\nquetzal    2\nelk        1\nName: count, dtype: int64 \n```", "```py\nIn [28]: idx = pd.date_range(\"2016-01-01\", periods=3)\n\nIn [29]: ser = pd.Series(idx) \n```", "```py\nIn [4]: ser.astype(\"datetime64[s]\")\nOut[4]:\n0   2016-01-01\n1   2016-01-02\n2   2016-01-03\ndtype: datetime64[ns] \n```", "```py\nIn [30]: ser.astype(\"datetime64[s]\")\nOut[30]: \n0   2016-01-01\n1   2016-01-02\n2   2016-01-03\ndtype: datetime64[s] \n```", "```py\nIn [31]: ser.astype(\"datetime64[D]\")\n---------------------------------------------------------------------------\nTypeError  Traceback (most recent call last)\nCell In[31], line 1\n----> 1 ser.astype(\"datetime64[D]\")\n\nFile ~/work/pandas/pandas/pandas/core/generic.py:6643, in NDFrame.astype(self, dtype, copy, errors)\n  6637     results = [\n 6638         ser.astype(dtype, copy=copy, errors=errors) for _, ser in self.items()\n  6639     ]\n  6641 else:\n  6642     # else, only a single dtype is given\n-> 6643     new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n  6644     res = self._constructor_from_mgr(new_data, axes=new_data.axes)\n  6645     return res.__finalize__(self, method=\"astype\")\n\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:430, in BaseBlockManager.astype(self, dtype, copy, errors)\n  427 elif using_copy_on_write():\n  428     copy = False\n--> 430 return self.apply(\n  431     \"astype\",\n  432     dtype=dtype,\n  433     copy=copy,\n  434     errors=errors,\n  435     using_cow=using_copy_on_write(),\n  436 )\n\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:363, in BaseBlockManager.apply(self, f, align_keys, **kwargs)\n  361         applied = b.apply(f, **kwargs)\n  362     else:\n--> 363         applied = getattr(b, f)(**kwargs)\n  364     result_blocks = extend_blocks(applied, result_blocks)\n  366 out = type(self).from_blocks(result_blocks, self.axes)\n\nFile ~/work/pandas/pandas/pandas/core/internals/blocks.py:758, in Block.astype(self, dtype, copy, errors, using_cow, squeeze)\n  755         raise ValueError(\"Can not squeeze with more than one column.\")\n  756     values = values[0, :]  # type: ignore[call-overload]\n--> 758 new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n  760 new_values = maybe_coerce_values(new_values)\n  762 refs = None\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:237, in astype_array_safe(values, dtype, copy, errors)\n  234     dtype = dtype.numpy_dtype\n  236 try:\n--> 237     new_values = astype_array(values, dtype, copy=copy)\n  238 except (ValueError, TypeError):\n  239     # e.g. _astype_nansafe can fail on object-dtype of strings\n  240     #  trying to convert to float\n  241     if errors == \"ignore\":\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:179, in astype_array(values, dtype, copy)\n  175     return values\n  177 if not isinstance(values, np.ndarray):\n  178     # i.e. ExtensionArray\n--> 179     values = values.astype(dtype, copy=copy)\n  181 else:\n  182     values = _astype_nansafe(values, dtype, copy=copy)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimes.py:739, in DatetimeArray.astype(self, dtype, copy)\n  737 elif isinstance(dtype, PeriodDtype):\n  738     return self.to_period(freq=dtype.freq)\n--> 739 return dtl.DatetimeLikeArrayMixin.astype(self, dtype, copy)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimelike.py:494, in DatetimeLikeArrayMixin.astype(self, dtype, copy)\n  490 elif (dtype.kind in \"mM\" and self.dtype != dtype) or dtype.kind == \"f\":\n  491     # disallow conversion between datetime/timedelta,\n  492     # and conversions for any datetimelike to float\n  493     msg = f\"Cannot cast {type(self).__name__} to dtype {dtype}\"\n--> 494     raise TypeError(msg)\n  495 else:\n  496     return np.asarray(self, dtype=dtype)\n\nTypeError: Cannot cast DatetimeArray to dtype datetime64[D] \n```", "```py\nIn [32]: idx = pd.timedelta_range(\"1 Day\", periods=3)\n\nIn [33]: ser = pd.Series(idx) \n```", "```py\nIn [7]: ser.astype(\"timedelta64[s]\")\nOut[7]:\n0     86400.0\n1    172800.0\n2    259200.0\ndtype: float64\n\nIn [8]: ser.astype(\"timedelta64[D]\")\nOut[8]:\n0    1.0\n1    2.0\n2    3.0\ndtype: float64 \n```", "```py\nIn [34]: ser.astype(\"timedelta64[s]\")\nOut[34]: \n0   1 days\n1   2 days\n2   3 days\ndtype: timedelta64[s]\n\nIn [35]: ser.astype(\"timedelta64[D]\")\n---------------------------------------------------------------------------\nValueError  Traceback (most recent call last)\nCell In[35], line 1\n----> 1 ser.astype(\"timedelta64[D]\")\n\nFile ~/work/pandas/pandas/pandas/core/generic.py:6643, in NDFrame.astype(self, dtype, copy, errors)\n  6637     results = [\n 6638         ser.astype(dtype, copy=copy, errors=errors) for _, ser in self.items()\n  6639     ]\n  6641 else:\n  6642     # else, only a single dtype is given\n-> 6643     new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n  6644     res = self._constructor_from_mgr(new_data, axes=new_data.axes)\n  6645     return res.__finalize__(self, method=\"astype\")\n\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:430, in BaseBlockManager.astype(self, dtype, copy, errors)\n  427 elif using_copy_on_write():\n  428     copy = False\n--> 430 return self.apply(\n  431     \"astype\",\n  432     dtype=dtype,\n  433     copy=copy,\n  434     errors=errors,\n  435     using_cow=using_copy_on_write(),\n  436 )\n\nFile ~/work/pandas/pandas/pandas/core/internals/managers.py:363, in BaseBlockManager.apply(self, f, align_keys, **kwargs)\n  361         applied = b.apply(f, **kwargs)\n  362     else:\n--> 363         applied = getattr(b, f)(**kwargs)\n  364     result_blocks = extend_blocks(applied, result_blocks)\n  366 out = type(self).from_blocks(result_blocks, self.axes)\n\nFile ~/work/pandas/pandas/pandas/core/internals/blocks.py:758, in Block.astype(self, dtype, copy, errors, using_cow, squeeze)\n  755         raise ValueError(\"Can not squeeze with more than one column.\")\n  756     values = values[0, :]  # type: ignore[call-overload]\n--> 758 new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n  760 new_values = maybe_coerce_values(new_values)\n  762 refs = None\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:237, in astype_array_safe(values, dtype, copy, errors)\n  234     dtype = dtype.numpy_dtype\n  236 try:\n--> 237     new_values = astype_array(values, dtype, copy=copy)\n  238 except (ValueError, TypeError):\n  239     # e.g. _astype_nansafe can fail on object-dtype of strings\n  240     #  trying to convert to float\n  241     if errors == \"ignore\":\n\nFile ~/work/pandas/pandas/pandas/core/dtypes/astype.py:179, in astype_array(values, dtype, copy)\n  175     return values\n  177 if not isinstance(values, np.ndarray):\n  178     # i.e. ExtensionArray\n--> 179     values = values.astype(dtype, copy=copy)\n  181 else:\n  182     values = _astype_nansafe(values, dtype, copy=copy)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/timedeltas.py:358, in TimedeltaArray.astype(self, dtype, copy)\n  354         return type(self)._simple_new(\n  355             res_values, dtype=res_values.dtype, freq=self.freq\n  356         )\n  357     else:\n--> 358         raise ValueError(\n  359             f\"Cannot convert from {self.dtype} to {dtype}. \"\n  360             \"Supported resolutions are 's', 'ms', 'us', 'ns'\"\n  361         )\n  363 return dtl.DatetimeLikeArrayMixin.astype(self, dtype, copy=copy)\n\nValueError: Cannot convert from timedelta64[ns] to timedelta64[D]. Supported resolutions are 's', 'ms', 'us', 'ns' \n```", "```py\nIn [2]: ts = pd.Timestamp(\"2016-01-01\", tz=\"UTC\")\nIn [3]: type(ts.tzinfo)\nOut[3]: pytz.UTC\n\nIn [4]: ts2 = pd.Timestamp(\"2016-01-01 04:05:06-07:00\")\nIn [3]: type(ts2.tzinfo)\nOut[5]: pytz._FixedOffset \n```", "```py\nIn [36]: ts = pd.Timestamp(\"2016-01-01\", tz=\"UTC\")\n\nIn [37]: type(ts.tzinfo)\nOut[37]: datetime.timezone\n\nIn [38]: ts2 = pd.Timestamp(\"2016-01-01 04:05:06-07:00\")\n\nIn [39]: type(ts2.tzinfo)\nOut[39]: datetime.timezone \n```", "```py\nIn [8]: pd.Series().index\nOut[8]:\nIndex([], dtype='object')\n\nIn [9] pd.DataFrame().axes\nOut[9]:\n[Index([], dtype='object'), Index([], dtype='object')] \n```", "```py\nIn [40]: pd.Series().index\nOut[40]: RangeIndex(start=0, stop=0, step=1)\n\nIn [41]: pd.DataFrame().axes\nOut[41]: [RangeIndex(start=0, stop=0, step=1), RangeIndex(start=0, stop=0, step=1)] \n```", "```py\nIn [1]: ser = pd.Series(['13-01-2000', '12-01-2000'])\nIn [2]: pd.to_datetime(ser)\nOut[2]:\n0   2000-01-13\n1   2000-12-01\ndtype: datetime64[ns] \n```", "```py\nIn [42]: ser = pd.Series(['13-01-2000', '12-01-2000'])\n\nIn [43]: pd.to_datetime(ser)\nOut[43]: \n0   2000-01-13\n1   2000-01-12\ndtype: datetime64[ns] \n```", "```py\nser = pd.Series(['13-01-2000', '12 January 2000'])\npd.to_datetime(ser, format='mixed', dayfirst=True) \n```", "```py\nser = pd.Series(['2020-01-01', '2020-01-01 03:00'])\npd.to_datetime(ser, format='ISO8601') \n```"]