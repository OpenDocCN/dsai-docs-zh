- en: COCO Dataset
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: COCO数据集
- en: 原文：[`docs.ultralytics.com/datasets/detect/coco/`](https://docs.ultralytics.com/datasets/detect/coco/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/datasets/detect/coco/`](https://docs.ultralytics.com/datasets/detect/coco/)
- en: The [COCO](https://cocodataset.org/#home) (Common Objects in Context) dataset
    is a large-scale object detection, segmentation, and captioning dataset. It is
    designed to encourage research on a wide variety of object categories and is commonly
    used for benchmarking computer vision models. It is an essential dataset for researchers
    and developers working on object detection, segmentation, and pose estimation
    tasks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[COCO](https://cocodataset.org/#home)（上下文中的常见对象）数据集是一个大规模对象检测、分割和字幕数据集。它旨在鼓励研究各种对象类别，并且通常用于计算机视觉模型的基准测试。对于从事对象检测、分割和姿态估计任务的研究人员和开发人员来说，它是一个必不可少的数据集。'
- en: '[`www.youtube.com/embed/uDrn9QZJ2lk`](https://www.youtube.com/embed/uDrn9QZJ2lk)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[`www.youtube.com/embed/uDrn9QZJ2lk`](https://www.youtube.com/embed/uDrn9QZJ2lk)'
- en: '**Watch:** Ultralytics COCO Dataset Overview'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**Watch:** Ultralytics COCO数据集概述'
- en: COCO Pretrained Models
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: COCO预训练模型
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '| 模型 | 尺寸 ^((像素)) | mAP^(val 50-95) | 速度 ^(CPU ONNX'
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: (ms)) | 速度 ^(A100 TensorRT
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: (ms)) | params ^((M)) | FLOPs ^((B)) |
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)
    | 640 | 37.3 | 80.4 | 0.99 | 3.2 | 8.7 |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)
    | 640 | 37.3 | 80.4 | 0.99 | 3.2 | 8.7 |'
- en: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)
    | 640 | 44.9 | 128.4 | 1.20 | 11.2 | 28.6 |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)
    | 640 | 44.9 | 128.4 | 1.20 | 11.2 | 28.6 |'
- en: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)
    | 640 | 50.2 | 234.7 | 1.83 | 25.9 | 78.9 |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)
    | 640 | 50.2 | 234.7 | 1.83 | 25.9 | 78.9 |'
- en: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt)
    | 640 | 52.9 | 375.2 | 2.39 | 43.7 | 165.2 |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt)
    | 640 | 52.9 | 375.2 | 2.39 | 43.7 | 165.2 |'
- en: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt)
    | 640 | 53.9 | 479.1 | 3.53 | 68.2 | 257.8 |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt)
    | 640 | 53.9 | 479.1 | 3.53 | 68.2 | 257.8 |'
- en: Key Features
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主要特点
- en: COCO contains 330K images, with 200K images having annotations for object detection,
    segmentation, and captioning tasks.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: COCO包含330K张图像，其中200K张图像具有对象检测、分割和字幕任务的注释。
- en: The dataset comprises 80 object categories, including common objects like cars,
    bicycles, and animals, as well as more specific categories such as umbrellas,
    handbags, and sports equipment.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集包括80个对象类别，包括常见对象如汽车、自行车和动物，以及更具体的类别，如雨伞、手提包和运动设备。
- en: Annotations include object bounding boxes, segmentation masks, and captions
    for each image.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注释包括每个图像的对象边界框、分割蒙版和字幕。
- en: COCO provides standardized evaluation metrics like mean Average Precision (mAP)
    for object detection, and mean Average Recall (mAR) for segmentation tasks, making
    it suitable for comparing model performance.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: COCO提供了标准化的评估指标，如对象检测的平均精度（mAP）和分割任务的平均召回率（mAR），适合于比较模型性能。
- en: Dataset Structure
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集结构
- en: 'The COCO dataset is split into three subsets:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: COCO数据集分为三个子集：
- en: '**Train2017**: This subset contains 118K images for training object detection,
    segmentation, and captioning models.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Train2017**: 这个子集包含118K张用于训练对象检测、分割和字幕模型的图像。'
- en: '**Val2017**: This subset has 5K images used for validation purposes during
    model training.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Val2017**: 这个子集包含用于模型训练验证目的的5K张图像。'
- en: '**Test2017**: This subset consists of 20K images used for testing and benchmarking
    the trained models. Ground truth annotations for this subset are not publicly
    available, and the results are submitted to the [COCO evaluation server](https://codalab.lisn.upsaclay.fr/competitions/7384)
    for performance evaluation.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Test2017**: 这个子集包含用于测试和基准测试训练模型的20K张图像。该子集的地面实况标注并未公开，结果将提交至[COCO评估服务器](https://codalab.lisn.upsaclay.fr/competitions/7384)进行性能评估。'
- en: Applications
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用
- en: The COCO dataset is widely used for training and evaluating deep learning models
    in object detection (such as YOLO, Faster R-CNN, and SSD), instance segmentation
    (such as Mask R-CNN), and keypoint detection (such as OpenPose). The dataset's
    diverse set of object categories, large number of annotated images, and standardized
    evaluation metrics make it an essential resource for computer vision researchers
    and practitioners.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: COCO 数据集广泛用于训练和评估深度学习模型，包括目标检测（如 YOLO、Faster R-CNN 和 SSD）、实例分割（如 Mask R-CNN）和关键点检测（如
    OpenPose）。该数据集具有多样的对象类别集合、大量注释图像以及标准化的评估指标，使其成为计算机视觉研究人员和从业者的重要资源。
- en: Dataset YAML
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集 YAML
- en: A YAML (Yet Another Markup Language) file is used to define the dataset configuration.
    It contains information about the dataset's paths, classes, and other relevant
    information. In the case of the COCO dataset, the `coco.yaml` file is maintained
    at [`github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: YAML（Yet Another Markup Language）文件用于定义数据集配置。它包含有关数据集路径、类别和其他相关信息的信息。在 COCO
    数据集的情况下，`coco.yaml` 文件维护在 [`github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml)。
- en: ultralytics/cfg/datasets/coco.yaml
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ultralytics/cfg/datasets/coco.yaml
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Usage
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用
- en: To train a YOLOv8n model on the COCO dataset for 100 epochs with an image size
    of 640, you can use the following code snippets. For a comprehensive list of available
    arguments, refer to the model Training page.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 COCO 数据集上训练 100 个 epochs 的 YOLOv8n 模型，并使用 640 的图像大小，可以使用以下代码片段。有关可用参数的详细列表，请参阅模型训练页面。
- en: Train Example
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 训练示例
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Sample Images and Annotations
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 样本图像和注释
- en: 'The COCO dataset contains a diverse set of images with various object categories
    and complex scenes. Here are some examples of images from the dataset, along with
    their corresponding annotations:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: COCO 数据集包含多样的图像集，具有各种对象类别和复杂场景。以下是数据集中的一些图像示例，以及它们的相应注释：
- en: '![Dataset sample image](img/f2aa95e453433e4aff2ebd64f746d29b.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![数据集示例图片](img/f2aa95e453433e4aff2ebd64f746d29b.png)'
- en: '**Mosaiced Image**: This image demonstrates a training batch composed of mosaiced
    dataset images. Mosaicing is a technique used during training that combines multiple
    images into a single image to increase the variety of objects and scenes within
    each training batch. This helps improve the model''s ability to generalize to
    different object sizes, aspect ratios, and contexts.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**镶嵌图像**：这幅图像展示了由镶嵌数据集图像组成的训练批次。镶嵌是训练过程中使用的一种技术，将多个图像合并成单个图像，以增加每个训练批次中对象和场景的多样性。这有助于提高模型对不同对象大小、长宽比和上下文的泛化能力。'
- en: The example showcases the variety and complexity of the images in the COCO dataset
    and the benefits of using mosaicing during the training process.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例展示了 COCO 数据集中图像的多样性和复杂性，以及在训练过程中使用镶嵌技术的好处。
- en: Citations and Acknowledgments
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引用和致谢
- en: 'If you use the COCO dataset in your research or development work, please cite
    the following paper:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在研究或开发工作中使用 COCO 数据集，请引用以下论文：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We would like to acknowledge the COCO Consortium for creating and maintaining
    this valuable resource for the computer vision community. For more information
    about the COCO dataset and its creators, visit the [COCO dataset website](https://cocodataset.org/#home).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望感谢 COCO 联合体为计算机视觉社区创建和维护这一宝贵资源。有关 COCO 数据集及其创建者的更多信息，请访问[COCO 数据集网站](https://cocodataset.org/#home)。
- en: FAQ
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题
- en: What is the COCO dataset and why is it important for computer vision?
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: COCO 数据集是什么，对计算机视觉的重要性在哪里？
- en: The [COCO dataset](https://cocodataset.org/#home) (Common Objects in Context)
    is a large-scale dataset used for object detection, segmentation, and captioning.
    It contains 330K images with detailed annotations for 80 object categories, making
    it essential for benchmarking and training computer vision models. Researchers
    use COCO due to its diverse categories and standardized evaluation metrics like
    mean Average Precision (mAP).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[COCO 数据集](https://cocodataset.org/#home)（上下文中的常见对象）是用于目标检测、分割和字幕的大规模数据集。它包含了
    33 万张图像，并对 80 种对象类别进行了详细的注释，因此对于基准测试和训练计算机视觉模型至关重要。研究人员使用 COCO 数据集，因为它包含多样的类别和标准化的评估指标，如平均精度（mAP）。'
- en: How can I train a YOLO model using the COCO dataset?
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何使用 COCO 数据集训练 YOLO 模型？
- en: 'To train a YOLOv8 model using the COCO dataset, you can use the following code
    snippets:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 COCO 数据集训练 YOLOv8 模型，可以使用以下代码片段：
- en: Train Example
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 训练示例
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Refer to the Training page for more details on available arguments.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 参考训练页面以获取更多关于可用参数的详细信息。
- en: What are the key features of the COCO dataset?
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: COCO 数据集的关键特征是什么？
- en: 'The COCO dataset includes:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: COCO 数据集包括：
- en: 330K images, with 200K annotated for object detection, segmentation, and captioning.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包括 330K 张图像，其中有 200K 张用于目标检测、分割和字幕。
- en: 80 object categories ranging from common items like cars and animals to specific
    ones like handbags and sports equipment.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包括 80 个物体类别，从常见物品如汽车和动物到特定物品如手提包和运动装备。
- en: Standardized evaluation metrics for object detection (mAP) and segmentation
    (mean Average Recall, mAR).
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化的目标检测评估指标（mAP）和分割评估指标（平均召回率 mAR）。
- en: '**Mosaicing** technique in training batches to enhance model generalization
    across various object sizes and contexts.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Mosaicing** 技术用于训练批次，以增强模型对各种物体尺寸和背景的泛化能力。'
- en: Where can I find pretrained YOLOv8 models trained on the COCO dataset?
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在哪里可以找到在 COCO 数据集上训练的预训练 YOLOv8 模型？
- en: 'Pretrained YOLOv8 models on the COCO dataset can be downloaded from the links
    provided in the documentation. Examples include:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在文档中提供的链接可以下载在 COCO 数据集上预训练的 YOLOv8 模型。例如：
- en: '[YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)'
- en: '[YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)'
- en: '[YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)'
- en: These models vary in size, mAP, and inference speed, providing options for different
    performance and resource requirements.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型在大小、mAP 和推理速度上各有不同，为不同性能和资源需求提供了选择。
- en: How is the COCO dataset structured and how do I use it?
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: COCO 数据集的结构及其使用方法？
- en: 'The COCO dataset is split into three subsets:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: COCO 数据集分为三个子集：
- en: '**Train2017**: 118K images for training.'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Train2017**: 用于训练的 118K 张图像。'
- en: '**Val2017**: 5K images for validation during training.'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Val2017**: 用于训练验证的 5K 张图像。'
- en: '**Test2017**: 20K images for benchmarking trained models. Results need to be
    submitted to the [COCO evaluation server](https://codalab.lisn.upsaclay.fr/competitions/7384)
    for performance evaluation.'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Test2017**: 用于评估训练模型的 20K 张图像。需将结果提交至[COCO 评估服务器](https://codalab.lisn.upsaclay.fr/competitions/7384)进行性能评估。'
- en: The dataset's YAML configuration file is available at [coco.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml),
    which defines paths, classes, and dataset details.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的 YAML 配置文件可在[coco.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml)找到，定义了路径、类别和数据集的详细信息。
