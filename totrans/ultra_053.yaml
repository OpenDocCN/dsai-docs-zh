- en: COCO-Seg Dataset
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: COCO-Seg 数据集
- en: 原文：[`docs.ultralytics.com/datasets/segment/coco/`](https://docs.ultralytics.com/datasets/segment/coco/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/datasets/segment/coco/`](https://docs.ultralytics.com/datasets/segment/coco/)
- en: The [COCO-Seg](https://cocodataset.org/#home) dataset, an extension of the COCO
    (Common Objects in Context) dataset, is specially designed to aid research in
    object instance segmentation. It uses the same images as COCO but introduces more
    detailed segmentation annotations. This dataset is a crucial resource for researchers
    and developers working on instance segmentation tasks, especially for training
    YOLO models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[COCO-Seg](https://cocodataset.org/#home) 数据集是 COCO（上下文中的常见对象）数据集的扩展，专门设计用于帮助对象实例分割的研究。它使用与
    COCO 相同的图像，但引入了更详细的分割注释。该数据集是研究人员和开发人员在实例分割任务中，特别是在训练 YOLO 模型时的重要资源。'
- en: COCO-Seg Pretrained Models
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: COCO-Seg 预训练模型
- en: '| Model | size ^((pixels)) | mAP^(box 50-95) | mAP^(mask 50-95) | Speed ^(CPU
    ONNX'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '| 模型 | 大小 ^((像素)) | mAP^(框 50-95) | mAP^(掩码 50-95) | 速度 ^(CPU ONNX'
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: (毫秒)) | 速度 ^(A100 TensorRT
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: (毫秒)) | 参数 ^((M)) | FLOPs ^((B)) |
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| [YOLOv8n-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-seg.pt)
    | 640 | 36.7 | 30.5 | 96.1 | 1.21 | 3.4 | 12.6 |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8n-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-seg.pt)
    | 640 | 36.7 | 30.5 | 96.1 | 1.21 | 3.4 | 12.6 |'
- en: '| [YOLOv8s-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-seg.pt)
    | 640 | 44.6 | 36.8 | 155.7 | 1.47 | 11.8 | 42.6 |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8s-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-seg.pt)
    | 640 | 44.6 | 36.8 | 155.7 | 1.47 | 11.8 | 42.6 |'
- en: '| [YOLOv8m-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-seg.pt)
    | 640 | 49.9 | 40.8 | 317.0 | 2.18 | 27.3 | 110.2 |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8m-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-seg.pt)
    | 640 | 49.9 | 40.8 | 317.0 | 2.18 | 27.3 | 110.2 |'
- en: '| [YOLOv8l-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-seg.pt)
    | 640 | 52.3 | 42.6 | 572.4 | 2.79 | 46.0 | 220.5 |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8l-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-seg.pt)
    | 640 | 52.3 | 42.6 | 572.4 | 2.79 | 46.0 | 220.5 |'
- en: '| [YOLOv8x-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-seg.pt)
    | 640 | 53.4 | 43.4 | 712.1 | 4.02 | 71.8 | 344.1 |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8x-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-seg.pt)
    | 640 | 53.4 | 43.4 | 712.1 | 4.02 | 71.8 | 344.1 |'
- en: Key Features
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关键特性
- en: COCO-Seg retains the original 330K images from COCO.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: COCO-Seg 保留了 COCO 的原始330K张图像。
- en: The dataset consists of the same 80 object categories found in the original
    COCO dataset.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集包含与原始 COCO 数据集相同的80个对象类别。
- en: Annotations now include more detailed instance segmentation masks for each object
    in the images.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注释现在包括每个图像中每个对象的更详细的实例分割掩码。
- en: COCO-Seg provides standardized evaluation metrics like mean Average Precision
    (mAP) for object detection, and mean Average Recall (mAR) for instance segmentation
    tasks, enabling effective comparison of model performance.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: COCO-Seg 提供标准化的评估指标，如对象检测的平均精度（mAP）和实例分割任务的平均召回率（mAR），以便有效比较模型性能。
- en: Dataset Structure
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集结构
- en: 'The COCO-Seg dataset is partitioned into three subsets:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: COCO-Seg 数据集分为三个子集：
- en: '**Train2017**: This subset contains 118K images for training instance segmentation
    models.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Train2017**：该子集包含118K张用于训练实例分割模型的图像。'
- en: '**Val2017**: This subset includes 5K images used for validation purposes during
    model training.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Val2017**：该子集包括5K张用于模型训练期间验证目的的图像。'
- en: '**Test2017**: This subset encompasses 20K images used for testing and benchmarking
    the trained models. Ground truth annotations for this subset are not publicly
    available, and the results are submitted to the [COCO evaluation server](https://codalab.lisn.upsaclay.fr/competitions/7383)
    for performance evaluation.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Test2017**：该子集包含20K张用于测试和基准训练模型的图像。该子集的真实注释未公开，结果提交至 [COCO 评估服务器](https://codalab.lisn.upsaclay.fr/competitions/7383)
    进行性能评估。'
- en: Applications
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用
- en: COCO-Seg is widely used for training and evaluating deep learning models in
    instance segmentation, such as the YOLO models. The large number of annotated
    images, the diversity of object categories, and the standardized evaluation metrics
    make it an indispensable resource for computer vision researchers and practitioners.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: COCO-Seg 广泛用于训练和评估实例分割中的深度学习模型，如 YOLO 模型。大量的注释图像、对象类别的多样性以及标准化的评估指标使其成为计算机视觉研究人员和从业者不可或缺的资源。
- en: Dataset YAML
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集 YAML
- en: A YAML (Yet Another Markup Language) file is used to define the dataset configuration.
    It contains information about the dataset's paths, classes, and other relevant
    information. In the case of the COCO-Seg dataset, the `coco.yaml` file is maintained
    at [`github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用YAML（Yet Another Markup Language）文件定义数据集配置。它包含有关数据集路径、类别和其他相关信息的信息。在COCO-Seg数据集的情况下，`coco.yaml`文件位于[`github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml)。
- en: ultralytics/cfg/datasets/coco.yaml
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ultralytics/cfg/datasets/coco.yaml
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Usage
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用法
- en: To train a YOLOv8n-seg model on the COCO-Seg dataset for 100 epochs with an
    image size of 640, you can use the following code snippets. For a comprehensive
    list of available arguments, refer to the model Training page.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要在COCO-Seg数据集上训练100个epochs、图像大小为640的YOLOv8n-seg模型，您可以使用以下代码片段。有关可用参数的详细列表，请参考模型训练页面。
- en: Train Example
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 训练示例
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Sample Images and Annotations
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例图像和注释
- en: 'COCO-Seg, like its predecessor COCO, contains a diverse set of images with
    various object categories and complex scenes. However, COCO-Seg introduces more
    detailed instance segmentation masks for each object in the images. Here are some
    examples of images from the dataset, along with their corresponding instance segmentation
    masks:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 与其前身COCO一样，COCO-Seg包含各种对象类别和复杂场景的图像。然而，COCO-Seg为图像中的每个对象引入了更详细的实例分割蒙版。以下是数据集中一些图像的示例，以及它们对应的实例分割蒙版：
- en: '![Dataset sample image](img/bde4040cf8681815abc7d465309f9ba4.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![数据集示例图像](img/bde4040cf8681815abc7d465309f9ba4.png)'
- en: '**Mosaiced Image**: This image demonstrates a training batch composed of mosaiced
    dataset images. Mosaicing is a technique used during training that combines multiple
    images into a single image to increase the variety of objects and scenes within
    each training batch. This aids the model''s ability to generalize to different
    object sizes, aspect ratios, and contexts.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拼接图像**：这张图片展示了由拼接数据集图像组成的训练批次。拼接是一种在训练过程中将多个图像合并成单个图像的技术，以增加每个训练批次中对象和场景的多样性。这有助于模型泛化到不同的对象大小、长宽比和上下文。'
- en: The example showcases the variety and complexity of the images in the COCO-Seg
    dataset and the benefits of using mosaicing during the training process.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例展示了COCO-Seg数据集中图像的多样性和复杂性，以及在训练过程中使用拼接的好处。
- en: Citations and Acknowledgments
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引用和致谢
- en: 'If you use the COCO-Seg dataset in your research or development work, please
    cite the original COCO paper and acknowledge the extension to COCO-Seg:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在研究或开发工作中使用COCO-Seg数据集，请引用原始COCO论文，并承认其扩展到COCO-Seg：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We extend our thanks to the COCO Consortium for creating and maintaining this
    invaluable resource for the computer vision community. For more information about
    the COCO dataset and its creators, visit the [COCO dataset website](https://cocodataset.org/#home).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢COCO联盟为计算机视觉社区创建和维护这一宝贵资源。有关COCO数据集及其创建者的更多信息，请访问[COCO数据集网站](https://cocodataset.org/#home)。
- en: FAQ
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题解答
- en: What is the COCO-Seg dataset and how does it differ from the original COCO dataset?
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: COCO-Seg数据集是什么，与原始COCO数据集有何不同？
- en: The [COCO-Seg](https://cocodataset.org/#home) dataset is an extension of the
    original COCO (Common Objects in Context) dataset, specifically designed for instance
    segmentation tasks. While it uses the same images as the COCO dataset, COCO-Seg
    includes more detailed segmentation annotations, making it a powerful resource
    for researchers and developers focusing on object instance segmentation.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[COCO-Seg](https://cocodataset.org/#home)数据集是原始COCO（Context中的公共对象）数据集的扩展，专为实例分割任务设计。虽然使用与COCO数据集相同的图像，但COCO-Seg包括更详细的实例分割标注，使其成为专注于对象实例分割的研究人员和开发人员的强大资源。'
- en: How can I train a YOLOv8 model using the COCO-Seg dataset?
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何使用COCO-Seg数据集训练YOLOv8模型？
- en: To train a YOLOv8n-seg model on the COCO-Seg dataset for 100 epochs with an
    image size of 640, you can use the following code snippets. For a detailed list
    of available arguments, refer to the model Training page.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要在COCO-Seg数据集上使用大小为640的图像，训练100个epochs的YOLOv8n-seg模型，您可以使用以下代码片段。有关可用参数的详细列表，请参考模型训练页面。
- en: Train Example
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 训练示例
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: What are the key features of the COCO-Seg dataset?
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: COCO-Seg数据集的关键特点是什么？
- en: 'The COCO-Seg dataset includes several key features:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: COCO-Seg数据集包括几个关键特点：
- en: Retains the original 330K images from the COCO dataset.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保留了COCO数据集的原始330K张图像。
- en: Annotates the same 80 object categories found in the original COCO.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注释了原始COCO中发现的相同80个对象类别。
- en: Provides more detailed instance segmentation masks for each object.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为每个对象提供更详细的实例分割掩模。
- en: Uses standardized evaluation metrics such as mean Average Precision (mAP) for
    object detection and mean Average Recall (mAR) for instance segmentation tasks.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用标准化的评估指标，如物体检测的平均精度（mAP）和实例分割任务的平均召回率（mAR）。
- en: What pretrained models are available for COCO-Seg, and what are their performance
    metrics?
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 有关COCO-Seg的预训练模型及其性能指标是什么？
- en: 'The COCO-Seg dataset supports multiple pretrained YOLOv8 segmentation models
    with varying performance metrics. Here''s a summary of the available models and
    their key metrics:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: COCO-Seg数据集支持多个预训练的YOLOv8分割模型，具有不同的性能指标。以下是可用模型及其关键指标的摘要：
- en: '| Model | size ^((pixels)) | mAP^(box 50-95) | mAP^(mask 50-95) | Speed ^(CPU
    ONNX'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '| 模型 | 大小 ^((像素)) | mAP^(box 50-95) | mAP^(mask 50-95) | 速度 ^(CPU ONNX'
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: (ms)) | 速度 ^(A100 TensorRT
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: (ms)) | 参数 ^((M)) | FLOPs ^((B)) |
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| [YOLOv8n-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-seg.pt)
    | 640 | 36.7 | 30.5 | 96.1 | 1.21 | 3.4 | 12.6 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8n-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-seg.pt)
    | 640 | 36.7 | 30.5 | 96.1 | 1.21 | 3.4 | 12.6 |'
- en: '| [YOLOv8s-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-seg.pt)
    | 640 | 44.6 | 36.8 | 155.7 | 1.47 | 11.8 | 42.6 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8s-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-seg.pt)
    | 640 | 44.6 | 36.8 | 155.7 | 1.47 | 11.8 | 42.6 |'
- en: '| [YOLOv8m-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-seg.pt)
    | 640 | 49.9 | 40.8 | 317.0 | 2.18 | 27.3 | 110.2 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8m-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-seg.pt)
    | 640 | 49.9 | 40.8 | 317.0 | 2.18 | 27.3 | 110.2 |'
- en: '| [YOLOv8l-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-seg.pt)
    | 640 | 52.3 | 42.6 | 572.4 | 2.79 | 46.0 | 220.5 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8l-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-seg.pt)
    | 640 | 52.3 | 42.6 | 572.4 | 2.79 | 46.0 | 220.5 |'
- en: '| [YOLOv8x-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-seg.pt)
    | 640 | 53.4 | 43.4 | 712.1 | 4.02 | 71.8 | 344.1 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8x-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-seg.pt)
    | 640 | 53.4 | 43.4 | 712.1 | 4.02 | 71.8 | 344.1 |'
- en: How is the COCO-Seg dataset structured and what subsets does it contain?
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: COCO-Seg数据集的结构是如何的，它包含哪些子集？
- en: 'The COCO-Seg dataset is partitioned into three subsets for specific training
    and evaluation needs:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: COCO-Seg数据集被划分为三个子集，用于特定的训练和评估需求：
- en: '**Train2017**: Contains 118K images used primarily for training instance segmentation
    models.'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Train2017**: 包含118K张图像，主要用于训练实例分割模型。'
- en: '**Val2017**: Comprises 5K images utilized for validation during the training
    process.'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Val2017**: 包括5K张图像，在训练过程中用于验证。'
- en: '**Test2017**: Encompasses 20K images reserved for testing and benchmarking
    trained models. Note that ground truth annotations for this subset are not publicly
    available, and performance results are submitted to the [COCO evaluation server](https://codalab.lisn.upsaclay.fr/competitions/7383)
    for assessment.'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Test2017**: 包括20K张图像，专门用于测试和基准测试已训练模型的性能。请注意，此子集的地面实况注释不公开提供，性能结果提交至[COCO评估服务器](https://codalab.lisn.upsaclay.fr/competitions/7383)进行评估。'
