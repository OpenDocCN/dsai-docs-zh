- en: Fast Segment Anything Model (FastSAM)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Fast Segment Anything Model (FastSAM)
- en: 原文：[`docs.ultralytics.com/models/fast-sam/`](https://docs.ultralytics.com/models/fast-sam/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/models/fast-sam/`](https://docs.ultralytics.com/models/fast-sam/)
- en: The Fast Segment Anything Model (FastSAM) is a novel, real-time CNN-based solution
    for the Segment Anything task. This task is designed to segment any object within
    an image based on various possible user interaction prompts. FastSAM significantly
    reduces computational demands while maintaining competitive performance, making
    it a practical choice for a variety of vision tasks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Fast Segment Anything Model (FastSAM) 是一种新颖的基于实时 CNN 的解决方案，用于任意分段任务。该任务旨在基于各种可能的用户交互提示对图像中的任意对象进行分割。FastSAM
    显著降低了计算需求，同时保持了竞争性能，使其成为各种视觉任务的实用选择。
- en: '[`www.youtube.com/embed/F7db-EHhxss`](https://www.youtube.com/embed/F7db-EHhxss)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[`www.youtube.com/embed/F7db-EHhxss`](https://www.youtube.com/embed/F7db-EHhxss)'
- en: '**Watch:** Object Tracking using FastSAM with Ultralytics'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**观看：** 使用 FastSAM 进行对象跟踪与 Ultralytics'
- en: Model Architecture
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型架构
- en: '![Fast Segment Anything Model (FastSAM) architecture overview](img/d6a00a050d052df768636ead7f971185.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![Fast Segment Anything Model (FastSAM) 架构概述](img/d6a00a050d052df768636ead7f971185.png)'
- en: Overview
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'FastSAM is designed to address the limitations of the Segment Anything Model
    (SAM), a heavy Transformer model with substantial computational resource requirements.
    The FastSAM decouples the segment anything task into two sequential stages: all-instance
    segmentation and prompt-guided selection. The first stage uses YOLOv8-seg to produce
    the segmentation masks of all instances in the image. In the second stage, it
    outputs the region-of-interest corresponding to the prompt.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: FastSAM 的设计旨在解决 Segment Anything Model (SAM) 的局限性，SAM 是一个具有重大计算资源要求的沉重 Transformer
    模型。FastSAM 将任意分段任务解耦为两个连续阶段：所有实例分割和提示引导选择。第一阶段使用 YOLOv8-seg 生成图像中所有实例的分割蒙版。在第二阶段，它输出与提示相对应的感兴趣区域。
- en: Key Features
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关键特点
- en: '**Real-time Solution:** By leveraging the computational efficiency of CNNs,
    FastSAM provides a real-time solution for the segment anything task, making it
    valuable for industrial applications that require quick results.'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实时解决方案：** 利用 CNN 的计算效率，FastSAM 提供了针对任意分段任务的实时解决方案，对于需要快速结果的工业应用非常有价值。'
- en: '**Efficiency and Performance:** FastSAM offers a significant reduction in computational
    and resource demands without compromising on performance quality. It achieves
    comparable performance to SAM but with drastically reduced computational resources,
    enabling real-time application.'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**效率和性能：** FastSAM 在不影响性能质量的前提下，显著减少了计算和资源需求。它实现了与 SAM 相当的性能，但计算资源大大减少，能够实时应用。'
- en: '**Prompt-guided Segmentation:** FastSAM can segment any object within an image
    guided by various possible user interaction prompts, providing flexibility and
    adaptability in different scenarios.'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提示引导分割：** FastSAM 可以根据各种可能的用户交互提示分割图像中的任意对象，在不同场景中提供灵活性和适应性。'
- en: '**Based on YOLOv8-seg:** FastSAM is based on YOLOv8-seg, an object detector
    equipped with an instance segmentation branch. This allows it to effectively produce
    the segmentation masks of all instances in an image.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**基于 YOLOv8-seg：** FastSAM 基于 YOLOv8-seg，这是一个装备有实例分割分支的物体检测器。这使得它能够有效地生成图像中所有实例的分割蒙版。'
- en: '**Competitive Results on Benchmarks:** On the object proposal task on MS COCO,
    FastSAM achieves high scores at a significantly faster speed than SAM on a single
    NVIDIA RTX 3090, demonstrating its efficiency and capability.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在基准测试中的竞争结果：** 在单个 NVIDIA RTX 3090 上，FastSAM 在 MS COCO 的对象提议任务上以显著更快的速度取得了高分，比
    SAM 更有效率和能力强大。'
- en: '**Practical Applications:** The proposed approach provides a new, practical
    solution for a large number of vision tasks at a really high speed, tens or hundreds
    of times faster than current methods.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实际应用：** 所提出的方法以极高的速度为大量视觉任务提供了新的实用解决方案，比当前方法快十倍甚至百倍。'
- en: '**Model Compression Feasibility:** FastSAM demonstrates the feasibility of
    a path that can significantly reduce the computational effort by introducing an
    artificial prior to the structure, thus opening new possibilities for large model
    architecture for general vision tasks.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型压缩可行性：** FastSAM 展示了通过引入结构人工先验显著减少计算工作的路径的可行性，从而为一般视觉任务的大型模型架构开辟了新的可能性。'
- en: Available Models, Supported Tasks, and Operating Modes
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可用模型、支持任务和操作模式
- en: This table presents the available models with their specific pre-trained weights,
    the tasks they support, and their compatibility with different operating modes
    like Inference, Validation, Training, and Export, indicated by ✅ emojis for supported
    modes and ❌ emojis for unsupported modes.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 此表格显示了可用模型及其特定的预训练权重，它们支持的任务以及它们与不同操作模式（推断、验证、训练和导出）的兼容性。支持的模式用✅表示，不支持的模式用❌表示。
- en: '| Model Type | Pre-trained Weights | Tasks Supported | Inference | Validation
    | Training | Export |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 模型类型 | 预训练权重 | 支持的任务 | 推断 | 验证 | 训练 | 导出 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| FastSAM-s | [FastSAM-s.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/FastSAM-s.pt)
    | Instance Segmentation | ✅ | ❌ | ❌ | ✅ |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| FastSAM-s | [FastSAM-s.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/FastSAM-s.pt)
    | 实例分割 | ✅ | ❌ | ❌ | ✅ |'
- en: '| FastSAM-x | [FastSAM-x.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/FastSAM-x.pt)
    | Instance Segmentation | ✅ | ❌ | ❌ | ✅ |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| FastSAM-x | [FastSAM-x.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/FastSAM-x.pt)
    | 实例分割 | ✅ | ❌ | ❌ | ✅ |'
- en: Usage Examples
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用示例
- en: The FastSAM models are easy to integrate into your Python applications. Ultralytics
    provides user-friendly Python API and CLI commands to streamline development.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: FastSAM模型易于集成到您的Python应用程序中。Ultralytics提供了用户友好的Python API和CLI命令，以简化开发流程。
- en: Predict Usage
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测用法
- en: 'To perform object detection on an image, use the `predict` method as shown
    below:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要在图像上执行目标检测，使用如下所示的`predict`方法：
- en: Example
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This snippet demonstrates the simplicity of loading a pre-trained model and
    running a prediction on an image.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码段演示了加载预训练模型并在图像上运行预测的简易性。
- en: FastSAMPredictor example
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: FastSAMPredictor示例
- en: This way you can run inference on image and get all the segment `results` once
    and run prompts inference multiple times without running inference multiple times.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，您可以在图像上运行推断并一次性获取所有段`results`，而无需多次运行推断。
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: All the returned `results` in above examples are Results object which allows
    access predicted masks and source image easily.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例中所有返回的`results`都是Results对象，可以轻松访问预测的掩模和源图像。
- en: Val Usage
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 验证用法
- en: 'Validation of the model on a dataset can be done as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集上验证模型可以按以下步骤完成：
- en: Example
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Please note that FastSAM only supports detection and segmentation of a single
    class of object. This means it will recognize and segment all objects as the same
    class. Therefore, when preparing the dataset, you need to convert all object category
    IDs to 0.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，FastSAM仅支持单类对象的检测和分割。这意味着它将所有对象识别并分割为相同的类别。因此，在准备数据集时，需要将所有对象的类别ID转换为0。
- en: Track Usage
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跟踪用法
- en: 'To perform object tracking on an image, use the `track` method as shown below:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要在图像上执行目标跟踪，使用如下所示的`track`方法：
- en: Example
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: FastSAM official Usage
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FastSAM官方用法
- en: 'FastSAM is also available directly from the [`github.com/CASIA-IVA-Lab/FastSAM`](https://github.com/CASIA-IVA-Lab/FastSAM)
    repository. Here is a brief overview of the typical steps you might take to use
    FastSAM:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: FastSAM还可以直接从[`github.com/CASIA-IVA-Lab/FastSAM`](https://github.com/CASIA-IVA-Lab/FastSAM)存储库获取。这里简要介绍了使用FastSAM的典型步骤：
- en: Installation
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装
- en: 'Clone the FastSAM repository:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆FastSAM存储库：
- en: '[PRE7]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Create and activate a Conda environment with Python 3.9:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建并激活一个带有Python 3.9的Conda环境：
- en: '[PRE8]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Navigate to the cloned repository and install the required packages:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航至克隆的存储库并安装所需的包：
- en: '[PRE9]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Install the CLIP model:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装CLIP模型：
- en: '[PRE10]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Example Usage
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用法示例
- en: Download a [model checkpoint](https://drive.google.com/file/d/1m1sjY4ihXBU1fZXdQ-Xdj-mDltW-2Rqv/view?usp=sharing).
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载[模型检查点](https://drive.google.com/file/d/1m1sjY4ihXBU1fZXdQ-Xdj-mDltW-2Rqv/view?usp=sharing)。
- en: 'Use FastSAM for inference. Example commands:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用FastSAM进行推断。示例命令：
- en: 'Segment everything in an image:'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在图像中分割所有内容：
- en: '[PRE11]'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Segment specific objects using text prompt:'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用文本提示分割特定对象：
- en: '[PRE12]'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Segment objects within a bounding box (provide box coordinates in xywh format):'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在边界框内分割对象（以xywh格式提供框坐标）：
- en: '[PRE13]'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Segment objects near specific points:'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在特定点附近分割对象：
- en: '[PRE14]'
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Additionally, you can try FastSAM through a [Colab demo](https://colab.research.google.com/drive/1oX14f6IneGGw612WgVlAiy91UHwFAvr9?usp=sharing)
    or on the [HuggingFace web demo](https://huggingface.co/spaces/An-619/FastSAM)
    for a visual experience.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您可以通过[Colab演示](https://colab.research.google.com/drive/1oX14f6IneGGw612WgVlAiy91UHwFAvr9?usp=sharing)或[HuggingFace网络演示](https://huggingface.co/spaces/An-619/FastSAM)来尝试FastSAM，获得视觉体验。
- en: Citations and Acknowledgements
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引文和致谢
- en: 'We would like to acknowledge the FastSAM authors for their significant contributions
    in the field of real-time instance segmentation:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢FastSAM的作者在实时实例分割领域做出的重要贡献：
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The original FastSAM paper can be found on [arXiv](https://arxiv.org/abs/2306.12156).
    The authors have made their work publicly available, and the codebase can be accessed
    on [GitHub](https://github.com/CASIA-IVA-Lab/FastSAM). We appreciate their efforts
    in advancing the field and making their work accessible to the broader community.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 最初的FastSAM论文可以在[arXiv](https://arxiv.org/abs/2306.12156)上找到。作者已经公开了他们的工作，并且代码库可以在[GitHub](https://github.com/CASIA-IVA-Lab/FastSAM)上访问。我们感谢他们在推动该领域发展并使其工作对更广泛的社区可用的努力。
- en: FAQ
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题解答（FAQ）
- en: What is FastSAM and how does it differ from SAM?
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FastSAM是什么，与SAM有何不同？
- en: 'FastSAM, short for Fast Segment Anything Model, is a real-time convolutional
    neural network (CNN)-based solution designed to reduce computational demands while
    maintaining high performance in object segmentation tasks. Unlike the Segment
    Anything Model (SAM), which uses a heavier Transformer-based architecture, FastSAM
    leverages Ultralytics YOLOv8-seg for efficient instance segmentation in two stages:
    all-instance segmentation followed by prompt-guided selection.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: FastSAM，即快速任意物体模型，是基于实时卷积神经网络（CNN）的解决方案，旨在减少计算需求，同时在物体分割任务中保持高性能。与使用更重的基于Transformer的架构的Segment
    Anything Model（SAM）不同，FastSAM利用Ultralytics YOLOv8-seg在两个阶段进行高效实例分割：全对象分割，然后是提示引导选择。
- en: How does FastSAM achieve real-time segmentation performance?
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FastSAM如何实现实时分割性能？
- en: FastSAM achieves real-time segmentation by decoupling the segmentation task
    into all-instance segmentation with YOLOv8-seg and prompt-guided selection stages.
    By utilizing the computational efficiency of CNNs, FastSAM offers significant
    reductions in computational and resource demands while maintaining competitive
    performance. This dual-stage approach enables FastSAM to deliver fast and efficient
    segmentation suitable for applications requiring quick results.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: FastSAM通过将分割任务解耦成全对象分割和提示引导选择两个阶段实现了实时分割。利用CNN的计算效率，FastSAM在减少计算和资源需求方面取得了显著成效，同时保持竞争性能。这种双阶段方法使FastSAM能够提供适用于需要快速结果的应用的快速高效的分割。
- en: What are the practical applications of FastSAM?
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FastSAM的实际应用有哪些？
- en: 'FastSAM is practical for a variety of computer vision tasks that require real-time
    segmentation performance. Applications include:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: FastSAM非常适用于需要实时分割性能的各种计算机视觉任务。应用包括：
- en: Industrial automation for quality control and assurance
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于质量控制和保证的工业自动化
- en: Real-time video analysis for security and surveillance
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于安全监控和监视的实时视频分析
- en: Autonomous vehicles for object detection and segmentation
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于物体检测和分割的自动驾驶车辆
- en: Medical imaging for precise and quick segmentation tasks
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于精确和快速分割任务的医学影像
- en: Its ability to handle various user interaction prompts makes FastSAM adaptable
    and flexible for diverse scenarios.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 其处理各种用户交互提示的能力使FastSAM适应性强，能够在各种情景下灵活应用。
- en: How do I use the FastSAM model for inference in Python?
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何在Python中使用FastSAM模型进行推理？
- en: 'To use FastSAM for inference in Python, you can follow the example below:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Python中使用FastSAM进行推理，可以参考以下示例：
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: For more details on inference methods, check the Predict Usage section of the
    documentation.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 有关推理方法的详细信息，请查看文档的预测使用部分。
- en: What types of prompts does FastSAM support for segmentation tasks?
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FastSAM支持哪些提示类型用于分割任务？
- en: 'FastSAM supports multiple prompt types for guiding the segmentation tasks:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: FastSAM支持多种提示类型来引导分割任务：
- en: '**Everything Prompt**: Generates segmentation for all visible objects.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全对象提示**：为所有可见对象生成分割结果。'
- en: '**Bounding Box (BBox) Prompt**: Segments objects within a specified bounding
    box.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**边界框（BBox）提示**：在指定的边界框内分割对象。'
- en: '**Text Prompt**: Uses a descriptive text to segment objects matching the description.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本提示**：使用描述性文本来分割与描述匹配的对象。'
- en: '**Point Prompt**: Segments objects near specific user-defined points.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**点提示**：根据用户定义的特定点附近分割对象。'
- en: This flexibility allows FastSAM to adapt to a wide range of user interaction
    scenarios, enhancing its utility across different applications. For more information
    on using these prompts, refer to the Key Features section.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这种灵活性使FastSAM能够适应广泛的用户交互场景，增强其在不同应用中的实用性。有关使用这些提示的更多信息，请参阅关键特性部分。
