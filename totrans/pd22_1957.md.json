["```py\nIn [1]: from pandas.tseries.offsets import CustomBusinessHour\n\nIn [2]: from pandas.tseries.holiday import USFederalHolidayCalendar\n\nIn [3]: bhour_us = CustomBusinessHour(calendar=USFederalHolidayCalendar()) \n```", "```py\nIn [4]: import datetime\n\nIn [5]: dt = datetime.datetime(2014, 1, 17, 15)\n\nIn [6]: dt + bhour_us\nOut[6]: Timestamp('2014-01-17 16:00:00') \n```", "```py\nIn [7]: dt + bhour_us * 2\nOut[7]: Timestamp('2014-01-20 09:00:00') \n```", "```py\nIn [8]: df = pd.DataFrame({\"A\": [1] * 20 + [2] * 12 + [3] * 8, \"B\": np.arange(40)})\n\nIn [9]: df\nOut[9]: \n A   B\n0   1   0\n1   1   1\n2   1   2\n3   1   3\n4   1   4\n.. ..  ..\n35  3  35\n36  3  36\n37  3  37\n38  3  38\n39  3  39\n\n[40 rows x 2 columns] \n```", "```py\nIn [1]: df.groupby(\"A\").apply(lambda x: x.rolling(4).B.mean())\nOut[1]:\nA\n1  0      NaN\n 1      NaN\n 2      NaN\n 3      1.5\n 4      2.5\n 5      3.5\n 6      4.5\n 7      5.5\n 8      6.5\n 9      7.5\n 10     8.5\n 11     9.5\n 12    10.5\n 13    11.5\n 14    12.5\n 15    13.5\n 16    14.5\n 17    15.5\n 18    16.5\n 19    17.5\n2  20     NaN\n 21     NaN\n 22     NaN\n 23    21.5\n 24    22.5\n 25    23.5\n 26    24.5\n 27    25.5\n 28    26.5\n 29    27.5\n 30    28.5\n 31    29.5\n3  32     NaN\n 33     NaN\n 34     NaN\n 35    33.5\n 36    34.5\n 37    35.5\n 38    36.5\n 39    37.5\nName: B, dtype: float64 \n```", "```py\nIn [10]: df.groupby(\"A\").rolling(4).B.mean()\nOut[10]: \nA \n1  0      NaN\n 1      NaN\n 2      NaN\n 3      1.5\n 4      2.5\n ... \n3  35    33.5\n 36    34.5\n 37    35.5\n 38    36.5\n 39    37.5\nName: B, Length: 40, dtype: float64 \n```", "```py\nIn [11]: df = pd.DataFrame(\n ....:    {\n ....:        \"date\": pd.date_range(start=\"2016-01-01\", periods=4, freq=\"W\"),\n ....:        \"group\": [1, 1, 2, 2],\n ....:        \"val\": [5, 6, 7, 8],\n ....:    }\n ....: ).set_index(\"date\")\n ....: \n\nIn [12]: df\nOut[12]: \n group  val\ndate \n2016-01-03      1    5\n2016-01-10      1    6\n2016-01-17      2    7\n2016-01-24      2    8\n\n[4 rows x 2 columns] \n```", "```py\nIn[1]: df.groupby(\"group\").apply(lambda x: x.resample(\"1D\").ffill())\nOut[1]:\n                  group  val\ngroup date\n1     2016-01-03      1    5\n      2016-01-04      1    5\n      2016-01-05      1    5\n      2016-01-06      1    5\n      2016-01-07      1    5\n      2016-01-08      1    5\n      2016-01-09      1    5\n      2016-01-10      1    6\n2     2016-01-17      2    7\n      2016-01-18      2    7\n      2016-01-19      2    7\n      2016-01-20      2    7\n      2016-01-21      2    7\n      2016-01-22      2    7\n      2016-01-23      2    7\n      2016-01-24      2    8 \n```", "```py\nIn[1]: df.groupby(\"group\").resample(\"1D\").ffill()\nOut[1]:\n                  group  val\ngroup date\n1     2016-01-03      1    5\n      2016-01-04      1    5\n      2016-01-05      1    5\n      2016-01-06      1    5\n      2016-01-07      1    5\n      2016-01-08      1    5\n      2016-01-09      1    5\n      2016-01-10      1    6\n2     2016-01-17      2    7\n      2016-01-18      2    7\n      2016-01-19      2    7\n      2016-01-20      2    7\n      2016-01-21      2    7\n      2016-01-22      2    7\n      2016-01-23      2    7\n      2016-01-24      2    8 \n```", "```py\nIn [13]: df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6], \"C\": [7, 8, 9]})\n\nIn [14]: df.where(lambda x: x > 4, lambda x: x + 10)\nOut[14]: \n A   B  C\n0  11  14  7\n1  12   5  8\n2  13   6  9\n\n[3 rows x 3 columns] \n```", "```py\n# callable returns bool indexer\nIn [15]: df.loc[lambda x: x.A >= 2, lambda x: x.sum() > 10]\nOut[15]: \n B  C\n1  5  8\n2  6  9\n\n[2 rows x 2 columns]\n\n# callable returns list of labels\nIn [16]: df.loc[lambda x: [1, 2], lambda x: [\"A\", \"B\"]]\nOut[16]: \n A  B\n1  2  5\n2  3  6\n\n[2 rows x 2 columns] \n```", "```py\nIn [17]: df[lambda x: \"A\"]\nOut[17]: \n0    1\n1    2\n2    3\nName: A, Length: 3, dtype: int64 \n```", "```py\nIn [18]: bb = pd.read_csv(\"data/baseball.csv\", index_col=\"id\")\n\nIn [19]: (bb.groupby([\"year\", \"team\"]).sum(numeric_only=True).loc[lambda df: df.r > 100])\nOut[19]: \n stint    g    ab    r    h  X2b  ...     so   ibb   hbp    sh    sf  gidp\nyear team                                   ... \n2007 CIN       6  379   745  101  203   35  ...  127.0  14.0   1.0   1.0  15.0  18.0\n DET       5  301  1062  162  283   54  ...  176.0   3.0  10.0   4.0   8.0  28.0\n HOU       4  311   926  109  218   47  ...  212.0   3.0   9.0  16.0   6.0  17.0\n LAN      11  413  1021  153  293   61  ...  141.0   8.0   9.0   3.0   8.0  29.0\n NYN      13  622  1854  240  509  101  ...  310.0  24.0  23.0  18.0  15.0  48.0\n SFN       5  482  1305  198  337   67  ...  188.0  51.0   8.0  16.0   6.0  41.0\n TEX       2  198   729  115  200   40  ...  140.0   4.0   5.0   2.0   8.0  16.0\n TOR       4  459  1408  187  378   96  ...  265.0  16.0  12.0   4.0  16.0  38.0\n\n[8 rows x 18 columns] \n```", "```py\nIn [20]: dft2 = pd.DataFrame(\n ....:    np.random.randn(20, 1),\n ....:    columns=[\"A\"],\n ....:    index=pd.MultiIndex.from_product(\n ....:        [pd.date_range(\"20130101\", periods=10, freq=\"12H\"), [\"a\", \"b\"]]\n ....:    ),\n ....: )\n ....:\n\nIn [21]: dft2\nOut[21]:\n A\n2013-01-01 00:00:00 a  0.469112\n b -0.282863\n2013-01-01 12:00:00 a -1.509059\n b -1.135632\n2013-01-02 00:00:00 a  1.212112\n...                         ...\n2013-01-04 12:00:00 b  0.271860\n2013-01-05 00:00:00 a -0.424972\n b  0.567020\n2013-01-05 12:00:00 a  0.276232\n b -1.087401\n\n[20 rows x 1 columns]\n\nIn [22]: dft2.loc[\"2013-01-05\"]\nOut[22]:\n A\n2013-01-05 00:00:00 a -0.424972\n b  0.567020\n2013-01-05 12:00:00 a  0.276232\n b -1.087401\n\n[4 rows x 1 columns] \n```", "```py\nIn [26]: idx = pd.IndexSlice\n\nIn [27]: dft2 = dft2.swaplevel(0, 1).sort_index()\n\nIn [28]: dft2\nOut[28]:\n A\na 2013-01-01 00:00:00  0.469112\n 2013-01-01 12:00:00 -1.509059\n 2013-01-02 00:00:00  1.212112\n 2013-01-02 12:00:00  0.119209\n 2013-01-03 00:00:00 -0.861849\n...                         ...\nb 2013-01-03 12:00:00  1.071804\n 2013-01-04 00:00:00 -0.706771\n 2013-01-04 12:00:00  0.271860\n 2013-01-05 00:00:00  0.567020\n 2013-01-05 12:00:00 -1.087401\n\n[20 rows x 1 columns]\n\nIn [29]: dft2.loc[idx[:, \"2013-01-05\"], :]\nOut[29]:\n A\na 2013-01-05 00:00:00 -0.424972\n 2013-01-05 12:00:00  0.276232\nb 2013-01-05 00:00:00  0.567020\n 2013-01-05 12:00:00 -1.087401\n\n[4 rows x 1 columns] \n```", "```py\nIn [20]: df = pd.DataFrame(\n ....:    {\"year\": [2015, 2016], \"month\": [2, 3], \"day\": [4, 5], \"hour\": [2, 3]}\n ....: )\n ....: \n\nIn [21]: df\nOut[21]: \n year  month  day  hour\n0  2015      2    4     2\n1  2016      3    5     3\n\n[2 rows x 4 columns] \n```", "```py\nIn [22]: pd.to_datetime(df)\nOut[22]: \n0   2015-02-04 02:00:00\n1   2016-03-05 03:00:00\nLength: 2, dtype: datetime64[ns] \n```", "```py\nIn [23]: pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\nOut[23]: \n0   2015-02-04\n1   2016-03-05\nLength: 2, dtype: datetime64[ns] \n```", "```py\n    In [24]: idx = pd.Index([1.0, 2.0, 3.0, 4.0], dtype=\"float\")\n\n    # default, allow_fill=True, fill_value=None\n    In [25]: idx.take([2, -1])\n    Out[25]: Index([3.0, 4.0], dtype='float64')\n\n    In [26]: idx.take([2, -1], fill_value=True)\n    Out[26]: Index([3.0, nan], dtype='float64') \n    ```", "```py\n    In [27]: idx = pd.Index([\"a|b\", \"a|c\", \"b|c\"])\n\n    In [28]: idx.str.get_dummies(\"|\")\n    Out[28]: \n    MultiIndex([(1, 1, 0),\n     (1, 0, 1),\n     (0, 1, 1)],\n     names=['a', 'b', 'c']) \n    ```", "```py\ns = pd.SparseArray([np.nan, np.nan, 1, 2, 3, np.nan, 4, 5, np.nan, 6])\ns.take(0)\ns.take([1, 2, 3]) \n```", "```py\nIn [29]: df = pd.DataFrame({\"A\": [\"a\", \"b\", \"a\"], \"B\": [1, 2, 3]})\n\nIn [30]: df\nOut[30]: \n A  B\n0  a  1\n1  b  2\n2  a  3\n\n[3 rows x 2 columns] \n```", "```py\nIn [3]: df.groupby('A', as_index=True)['B'].nth(0)\nOut[3]:\n0    1\n1    2\nName: B, dtype: int64\n\nIn [4]: df.groupby('A', as_index=False)['B'].nth(0)\nOut[4]:\n0    1\n1    2\nName: B, dtype: int64 \n```", "```py\nIn [31]: df.groupby(\"A\", as_index=True)[\"B\"].nth(0)\nOut[31]: \n0    1\n1    2\nName: B, Length: 2, dtype: int64\n\nIn [32]: df.groupby(\"A\", as_index=False)[\"B\"].nth(0)\nOut[32]: \n0    1\n1    2\nName: B, Length: 2, dtype: int64 \n```", "```py\nIn [33]: np.random.seed(1234)\n\nIn [34]: df = pd.DataFrame(np.random.randn(100, 2), columns=[\"a\", \"b\"])\n\nIn [35]: df[\"c\"] = np.random.randint(0, 4, 100) \n```", "```py\nIn [4]: df.groupby('c', sort=True).nth(1)\nOut[4]:\n a         b\nc\n0 -0.334077  0.002118\n1  0.036142 -2.074978\n2 -0.720589  0.887163\n3  0.859588 -0.636524\n\nIn [5]: df.groupby('c', sort=False).nth(1)\nOut[5]:\n a         b\nc\n0 -0.334077  0.002118\n1  0.036142 -2.074978\n2 -0.720589  0.887163\n3  0.859588 -0.636524 \n```", "```py\nIn [36]: df.groupby(\"c\", sort=True).nth(1)\nOut[36]: \n a         b  c\n2  -0.720589  0.887163  2\n3   0.859588 -0.636524  3\n7  -0.334077  0.002118  0\n21  0.036142 -2.074978  1\n\n[4 rows x 3 columns]\n\nIn [37]: df.groupby(\"c\", sort=False).nth(1)\nOut[37]: \n a         b  c\n2  -0.720589  0.887163  2\n3   0.859588 -0.636524  3\n7  -0.334077  0.002118  0\n21  0.036142 -2.074978  1\n\n[4 rows x 3 columns] \n```", "```py\nsp = pd.SparseDataFrame([1, 2, 3])\nsp \n```", "```py\nIn [2]: np.cumsum(sp, axis=0)\n...\nTypeError: cumsum() takes at most 2 arguments (4 given) \n```", "```py\nnp.cumsum(sp, axis=0) \n```", "```py\nIn [38]: df = pd.DataFrame(\n ....:    {\"date\": pd.to_datetime([\"10/10/2000\", \"11/10/2000\"]), \"value\": [10, 13]}\n ....: )\n ....: \n\nIn [39]: df\nOut[39]: \n date  value\n0 2000-10-10     10\n1 2000-11-10     13\n\n[2 rows x 2 columns] \n```", "```py\nIn [1]: df.groupby(pd.TimeGrouper(key='date',\n ...:                          freq='M')).apply(lambda x: x.value.sum())\nOut[1]:\n...\nTypeError: cannot concatenate a non-NDFrame object\n\n# Output is a Series\nIn [2]: df.groupby(pd.TimeGrouper(key='date',\n ...:                          freq='M')).apply(lambda x: x[['value']].sum())\nOut[2]:\ndate\n2000-10-31  value    10\n2000-11-30  value    13\ndtype: int64 \n```", "```py\n# Output is a Series\nIn [55]: df.groupby(pd.TimeGrouper(key='date',\n ...:                           freq='M')).apply(lambda x: x.value.sum())\nOut[55]:\ndate\n2000-10-31    10\n2000-11-30    13\nFreq: M, dtype: int64\n\n# Output is a DataFrame\nIn [56]: df.groupby(pd.TimeGrouper(key='date',\n ...:                           freq='M')).apply(lambda x: x[['value']].sum())\nOut[56]:\n value\ndate\n2000-10-31     10\n2000-11-30     13 \n```", "```py\nIn [1]: import io\n\nIn [2]: df = pd.read_csv(io.StringIO(''), engine='c')\n...\nValueError: No columns to parse from file\n\nIn [3]: df = pd.read_csv(io.StringIO(''), engine='python')\n...\nStopIteration \n```", "```py\nIn [1]: df = pd.read_csv(io.StringIO(''), engine='c')\n...\npandas.io.common.EmptyDataError: No columns to parse from file\n\nIn [2]: df = pd.read_csv(io.StringIO(''), engine='python')\n...\npandas.io.common.EmptyDataError: No columns to parse from file \n```", "```py\nIn [27]: pd.to_datetime(1420043460, unit='s', errors='coerce')\nOut[27]: NaT\n\nIn [28]: pd.to_datetime(11111111, unit='D', errors='ignore')\nOverflowError: Python int too large to convert to C long\n\nIn [29]: pd.to_datetime(11111111, unit='D', errors='raise')\nOverflowError: Python int too large to convert to C long \n```", "```py\nIn [2]: pd.to_datetime(1420043460, unit='s', errors='coerce')\nOut[2]: Timestamp('2014-12-31 16:31:00')\n\nIn [3]: pd.to_datetime(11111111, unit='D', errors='ignore')\nOut[3]: 11111111\n\nIn [4]: pd.to_datetime(11111111, unit='D', errors='raise')\nOutOfBoundsDatetime: cannot convert input with unit 'D' \n```", "```py\nIn [1]: from pandas.tseries.offsets import CustomBusinessHour\n\nIn [2]: from pandas.tseries.holiday import USFederalHolidayCalendar\n\nIn [3]: bhour_us = CustomBusinessHour(calendar=USFederalHolidayCalendar()) \n```", "```py\nIn [4]: import datetime\n\nIn [5]: dt = datetime.datetime(2014, 1, 17, 15)\n\nIn [6]: dt + bhour_us\nOut[6]: Timestamp('2014-01-17 16:00:00') \n```", "```py\nIn [7]: dt + bhour_us * 2\nOut[7]: Timestamp('2014-01-20 09:00:00') \n```", "```py\nIn [8]: df = pd.DataFrame({\"A\": [1] * 20 + [2] * 12 + [3] * 8, \"B\": np.arange(40)})\n\nIn [9]: df\nOut[9]: \n A   B\n0   1   0\n1   1   1\n2   1   2\n3   1   3\n4   1   4\n.. ..  ..\n35  3  35\n36  3  36\n37  3  37\n38  3  38\n39  3  39\n\n[40 rows x 2 columns] \n```", "```py\nIn [1]: df.groupby(\"A\").apply(lambda x: x.rolling(4).B.mean())\nOut[1]:\nA\n1  0      NaN\n 1      NaN\n 2      NaN\n 3      1.5\n 4      2.5\n 5      3.5\n 6      4.5\n 7      5.5\n 8      6.5\n 9      7.5\n 10     8.5\n 11     9.5\n 12    10.5\n 13    11.5\n 14    12.5\n 15    13.5\n 16    14.5\n 17    15.5\n 18    16.5\n 19    17.5\n2  20     NaN\n 21     NaN\n 22     NaN\n 23    21.5\n 24    22.5\n 25    23.5\n 26    24.5\n 27    25.5\n 28    26.5\n 29    27.5\n 30    28.5\n 31    29.5\n3  32     NaN\n 33     NaN\n 34     NaN\n 35    33.5\n 36    34.5\n 37    35.5\n 38    36.5\n 39    37.5\nName: B, dtype: float64 \n```", "```py\nIn [10]: df.groupby(\"A\").rolling(4).B.mean()\nOut[10]: \nA \n1  0      NaN\n 1      NaN\n 2      NaN\n 3      1.5\n 4      2.5\n ... \n3  35    33.5\n 36    34.5\n 37    35.5\n 38    36.5\n 39    37.5\nName: B, Length: 40, dtype: float64 \n```", "```py\nIn [11]: df = pd.DataFrame(\n ....:    {\n ....:        \"date\": pd.date_range(start=\"2016-01-01\", periods=4, freq=\"W\"),\n ....:        \"group\": [1, 1, 2, 2],\n ....:        \"val\": [5, 6, 7, 8],\n ....:    }\n ....: ).set_index(\"date\")\n ....: \n\nIn [12]: df\nOut[12]: \n group  val\ndate \n2016-01-03      1    5\n2016-01-10      1    6\n2016-01-17      2    7\n2016-01-24      2    8\n\n[4 rows x 2 columns] \n```", "```py\nIn[1]: df.groupby(\"group\").apply(lambda x: x.resample(\"1D\").ffill())\nOut[1]:\n                  group  val\ngroup date\n1     2016-01-03      1    5\n      2016-01-04      1    5\n      2016-01-05      1    5\n      2016-01-06      1    5\n      2016-01-07      1    5\n      2016-01-08      1    5\n      2016-01-09      1    5\n      2016-01-10      1    6\n2     2016-01-17      2    7\n      2016-01-18      2    7\n      2016-01-19      2    7\n      2016-01-20      2    7\n      2016-01-21      2    7\n      2016-01-22      2    7\n      2016-01-23      2    7\n      2016-01-24      2    8 \n```", "```py\nIn[1]: df.groupby(\"group\").resample(\"1D\").ffill()\nOut[1]:\n                  group  val\ngroup date\n1     2016-01-03      1    5\n      2016-01-04      1    5\n      2016-01-05      1    5\n      2016-01-06      1    5\n      2016-01-07      1    5\n      2016-01-08      1    5\n      2016-01-09      1    5\n      2016-01-10      1    6\n2     2016-01-17      2    7\n      2016-01-18      2    7\n      2016-01-19      2    7\n      2016-01-20      2    7\n      2016-01-21      2    7\n      2016-01-22      2    7\n      2016-01-23      2    7\n      2016-01-24      2    8 \n```", "```py\nIn [13]: df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6], \"C\": [7, 8, 9]})\n\nIn [14]: df.where(lambda x: x > 4, lambda x: x + 10)\nOut[14]: \n A   B  C\n0  11  14  7\n1  12   5  8\n2  13   6  9\n\n[3 rows x 3 columns] \n```", "```py\n# callable returns bool indexer\nIn [15]: df.loc[lambda x: x.A >= 2, lambda x: x.sum() > 10]\nOut[15]: \n B  C\n1  5  8\n2  6  9\n\n[2 rows x 2 columns]\n\n# callable returns list of labels\nIn [16]: df.loc[lambda x: [1, 2], lambda x: [\"A\", \"B\"]]\nOut[16]: \n A  B\n1  2  5\n2  3  6\n\n[2 rows x 2 columns] \n```", "```py\nIn [17]: df[lambda x: \"A\"]\nOut[17]: \n0    1\n1    2\n2    3\nName: A, Length: 3, dtype: int64 \n```", "```py\nIn [18]: bb = pd.read_csv(\"data/baseball.csv\", index_col=\"id\")\n\nIn [19]: (bb.groupby([\"year\", \"team\"]).sum(numeric_only=True).loc[lambda df: df.r > 100])\nOut[19]: \n stint    g    ab    r    h  X2b  ...     so   ibb   hbp    sh    sf  gidp\nyear team                                   ... \n2007 CIN       6  379   745  101  203   35  ...  127.0  14.0   1.0   1.0  15.0  18.0\n DET       5  301  1062  162  283   54  ...  176.0   3.0  10.0   4.0   8.0  28.0\n HOU       4  311   926  109  218   47  ...  212.0   3.0   9.0  16.0   6.0  17.0\n LAN      11  413  1021  153  293   61  ...  141.0   8.0   9.0   3.0   8.0  29.0\n NYN      13  622  1854  240  509  101  ...  310.0  24.0  23.0  18.0  15.0  48.0\n SFN       5  482  1305  198  337   67  ...  188.0  51.0   8.0  16.0   6.0  41.0\n TEX       2  198   729  115  200   40  ...  140.0   4.0   5.0   2.0   8.0  16.0\n TOR       4  459  1408  187  378   96  ...  265.0  16.0  12.0   4.0  16.0  38.0\n\n[8 rows x 18 columns] \n```", "```py\nIn [20]: dft2 = pd.DataFrame(\n ....:    np.random.randn(20, 1),\n ....:    columns=[\"A\"],\n ....:    index=pd.MultiIndex.from_product(\n ....:        [pd.date_range(\"20130101\", periods=10, freq=\"12H\"), [\"a\", \"b\"]]\n ....:    ),\n ....: )\n ....:\n\nIn [21]: dft2\nOut[21]:\n A\n2013-01-01 00:00:00 a  0.469112\n b -0.282863\n2013-01-01 12:00:00 a -1.509059\n b -1.135632\n2013-01-02 00:00:00 a  1.212112\n...                         ...\n2013-01-04 12:00:00 b  0.271860\n2013-01-05 00:00:00 a -0.424972\n b  0.567020\n2013-01-05 12:00:00 a  0.276232\n b -1.087401\n\n[20 rows x 1 columns]\n\nIn [22]: dft2.loc[\"2013-01-05\"]\nOut[22]:\n A\n2013-01-05 00:00:00 a -0.424972\n b  0.567020\n2013-01-05 12:00:00 a  0.276232\n b -1.087401\n\n[4 rows x 1 columns] \n```", "```py\nIn [26]: idx = pd.IndexSlice\n\nIn [27]: dft2 = dft2.swaplevel(0, 1).sort_index()\n\nIn [28]: dft2\nOut[28]:\n A\na 2013-01-01 00:00:00  0.469112\n 2013-01-01 12:00:00 -1.509059\n 2013-01-02 00:00:00  1.212112\n 2013-01-02 12:00:00  0.119209\n 2013-01-03 00:00:00 -0.861849\n...                         ...\nb 2013-01-03 12:00:00  1.071804\n 2013-01-04 00:00:00 -0.706771\n 2013-01-04 12:00:00  0.271860\n 2013-01-05 00:00:00  0.567020\n 2013-01-05 12:00:00 -1.087401\n\n[20 rows x 1 columns]\n\nIn [29]: dft2.loc[idx[:, \"2013-01-05\"], :]\nOut[29]:\n A\na 2013-01-05 00:00:00 -0.424972\n 2013-01-05 12:00:00  0.276232\nb 2013-01-05 00:00:00  0.567020\n 2013-01-05 12:00:00 -1.087401\n\n[4 rows x 1 columns] \n```", "```py\nIn [20]: df = pd.DataFrame(\n ....:    {\"year\": [2015, 2016], \"month\": [2, 3], \"day\": [4, 5], \"hour\": [2, 3]}\n ....: )\n ....: \n\nIn [21]: df\nOut[21]: \n year  month  day  hour\n0  2015      2    4     2\n1  2016      3    5     3\n\n[2 rows x 4 columns] \n```", "```py\nIn [22]: pd.to_datetime(df)\nOut[22]: \n0   2015-02-04 02:00:00\n1   2016-03-05 03:00:00\nLength: 2, dtype: datetime64[ns] \n```", "```py\nIn [23]: pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\nOut[23]: \n0   2015-02-04\n1   2016-03-05\nLength: 2, dtype: datetime64[ns] \n```", "```py\n    In [24]: idx = pd.Index([1.0, 2.0, 3.0, 4.0], dtype=\"float\")\n\n    # default, allow_fill=True, fill_value=None\n    In [25]: idx.take([2, -1])\n    Out[25]: Index([3.0, 4.0], dtype='float64')\n\n    In [26]: idx.take([2, -1], fill_value=True)\n    Out[26]: Index([3.0, nan], dtype='float64') \n    ```", "```py\n    In [27]: idx = pd.Index([\"a|b\", \"a|c\", \"b|c\"])\n\n    In [28]: idx.str.get_dummies(\"|\")\n    Out[28]: \n    MultiIndex([(1, 1, 0),\n     (1, 0, 1),\n     (0, 1, 1)],\n     names=['a', 'b', 'c']) \n    ```", "```py\nIn [1]: from pandas.tseries.offsets import CustomBusinessHour\n\nIn [2]: from pandas.tseries.holiday import USFederalHolidayCalendar\n\nIn [3]: bhour_us = CustomBusinessHour(calendar=USFederalHolidayCalendar()) \n```", "```py\nIn [4]: import datetime\n\nIn [5]: dt = datetime.datetime(2014, 1, 17, 15)\n\nIn [6]: dt + bhour_us\nOut[6]: Timestamp('2014-01-17 16:00:00') \n```", "```py\nIn [7]: dt + bhour_us * 2\nOut[7]: Timestamp('2014-01-20 09:00:00') \n```", "```py\nIn [8]: df = pd.DataFrame({\"A\": [1] * 20 + [2] * 12 + [3] * 8, \"B\": np.arange(40)})\n\nIn [9]: df\nOut[9]: \n A   B\n0   1   0\n1   1   1\n2   1   2\n3   1   3\n4   1   4\n.. ..  ..\n35  3  35\n36  3  36\n37  3  37\n38  3  38\n39  3  39\n\n[40 rows x 2 columns] \n```", "```py\nIn [1]: df.groupby(\"A\").apply(lambda x: x.rolling(4).B.mean())\nOut[1]:\nA\n1  0      NaN\n 1      NaN\n 2      NaN\n 3      1.5\n 4      2.5\n 5      3.5\n 6      4.5\n 7      5.5\n 8      6.5\n 9      7.5\n 10     8.5\n 11     9.5\n 12    10.5\n 13    11.5\n 14    12.5\n 15    13.5\n 16    14.5\n 17    15.5\n 18    16.5\n 19    17.5\n2  20     NaN\n 21     NaN\n 22     NaN\n 23    21.5\n 24    22.5\n 25    23.5\n 26    24.5\n 27    25.5\n 28    26.5\n 29    27.5\n 30    28.5\n 31    29.5\n3  32     NaN\n 33     NaN\n 34     NaN\n 35    33.5\n 36    34.5\n 37    35.5\n 38    36.5\n 39    37.5\nName: B, dtype: float64 \n```", "```py\nIn [10]: df.groupby(\"A\").rolling(4).B.mean()\nOut[10]: \nA \n1  0      NaN\n 1      NaN\n 2      NaN\n 3      1.5\n 4      2.5\n ... \n3  35    33.5\n 36    34.5\n 37    35.5\n 38    36.5\n 39    37.5\nName: B, Length: 40, dtype: float64 \n```", "```py\nIn [11]: df = pd.DataFrame(\n ....:    {\n ....:        \"date\": pd.date_range(start=\"2016-01-01\", periods=4, freq=\"W\"),\n ....:        \"group\": [1, 1, 2, 2],\n ....:        \"val\": [5, 6, 7, 8],\n ....:    }\n ....: ).set_index(\"date\")\n ....: \n\nIn [12]: df\nOut[12]: \n group  val\ndate \n2016-01-03      1    5\n2016-01-10      1    6\n2016-01-17      2    7\n2016-01-24      2    8\n\n[4 rows x 2 columns] \n```", "```py\nIn[1]: df.groupby(\"group\").apply(lambda x: x.resample(\"1D\").ffill())\nOut[1]:\n                  group  val\ngroup date\n1     2016-01-03      1    5\n      2016-01-04      1    5\n      2016-01-05      1    5\n      2016-01-06      1    5\n      2016-01-07      1    5\n      2016-01-08      1    5\n      2016-01-09      1    5\n      2016-01-10      1    6\n2     2016-01-17      2    7\n      2016-01-18      2    7\n      2016-01-19      2    7\n      2016-01-20      2    7\n      2016-01-21      2    7\n      2016-01-22      2    7\n      2016-01-23      2    7\n      2016-01-24      2    8 \n```", "```py\nIn[1]: df.groupby(\"group\").resample(\"1D\").ffill()\nOut[1]:\n                  group  val\ngroup date\n1     2016-01-03      1    5\n      2016-01-04      1    5\n      2016-01-05      1    5\n      2016-01-06      1    5\n      2016-01-07      1    5\n      2016-01-08      1    5\n      2016-01-09      1    5\n      2016-01-10      1    6\n2     2016-01-17      2    7\n      2016-01-18      2    7\n      2016-01-19      2    7\n      2016-01-20      2    7\n      2016-01-21      2    7\n      2016-01-22      2    7\n      2016-01-23      2    7\n      2016-01-24      2    8 \n```", "```py\nIn [13]: df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6], \"C\": [7, 8, 9]})\n\nIn [14]: df.where(lambda x: x > 4, lambda x: x + 10)\nOut[14]: \n A   B  C\n0  11  14  7\n1  12   5  8\n2  13   6  9\n\n[3 rows x 3 columns] \n```", "```py\n# callable returns bool indexer\nIn [15]: df.loc[lambda x: x.A >= 2, lambda x: x.sum() > 10]\nOut[15]: \n B  C\n1  5  8\n2  6  9\n\n[2 rows x 2 columns]\n\n# callable returns list of labels\nIn [16]: df.loc[lambda x: [1, 2], lambda x: [\"A\", \"B\"]]\nOut[16]: \n A  B\n1  2  5\n2  3  6\n\n[2 rows x 2 columns] \n```", "```py\nIn [17]: df[lambda x: \"A\"]\nOut[17]: \n0    1\n1    2\n2    3\nName: A, Length: 3, dtype: int64 \n```", "```py\nIn [18]: bb = pd.read_csv(\"data/baseball.csv\", index_col=\"id\")\n\nIn [19]: (bb.groupby([\"year\", \"team\"]).sum(numeric_only=True).loc[lambda df: df.r > 100])\nOut[19]: \n stint    g    ab    r    h  X2b  ...     so   ibb   hbp    sh    sf  gidp\nyear team                                   ... \n2007 CIN       6  379   745  101  203   35  ...  127.0  14.0   1.0   1.0  15.0  18.0\n DET       5  301  1062  162  283   54  ...  176.0   3.0  10.0   4.0   8.0  28.0\n HOU       4  311   926  109  218   47  ...  212.0   3.0   9.0  16.0   6.0  17.0\n LAN      11  413  1021  153  293   61  ...  141.0   8.0   9.0   3.0   8.0  29.0\n NYN      13  622  1854  240  509  101  ...  310.0  24.0  23.0  18.0  15.0  48.0\n SFN       5  482  1305  198  337   67  ...  188.0  51.0   8.0  16.0   6.0  41.0\n TEX       2  198   729  115  200   40  ...  140.0   4.0   5.0   2.0   8.0  16.0\n TOR       4  459  1408  187  378   96  ...  265.0  16.0  12.0   4.0  16.0  38.0\n\n[8 rows x 18 columns] \n```", "```py\nIn [13]: df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6], \"C\": [7, 8, 9]})\n\nIn [14]: df.where(lambda x: x > 4, lambda x: x + 10)\nOut[14]: \n A   B  C\n0  11  14  7\n1  12   5  8\n2  13   6  9\n\n[3 rows x 3 columns] \n```", "```py\n# callable returns bool indexer\nIn [15]: df.loc[lambda x: x.A >= 2, lambda x: x.sum() > 10]\nOut[15]: \n B  C\n1  5  8\n2  6  9\n\n[2 rows x 2 columns]\n\n# callable returns list of labels\nIn [16]: df.loc[lambda x: [1, 2], lambda x: [\"A\", \"B\"]]\nOut[16]: \n A  B\n1  2  5\n2  3  6\n\n[2 rows x 2 columns] \n```", "```py\nIn [17]: df[lambda x: \"A\"]\nOut[17]: \n0    1\n1    2\n2    3\nName: A, Length: 3, dtype: int64 \n```", "```py\nIn [18]: bb = pd.read_csv(\"data/baseball.csv\", index_col=\"id\")\n\nIn [19]: (bb.groupby([\"year\", \"team\"]).sum(numeric_only=True).loc[lambda df: df.r > 100])\nOut[19]: \n stint    g    ab    r    h  X2b  ...     so   ibb   hbp    sh    sf  gidp\nyear team                                   ... \n2007 CIN       6  379   745  101  203   35  ...  127.0  14.0   1.0   1.0  15.0  18.0\n DET       5  301  1062  162  283   54  ...  176.0   3.0  10.0   4.0   8.0  28.0\n HOU       4  311   926  109  218   47  ...  212.0   3.0   9.0  16.0   6.0  17.0\n LAN      11  413  1021  153  293   61  ...  141.0   8.0   9.0   3.0   8.0  29.0\n NYN      13  622  1854  240  509  101  ...  310.0  24.0  23.0  18.0  15.0  48.0\n SFN       5  482  1305  198  337   67  ...  188.0  51.0   8.0  16.0   6.0  41.0\n TEX       2  198   729  115  200   40  ...  140.0   4.0   5.0   2.0   8.0  16.0\n TOR       4  459  1408  187  378   96  ...  265.0  16.0  12.0   4.0  16.0  38.0\n\n[8 rows x 18 columns] \n```", "```py\nIn [20]: dft2 = pd.DataFrame(\n ....:    np.random.randn(20, 1),\n ....:    columns=[\"A\"],\n ....:    index=pd.MultiIndex.from_product(\n ....:        [pd.date_range(\"20130101\", periods=10, freq=\"12H\"), [\"a\", \"b\"]]\n ....:    ),\n ....: )\n ....:\n\nIn [21]: dft2\nOut[21]:\n A\n2013-01-01 00:00:00 a  0.469112\n b -0.282863\n2013-01-01 12:00:00 a -1.509059\n b -1.135632\n2013-01-02 00:00:00 a  1.212112\n...                         ...\n2013-01-04 12:00:00 b  0.271860\n2013-01-05 00:00:00 a -0.424972\n b  0.567020\n2013-01-05 12:00:00 a  0.276232\n b -1.087401\n\n[20 rows x 1 columns]\n\nIn [22]: dft2.loc[\"2013-01-05\"]\nOut[22]:\n A\n2013-01-05 00:00:00 a -0.424972\n b  0.567020\n2013-01-05 12:00:00 a  0.276232\n b -1.087401\n\n[4 rows x 1 columns] \n```", "```py\nIn [26]: idx = pd.IndexSlice\n\nIn [27]: dft2 = dft2.swaplevel(0, 1).sort_index()\n\nIn [28]: dft2\nOut[28]:\n A\na 2013-01-01 00:00:00  0.469112\n 2013-01-01 12:00:00 -1.509059\n 2013-01-02 00:00:00  1.212112\n 2013-01-02 12:00:00  0.119209\n 2013-01-03 00:00:00 -0.861849\n...                         ...\nb 2013-01-03 12:00:00  1.071804\n 2013-01-04 00:00:00 -0.706771\n 2013-01-04 12:00:00  0.271860\n 2013-01-05 00:00:00  0.567020\n 2013-01-05 12:00:00 -1.087401\n\n[20 rows x 1 columns]\n\nIn [29]: dft2.loc[idx[:, \"2013-01-05\"], :]\nOut[29]:\n A\na 2013-01-05 00:00:00 -0.424972\n 2013-01-05 12:00:00  0.276232\nb 2013-01-05 00:00:00  0.567020\n 2013-01-05 12:00:00 -1.087401\n\n[4 rows x 1 columns] \n```", "```py\nIn [20]: df = pd.DataFrame(\n ....:    {\"year\": [2015, 2016], \"month\": [2, 3], \"day\": [4, 5], \"hour\": [2, 3]}\n ....: )\n ....: \n\nIn [21]: df\nOut[21]: \n year  month  day  hour\n0  2015      2    4     2\n1  2016      3    5     3\n\n[2 rows x 4 columns] \n```", "```py\nIn [22]: pd.to_datetime(df)\nOut[22]: \n0   2015-02-04 02:00:00\n1   2016-03-05 03:00:00\nLength: 2, dtype: datetime64[ns] \n```", "```py\nIn [23]: pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\nOut[23]: \n0   2015-02-04\n1   2016-03-05\nLength: 2, dtype: datetime64[ns] \n```", "```py\n    In [24]: idx = pd.Index([1.0, 2.0, 3.0, 4.0], dtype=\"float\")\n\n    # default, allow_fill=True, fill_value=None\n    In [25]: idx.take([2, -1])\n    Out[25]: Index([3.0, 4.0], dtype='float64')\n\n    In [26]: idx.take([2, -1], fill_value=True)\n    Out[26]: Index([3.0, nan], dtype='float64') \n    ```", "```py\n    In [27]: idx = pd.Index([\"a|b\", \"a|c\", \"b|c\"])\n\n    In [28]: idx.str.get_dummies(\"|\")\n    Out[28]: \n    MultiIndex([(1, 1, 0),\n     (1, 0, 1),\n     (0, 1, 1)],\n     names=['a', 'b', 'c']) \n    ```", "```py\ns = pd.SparseArray([np.nan, np.nan, 1, 2, 3, np.nan, 4, 5, np.nan, 6])\ns.take(0)\ns.take([1, 2, 3]) \n```", "```py\nIn [29]: df = pd.DataFrame({\"A\": [\"a\", \"b\", \"a\"], \"B\": [1, 2, 3]})\n\nIn [30]: df\nOut[30]: \n A  B\n0  a  1\n1  b  2\n2  a  3\n\n[3 rows x 2 columns] \n```", "```py\nIn [3]: df.groupby('A', as_index=True)['B'].nth(0)\nOut[3]:\n0    1\n1    2\nName: B, dtype: int64\n\nIn [4]: df.groupby('A', as_index=False)['B'].nth(0)\nOut[4]:\n0    1\n1    2\nName: B, dtype: int64 \n```", "```py\nIn [31]: df.groupby(\"A\", as_index=True)[\"B\"].nth(0)\nOut[31]: \n0    1\n1    2\nName: B, Length: 2, dtype: int64\n\nIn [32]: df.groupby(\"A\", as_index=False)[\"B\"].nth(0)\nOut[32]: \n0    1\n1    2\nName: B, Length: 2, dtype: int64 \n```", "```py\nIn [33]: np.random.seed(1234)\n\nIn [34]: df = pd.DataFrame(np.random.randn(100, 2), columns=[\"a\", \"b\"])\n\nIn [35]: df[\"c\"] = np.random.randint(0, 4, 100) \n```", "```py\nIn [4]: df.groupby('c', sort=True).nth(1)\nOut[4]:\n a         b\nc\n0 -0.334077  0.002118\n1  0.036142 -2.074978\n2 -0.720589  0.887163\n3  0.859588 -0.636524\n\nIn [5]: df.groupby('c', sort=False).nth(1)\nOut[5]:\n a         b\nc\n0 -0.334077  0.002118\n1  0.036142 -2.074978\n2 -0.720589  0.887163\n3  0.859588 -0.636524 \n```", "```py\nIn [36]: df.groupby(\"c\", sort=True).nth(1)\nOut[36]: \n a         b  c\n2  -0.720589  0.887163  2\n3   0.859588 -0.636524  3\n7  -0.334077  0.002118  0\n21  0.036142 -2.074978  1\n\n[4 rows x 3 columns]\n\nIn [37]: df.groupby(\"c\", sort=False).nth(1)\nOut[37]: \n a         b  c\n2  -0.720589  0.887163  2\n3   0.859588 -0.636524  3\n7  -0.334077  0.002118  0\n21  0.036142 -2.074978  1\n\n[4 rows x 3 columns] \n```", "```py\nsp = pd.SparseDataFrame([1, 2, 3])\nsp \n```", "```py\nIn [2]: np.cumsum(sp, axis=0)\n...\nTypeError: cumsum() takes at most 2 arguments (4 given) \n```", "```py\nnp.cumsum(sp, axis=0) \n```", "```py\nIn [38]: df = pd.DataFrame(\n ....:    {\"date\": pd.to_datetime([\"10/10/2000\", \"11/10/2000\"]), \"value\": [10, 13]}\n ....: )\n ....: \n\nIn [39]: df\nOut[39]: \n date  value\n0 2000-10-10     10\n1 2000-11-10     13\n\n[2 rows x 2 columns] \n```", "```py\nIn [1]: df.groupby(pd.TimeGrouper(key='date',\n ...:                          freq='M')).apply(lambda x: x.value.sum())\nOut[1]:\n...\nTypeError: cannot concatenate a non-NDFrame object\n\n# Output is a Series\nIn [2]: df.groupby(pd.TimeGrouper(key='date',\n ...:                          freq='M')).apply(lambda x: x[['value']].sum())\nOut[2]:\ndate\n2000-10-31  value    10\n2000-11-30  value    13\ndtype: int64 \n```", "```py\n# Output is a Series\nIn [55]: df.groupby(pd.TimeGrouper(key='date',\n ...:                           freq='M')).apply(lambda x: x.value.sum())\nOut[55]:\ndate\n2000-10-31    10\n2000-11-30    13\nFreq: M, dtype: int64\n\n# Output is a DataFrame\nIn [56]: df.groupby(pd.TimeGrouper(key='date',\n ...:                           freq='M')).apply(lambda x: x[['value']].sum())\nOut[56]:\n value\ndate\n2000-10-31     10\n2000-11-30     13 \n```", "```py\nIn [1]: import io\n\nIn [2]: df = pd.read_csv(io.StringIO(''), engine='c')\n...\nValueError: No columns to parse from file\n\nIn [3]: df = pd.read_csv(io.StringIO(''), engine='python')\n...\nStopIteration \n```", "```py\nIn [1]: df = pd.read_csv(io.StringIO(''), engine='c')\n...\npandas.io.common.EmptyDataError: No columns to parse from file\n\nIn [2]: df = pd.read_csv(io.StringIO(''), engine='python')\n...\npandas.io.common.EmptyDataError: No columns to parse from file \n```", "```py\nIn [27]: pd.to_datetime(1420043460, unit='s', errors='coerce')\nOut[27]: NaT\n\nIn [28]: pd.to_datetime(11111111, unit='D', errors='ignore')\nOverflowError: Python int too large to convert to C long\n\nIn [29]: pd.to_datetime(11111111, unit='D', errors='raise')\nOverflowError: Python int too large to convert to C long \n```", "```py\nIn [2]: pd.to_datetime(1420043460, unit='s', errors='coerce')\nOut[2]: Timestamp('2014-12-31 16:31:00')\n\nIn [3]: pd.to_datetime(11111111, unit='D', errors='ignore')\nOut[3]: 11111111\n\nIn [4]: pd.to_datetime(11111111, unit='D', errors='raise')\nOutOfBoundsDatetime: cannot convert input with unit 'D' \n```", "```py\nIn [29]: df = pd.DataFrame({\"A\": [\"a\", \"b\", \"a\"], \"B\": [1, 2, 3]})\n\nIn [30]: df\nOut[30]: \n A  B\n0  a  1\n1  b  2\n2  a  3\n\n[3 rows x 2 columns] \n```", "```py\nIn [3]: df.groupby('A', as_index=True)['B'].nth(0)\nOut[3]:\n0    1\n1    2\nName: B, dtype: int64\n\nIn [4]: df.groupby('A', as_index=False)['B'].nth(0)\nOut[4]:\n0    1\n1    2\nName: B, dtype: int64 \n```", "```py\nIn [31]: df.groupby(\"A\", as_index=True)[\"B\"].nth(0)\nOut[31]: \n0    1\n1    2\nName: B, Length: 2, dtype: int64\n\nIn [32]: df.groupby(\"A\", as_index=False)[\"B\"].nth(0)\nOut[32]: \n0    1\n1    2\nName: B, Length: 2, dtype: int64 \n```", "```py\nIn [33]: np.random.seed(1234)\n\nIn [34]: df = pd.DataFrame(np.random.randn(100, 2), columns=[\"a\", \"b\"])\n\nIn [35]: df[\"c\"] = np.random.randint(0, 4, 100) \n```", "```py\nIn [4]: df.groupby('c', sort=True).nth(1)\nOut[4]:\n a         b\nc\n0 -0.334077  0.002118\n1  0.036142 -2.074978\n2 -0.720589  0.887163\n3  0.859588 -0.636524\n\nIn [5]: df.groupby('c', sort=False).nth(1)\nOut[5]:\n a         b\nc\n0 -0.334077  0.002118\n1  0.036142 -2.074978\n2 -0.720589  0.887163\n3  0.859588 -0.636524 \n```", "```py\nIn [36]: df.groupby(\"c\", sort=True).nth(1)\nOut[36]: \n a         b  c\n2  -0.720589  0.887163  2\n3   0.859588 -0.636524  3\n7  -0.334077  0.002118  0\n21  0.036142 -2.074978  1\n\n[4 rows x 3 columns]\n\nIn [37]: df.groupby(\"c\", sort=False).nth(1)\nOut[37]: \n a         b  c\n2  -0.720589  0.887163  2\n3   0.859588 -0.636524  3\n7  -0.334077  0.002118  0\n21  0.036142 -2.074978  1\n\n[4 rows x 3 columns] \n```", "```py\nsp = pd.SparseDataFrame([1, 2, 3])\nsp \n```", "```py\nIn [2]: np.cumsum(sp, axis=0)\n...\nTypeError: cumsum() takes at most 2 arguments (4 given) \n```", "```py\nnp.cumsum(sp, axis=0) \n```", "```py\nIn [38]: df = pd.DataFrame(\n ....:    {\"date\": pd.to_datetime([\"10/10/2000\", \"11/10/2000\"]), \"value\": [10, 13]}\n ....: )\n ....: \n\nIn [39]: df\nOut[39]: \n date  value\n0 2000-10-10     10\n1 2000-11-10     13\n\n[2 rows x 2 columns] \n```", "```py\nIn [1]: df.groupby(pd.TimeGrouper(key='date',\n ...:                          freq='M')).apply(lambda x: x.value.sum())\nOut[1]:\n...\nTypeError: cannot concatenate a non-NDFrame object\n\n# Output is a Series\nIn [2]: df.groupby(pd.TimeGrouper(key='date',\n ...:                          freq='M')).apply(lambda x: x[['value']].sum())\nOut[2]:\ndate\n2000-10-31  value    10\n2000-11-30  value    13\ndtype: int64 \n```", "```py\n# Output is a Series\nIn [55]: df.groupby(pd.TimeGrouper(key='date',\n ...:                           freq='M')).apply(lambda x: x.value.sum())\nOut[55]:\ndate\n2000-10-31    10\n2000-11-30    13\nFreq: M, dtype: int64\n\n# Output is a DataFrame\nIn [56]: df.groupby(pd.TimeGrouper(key='date',\n ...:                           freq='M')).apply(lambda x: x[['value']].sum())\nOut[56]:\n value\ndate\n2000-10-31     10\n2000-11-30     13 \n```", "```py\nIn [1]: import io\n\nIn [2]: df = pd.read_csv(io.StringIO(''), engine='c')\n...\nValueError: No columns to parse from file\n\nIn [3]: df = pd.read_csv(io.StringIO(''), engine='python')\n...\nStopIteration \n```", "```py\nIn [1]: df = pd.read_csv(io.StringIO(''), engine='c')\n...\npandas.io.common.EmptyDataError: No columns to parse from file\n\nIn [2]: df = pd.read_csv(io.StringIO(''), engine='python')\n...\npandas.io.common.EmptyDataError: No columns to parse from file \n```", "```py\nIn [27]: pd.to_datetime(1420043460, unit='s', errors='coerce')\nOut[27]: NaT\n\nIn [28]: pd.to_datetime(11111111, unit='D', errors='ignore')\nOverflowError: Python int too large to convert to C long\n\nIn [29]: pd.to_datetime(11111111, unit='D', errors='raise')\nOverflowError: Python int too large to convert to C long \n```", "```py\nIn [2]: pd.to_datetime(1420043460, unit='s', errors='coerce')\nOut[2]: Timestamp('2014-12-31 16:31:00')\n\nIn [3]: pd.to_datetime(11111111, unit='D', errors='ignore')\nOut[3]: 11111111\n\nIn [4]: pd.to_datetime(11111111, unit='D', errors='raise')\nOutOfBoundsDatetime: cannot convert input with unit 'D' \n```"]