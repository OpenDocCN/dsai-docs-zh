- en: pandas.DataFrame.to_parquet
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: pandas.DataFrame.to_parquet
- en: 原文：[https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html)
- en: '[PRE0]'
  id: totrans-2
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Write a DataFrame to the binary parquet format.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 将 DataFrame 写入二进制 parquet 格式。
- en: This function writes the dataframe as a [parquet file](https://parquet.apache.org/).
    You can choose different parquet backends, and have the option of compression.
    See [the user guide](../../user_guide/io.html#io-parquet) for more details.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将数据框写入 [parquet 文件](https://parquet.apache.org/)。您可以选择不同的 parquet 后端，并选择是否压缩。有关更多详细信息，请参阅
    [用户指南](../../user_guide/io.html#io-parquet)。
- en: 'Parameters:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '参数:'
- en: '**path**str, path object, file-like object, or None, default None'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**path**str、path 对象、文件样对象或 None，默认为 None'
- en: String, path object (implementing `os.PathLike[str]`), or file-like object implementing
    a binary `write()` function. If None, the result is returned as bytes. If a string
    or path, it will be used as Root Directory path when writing a partitioned dataset.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串、路径对象（实现 `os.PathLike[str]`）或实现二进制 `write()` 函数的文件样对象。如果为 None，则结果将返回为 bytes。如果为字符串或路径，则将其用作写入分区数据集时的根目录路径。
- en: '**engine**{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**engine**{‘auto’, ‘pyarrow’, ‘fastparquet’}，默认为 ''auto'''
- en: Parquet library to use. If ‘auto’, then the option `io.parquet.engine` is used.
    The default `io.parquet.engine` behavior is to try ‘pyarrow’, falling back to
    ‘fastparquet’ if ‘pyarrow’ is unavailable.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用的 parquet 库。如果为 ‘auto’，则使用选项 `io.parquet.engine`。默认 `io.parquet.engine` 行为是尝试
    ‘pyarrow’，如果 ‘pyarrow’ 不可用，则退回到 ‘fastparquet’。
- en: '**compression**str or None, default ‘snappy’'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**compression**str 或 None，默认为 ''snappy'''
- en: 'Name of the compression to use. Use `None` for no compression. Supported options:
    ‘snappy’, ‘gzip’, ‘brotli’, ‘lz4’, ‘zstd’.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '要使用的压缩名称。使用 `None` 表示不压缩。支持的选项: ‘snappy’、‘gzip’、‘brotli’、‘lz4’、‘zstd’。'
- en: '**index**bool, default None'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**index**bool，默认为 None'
- en: If `True`, include the dataframe’s index(es) in the file output. If `False`,
    they will not be written to the file. If `None`, similar to `True` the dataframe’s
    index(es) will be saved. However, instead of being saved as values, the RangeIndex
    will be stored as a range in the metadata so it doesn’t require much space and
    is faster. Other indexes will be included as columns in the file output.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果为 `True`，则将数据框的索引(es)包含在文件输出中。如果为 `False`，则不会将其写入文件。如果为 `None`，类似于 `True`，将保存数据框的索引(es)。但是，而不是保存为值，RangeIndex
    将作为元数据中的范围存储，因此不需要太多空间并且更快。其他索引将包含在文件输出中作为列。
- en: '**partition_cols**list, optional, default None'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**partition_cols**列表，可选，默认为 None'
- en: Column names by which to partition the dataset. Columns are partitioned in the
    order they are given. Must be None if path is not a string.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 按照哪些列对数据集进行分区。按给定的顺序分区列。如果路径不是字符串，则必须为 None。
- en: '**storage_options**dict, optional'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**storage_options**字典，可选'
- en: Extra options that make sense for a particular storage connection, e.g. host,
    port, username, password, etc. For HTTP(S) URLs the key-value pairs are forwarded
    to `urllib.request.Request` as header options. For other URLs (e.g. starting with
    “s3://”, and “gcs://”) the key-value pairs are forwarded to `fsspec.open`. Please
    see `fsspec` and `urllib` for more details, and for more examples on storage options
    refer [here](https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特定存储连接有意义的额外选项，例如主机、端口、用户名、密码等。对于 HTTP(S) URL，键值对将作为头选项转发给 `urllib.request.Request`。对于其他
    URL（例如以 “s3://” 和 “gcs://” 开头的 URL），键值对将转发给 `fsspec.open`。请参阅 `fsspec` 和 `urllib`
    以获取更多详细信息，并参阅此处的存储选项的更多示例 [here](https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files)。
- en: '****kwargs**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '****kwargs**'
- en: Additional arguments passed to the parquet library. See [pandas io](../../user_guide/io.html#io-parquet)
    for more details.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 传递给 parquet 库的附加参数。有关更多详细信息，请参阅 [pandas io](../../user_guide/io.html#io-parquet)。
- en: 'Returns:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '返回:'
- en: bytes if no path argument is provided else None
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果未提供路径参数，则为 bytes，否则为 None
- en: See also
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 另请参见
- en: '[`read_parquet`](pandas.read_parquet.html#pandas.read_parquet "pandas.read_parquet")'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[`read_parquet`](pandas.read_parquet.html#pandas.read_parquet "pandas.read_parquet")'
- en: Read a parquet file.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 读取一个 parquet 文件。
- en: '[`DataFrame.to_orc`](pandas.DataFrame.to_orc.html#pandas.DataFrame.to_orc "pandas.DataFrame.to_orc")'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[`DataFrame.to_orc`](pandas.DataFrame.to_orc.html#pandas.DataFrame.to_orc "pandas.DataFrame.to_orc")'
- en: Write an orc file.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 写入 orc 文件。
- en: '[`DataFrame.to_csv`](pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv "pandas.DataFrame.to_csv")'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[`DataFrame.to_csv`](pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv "pandas.DataFrame.to_csv")'
- en: Write a csv file.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 写入 csv 文件。
- en: '[`DataFrame.to_sql`](pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql "pandas.DataFrame.to_sql")'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[`DataFrame.to_sql`](pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql "pandas.DataFrame.to_sql")'
- en: Write to a sql table.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 写入到一个 SQL 表中。
- en: '[`DataFrame.to_hdf`](pandas.DataFrame.to_hdf.html#pandas.DataFrame.to_hdf "pandas.DataFrame.to_hdf")'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[`DataFrame.to_hdf`](pandas.DataFrame.to_hdf.html#pandas.DataFrame.to_hdf "pandas.DataFrame.to_hdf")'
- en: Write to hdf.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 写入到 hdf 中。
- en: Notes
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This function requires either the [fastparquet](https://pypi.org/project/fastparquet)
    or [pyarrow](https://arrow.apache.org/docs/python/) library.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数需要使用 [fastparquet](https://pypi.org/project/fastparquet) 或 [pyarrow](https://arrow.apache.org/docs/python/)
    库。
- en: Examples
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If you want to get a buffer to the parquet content you can use a io.BytesIO
    object, as long as you don’t use partition_cols, which creates multiple files.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要获取一个 parquet 内容的缓冲区，你可以使用一个 io.BytesIO 对象，只要你不使用 partition_cols，这会创建多个文件。
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
