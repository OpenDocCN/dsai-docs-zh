- en: Finite Difference Approximations to Derivatives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://docs.sympy.org/latest/explanation/special_topics/finite_diff_derivatives.html](https://docs.sympy.org/latest/explanation/special_topics/finite_diff_derivatives.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finite difference approximations to derivatives are quite important in numerical
    analysis and computational physics. In this tutorial, we show how to use SymPy
    to compute approximations of varying accuracy. The hope is that these notes could
    be useful for the practicing researcher who is developing code in some language
    and needs to be able to efficiently generate finite difference formulae for various
    approximations.
  prefs: []
  type: TYPE_NORMAL
- en: In order to establish notation, we first state that we envision that there exists
    a continuous function F of a single variable x, with F having as many derivatives
    as desired. We sample x values uniformly at points along the real line separated
    by h. In most cases we want h to be small in some sense. F(x) may be expanded
    about some point \(x_{0}\) via the usual Taylor series expansion. Let \(x = x_{0}
    + h\). Then the Taylor expansion is
  prefs: []
  type: TYPE_NORMAL
- en: \[F(x_{0}+h) = F(x_{0}) + \big(\frac{dF}{dx}\big)_{x_{0}} * h + \frac{1}{2!}
    \big(\frac{d^{2}F }{dx^{2}}\big)_{x_{0}}* h^2 + \frac{1}{3!} \big(\frac{d^{3}F
    }{dx^{3}}\big)_{x_{0}}* h^3 + ...\]
  prefs: []
  type: TYPE_NORMAL
- en: In order to simplify the notation, we now define a set of coefficients \(c_{n}\),
    where
  prefs: []
  type: TYPE_NORMAL
- en: \[c_{n} := \frac{1}{n!} \big(\frac{d^{n}F }{dx^{n}}\big)_{x_{0}}.\]
  prefs: []
  type: TYPE_NORMAL
- en: 'So now our series has the form:'
  prefs: []
  type: TYPE_NORMAL
- en: \[F(x_{0}+h) = F(x_{0}) + c_{1} * h + c_{2}* h^2 + c_{3}* h^3 + ...\]
  prefs: []
  type: TYPE_NORMAL
- en: In the following we will only use a finite grid of values \(x_{i}\) with \(i\)
    running from \(1,...,N\) and the corresponding values of our function F at these
    grid points denoted by \(F_{i}\). So the problem is how to generate approximate
    values for the derivatives of F with the constraint that we use a subset of the
    finite set of pairs \((x_{i},F_{i})\) of size N.
  prefs: []
  type: TYPE_NORMAL
- en: What follows are manipulations using SymPy to formulate approximations for derivatives
    of a given order and to assess its accuracy. First, we use SymPy to derive the
    approximations by using a rather brute force method frequently covered in introductory
    treatments. Later we shall make use of other SymPy functions which get the job
    done with more efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: A Direct Method Using SymPy Matrices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we let \(x_{0} = x_{i}\), evaluate the series at \(x_{i+1}=x_{i}+ h\) and
    truncate all terms above \(O(h^1)\) we can solve for the single coefficient \(c_{1}\)
    and obtain an approximation to the first derivative:'
  prefs: []
  type: TYPE_NORMAL
- en: \[\big(\frac{dF}{dx}\big)_{x_{0}} \approx \frac{F_{i+1} - F_{i}}{h} + O(h)\]
  prefs: []
  type: TYPE_NORMAL
- en: where the \(O(h)\) refers to the lowest order term in the series in \(h\). This
    establishes that the derivative approximation is of first order accuracy. Put
    another way, if we decide that we can only use the two pairs \((x_{i},F_{i})\)
    and \((x_{i+1},F_{i+1})\) we obtain a “first order accurate” derivative.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to \((x_{i},F_{i})\) we next use the two points \((x_{i+1},F_{i+1})\)
    and \((x_{i+2},F_{i+2})\). Then we have two equations:'
  prefs: []
  type: TYPE_NORMAL
- en: \[F_{i+1} = F_{i} + c_{1}* h + \frac{1}{2}*c_{2}*h^2 + \frac{1}{3!}*c_{3}*h^3
    + ...\]\[F_{i+2} = F_{i} + c_{1}* (2h) + \frac{1}{2}*c_{2}*(2h)^2 + \frac{1}{3!}*c_{3}*(2h)^3
    + ...\]
  prefs: []
  type: TYPE_NORMAL
- en: If we again want to find the first derivative (\(c_{1}\)), we can do that by
    eliminating the term involving \(c_{2}\) from the two equations. We show how to
    do it using SymPy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Vector of right hand sides:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Now we make a matrix consisting of the coefficients of the c_i in the nth degree
    polynomial P.
  prefs: []
  type: TYPE_NORMAL
- en: 'Coefficients of \(c_i\) evaluated at \(x_i\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Coefficients of \(c_i\) evaluated at \(x_i + h\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Coefficients of \(c_i\) evaluated at \(x_i + 2*h\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Matrix of the coefficients is 3x3 in this case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Matrix form of the three equations for the \(c_i\) is M*X = R:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution is obtained by directly inverting the 3x3 matrix M:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note that all three coefficients make up the solution. The desired first derivative
    is coefficient \(c_1\) which is X[1].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'It is instructive to compute another three-point approximation to the first
    derivative, except centering the approximation at \(x_i\) and thus using points
    at \(x_{i-1}\), \(x_{i}\), and \(x_{i+1}\). So here is how this can be done using
    the ‘brute force’ method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the matrix of coefficients we next form the right-hand-side
    and solve by inverting \(M\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: These two examples serve to show how one can directly find second order accurate
    first derivatives using SymPy. The first example uses values of \(x\) and \(F\)
    at all three points \(x_i\), \(x_{i+1}\), and \(x_{i+2}\) whereas the second example
    only uses values of \(x\) at the two points \(x_{i-1}\) and \(x_{i+1}\) and thus
    is a bit more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: From these two simple examples a general rule is that if one wants a first derivative
    to be accurate to \(O(h^{n})\) then one needs n+1 function values in the approximating
    polynomial (here provided via the function \(P(x,x0,c,n)\)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s assess the question of the accuracy of the centered difference result
    to see how we determine that it is really second order. To do this we take the
    result for \(dF/dx\) and substitute in the polynomial expansion for a higher order
    polynomial and see what we get. To this end, we make a set of eight coefficients
    d and use them to perform the check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Thus we see that indeed the derivative is \(c_1\) with the next term in the
    series of order \(h^2\).
  prefs: []
  type: TYPE_NORMAL
- en: However, it can quickly become rather tedious to generalize the direct method
    as presented above when attempting to generate a derivative approximation to high
    order, such as 6 or 8 although the method certainly works and using the present
    method is certainly less tedious than performing the calculations by hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have seen in the discussion above, the simple centered approximation
    for the first derivative only uses two point values of the \((x_{i},F_{i})\) pairs.
    This works fine until one encounters the last point in the domain, say at \(i=N\).
    Since our centered derivative approximation would use data at the point \((x_{N+1},F_{N+1})\)
    we see that the derivative formula will not work. So, what to do? Well, a simple
    way to handle this is to devise a different formula for this last point which
    uses points for which we do have values. This is the so-called backward difference
    formula. To obtain it, we can use the same direct approach, except now us the
    three points \((x_{N},F_{N})\), \((x_{N-1},F_{N-1})\), and \((x_{N-2},F_{N-2})\)
    and center the approximation at \((x_{N},F_{N})\). Here is how it can be done
    using SymPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we make a matrix consisting of the coefficients of the \(c_i\) in the dth
    degree polynomial P coefficients of \(c_i\) evaluated at \(x_i, x_{i-1},\) and
    \(x_{i+1}\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we construct the \(3 \times 3\) matrix of the coefficients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Then we invert \(M\) and write the solution to the \(3 \times 3\) system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The matrix form of the three equations for the c_i is \(M*C = R\). The solution
    is obtained by directly inverting \(M\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The first derivative is coefficient \(c_1\) which is \(X[1]\). Thus the second
    order accurate approximation for the first derivative is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Of course, we can devise a similar formula for the value of the derivative at
    the left end of the set of points at \((x_{1},F_{1})\) in terms of values at \((x_{2},F_{2})\)
    and \((x_{3},F_{3})\).
  prefs: []
  type: TYPE_NORMAL
- en: Also, we note that output of formats appropriate to Fortran, C, etc. may be
    done in the examples given above.
  prefs: []
  type: TYPE_NORMAL
- en: Next we show how to perform these and many other discritizations of derivatives,
    but using a much more efficient approach originally due to Bengt Fornberg and
    now incorporated into SymPy.
  prefs: []
  type: TYPE_NORMAL
- en: '[Finite differences](../../tutorials/intro-tutorial/calculus.html#calculus-finite-differences)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Finite difference weights](../../modules/calculus/index.html#finite-diff)'
  prefs: []
  type: TYPE_NORMAL
