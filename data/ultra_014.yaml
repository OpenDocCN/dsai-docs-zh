- en: Pose Estimation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 姿势估计
- en: 原文：[`docs.ultralytics.com/tasks/pose/`](https://docs.ultralytics.com/tasks/pose/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/tasks/pose/`](https://docs.ultralytics.com/tasks/pose/)
- en: '![Pose estimation examples](img/48a7c9a6d42399ce7eddc7553488109a.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![姿势估计示例](img/48a7c9a6d42399ce7eddc7553488109a.png)'
- en: Pose estimation is a task that involves identifying the location of specific
    points in an image, usually referred to as keypoints. The keypoints can represent
    various parts of the object such as joints, landmarks, or other distinctive features.
    The locations of the keypoints are usually represented as a set of 2D `[x, y]`
    or 3D `[x, y, visible]` coordinates.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 姿势估计是一项任务，涉及在图像中识别特定点的位置，通常称为关键点。关键点可以代表对象的各种部位，如关节、地标或其他显著特征。关键点的位置通常表示为一组2D
    `[x, y]` 或3D `[x, y, visible]`坐标。
- en: The output of a pose estimation model is a set of points that represent the
    keypoints on an object in the image, usually along with the confidence scores
    for each point. Pose estimation is a good choice when you need to identify specific
    parts of an object in a scene, and their location in relation to each other.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 姿势估计模型的输出是一组点，表示图像中对象的关键点，通常还包括每个点的置信度分数。当您需要识别场景中对象特定部分及其相互位置时，姿势估计是一个不错的选择。
- en: '|'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[`www.youtube.com/embed/Y28xXQmju64?si=pCY4ZwejZFu6Z4kZ`](https://www.youtube.com/embed/Y28xXQmju64?si=pCY4ZwejZFu6Z4kZ)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[`www.youtube.com/embed/Y28xXQmju64?si=pCY4ZwejZFu6Z4kZ`](https://www.youtube.com/embed/Y28xXQmju64?si=pCY4ZwejZFu6Z4kZ)'
- en: '**Watch:** Pose Estimation with Ultralytics YOLOv8. |'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**观看：** 与Ultralytics YOLOv8一起的姿势估计。'
- en: '[`www.youtube.com/embed/aeAX6vWpfR0`](https://www.youtube.com/embed/aeAX6vWpfR0)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[`www.youtube.com/embed/aeAX6vWpfR0`](https://www.youtube.com/embed/aeAX6vWpfR0)'
- en: '**Watch:** Pose Estimation with Ultralytics HUB. |'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**观看：** 与Ultralytics HUB一起的姿势估计。'
- en: Tip
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: YOLOv8 *pose* models use the `-pose` suffix, i.e. `yolov8n-pose.pt`. These models
    are trained on the [COCO keypoints](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco-pose.yaml)
    dataset and are suitable for a variety of pose estimation tasks.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv8 *pose*模型使用`-pose`后缀，例如`yolov8n-pose.pt`。这些模型是在[COCO关键点](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco-pose.yaml)数据集上训练的，适用于各种姿势估计任务。
- en: 'In the default YOLOv8 pose model, there are 17 keypoints, each representing
    a different part of the human body. Here is the mapping of each index to its respective
    body joint:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在默认的YOLOv8姿势模型中，有17个关键点，每个代表人体不同部位。以下是每个索引与其对应身体关节的映射：
- en: '0: Nose 1: Left Eye 2: Right Eye 3: Left Ear 4: Right Ear 5: Left Shoulder
    6: Right Shoulder 7: Left Elbow 8: Right Elbow 9: Left Wrist 10: Right Wrist 11:
    Left Hip 12: Right Hip 13: Left Knee 14: Right Knee 15: Left Ankle 16: Right Ankle'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '0: 鼻子 1: 左眼 2: 右眼 3: 左耳 4: 右耳 5: 左肩 6: 右肩 7: 左肘 8: 右肘 9: 左腕 10: 右腕 11: 左髋 12:
    右髋 13: 左膝 14: 右膝 15: 左踝 16: 右踝'
- en: '[Models](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v8)'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[模型](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v8)'
- en: YOLOv8 pretrained Pose models are shown here. Detect, Segment and Pose models
    are pretrained on the [COCO](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml)
    dataset, while Classify models are pretrained on the [ImageNet](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/ImageNet.yaml)
    dataset.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv8预训练的姿势模型显示在这里。检测、分割和姿势模型在[COCO](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml)数据集上进行了预训练，而分类模型则在[ImageNet](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/ImageNet.yaml)数据集上进行了预训练。
- en: '[Models](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models)
    download automatically from the latest Ultralytics [release](https://github.com/ultralytics/assets/releases)
    on first use.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[模型](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models)将在首次使用时自动从最新的Ultralytics
    [发布](https://github.com/ultralytics/assets/releases)中下载。'
- en: '| Model | size ^((pixels)) | mAP^(pose 50-95) | mAP^(pose 50) | Speed ^(CPU
    ONNX'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '| 模型 | 大小 ^((像素)) | mAP^(姿势 50-95) | mAP^(姿势 50) | 速度 ^(CPU ONNX'
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: (ms)) | 速度 ^(A100 TensorRT
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: (ms)) | 参数 ^((M)) | FLOPs ^((B)) |
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| [YOLOv8n-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-pose.pt)
    | 640 | 50.4 | 80.1 | 131.8 | 1.18 | 3.3 | 9.2 |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8n-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-pose.pt)
    | 640 | 50.4 | 80.1 | 131.8 | 1.18 | 3.3 | 9.2 |'
- en: '| [YOLOv8s-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-pose.pt)
    | 640 | 60.0 | 86.2 | 233.2 | 1.42 | 11.6 | 30.2 |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8s-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-pose.pt)
    | 640 | 60.0 | 86.2 | 233.2 | 1.42 | 11.6 | 30.2 |'
- en: '| [YOLOv8m-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-pose.pt)
    | 640 | 65.0 | 88.8 | 456.3 | 2.00 | 26.4 | 81.0 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8m-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-pose.pt)
    | 640 | 65.0 | 88.8 | 456.3 | 2.00 | 26.4 | 81.0 |'
- en: '| [YOLOv8l-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-pose.pt)
    | 640 | 67.6 | 90.0 | 784.5 | 2.59 | 44.4 | 168.6 |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8l-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-pose.pt)
    | 640 | 67.6 | 90.0 | 784.5 | 2.59 | 44.4 | 168.6 |'
- en: '| [YOLOv8x-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-pose.pt)
    | 640 | 69.2 | 90.2 | 1607.1 | 3.73 | 69.4 | 263.2 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8x-pose](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-pose.pt)
    | 640 | 69.2 | 90.2 | 1607.1 | 3.73 | 69.4 | 263.2 |'
- en: '| [YOLOv8x-pose-p6](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-pose-p6.pt)
    | 1280 | 71.6 | 91.2 | 4088.7 | 10.04 | 99.1 | 1066.4 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8x-pose-p6](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-pose-p6.pt)
    | 1280 | 71.6 | 91.2 | 4088.7 | 10.04 | 99.1 | 1066.4 |'
- en: '**mAP^(val)** values are for single-model single-scale on [COCO Keypoints val2017](https://cocodataset.org)
    dataset.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mAP^(val)**值适用于[COCO关键点val2017](https://cocodataset.org)数据集上的单一模型单一尺度。'
- en: Reproduce by `yolo val pose data=coco-pose.yaml device=0`
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过`yolo val pose data=coco-pose.yaml device=0`重现
- en: '**Speed** averaged over COCO val images using an [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/)
    instance.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度**是使用[Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/)实例对COCO验证图像进行平均化。'
- en: Reproduce by `yolo val pose data=coco8-pose.yaml batch=1 device=0|cpu`
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过`yolo val pose data=coco8-pose.yaml batch=1 device=0|cpu`重现
- en: Train
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练
- en: Train a YOLOv8-pose model on the COCO128-pose dataset.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在COCO128-pose数据集上训练YOLOv8-pose模型。
- en: Example
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Dataset format
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集格式
- en: YOLO pose dataset format can be found in detail in the Dataset Guide. To convert
    your existing dataset from other formats (like COCO etc.) to YOLO format, please
    use [JSON2YOLO](https://github.com/ultralytics/JSON2YOLO) tool by Ultralytics.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO姿势数据集格式详见数据集指南。要将现有数据集（如COCO等）转换为YOLO格式，请使用[Ultralytics的JSON2YOLO](https://github.com/ultralytics/JSON2YOLO)工具。
- en: Val
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证
- en: Validate trained YOLOv8n-pose model accuracy on the COCO128-pose dataset. No
    argument need to passed as the `model` retains its training `data` and arguments
    as model attributes.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在COCO128-pose数据集上验证训练的YOLOv8n-pose模型准确性。作为模型属性，不需要传递任何参数。
- en: Example
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Predict
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测
- en: Use a trained YOLOv8n-pose model to run predictions on images.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用训练的YOLOv8n-pose模型对图像进行预测。
- en: Example
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: See full `predict` mode details in the Predict page.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测页面查看完整的`predict`模式详细信息。
- en: Export
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导出
- en: Export a YOLOv8n Pose model to a different format like ONNX, CoreML, etc.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 将YOLOv8n Pose模型导出到ONNX、CoreML等不同格式。
- en: Example
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Available YOLOv8-pose export formats are in the table below. You can export
    to any format using the `format` argument, i.e. `format='onnx'` or `format='engine'`.
    You can predict or validate directly on exported models, i.e. `yolo predict model=yolov8n-pose.onnx`.
    Usage examples are shown for your model after export completes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的YOLOv8-pose导出格式如下表所示。您可以使用`format`参数导出到任何格式，例如`format='onnx'`或`format='engine'`。导出完成后，您可以直接在导出的模型上进行预测或验证，例如`yolo
    predict model=yolov8n-pose.onnx`。使用示例在导出模型后显示您的模型。
- en: '| Format | `format` Argument | Model | Metadata | Arguments |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 格式 | `format`参数 | 模型 | 元数据 | 参数 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| [PyTorch](https://pytorch.org/) | - | `yolov8n-pose.pt` | ✅ | - |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| [PyTorch](https://pytorch.org/) | - | `yolov8n-pose.pt` | ✅ | - |'
- en: '| TorchScript | `torchscript` | `yolov8n-pose.torchscript` | ✅ | `imgsz`, `optimize`,
    `batch` |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| TorchScript | `torchscript` | `yolov8n-pose.torchscript` | ✅ | `imgsz`, `optimize`,
    `batch` |'
- en: '| ONNX | `onnx` | `yolov8n-pose.onnx` | ✅ | `imgsz`, `half`, `dynamic`, `simplify`,
    `opset`, `batch` |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| ONNX | `onnx` | `yolov8n-pose.onnx` | ✅ | `imgsz`, `half`, `dynamic`, `simplify`,
    `opset`, `batch` |'
- en: '| OpenVINO | `openvino` | `yolov8n-pose_openvino_model/` | ✅ | `imgsz`, `half`,
    `int8`, `batch`, `dynamic` |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| OpenVINO | `openvino` | `yolov8n-pose_openvino_model/` | ✅ | `imgsz`, `half`,
    `int8`, `batch`, `dynamic` |'
- en: '| TensorRT | `engine` | `yolov8n-pose.engine` | ✅ | `imgsz`, `half`, `dynamic`,
    `simplify`, `workspace`, `int8`, `batch` |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| TensorRT | `engine` | `yolov8n-pose.engine` | ✅ | `imgsz`, `half`, `dynamic`,
    `simplify`, `workspace`, `int8`, `batch` |'
- en: '| CoreML | `coreml` | `yolov8n-pose.mlpackage` | ✅ | `imgsz`, `half`, `int8`,
    `nms`, `batch` |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| CoreML | `coreml` | `yolov8n-pose.mlpackage` | ✅ | `imgsz`, `half`, `int8`,
    `nms`, `batch` |'
- en: '| TF SavedModel | `saved_model` | `yolov8n-pose_saved_model/` | ✅ | `imgsz`,
    `keras`, `int8`, `batch` |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| TF SavedModel | `saved_model` | `yolov8n-pose_saved_model/` | ✅ | `imgsz`,
    `keras`, `int8`, `batch` |'
- en: '| TF GraphDef | `pb` | `yolov8n-pose.pb` | ❌ | `imgsz`, `batch` |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| TF GraphDef | `pb` | `yolov8n-pose.pb` | ❌ | `imgsz`, `batch` |'
- en: '| TF Lite | `tflite` | `yolov8n-pose.tflite` | ✅ | `imgsz`, `half`, `int8`,
    `batch` |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| TF Lite | `tflite` | `yolov8n-pose.tflite` | ✅ | `imgsz`, `half`, `int8`,
    `batch` |'
- en: '| TF Edge TPU | `edgetpu` | `yolov8n-pose_edgetpu.tflite` | ✅ | `imgsz` |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| TF Edge TPU | `edgetpu` | `yolov8n-pose_edgetpu.tflite` | ✅ | `imgsz` |'
- en: '| TF.js | `tfjs` | `yolov8n-pose_web_model/` | ✅ | `imgsz`, `half`, `int8`,
    `batch` |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| TF.js | `tfjs` | `yolov8n-pose_web_model/` | ✅ | `imgsz`, `half`, `int8`,
    `batch` |'
- en: '| PaddlePaddle | `paddle` | `yolov8n-pose_paddle_model/` | ✅ | `imgsz`, `batch`
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| PaddlePaddle | `paddle` | `yolov8n-pose_paddle_model/` | ✅ | `imgsz`, `batch`
    |'
- en: '| NCNN | `ncnn` | `yolov8n-pose_ncnn_model/` | ✅ | `imgsz`, `half`, `batch`
    |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| NCNN | `ncnn` | `yolov8n-pose_ncnn_model/` | ✅ | `imgsz`, `half`, `batch`
    |'
- en: See full `export` details in the Export page.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅导出页面以查看完整的导出细节。
- en: FAQ
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题解答
- en: What is Pose Estimation with Ultralytics YOLOv8 and how does it work?
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是使用Ultralytics YOLOv8进行姿势估计，它是如何工作的？
- en: Pose estimation with Ultralytics YOLOv8 involves identifying specific points,
    known as keypoints, in an image. These keypoints typically represent joints or
    other important features of the object. The output includes the `[x, y]` coordinates
    and confidence scores for each point. YOLOv8-pose models are specifically designed
    for this task and use the `-pose` suffix, such as `yolov8n-pose.pt`. These models
    are pre-trained on datasets like [COCO keypoints](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco-pose.yaml)
    and can be used for various pose estimation tasks. For more information, visit
    the Pose Estimation Page.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Ultralytics YOLOv8进行姿势估计涉及在图像中识别特定点，称为关键点。这些关键点通常代表对象的关节或其他重要特征。输出包括每个点的`[x,
    y]`坐标和置信度分数。YOLOv8-pose模型专门设计用于此任务，并使用`-pose`后缀，如`yolov8n-pose.pt`。这些模型预先在数据集（如[COCO关键点](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco-pose.yaml)）上进行了训练，并可用于各种姿势估计任务。欲了解更多信息，请访问姿势估计页面。
- en: How can I train a YOLOv8-pose model on a custom dataset?
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何在自定义数据集上训练YOLOv8-pose模型？
- en: Training a YOLOv8-pose model on a custom dataset involves loading a model, either
    a new model defined by a YAML file or a pre-trained model. You can then start
    the training process using your specified dataset and parameters.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在自定义数据集上训练YOLOv8-pose模型涉及加载模型，可以是由YAML文件定义的新模型或预训练模型。然后，您可以使用指定的数据集和参数开始训练过程。
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: For comprehensive details on training, refer to the Train Section.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解有关训练的详细信息，请参阅训练部分。
- en: How do I validate a trained YOLOv8-pose model?
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何验证已训练的YOLOv8-pose模型？
- en: 'Validation of a YOLOv8-pose model involves assessing its accuracy using the
    same dataset parameters retained during training. Here''s an example:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 验证YOLOv8-pose模型涉及使用在训练期间保留的相同数据集参数来评估其准确性。以下是一个示例：
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For more information, visit the Val Section.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多信息，请访问验证部分。
- en: Can I export a YOLOv8-pose model to other formats, and how?
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我可以将YOLOv8-pose模型导出为其他格式吗？如何操作？
- en: Yes, you can export a YOLOv8-pose model to various formats like ONNX, CoreML,
    TensorRT, and more. This can be done using either Python or the Command Line Interface
    (CLI).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，您可以将YOLOv8-pose模型导出为ONNX、CoreML、TensorRT等各种格式。可以使用Python或命令行界面（CLI）来完成此操作。
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Refer to the Export Section for more details.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多详细信息，请参阅导出部分。
- en: What are the available Ultralytics YOLOv8-pose models and their performance
    metrics?
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可用的Ultralytics YOLOv8-pose模型及其性能指标是什么？
- en: Ultralytics YOLOv8 offers various pretrained pose models such as YOLOv8n-pose,
    YOLOv8s-pose, YOLOv8m-pose, among others. These models differ in size, accuracy
    (mAP), and speed. For instance, the YOLOv8n-pose model achieves a mAP^(pose)50-95
    of 50.4 and an mAP^(pose)50 of 80.1\. For a complete list and performance details,
    visit the Models Section.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics YOLOv8提供各种预训练姿势模型，如YOLOv8n-pose、YOLOv8s-pose、YOLOv8m-pose等。这些模型在尺寸、准确性（mAP）和速度上有所不同。例如，YOLOv8n-pose模型实现了mAP^(pose)50-95为50.4和mAP^(pose)50为80.1。有关完整列表和性能详细信息，请访问模型部分。
