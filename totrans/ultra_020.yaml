- en: Meituan YOLOv6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/models/yolov6/`](https://docs.ultralytics.com/models/yolov6/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Meituan](https://about.meituan.com/) YOLOv6 is a cutting-edge object detector
    that offers remarkable balance between speed and accuracy, making it a popular
    choice for real-time applications. This model introduces several notable enhancements
    on its architecture and training scheme, including the implementation of a Bi-directional
    Concatenation (BiC) module, an anchor-aided training (AAT) strategy, and an improved
    backbone and neck design for state-of-the-art accuracy on the COCO dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Meituan YOLOv6](img/fe0809dd4db6eee8f8a602e37687b42c.png) ![Model example
    image](img/bf4a306e2ae2fcd590bfec78ca794a37.png) **Overview of YOLOv6.** Model
    architecture diagram showing the redesigned network components and training strategies
    that have led to significant performance improvements. (a) The neck of YOLOv6
    (N and S are shown). Note for M/L, RepBlocks is replaced with CSPStackRep. (b)
    The structure of a BiC module. (c) A SimCSPSPPF block. ([source](https://arxiv.org/pdf/2301.05586.pdf)).'
  prefs: []
  type: TYPE_NORMAL
- en: Key Features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Bidirectional Concatenation (BiC) Module:** YOLOv6 introduces a BiC module
    in the neck of the detector, enhancing localization signals and delivering performance
    gains with negligible speed degradation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anchor-Aided Training (AAT) Strategy:** This model proposes AAT to enjoy
    the benefits of both anchor-based and anchor-free paradigms without compromising
    inference efficiency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhanced Backbone and Neck Design:** By deepening YOLOv6 to include another
    stage in the backbone and neck, this model achieves state-of-the-art performance
    on the COCO dataset at high-resolution input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Self-Distillation Strategy:** A new self-distillation strategy is implemented
    to boost the performance of smaller models of YOLOv6, enhancing the auxiliary
    regression branch during training and removing it at inference to avoid a marked
    speed decline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'YOLOv6 provides various pre-trained models with different scales:'
  prefs: []
  type: TYPE_NORMAL
- en: 'YOLOv6-N: 37.5% AP on COCO val2017 at 1187 FPS with NVIDIA Tesla T4 GPU.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'YOLOv6-S: 45.0% AP at 484 FPS.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'YOLOv6-M: 50.0% AP at 226 FPS.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'YOLOv6-L: 52.8% AP at 116 FPS.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'YOLOv6-L6: State-of-the-art accuracy in real-time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: YOLOv6 also provides quantized models for different precisions and models optimized
    for mobile platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Usage Examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This example provides simple YOLOv6 training and inference examples. For full
    documentation on these and other modes see the Predict, Train, Val and Export
    docs pages.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: 'PyTorch pretrained `*.pt` models as well as configuration `*.yaml` files can
    be passed to the `YOLO()` class to create a model instance in python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'CLI commands are available to directly run the models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Supported Tasks and Modes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The YOLOv6 series offers a range of models, each optimized for high-performance
    Object Detection. These models cater to varying computational needs and accuracy
    requirements, making them versatile for a wide array of applications.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model Type | Pre-trained Weights | Tasks Supported | Inference | Validation
    | Training | Export |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv6-N | `yolov6-n.pt` | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv6-S | `yolov6-s.pt` | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv6-M | `yolov6-m.pt` | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv6-L | `yolov6-l.pt` | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv6-L6 | `yolov6-l6.pt` | Object Detection | ✅ | ✅ | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: This table provides a detailed overview of the YOLOv6 model variants, highlighting
    their capabilities in object detection tasks and their compatibility with various
    operational modes such as Inference, Validation, Training, and Export. This comprehensive
    support ensures that users can fully leverage the capabilities of YOLOv6 models
    in a broad range of object detection scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Citations and Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We would like to acknowledge the authors for their significant contributions
    in the field of real-time object detection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The original YOLOv6 paper can be found on [arXiv](https://arxiv.org/abs/2301.05586).
    The authors have made their work publicly available, and the codebase can be accessed
    on [GitHub](https://github.com/meituan/YOLOv6). We appreciate their efforts in
    advancing the field and making their work accessible to the broader community.
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is Meituan YOLOv6 and what makes it unique?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Meituan YOLOv6 is a state-of-the-art object detector that balances speed and
    accuracy, ideal for real-time applications. It features notable architectural
    enhancements like the Bi-directional Concatenation (BiC) module and an Anchor-Aided
    Training (AAT) strategy. These innovations provide substantial performance gains
    with minimal speed degradation, making YOLOv6 a competitive choice for object
    detection tasks.
  prefs: []
  type: TYPE_NORMAL
- en: How does the Bi-directional Concatenation (BiC) Module in YOLOv6 improve performance?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Bi-directional Concatenation (BiC) module in YOLOv6 enhances localization
    signals in the detector's neck, delivering performance improvements with negligible
    speed impact. This module effectively combines different feature maps, increasing
    the model's ability to detect objects accurately. For more details on YOLOv6's
    features, refer to the Key Features section.
  prefs: []
  type: TYPE_NORMAL
- en: How can I train a YOLOv6 model using Ultralytics?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can train a YOLOv6 model using Ultralytics with simple Python or CLI commands.
    For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: For more information, visit the Train page.
  prefs: []
  type: TYPE_NORMAL
- en: What are the different versions of YOLOv6 and their performance metrics?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'YOLOv6 offers multiple versions, each optimized for different performance requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: 'YOLOv6-N: 37.5% AP at 1187 FPS'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'YOLOv6-S: 45.0% AP at 484 FPS'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'YOLOv6-M: 50.0% AP at 226 FPS'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'YOLOv6-L: 52.8% AP at 116 FPS'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'YOLOv6-L6: State-of-the-art accuracy in real-time scenarios'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These models are evaluated on the COCO dataset using an NVIDIA Tesla T4 GPU.
    For more on performance metrics, see the Performance Metrics section.
  prefs: []
  type: TYPE_NORMAL
- en: How does the Anchor-Aided Training (AAT) strategy benefit YOLOv6?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Anchor-Aided Training (AAT) in YOLOv6 combines elements of anchor-based and
    anchor-free approaches, enhancing the model's detection capabilities without compromising
    inference efficiency. This strategy leverages anchors during training to improve
    bounding box predictions, making YOLOv6 effective in diverse object detection
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Which operational modes are supported by YOLOv6 models in Ultralytics?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv6 supports various operational modes including Inference, Validation, Training,
    and Export. This flexibility allows users to fully exploit the model's capabilities
    in different scenarios. Check out the Supported Tasks and Modes section for a
    detailed overview of each mode.
  prefs: []
  type: TYPE_NORMAL
