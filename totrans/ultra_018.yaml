- en: 'YOLOv4: High-Speed and Precise Object Detection'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: YOLOv4：高速和精确的物体检测
- en: 原文：[`docs.ultralytics.com/models/yolov4/`](https://docs.ultralytics.com/models/yolov4/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/models/yolov4/`](https://docs.ultralytics.com/models/yolov4/)
- en: Welcome to the Ultralytics documentation page for YOLOv4, a state-of-the-art,
    real-time object detector launched in 2020 by Alexey Bochkovskiy at [`github.com/AlexeyAB/darknet`](https://github.com/AlexeyAB/darknet).
    YOLOv4 is designed to provide the optimal balance between speed and accuracy,
    making it an excellent choice for many applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎访问Ultralytics关于YOLOv4的文档页面，这是一款由Alexey Bochkovskiy于2020年推出的最先进的实时物体检测器，托管在[`github.com/AlexeyAB/darknet`](https://github.com/AlexeyAB/darknet)。YOLOv4旨在提供速度和准确性之间的最佳平衡，使其成为许多应用的优秀选择。
- en: '![YOLOv4 architecture diagram](img/061ca1dd8072de2fda4f60564bb8a6f7.png) **YOLOv4
    architecture diagram**. Showcasing the intricate network design of YOLOv4, including
    the backbone, neck, and head components, and their interconnected layers for optimal
    real-time object detection.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '![YOLOv4架构图](img/061ca1dd8072de2fda4f60564bb8a6f7.png) **YOLOv4架构图**。展示了YOLOv4的复杂网络设计，包括主干、颈部和头部组件及其互连层，以实现最佳的实时物体检测。'
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: YOLOv4 stands for You Only Look Once version 4\. It is a real-time object detection
    model developed to address the limitations of previous YOLO versions like YOLOv3
    and other object detection models. Unlike other convolutional neural network (CNN)
    based object detectors, YOLOv4 is not only applicable for recommendation systems
    but also for standalone process management and human input reduction. Its operation
    on conventional graphics processing units (GPUs) allows for mass usage at an affordable
    price, and it is designed to work in real-time on a conventional GPU while requiring
    only one such GPU for training.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv4代表You Only Look Once第4版。它是一种实时物体检测模型，旨在解决之前YOLO版本（如YOLOv3）和其他物体检测模型的局限性。与其他基于卷积神经网络（CNN）的物体检测器不同，YOLOv4不仅适用于推荐系统，还适用于独立的过程管理和人员输入减少。它在传统图形处理单元（GPU）上的运行使得可以以实惠的价格进行大规模使用，并且设计成能在传统GPU上实时工作，仅需要一台这样的GPU进行训练。
- en: Architecture
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构
- en: YOLOv4 makes use of several innovative features that work together to optimize
    its performance. These include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections
    (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT),
    Mish-activation, Mosaic data augmentation, DropBlock regularization, and CIoU
    loss. These features are combined to achieve state-of-the-art results.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv4利用几种创新功能共同优化其性能。这些功能包括加权残差连接（WRC）、跨阶段部分连接（CSP）、交叉小批量归一化（CmBN）、自对抗训练（SAT）、Mish激活、马赛克数据增强、DropBlock正则化和CIoU损失。这些特性结合起来实现了最先进的结果。
- en: A typical object detector is composed of several parts including the input,
    the backbone, the neck, and the head. The backbone of YOLOv4 is pre-trained on
    ImageNet and is used to predict classes and bounding boxes of objects. The backbone
    could be from several models including VGG, ResNet, ResNeXt, or DenseNet. The
    neck part of the detector is used to collect feature maps from different stages
    and usually includes several bottom-up paths and several top-down paths. The head
    part is what is used to make the final object detections and classifications.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的物体检测器由几部分组成，包括输入、主干、颈部和头部。YOLOv4的主干在ImageNet上进行了预训练，并用于预测物体的类别和边界框。主干可以来自多个模型，包括VGG、ResNet、ResNeXt或DenseNet。检测器的颈部用于从不同阶段收集特征图，通常包括多个自底向上的路径和多个自顶向下的路径。头部部分用于进行最终的物体检测和分类。
- en: Bag of Freebies
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Bag of Freebies
- en: YOLOv4 also makes use of methods known as "bag of freebies," which are techniques
    that improve the accuracy of the model during training without increasing the
    cost of inference. Data augmentation is a common bag of freebies technique used
    in object detection, which increases the variability of the input images to improve
    the robustness of the model. Some examples of data augmentation include photometric
    distortions (adjusting the brightness, contrast, hue, saturation, and noise of
    an image) and geometric distortions (adding random scaling, cropping, flipping,
    and rotating). These techniques help the model to generalize better to different
    types of images.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv4还利用被称为“freebies包”的方法，这些技术在训练期间提高模型的准确性而不增加推理成本。数据增强是物体检测中常用的freebies包技术，它增加输入图像的变化，以提高模型的鲁棒性。一些数据增强的例子包括光度失真（调整图像的亮度、对比度、色调、饱和度和噪声）和几何失真（添加随机缩放、裁剪、翻转和旋转）。这些技术有助于模型更好地泛化到不同类型的图像。
- en: Features and Performance
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特性和性能
- en: YOLOv4 is designed for optimal speed and accuracy in object detection. The architecture
    of YOLOv4 includes CSPDarknet53 as the backbone, PANet as the neck, and YOLOv3
    as the detection head. This design allows YOLOv4 to perform object detection at
    an impressive speed, making it suitable for real-time applications. YOLOv4 also
    excels in accuracy, achieving state-of-the-art results in object detection benchmarks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv4旨在在目标检测中实现最佳的速度和准确性。YOLOv4的架构包括CSPDarknet53作为骨干网络，PANet作为颈部，YOLOv3作为检测头。这种设计使YOLOv4能够以令人印象深刻的速度进行目标检测，使其适用于实时应用。YOLOv4在准确性方面也表现出色，在目标检测基准测试中取得了最新的成果。
- en: Usage Examples
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用示例
- en: As of the time of writing, Ultralytics does not currently support YOLOv4 models.
    Therefore, any users interested in using YOLOv4 will need to refer directly to
    the YOLOv4 GitHub repository for installation and usage instructions.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写时，Ultralytics当前不支持YOLOv4模型。因此，有兴趣使用YOLOv4的用户需要直接参考YOLOv4 GitHub存储库获取安装和使用说明。
- en: 'Here is a brief overview of the typical steps you might take to use YOLOv4:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是您可能用来使用YOLOv4的典型步骤的简要概述：
- en: 'Visit the YOLOv4 GitHub repository: [`github.com/AlexeyAB/darknet`](https://github.com/AlexeyAB/darknet).'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问YOLOv4 GitHub存储库：[`github.com/AlexeyAB/darknet`](https://github.com/AlexeyAB/darknet)。
- en: Follow the instructions provided in the README file for installation. This typically
    involves cloning the repository, installing necessary dependencies, and setting
    up any necessary environment variables.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照README文件中提供的说明进行安装。通常包括克隆存储库，安装必要的依赖项，并设置任何必要的环境变量。
- en: Once installation is complete, you can train and use the model as per the usage
    instructions provided in the repository. This usually involves preparing your
    dataset, configuring the model parameters, training the model, and then using
    the trained model to perform object detection.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装完成后，按照存储库中提供的使用说明训练和使用模型。通常包括准备数据集，配置模型参数，训练模型，然后使用训练好的模型进行目标检测。
- en: Please note that the specific steps may vary depending on your specific use
    case and the current state of the YOLOv4 repository. Therefore, it is strongly
    recommended to refer directly to the instructions provided in the YOLOv4 GitHub
    repository.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，具体步骤可能因您的具体用例和YOLOv4存储库的当前状态而异。因此，强烈建议直接参考YOLOv4 GitHub存储库中提供的说明。
- en: We regret any inconvenience this may cause and will strive to update this document
    with usage examples for Ultralytics once support for YOLOv4 is implemented.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对可能引起的任何不便表示歉意，并将努力更新此文档，以包含Ultralytics对YOLOv4实现支持后的使用示例。
- en: Conclusion
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: YOLOv4 is a powerful and efficient object detection model that strikes a balance
    between speed and accuracy. Its use of unique features and bag of freebies techniques
    during training allows it to perform excellently in real-time object detection
    tasks. YOLOv4 can be trained and used by anyone with a conventional GPU, making
    it accessible and practical for a wide range of applications.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv4是一种强大且高效的目标检测模型，它在速度和准确性之间取得了良好的平衡。它在训练期间采用独特的特性和freebies包技术，使其在实时目标检测任务中表现出色。YOLOv4可以由任何具有常规GPU的人进行训练和使用，使其对各种应用都具有可访问性和实用性。
- en: Citations and Acknowledgements
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引用和致谢
- en: 'We would like to acknowledge the YOLOv4 authors for their significant contributions
    in the field of real-time object detection:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢YOLOv4的作者在实时目标检测领域做出的重要贡献：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The original YOLOv4 paper can be found on [arXiv](https://arxiv.org/abs/2004.10934).
    The authors have made their work publicly available, and the codebase can be accessed
    on [GitHub](https://github.com/AlexeyAB/darknet). We appreciate their efforts
    in advancing the field and making their work accessible to the broader community.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is YOLOv4 and why should I use it for object detection?
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv4, which stands for "You Only Look Once version 4," is a state-of-the-art
    real-time object detection model developed by Alexey Bochkovskiy in 2020\. It
    achieves an optimal balance between speed and accuracy, making it highly suitable
    for real-time applications. YOLOv4's architecture incorporates several innovative
    features like Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections
    (CSP), and Self-adversarial-training (SAT), among others, to achieve state-of-the-art
    results. If you're looking for a high-performance model that operates efficiently
    on conventional GPUs, YOLOv4 is an excellent choice.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: How does the architecture of YOLOv4 enhance its performance?
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The architecture of YOLOv4 includes several key components: the backbone, the
    neck, and the head. The backbone, which can be models like VGG, ResNet, or CSPDarknet53,
    is pre-trained to predict classes and bounding boxes. The neck, utilizing PANet,
    connects feature maps from different stages for comprehensive data extraction.
    Finally, the head, which uses configurations from YOLOv3, makes the final object
    detections. YOLOv4 also employs "bag of freebies" techniques like mosaic data
    augmentation and DropBlock regularization, further optimizing its speed and accuracy.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: What are "bag of freebies" in the context of YOLOv4?
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '"Bag of freebies" refers to methods that improve the training accuracy of YOLOv4
    without increasing the cost of inference. These techniques include various forms
    of data augmentation like photometric distortions (adjusting brightness, contrast,
    etc.) and geometric distortions (scaling, cropping, flipping, rotating). By increasing
    the variability of the input images, these augmentations help YOLOv4 generalize
    better to different types of images, thereby improving its robustness and accuracy
    without compromising its real-time performance.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Why is YOLOv4 considered suitable for real-time object detection on conventional
    GPUs?
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: YOLOv4 is designed to optimize both speed and accuracy, making it ideal for
    real-time object detection tasks that require quick and reliable performance.
    It operates efficiently on conventional GPUs, needing only one for both training
    and inference. This makes it accessible and practical for various applications
    ranging from recommendation systems to standalone process management, thereby
    reducing the need for extensive hardware setups and making it a cost-effective
    solution for real-time object detection.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: How can I get started with YOLOv4 if Ultralytics does not currently support
    it?
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To get started with YOLOv4, you should visit the official [YOLOv4 GitHub repository](https://github.com/AlexeyAB/darknet).
    Follow the installation instructions provided in the README file, which typically
    include cloning the repository, installing dependencies, and setting up environment
    variables. Once installed, you can train the model by preparing your dataset,
    configuring the model parameters, and following the usage instructions provided.
    Since Ultralytics does not currently support YOLOv4, it is recommended to refer
    directly to the YOLOv4 GitHub for the most up-to-date and detailed guidance.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用YOLOv4，请访问官方[YOLOv4 GitHub 代码库](https://github.com/AlexeyAB/darknet)。按照
    README 文件中提供的安装说明操作，通常包括克隆代码库、安装依赖项和设置环境变量。安装完成后，您可以通过准备数据集、配置模型参数和按照提供的使用说明来训练模型。由于Ultralytics目前不支持YOLOv4，建议直接参考YOLOv4
    GitHub获取最新和详细的指导。
