- en: COCO Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/datasets/detect/coco/`](https://docs.ultralytics.com/datasets/detect/coco/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The [COCO](https://cocodataset.org/#home) (Common Objects in Context) dataset
    is a large-scale object detection, segmentation, and captioning dataset. It is
    designed to encourage research on a wide variety of object categories and is commonly
    used for benchmarking computer vision models. It is an essential dataset for researchers
    and developers working on object detection, segmentation, and pose estimation
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '[`www.youtube.com/embed/uDrn9QZJ2lk`](https://www.youtube.com/embed/uDrn9QZJ2lk)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch:** Ultralytics COCO Dataset Overview'
  prefs: []
  type: TYPE_NORMAL
- en: COCO Pretrained Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)
    | 640 | 37.3 | 80.4 | 0.99 | 3.2 | 8.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)
    | 640 | 44.9 | 128.4 | 1.20 | 11.2 | 28.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)
    | 640 | 50.2 | 234.7 | 1.83 | 25.9 | 78.9 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt)
    | 640 | 52.9 | 375.2 | 2.39 | 43.7 | 165.2 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt)
    | 640 | 53.9 | 479.1 | 3.53 | 68.2 | 257.8 |'
  prefs: []
  type: TYPE_TB
- en: Key Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: COCO contains 330K images, with 200K images having annotations for object detection,
    segmentation, and captioning tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dataset comprises 80 object categories, including common objects like cars,
    bicycles, and animals, as well as more specific categories such as umbrellas,
    handbags, and sports equipment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Annotations include object bounding boxes, segmentation masks, and captions
    for each image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: COCO provides standardized evaluation metrics like mean Average Precision (mAP)
    for object detection, and mean Average Recall (mAR) for segmentation tasks, making
    it suitable for comparing model performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset Structure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The COCO dataset is split into three subsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Train2017**: This subset contains 118K images for training object detection,
    segmentation, and captioning models.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Val2017**: This subset has 5K images used for validation purposes during
    model training.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Test2017**: This subset consists of 20K images used for testing and benchmarking
    the trained models. Ground truth annotations for this subset are not publicly
    available, and the results are submitted to the [COCO evaluation server](https://codalab.lisn.upsaclay.fr/competitions/7384)
    for performance evaluation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The COCO dataset is widely used for training and evaluating deep learning models
    in object detection (such as YOLO, Faster R-CNN, and SSD), instance segmentation
    (such as Mask R-CNN), and keypoint detection (such as OpenPose). The dataset's
    diverse set of object categories, large number of annotated images, and standardized
    evaluation metrics make it an essential resource for computer vision researchers
    and practitioners.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset YAML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A YAML (Yet Another Markup Language) file is used to define the dataset configuration.
    It contains information about the dataset's paths, classes, and other relevant
    information. In the case of the COCO dataset, the `coco.yaml` file is maintained
    at [`github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml).
  prefs: []
  type: TYPE_NORMAL
- en: ultralytics/cfg/datasets/coco.yaml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To train a YOLOv8n model on the COCO dataset for 100 epochs with an image size
    of 640, you can use the following code snippets. For a comprehensive list of available
    arguments, refer to the model Training page.
  prefs: []
  type: TYPE_NORMAL
- en: Train Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Sample Images and Annotations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The COCO dataset contains a diverse set of images with various object categories
    and complex scenes. Here are some examples of images from the dataset, along with
    their corresponding annotations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dataset sample image](img/f2aa95e453433e4aff2ebd64f746d29b.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Mosaiced Image**: This image demonstrates a training batch composed of mosaiced
    dataset images. Mosaicing is a technique used during training that combines multiple
    images into a single image to increase the variety of objects and scenes within
    each training batch. This helps improve the model''s ability to generalize to
    different object sizes, aspect ratios, and contexts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The example showcases the variety and complexity of the images in the COCO dataset
    and the benefits of using mosaicing during the training process.
  prefs: []
  type: TYPE_NORMAL
- en: Citations and Acknowledgments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you use the COCO dataset in your research or development work, please cite
    the following paper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We would like to acknowledge the COCO Consortium for creating and maintaining
    this valuable resource for the computer vision community. For more information
    about the COCO dataset and its creators, visit the [COCO dataset website](https://cocodataset.org/#home).
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is the COCO dataset and why is it important for computer vision?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The [COCO dataset](https://cocodataset.org/#home) (Common Objects in Context)
    is a large-scale dataset used for object detection, segmentation, and captioning.
    It contains 330K images with detailed annotations for 80 object categories, making
    it essential for benchmarking and training computer vision models. Researchers
    use COCO due to its diverse categories and standardized evaluation metrics like
    mean Average Precision (mAP).
  prefs: []
  type: TYPE_NORMAL
- en: How can I train a YOLO model using the COCO dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To train a YOLOv8 model using the COCO dataset, you can use the following code
    snippets:'
  prefs: []
  type: TYPE_NORMAL
- en: Train Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Refer to the Training page for more details on available arguments.
  prefs: []
  type: TYPE_NORMAL
- en: What are the key features of the COCO dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The COCO dataset includes:'
  prefs: []
  type: TYPE_NORMAL
- en: 330K images, with 200K annotated for object detection, segmentation, and captioning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 80 object categories ranging from common items like cars and animals to specific
    ones like handbags and sports equipment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Standardized evaluation metrics for object detection (mAP) and segmentation
    (mean Average Recall, mAR).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mosaicing** technique in training batches to enhance model generalization
    across various object sizes and contexts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where can I find pretrained YOLOv8 models trained on the COCO dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Pretrained YOLOv8 models on the COCO dataset can be downloaded from the links
    provided in the documentation. Examples include:'
  prefs: []
  type: TYPE_NORMAL
- en: '[YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These models vary in size, mAP, and inference speed, providing options for different
    performance and resource requirements.
  prefs: []
  type: TYPE_NORMAL
- en: How is the COCO dataset structured and how do I use it?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The COCO dataset is split into three subsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Train2017**: 118K images for training.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Val2017**: 5K images for validation during training.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Test2017**: 20K images for benchmarking trained models. Results need to be
    submitted to the [COCO evaluation server](https://codalab.lisn.upsaclay.fr/competitions/7384)
    for performance evaluation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The dataset's YAML configuration file is available at [coco.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml),
    which defines paths, classes, and dataset details.
  prefs: []
  type: TYPE_NORMAL
