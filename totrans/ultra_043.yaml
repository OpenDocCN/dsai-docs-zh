- en: Open Images V7 Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/datasets/detect/open-images-v7/`](https://docs.ultralytics.com/datasets/detect/open-images-v7/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Open Images V7](https://storage.googleapis.com/openimages/web/index.html)
    is a versatile and expansive dataset championed by Google. Aimed at propelling
    research in the realm of computer vision, it boasts a vast collection of images
    annotated with a plethora of data, including image-level labels, object bounding
    boxes, object segmentation masks, visual relationships, and localized narratives.'
  prefs: []
  type: TYPE_NORMAL
- en: '[`www.youtube.com/embed/u3pLlgzUeV8`](https://www.youtube.com/embed/u3pLlgzUeV8)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Watch:** Object Detection using OpenImagesV7 Pretrained Model'
  prefs: []
  type: TYPE_NORMAL
- en: Open Images V7 Pretrained Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-oiv7.pt)
    | 640 | 18.4 | 142.4 | 1.21 | 3.5 | 10.5 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-oiv7.pt)
    | 640 | 27.7 | 183.1 | 1.40 | 11.4 | 29.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-oiv7.pt)
    | 640 | 33.6 | 408.5 | 2.26 | 26.2 | 80.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-oiv7.pt)
    | 640 | 34.9 | 596.9 | 2.43 | 44.1 | 167.4 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-oiv7.pt)
    | 640 | 36.3 | 860.6 | 3.56 | 68.7 | 260.6 |'
  prefs: []
  type: TYPE_TB
- en: '![Open Images V7 classes visual](img/7c2d0288343fcb2bd8111441fe64b145.png)'
  prefs: []
  type: TYPE_IMG
- en: Key Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Encompasses ~9M images annotated in various ways to suit multiple computer vision
    tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Houses a staggering 16M bounding boxes across 600 object classes in 1.9M images.
    These boxes are primarily hand-drawn by experts ensuring high precision.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visual relationship annotations totaling 3.3M are available, detailing 1,466
    unique relationship triplets, object properties, and human activities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: V5 introduced segmentation masks for 2.8M objects across 350 classes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: V6 introduced 675k localized narratives that amalgamate voice, text, and mouse
    traces highlighting described objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: V7 introduced 66.4M point-level labels on 1.4M images, spanning 5,827 classes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encompasses 61.4M image-level labels across a diverse set of 20,638 classes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provides a unified platform for image classification, object detection, relationship
    detection, instance segmentation, and multimodal image descriptions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset Structure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Open Images V7 is structured in multiple components catering to varied computer
    vision challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Images**: About 9 million images, often showcasing intricate scenes with
    an average of 8.3 objects per image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bounding Boxes**: Over 16 million boxes that demarcate objects across 600
    categories.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Segmentation Masks**: These detail the exact boundary of 2.8M objects across
    350 classes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visual Relationships**: 3.3M annotations indicating object relationships,
    properties, and actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Localized Narratives**: 675k descriptions combining voice, text, and mouse
    traces.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Point-Level Labels**: 66.4M labels across 1.4M images, suitable for zero/few-shot
    semantic segmentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Open Images V7 is a cornerstone for training and evaluating state-of-the-art
    models in various computer vision tasks. The dataset's broad scope and high-quality
    annotations make it indispensable for researchers and developers specializing
    in computer vision.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset YAML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Typically, datasets come with a YAML (Yet Another Markup Language) file that
    delineates the dataset's configuration. For the case of Open Images V7, a hypothetical
    `OpenImagesV7.yaml` might exist. For accurate paths and configurations, one should
    refer to the dataset's official repository or documentation.
  prefs: []
  type: TYPE_NORMAL
- en: OpenImagesV7.yaml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To train a YOLOv8n model on the Open Images V7 dataset for 100 epochs with an
    image size of 640, you can use the following code snippets. For a comprehensive
    list of available arguments, refer to the model Training page.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs: []
  type: TYPE_NORMAL
- en: The complete Open Images V7 dataset comprises 1,743,042 training images and
    41,620 validation images, requiring approximately **561 GB of storage space**
    upon download.
  prefs: []
  type: TYPE_NORMAL
- en: 'Executing the commands provided below will trigger an automatic download of
    the full dataset if it''s not already present locally. Before running the below
    example it''s crucial to:'
  prefs: []
  type: TYPE_NORMAL
- en: Verify that your device has enough storage capacity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure a robust and speedy internet connection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Train Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Sample Data and Annotations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Illustrations of the dataset help provide insights into its richness:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dataset sample image](img/38cf6c99add645a565b3f5ed41237ab9.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Open Images V7**: This image exemplifies the depth and detail of annotations
    available, including bounding boxes, relationships, and segmentation masks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Researchers can gain invaluable insights into the array of computer vision challenges
    that the dataset addresses, from basic object detection to intricate relationship
    identification.
  prefs: []
  type: TYPE_NORMAL
- en: Citations and Acknowledgments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For those employing Open Images V7 in their work, it''s prudent to cite the
    relevant papers and acknowledge the creators:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: A heartfelt acknowledgment goes out to the Google AI team for creating and maintaining
    the Open Images V7 dataset. For a deep dive into the dataset and its offerings,
    navigate to the [official Open Images V7 website](https://storage.googleapis.com/openimages/web/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is the Open Images V7 dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Open Images V7 is an extensive and versatile dataset created by Google, designed
    to advance research in computer vision. It includes image-level labels, object
    bounding boxes, object segmentation masks, visual relationships, and localized
    narratives, making it ideal for various computer vision tasks such as object detection,
    segmentation, and relationship detection.
  prefs: []
  type: TYPE_NORMAL
- en: How do I train a YOLOv8 model on the Open Images V7 dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To train a YOLOv8 model on the Open Images V7 dataset, you can use both Python
    and CLI commands. Here''s an example of training the YOLOv8n model for 100 epochs
    with an image size of 640:'
  prefs: []
  type: TYPE_NORMAL
- en: Train Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: For more details on arguments and settings, refer to the Training page.
  prefs: []
  type: TYPE_NORMAL
- en: What are some key features of the Open Images V7 dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Open Images V7 dataset includes approximately 9 million images with various
    annotations: - **Bounding Boxes**: 16 million bounding boxes across 600 object
    classes. - **Segmentation Masks**: Masks for 2.8 million objects across 350 classes.
    - **Visual Relationships**: 3.3 million annotations indicating relationships,
    properties, and actions. - **Localized Narratives**: 675,000 descriptions combining
    voice, text, and mouse traces. - **Point-Level Labels**: 66.4 million labels across
    1.4 million images. - **Image-Level Labels**: 61.4 million labels across 20,638
    classes.'
  prefs: []
  type: TYPE_NORMAL
- en: What pretrained models are available for the Open Images V7 dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Ultralytics provides several YOLOv8 pretrained models for the Open Images V7
    dataset, each with different sizes and performance metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-oiv7.pt)
    | 640 | 18.4 | 142.4 | 1.21 | 3.5 | 10.5 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-oiv7.pt)
    | 640 | 27.7 | 183.1 | 1.40 | 11.4 | 29.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-oiv7.pt)
    | 640 | 33.6 | 408.5 | 2.26 | 26.2 | 80.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-oiv7.pt)
    | 640 | 34.9 | 596.9 | 2.43 | 44.1 | 167.4 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-oiv7.pt)
    | 640 | 36.3 | 860.6 | 3.56 | 68.7 | 260.6 |'
  prefs: []
  type: TYPE_TB
- en: What applications can the Open Images V7 dataset be used for?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Open Images V7 dataset supports a variety of computer vision tasks including:
    - **Image Classification** - **Object Detection** - **Instance Segmentation**
    - **Visual Relationship Detection** - **Multimodal Image Descriptions**'
  prefs: []
  type: TYPE_NORMAL
- en: Its comprehensive annotations and broad scope make it suitable for training
    and evaluating advanced machine learning models, as highlighted in practical use
    cases detailed in our applications section.
  prefs: []
  type: TYPE_NORMAL
