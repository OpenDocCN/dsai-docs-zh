["```py\nIn [1]: import datetime\n\nIn [2]: dti = pd.to_datetime(\n ...:    [\"1/1/2018\", np.datetime64(\"2018-01-01\"), datetime.datetime(2018, 1, 1)]\n ...: )\n ...: \n\nIn [3]: dti\nOut[3]: DatetimeIndex(['2018-01-01', '2018-01-01', '2018-01-01'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [4]: dti = pd.date_range(\"2018-01-01\", periods=3, freq=\"h\")\n\nIn [5]: dti\nOut[5]: \nDatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 01:00:00',\n '2018-01-01 02:00:00'],\n dtype='datetime64[ns]', freq='h') \n```", "```py\nIn [6]: dti = dti.tz_localize(\"UTC\")\n\nIn [7]: dti\nOut[7]: \nDatetimeIndex(['2018-01-01 00:00:00+00:00', '2018-01-01 01:00:00+00:00',\n '2018-01-01 02:00:00+00:00'],\n dtype='datetime64[ns, UTC]', freq='h')\n\nIn [8]: dti.tz_convert(\"US/Pacific\")\nOut[8]: \nDatetimeIndex(['2017-12-31 16:00:00-08:00', '2017-12-31 17:00:00-08:00',\n '2017-12-31 18:00:00-08:00'],\n dtype='datetime64[ns, US/Pacific]', freq='h') \n```", "```py\nIn [9]: idx = pd.date_range(\"2018-01-01\", periods=5, freq=\"h\")\n\nIn [10]: ts = pd.Series(range(len(idx)), index=idx)\n\nIn [11]: ts\nOut[11]: \n2018-01-01 00:00:00    0\n2018-01-01 01:00:00    1\n2018-01-01 02:00:00    2\n2018-01-01 03:00:00    3\n2018-01-01 04:00:00    4\nFreq: h, dtype: int64\n\nIn [12]: ts.resample(\"2h\").mean()\nOut[12]: \n2018-01-01 00:00:00    0.5\n2018-01-01 02:00:00    2.5\n2018-01-01 04:00:00    4.0\nFreq: 2h, dtype: float64 \n```", "```py\nIn [13]: friday = pd.Timestamp(\"2018-01-05\")\n\nIn [14]: friday.day_name()\nOut[14]: 'Friday'\n\n# Add 1 day\nIn [15]: saturday = friday + pd.Timedelta(\"1 day\")\n\nIn [16]: saturday.day_name()\nOut[16]: 'Saturday'\n\n# Add 1 business day (Friday --> Monday)\nIn [17]: monday = friday + pd.offsets.BDay()\n\nIn [18]: monday.day_name()\nOut[18]: 'Monday' \n```", "```py\nIn [19]: pd.Series(range(3), index=pd.date_range(\"2000\", freq=\"D\", periods=3))\nOut[19]: \n2000-01-01    0\n2000-01-02    1\n2000-01-03    2\nFreq: D, dtype: int64 \n```", "```py\nIn [20]: pd.Series(pd.date_range(\"2000\", freq=\"D\", periods=3))\nOut[20]: \n0   2000-01-01\n1   2000-01-02\n2   2000-01-03\ndtype: datetime64[ns] \n```", "```py\nIn [21]: pd.Series(pd.period_range(\"1/1/2011\", freq=\"M\", periods=3))\nOut[21]: \n0    2011-01\n1    2011-02\n2    2011-03\ndtype: period[M]\n\nIn [22]: pd.Series([pd.DateOffset(1), pd.DateOffset(2)])\nOut[22]: \n0         <DateOffset>\n1    <2 * DateOffsets>\ndtype: object\n\nIn [23]: pd.Series(pd.date_range(\"1/1/2011\", freq=\"ME\", periods=3))\nOut[23]: \n0   2011-01-31\n1   2011-02-28\n2   2011-03-31\ndtype: datetime64[ns] \n```", "```py\nIn [24]: pd.Timestamp(pd.NaT)\nOut[24]: NaT\n\nIn [25]: pd.Timedelta(pd.NaT)\nOut[25]: NaT\n\nIn [26]: pd.Period(pd.NaT)\nOut[26]: NaT\n\n# Equality acts as np.nan would\nIn [27]: pd.NaT == pd.NaT\nOut[27]: False \n```", "```py\nIn [28]: import datetime\n\nIn [29]: pd.Timestamp(datetime.datetime(2012, 5, 1))\nOut[29]: Timestamp('2012-05-01 00:00:00')\n\nIn [30]: pd.Timestamp(\"2012-05-01\")\nOut[30]: Timestamp('2012-05-01 00:00:00')\n\nIn [31]: pd.Timestamp(2012, 5, 1)\nOut[31]: Timestamp('2012-05-01 00:00:00') \n```", "```py\nIn [32]: pd.Period(\"2011-01\")\nOut[32]: Period('2011-01', 'M')\n\nIn [33]: pd.Period(\"2012-05\", freq=\"D\")\nOut[33]: Period('2012-05-01', 'D') \n```", "```py\nIn [34]: dates = [\n ....:    pd.Timestamp(\"2012-05-01\"),\n ....:    pd.Timestamp(\"2012-05-02\"),\n ....:    pd.Timestamp(\"2012-05-03\"),\n ....: ]\n ....: \n\nIn [35]: ts = pd.Series(np.random.randn(3), dates)\n\nIn [36]: type(ts.index)\nOut[36]: pandas.core.indexes.datetimes.DatetimeIndex\n\nIn [37]: ts.index\nOut[37]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)\n\nIn [38]: ts\nOut[38]: \n2012-05-01    0.469112\n2012-05-02   -0.282863\n2012-05-03   -1.509059\ndtype: float64\n\nIn [39]: periods = [pd.Period(\"2012-01\"), pd.Period(\"2012-02\"), pd.Period(\"2012-03\")]\n\nIn [40]: ts = pd.Series(np.random.randn(3), periods)\n\nIn [41]: type(ts.index)\nOut[41]: pandas.core.indexes.period.PeriodIndex\n\nIn [42]: ts.index\nOut[42]: PeriodIndex(['2012-01', '2012-02', '2012-03'], dtype='period[M]')\n\nIn [43]: ts\nOut[43]: \n2012-01   -1.135632\n2012-02    1.212112\n2012-03   -0.173215\nFreq: M, dtype: float64 \n```", "```py\nIn [44]: pd.to_datetime(pd.Series([\"Jul 31, 2009\", \"Jan 10, 2010\", None]))\nOut[44]: \n0   2009-07-31\n1   2010-01-10\n2          NaT\ndtype: datetime64[ns]\n\nIn [45]: pd.to_datetime([\"2005/11/23\", \"2010/12/31\"])\nOut[45]: DatetimeIndex(['2005-11-23', '2010-12-31'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [46]: pd.to_datetime([\"04-01-2012 10:00\"], dayfirst=True)\nOut[46]: DatetimeIndex(['2012-01-04 10:00:00'], dtype='datetime64[ns]', freq=None)\n\nIn [47]: pd.to_datetime([\"04-14-2012 10:00\"], dayfirst=True)\nOut[47]: DatetimeIndex(['2012-04-14 10:00:00'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [48]: pd.to_datetime(\"2010/11/12\")\nOut[48]: Timestamp('2010-11-12 00:00:00')\n\nIn [49]: pd.Timestamp(\"2010/11/12\")\nOut[49]: Timestamp('2010-11-12 00:00:00') \n```", "```py\nIn [50]: pd.DatetimeIndex([\"2018-01-01\", \"2018-01-03\", \"2018-01-05\"])\nOut[50]: DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [51]: pd.DatetimeIndex([\"2018-01-01\", \"2018-01-03\", \"2018-01-05\"], freq=\"infer\")\nOut[51]: DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], dtype='datetime64[ns]', freq='2D') \n```", "```py\nIn [52]: pd.to_datetime(\"2010/11/12\", format=\"%Y/%m/%d\")\nOut[52]: Timestamp('2010-11-12 00:00:00')\n\nIn [53]: pd.to_datetime(\"12-11-2010 00:00\", format=\"%d-%m-%Y %H:%M\")\nOut[53]: Timestamp('2010-11-12 00:00:00') \n```", "```py\nIn [54]: df = pd.DataFrame(\n ....:    {\"year\": [2015, 2016], \"month\": [2, 3], \"day\": [4, 5], \"hour\": [2, 3]}\n ....: )\n ....: \n\nIn [55]: pd.to_datetime(df)\nOut[55]: \n0   2015-02-04 02:00:00\n1   2016-03-05 03:00:00\ndtype: datetime64[ns] \n```", "```py\nIn [56]: pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\nOut[56]: \n0   2015-02-04\n1   2016-03-05\ndtype: datetime64[ns] \n```", "```py\nIn [57]: pd.to_datetime(['2009/07/31', 'asd'], errors='raise')\n---------------------------------------------------------------------------\nValueError  Traceback (most recent call last)\nCell In[57], line 1\n----> 1 pd.to_datetime(['2009/07/31', 'asd'], errors='raise')\n\nFile ~/work/pandas/pandas/pandas/core/tools/datetimes.py:1099, in to_datetime(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\n  1097         result = _convert_and_box_cache(argc, cache_array)\n  1098     else:\n-> 1099         result = convert_listlike(argc, format)\n  1100 else:\n  1101     result = convert_listlike(np.array([arg]), format)[0]\n\nFile ~/work/pandas/pandas/pandas/core/tools/datetimes.py:433, in _convert_listlike_datetimes(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\n  431 # `format` could be inferred, or user didn't ask for mixed-format parsing.\n  432 if format is not None and format != \"mixed\":\n--> 433     return _array_strptime_with_fallback(arg, name, utc, format, exact, errors)\n  435 result, tz_parsed = objects_to_datetime64(\n  436     arg,\n  437     dayfirst=dayfirst,\n   (...)\n  441     allow_object=True,\n  442 )\n  444 if tz_parsed is not None:\n  445     # We can take a shortcut since the datetime64 numpy array\n  446     # is in UTC\n\nFile ~/work/pandas/pandas/pandas/core/tools/datetimes.py:467, in _array_strptime_with_fallback(arg, name, utc, fmt, exact, errors)\n  456 def _array_strptime_with_fallback(\n  457     arg,\n  458     name,\n   (...)\n  462     errors: str,\n  463 ) -> Index:\n  464  \"\"\"\n  465 Call array_strptime, with fallback behavior depending on 'errors'.\n  466 \"\"\"\n--> 467     result, tz_out = array_strptime(arg, fmt, exact=exact, errors=errors, utc=utc)\n  468     if tz_out is not None:\n  469         unit = np.datetime_data(result.dtype)[0]\n\nFile strptime.pyx:501, in pandas._libs.tslibs.strptime.array_strptime()\n\nFile strptime.pyx:451, in pandas._libs.tslibs.strptime.array_strptime()\n\nFile strptime.pyx:583, in pandas._libs.tslibs.strptime._parse_with_format()\n\nValueError: time data \"asd\" doesn't match format \"%Y/%m/%d\", at position 1\\. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this. \n```", "```py\nIn [58]: pd.to_datetime([\"2009/07/31\", \"asd\"], errors=\"coerce\")\nOut[58]: DatetimeIndex(['2009-07-31', 'NaT'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [59]: pd.to_datetime(\n ....:    [1349720105, 1349806505, 1349892905, 1349979305, 1350065705], unit=\"s\"\n ....: )\n ....: \nOut[59]: \nDatetimeIndex(['2012-10-08 18:15:05', '2012-10-09 18:15:05',\n '2012-10-10 18:15:05', '2012-10-11 18:15:05',\n '2012-10-12 18:15:05'],\n dtype='datetime64[ns]', freq=None)\n\nIn [60]: pd.to_datetime(\n ....:    [1349720105100, 1349720105200, 1349720105300, 1349720105400, 1349720105500],\n ....:    unit=\"ms\",\n ....: )\n ....: \nOut[60]: \nDatetimeIndex(['2012-10-08 18:15:05.100000', '2012-10-08 18:15:05.200000',\n '2012-10-08 18:15:05.300000', '2012-10-08 18:15:05.400000',\n '2012-10-08 18:15:05.500000'],\n dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [61]: pd.Timestamp(1262347200000000000).tz_localize(\"US/Pacific\")\nOut[61]: Timestamp('2010-01-01 12:00:00-0800', tz='US/Pacific')\n\nIn [62]: pd.DatetimeIndex([1262347200000000000]).tz_localize(\"US/Pacific\")\nOut[62]: DatetimeIndex(['2010-01-01 12:00:00-08:00'], dtype='datetime64[ns, US/Pacific]', freq=None) \n```", "```py\nIn [63]: pd.to_datetime([1490195805.433, 1490195805.433502912], unit=\"s\")\nOut[63]: DatetimeIndex(['2017-03-22 15:16:45.433000088', '2017-03-22 15:16:45.433502913'], dtype='datetime64[ns]', freq=None)\n\nIn [64]: pd.to_datetime(1490195805433502912, unit=\"ns\")\nOut[64]: Timestamp('2017-03-22 15:16:45.433502912') \n```", "```py\nIn [65]: stamps = pd.date_range(\"2012-10-08 18:15:05\", periods=4, freq=\"D\")\n\nIn [66]: stamps\nOut[66]: \nDatetimeIndex(['2012-10-08 18:15:05', '2012-10-09 18:15:05',\n '2012-10-10 18:15:05', '2012-10-11 18:15:05'],\n dtype='datetime64[ns]', freq='D') \n```", "```py\nIn [67]: (stamps - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta(\"1s\")\nOut[67]: Index([1349720105, 1349806505, 1349892905, 1349979305], dtype='int64') \n```", "```py\nIn [68]: pd.to_datetime([1, 2, 3], unit=\"D\", origin=pd.Timestamp(\"1960-01-01\"))\nOut[68]: DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [69]: pd.to_datetime([1, 2, 3], unit=\"D\")\nOut[69]: DatetimeIndex(['1970-01-02', '1970-01-03', '1970-01-04'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [70]: dates = [\n ....:    datetime.datetime(2012, 5, 1),\n ....:    datetime.datetime(2012, 5, 2),\n ....:    datetime.datetime(2012, 5, 3),\n ....: ]\n ....: \n\n# Note the frequency information\nIn [71]: index = pd.DatetimeIndex(dates)\n\nIn [72]: index\nOut[72]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)\n\n# Automatically converted to DatetimeIndex\nIn [73]: index = pd.Index(dates)\n\nIn [74]: index\nOut[74]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [75]: start = datetime.datetime(2011, 1, 1)\n\nIn [76]: end = datetime.datetime(2012, 1, 1)\n\nIn [77]: index = pd.date_range(start, end)\n\nIn [78]: index\nOut[78]: \nDatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03', '2011-01-04',\n '2011-01-05', '2011-01-06', '2011-01-07', '2011-01-08',\n '2011-01-09', '2011-01-10',\n ...\n '2011-12-23', '2011-12-24', '2011-12-25', '2011-12-26',\n '2011-12-27', '2011-12-28', '2011-12-29', '2011-12-30',\n '2011-12-31', '2012-01-01'],\n dtype='datetime64[ns]', length=366, freq='D')\n\nIn [79]: index = pd.bdate_range(start, end)\n\nIn [80]: index\nOut[80]: \nDatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',\n '2011-01-07', '2011-01-10', '2011-01-11', '2011-01-12',\n '2011-01-13', '2011-01-14',\n ...\n '2011-12-19', '2011-12-20', '2011-12-21', '2011-12-22',\n '2011-12-23', '2011-12-26', '2011-12-27', '2011-12-28',\n '2011-12-29', '2011-12-30'],\n dtype='datetime64[ns]', length=260, freq='B') \n```", "```py\nIn [81]: pd.date_range(start, periods=1000, freq=\"ME\")\nOut[81]: \nDatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-30',\n '2011-05-31', '2011-06-30', '2011-07-31', '2011-08-31',\n '2011-09-30', '2011-10-31',\n ...\n '2093-07-31', '2093-08-31', '2093-09-30', '2093-10-31',\n '2093-11-30', '2093-12-31', '2094-01-31', '2094-02-28',\n '2094-03-31', '2094-04-30'],\n dtype='datetime64[ns]', length=1000, freq='ME')\n\nIn [82]: pd.bdate_range(start, periods=250, freq=\"BQS\")\nOut[82]: \nDatetimeIndex(['2011-01-03', '2011-04-01', '2011-07-01', '2011-10-03',\n '2012-01-02', '2012-04-02', '2012-07-02', '2012-10-01',\n '2013-01-01', '2013-04-01',\n ...\n '2071-01-01', '2071-04-01', '2071-07-01', '2071-10-01',\n '2072-01-01', '2072-04-01', '2072-07-01', '2072-10-03',\n '2073-01-02', '2073-04-03'],\n dtype='datetime64[ns]', length=250, freq='BQS-JAN') \n```", "```py\nIn [83]: pd.date_range(start, end, freq=\"BME\")\nOut[83]: \nDatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',\n '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',\n '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30'],\n dtype='datetime64[ns]', freq='BME')\n\nIn [84]: pd.date_range(start, end, freq=\"W\")\nOut[84]: \nDatetimeIndex(['2011-01-02', '2011-01-09', '2011-01-16', '2011-01-23',\n '2011-01-30', '2011-02-06', '2011-02-13', '2011-02-20',\n '2011-02-27', '2011-03-06', '2011-03-13', '2011-03-20',\n '2011-03-27', '2011-04-03', '2011-04-10', '2011-04-17',\n '2011-04-24', '2011-05-01', '2011-05-08', '2011-05-15',\n '2011-05-22', '2011-05-29', '2011-06-05', '2011-06-12',\n '2011-06-19', '2011-06-26', '2011-07-03', '2011-07-10',\n '2011-07-17', '2011-07-24', '2011-07-31', '2011-08-07',\n '2011-08-14', '2011-08-21', '2011-08-28', '2011-09-04',\n '2011-09-11', '2011-09-18', '2011-09-25', '2011-10-02',\n '2011-10-09', '2011-10-16', '2011-10-23', '2011-10-30',\n '2011-11-06', '2011-11-13', '2011-11-20', '2011-11-27',\n '2011-12-04', '2011-12-11', '2011-12-18', '2011-12-25',\n '2012-01-01'],\n dtype='datetime64[ns]', freq='W-SUN')\n\nIn [85]: pd.bdate_range(end=end, periods=20)\nOut[85]: \nDatetimeIndex(['2011-12-05', '2011-12-06', '2011-12-07', '2011-12-08',\n '2011-12-09', '2011-12-12', '2011-12-13', '2011-12-14',\n '2011-12-15', '2011-12-16', '2011-12-19', '2011-12-20',\n '2011-12-21', '2011-12-22', '2011-12-23', '2011-12-26',\n '2011-12-27', '2011-12-28', '2011-12-29', '2011-12-30'],\n dtype='datetime64[ns]', freq='B')\n\nIn [86]: pd.bdate_range(start=start, periods=20)\nOut[86]: \nDatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',\n '2011-01-07', '2011-01-10', '2011-01-11', '2011-01-12',\n '2011-01-13', '2011-01-14', '2011-01-17', '2011-01-18',\n '2011-01-19', '2011-01-20', '2011-01-21', '2011-01-24',\n '2011-01-25', '2011-01-26', '2011-01-27', '2011-01-28'],\n dtype='datetime64[ns]', freq='B') \n```", "```py\nIn [87]: pd.date_range(\"2018-01-01\", \"2018-01-05\", periods=5)\nOut[87]: \nDatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n '2018-01-05'],\n dtype='datetime64[ns]', freq=None)\n\nIn [88]: pd.date_range(\"2018-01-01\", \"2018-01-05\", periods=10)\nOut[88]: \nDatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 10:40:00',\n '2018-01-01 21:20:00', '2018-01-02 08:00:00',\n '2018-01-02 18:40:00', '2018-01-03 05:20:00',\n '2018-01-03 16:00:00', '2018-01-04 02:40:00',\n '2018-01-04 13:20:00', '2018-01-05 00:00:00'],\n dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [89]: weekmask = \"Mon Wed Fri\"\n\nIn [90]: holidays = [datetime.datetime(2011, 1, 5), datetime.datetime(2011, 3, 14)]\n\nIn [91]: pd.bdate_range(start, end, freq=\"C\", weekmask=weekmask, holidays=holidays)\nOut[91]: \nDatetimeIndex(['2011-01-03', '2011-01-07', '2011-01-10', '2011-01-12',\n '2011-01-14', '2011-01-17', '2011-01-19', '2011-01-21',\n '2011-01-24', '2011-01-26',\n ...\n '2011-12-09', '2011-12-12', '2011-12-14', '2011-12-16',\n '2011-12-19', '2011-12-21', '2011-12-23', '2011-12-26',\n '2011-12-28', '2011-12-30'],\n dtype='datetime64[ns]', length=154, freq='C')\n\nIn [92]: pd.bdate_range(start, end, freq=\"CBMS\", weekmask=weekmask)\nOut[92]: \nDatetimeIndex(['2011-01-03', '2011-02-02', '2011-03-02', '2011-04-01',\n '2011-05-02', '2011-06-01', '2011-07-01', '2011-08-01',\n '2011-09-02', '2011-10-03', '2011-11-02', '2011-12-02'],\n dtype='datetime64[ns]', freq='CBMS') \n```", "```py\nIn [93]: pd.Timestamp.min\nOut[93]: Timestamp('1677-09-21 00:12:43.145224193')\n\nIn [94]: pd.Timestamp.max\nOut[94]: Timestamp('2262-04-11 23:47:16.854775807') \n```", "```py\nIn [95]: rng = pd.date_range(start, end, freq=\"BME\")\n\nIn [96]: ts = pd.Series(np.random.randn(len(rng)), index=rng)\n\nIn [97]: ts.index\nOut[97]: \nDatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',\n '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',\n '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30'],\n dtype='datetime64[ns]', freq='BME')\n\nIn [98]: ts[:5].index\nOut[98]: \nDatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',\n '2011-05-31'],\n dtype='datetime64[ns]', freq='BME')\n\nIn [99]: ts[::2].index\nOut[99]: \nDatetimeIndex(['2011-01-31', '2011-03-31', '2011-05-31', '2011-07-29',\n '2011-09-30', '2011-11-30'],\n dtype='datetime64[ns]', freq='2BME') \n```", "```py\nIn [100]: ts[\"1/31/2011\"]\nOut[100]: 0.11920871129693428\n\nIn [101]: ts[datetime.datetime(2011, 12, 25):]\nOut[101]: \n2011-12-30    0.56702\nFreq: BME, dtype: float64\n\nIn [102]: ts[\"10/31/2011\":\"12/31/2011\"]\nOut[102]: \n2011-10-31    0.271860\n2011-11-30   -0.424972\n2011-12-30    0.567020\nFreq: BME, dtype: float64 \n```", "```py\nIn [103]: ts[\"2011\"]\nOut[103]: \n2011-01-31    0.119209\n2011-02-28   -1.044236\n2011-03-31   -0.861849\n2011-04-29   -2.104569\n2011-05-31   -0.494929\n2011-06-30    1.071804\n2011-07-29    0.721555\n2011-08-31   -0.706771\n2011-09-30   -1.039575\n2011-10-31    0.271860\n2011-11-30   -0.424972\n2011-12-30    0.567020\nFreq: BME, dtype: float64\n\nIn [104]: ts[\"2011-6\"]\nOut[104]: \n2011-06-30    1.071804\nFreq: BME, dtype: float64 \n```", "```py\nIn [105]: dft = pd.DataFrame(\n .....:    np.random.randn(100000, 1),\n .....:    columns=[\"A\"],\n .....:    index=pd.date_range(\"20130101\", periods=100000, freq=\"min\"),\n .....: )\n .....: \n\nIn [106]: dft\nOut[106]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-03-11 10:35:00 -0.747967\n2013-03-11 10:36:00 -0.034523\n2013-03-11 10:37:00 -0.201754\n2013-03-11 10:38:00 -1.509067\n2013-03-11 10:39:00 -1.693043\n\n[100000 rows x 1 columns]\n\nIn [107]: dft.loc[\"2013\"]\nOut[107]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-03-11 10:35:00 -0.747967\n2013-03-11 10:36:00 -0.034523\n2013-03-11 10:37:00 -0.201754\n2013-03-11 10:38:00 -1.509067\n2013-03-11 10:39:00 -1.693043\n\n[100000 rows x 1 columns] \n```", "```py\nIn [108]: dft[\"2013-1\":\"2013-2\"]\nOut[108]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-02-28 23:55:00  0.850929\n2013-02-28 23:56:00  0.976712\n2013-02-28 23:57:00 -2.693884\n2013-02-28 23:58:00 -1.575535\n2013-02-28 23:59:00 -1.573517\n\n[84960 rows x 1 columns] \n```", "```py\nIn [109]: dft[\"2013-1\":\"2013-2-28\"]\nOut[109]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-02-28 23:55:00  0.850929\n2013-02-28 23:56:00  0.976712\n2013-02-28 23:57:00 -2.693884\n2013-02-28 23:58:00 -1.575535\n2013-02-28 23:59:00 -1.573517\n\n[84960 rows x 1 columns] \n```", "```py\nIn [110]: dft[\"2013-1\":\"2013-2-28 00:00:00\"]\nOut[110]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-02-27 23:56:00  1.197749\n2013-02-27 23:57:00  0.720521\n2013-02-27 23:58:00 -0.072718\n2013-02-27 23:59:00 -0.681192\n2013-02-28 00:00:00 -0.557501\n\n[83521 rows x 1 columns] \n```", "```py\nIn [111]: dft[\"2013-1-15\":\"2013-1-15 12:30:00\"]\nOut[111]: \n A\n2013-01-15 00:00:00 -0.984810\n2013-01-15 00:01:00  0.941451\n2013-01-15 00:02:00  1.559365\n2013-01-15 00:03:00  1.034374\n2013-01-15 00:04:00 -1.480656\n...                       ...\n2013-01-15 12:26:00  0.371454\n2013-01-15 12:27:00 -0.930806\n2013-01-15 12:28:00 -0.069177\n2013-01-15 12:29:00  0.066510\n2013-01-15 12:30:00 -0.003945\n\n[751 rows x 1 columns] \n```", "```py\nIn [112]: dft2 = pd.DataFrame(\n .....:    np.random.randn(20, 1),\n .....:    columns=[\"A\"],\n .....:    index=pd.MultiIndex.from_product(\n .....:        [pd.date_range(\"20130101\", periods=10, freq=\"12h\"), [\"a\", \"b\"]]\n .....:    ),\n .....: )\n .....: \n\nIn [113]: dft2\nOut[113]: \n A\n2013-01-01 00:00:00 a -0.298694\n b  0.823553\n2013-01-01 12:00:00 a  0.943285\n b -1.479399\n2013-01-02 00:00:00 a -1.643342\n...                         ...\n2013-01-04 12:00:00 b  0.069036\n2013-01-05 00:00:00 a  0.122297\n b  1.422060\n2013-01-05 12:00:00 a  0.370079\n b  1.016331\n\n[20 rows x 1 columns]\n\nIn [114]: dft2.loc[\"2013-01-05\"]\nOut[114]: \n A\n2013-01-05 00:00:00 a  0.122297\n b  1.422060\n2013-01-05 12:00:00 a  0.370079\n b  1.016331\n\nIn [115]: idx = pd.IndexSlice\n\nIn [116]: dft2 = dft2.swaplevel(0, 1).sort_index()\n\nIn [117]: dft2.loc[idx[:, \"2013-01-05\"], :]\nOut[117]: \n A\na 2013-01-05 00:00:00  0.122297\n 2013-01-05 12:00:00  0.370079\nb 2013-01-05 00:00:00  1.422060\n 2013-01-05 12:00:00  1.016331 \n```", "```py\nIn [118]: df = pd.DataFrame([0], index=pd.DatetimeIndex([\"2019-01-01\"], tz=\"US/Pacific\"))\n\nIn [119]: df\nOut[119]: \n 0\n2019-01-01 00:00:00-08:00  0\n\nIn [120]: df[\"2019-01-01 12:00:00+04:00\":\"2019-01-01 13:00:00+04:00\"]\nOut[120]: \n 0\n2019-01-01 00:00:00-08:00  0 \n```", "```py\nIn [121]: series_minute = pd.Series(\n .....:    [1, 2, 3],\n .....:    pd.DatetimeIndex(\n .....:        [\"2011-12-31 23:59:00\", \"2012-01-01 00:00:00\", \"2012-01-01 00:02:00\"]\n .....:    ),\n .....: )\n .....: \n\nIn [122]: series_minute.index.resolution\nOut[122]: 'minute' \n```", "```py\nIn [123]: series_minute[\"2011-12-31 23\"]\nOut[123]: \n2011-12-31 23:59:00    1\ndtype: int64 \n```", "```py\nIn [124]: series_minute[\"2011-12-31 23:59\"]\nOut[124]: 1\n\nIn [125]: series_minute[\"2011-12-31 23:59:00\"]\nOut[125]: 1 \n```", "```py\nIn [126]: series_second = pd.Series(\n .....:    [1, 2, 3],\n .....:    pd.DatetimeIndex(\n .....:        [\"2011-12-31 23:59:59\", \"2012-01-01 00:00:00\", \"2012-01-01 00:00:01\"]\n .....:    ),\n .....: )\n .....: \n\nIn [127]: series_second.index.resolution\nOut[127]: 'second'\n\nIn [128]: series_second[\"2011-12-31 23:59\"]\nOut[128]: \n2011-12-31 23:59:59    1\ndtype: int64 \n```", "```py\nIn [129]: dft_minute = pd.DataFrame(\n .....:    {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}, index=series_minute.index\n .....: )\n .....: \n\nIn [130]: dft_minute.loc[\"2011-12-31 23\"]\nOut[130]: \n a  b\n2011-12-31 23:59:00  1  4 \n```", "```py\nIn [131]: dft_minute.loc[\"2011-12-31 23:59\"]\nOut[131]: \na    1\nb    4\nName: 2011-12-31 23:59:00, dtype: int64 \n```", "```py\nIn [132]: series_monthly = pd.Series(\n .....:    [1, 2, 3], pd.DatetimeIndex([\"2011-12\", \"2012-01\", \"2012-02\"])\n .....: )\n .....: \n\nIn [133]: series_monthly.index.resolution\nOut[133]: 'day'\n\nIn [134]: series_monthly[\"2011-12\"]  # returns Series\nOut[134]: \n2011-12-01    1\ndtype: int64 \n```", "```py\nIn [135]: dft[datetime.datetime(2013, 1, 1): datetime.datetime(2013, 2, 28)]\nOut[135]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-02-27 23:56:00  1.197749\n2013-02-27 23:57:00  0.720521\n2013-02-27 23:58:00 -0.072718\n2013-02-27 23:59:00 -0.681192\n2013-02-28 00:00:00 -0.557501\n\n[83521 rows x 1 columns] \n```", "```py\nIn [136]: dft[\n .....:    datetime.datetime(2013, 1, 1, 10, 12, 0): datetime.datetime(\n .....:        2013, 2, 28, 10, 12, 0\n .....:    )\n .....: ]\n .....: \nOut[136]: \n A\n2013-01-01 10:12:00  0.565375\n2013-01-01 10:13:00  0.068184\n2013-01-01 10:14:00  0.788871\n2013-01-01 10:15:00 -0.280343\n2013-01-01 10:16:00  0.931536\n...                       ...\n2013-02-28 10:08:00  0.148098\n2013-02-28 10:09:00 -0.388138\n2013-02-28 10:10:00  0.139348\n2013-02-28 10:11:00  0.085288\n2013-02-28 10:12:00  0.950146\n\n[83521 rows x 1 columns] \n```", "```py\nIn [137]: rng2 = pd.date_range(\"2011-01-01\", \"2012-01-01\", freq=\"W\")\n\nIn [138]: ts2 = pd.Series(np.random.randn(len(rng2)), index=rng2)\n\nIn [139]: ts2.truncate(before=\"2011-11\", after=\"2011-12\")\nOut[139]: \n2011-11-06    0.437823\n2011-11-13   -0.293083\n2011-11-20   -0.059881\n2011-11-27    1.252450\nFreq: W-SUN, dtype: float64\n\nIn [140]: ts2[\"2011-11\":\"2011-12\"]\nOut[140]: \n2011-11-06    0.437823\n2011-11-13   -0.293083\n2011-11-20   -0.059881\n2011-11-27    1.252450\n2011-12-04    0.046611\n2011-12-11    0.059478\n2011-12-18   -0.286539\n2011-12-25    0.841669\nFreq: W-SUN, dtype: float64 \n```", "```py\nIn [141]: ts2.iloc[[0, 2, 6]].index\nOut[141]: DatetimeIndex(['2011-01-02', '2011-01-16', '2011-02-13'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [142]: idx = pd.date_range(start=\"2019-12-29\", freq=\"D\", periods=4)\n\nIn [143]: idx.isocalendar()\nOut[143]: \n year  week  day\n2019-12-29  2019    52    7\n2019-12-30  2020     1    1\n2019-12-31  2020     1    2\n2020-01-01  2020     1    3\n\nIn [144]: idx.to_series().dt.isocalendar()\nOut[144]: \n year  week  day\n2019-12-29  2019    52    7\n2019-12-30  2020     1    1\n2019-12-31  2020     1    2\n2020-01-01  2020     1    3 \n```", "```py\n# This particular day contains a day light savings time transition\nIn [145]: ts = pd.Timestamp(\"2016-10-30 00:00:00\", tz=\"Europe/Helsinki\")\n\n# Respects absolute time\nIn [146]: ts + pd.Timedelta(days=1)\nOut[146]: Timestamp('2016-10-30 23:00:00+0200', tz='Europe/Helsinki')\n\n# Respects calendar time\nIn [147]: ts + pd.DateOffset(days=1)\nOut[147]: Timestamp('2016-10-31 00:00:00+0200', tz='Europe/Helsinki')\n\nIn [148]: friday = pd.Timestamp(\"2018-01-05\")\n\nIn [149]: friday.day_name()\nOut[149]: 'Friday'\n\n# Add 2 business days (Friday --> Tuesday)\nIn [150]: two_business_days = 2 * pd.offsets.BDay()\n\nIn [151]: friday + two_business_days\nOut[151]: Timestamp('2018-01-09 00:00:00')\n\nIn [152]: (friday + two_business_days).day_name()\nOut[152]: 'Tuesday' \n```", "```py\nIn [153]: ts = pd.Timestamp(\"2018-01-06 00:00:00\")\n\nIn [154]: ts.day_name()\nOut[154]: 'Saturday'\n\n# BusinessHour's valid offset dates are Monday through Friday\nIn [155]: offset = pd.offsets.BusinessHour(start=\"09:00\")\n\n# Bring the date to the closest offset date (Monday)\nIn [156]: offset.rollforward(ts)\nOut[156]: Timestamp('2018-01-08 09:00:00')\n\n# Date is brought to the closest offset date first and then the hour is added\nIn [157]: ts + offset\nOut[157]: Timestamp('2018-01-08 10:00:00') \n```", "```py\nIn [158]: ts = pd.Timestamp(\"2014-01-01 09:00\")\n\nIn [159]: day = pd.offsets.Day()\n\nIn [160]: day + ts\nOut[160]: Timestamp('2014-01-02 09:00:00')\n\nIn [161]: (day + ts).normalize()\nOut[161]: Timestamp('2014-01-02 00:00:00')\n\nIn [162]: ts = pd.Timestamp(\"2014-01-01 22:00\")\n\nIn [163]: hour = pd.offsets.Hour()\n\nIn [164]: hour + ts\nOut[164]: Timestamp('2014-01-01 23:00:00')\n\nIn [165]: (hour + ts).normalize()\nOut[165]: Timestamp('2014-01-01 00:00:00')\n\nIn [166]: (hour + pd.Timestamp(\"2014-01-01 23:30\")).normalize()\nOut[166]: Timestamp('2014-01-02 00:00:00') \n```", "```py\nIn [167]: d = datetime.datetime(2008, 8, 18, 9, 0)\n\nIn [168]: d\nOut[168]: datetime.datetime(2008, 8, 18, 9, 0)\n\nIn [169]: d + pd.offsets.Week()\nOut[169]: Timestamp('2008-08-25 09:00:00')\n\nIn [170]: d + pd.offsets.Week(weekday=4)\nOut[170]: Timestamp('2008-08-22 09:00:00')\n\nIn [171]: (d + pd.offsets.Week(weekday=4)).weekday()\nOut[171]: 4\n\nIn [172]: d - pd.offsets.Week()\nOut[172]: Timestamp('2008-08-11 09:00:00') \n```", "```py\nIn [173]: d + pd.offsets.Week(normalize=True)\nOut[173]: Timestamp('2008-08-25 00:00:00')\n\nIn [174]: d - pd.offsets.Week(normalize=True)\nOut[174]: Timestamp('2008-08-11 00:00:00') \n```", "```py\nIn [175]: d + pd.offsets.YearEnd()\nOut[175]: Timestamp('2008-12-31 09:00:00')\n\nIn [176]: d + pd.offsets.YearEnd(month=6)\nOut[176]: Timestamp('2009-06-30 09:00:00') \n```", "```py\nIn [177]: rng = pd.date_range(\"2012-01-01\", \"2012-01-03\")\n\nIn [178]: s = pd.Series(rng)\n\nIn [179]: rng\nOut[179]: DatetimeIndex(['2012-01-01', '2012-01-02', '2012-01-03'], dtype='datetime64[ns]', freq='D')\n\nIn [180]: rng + pd.DateOffset(months=2)\nOut[180]: DatetimeIndex(['2012-03-01', '2012-03-02', '2012-03-03'], dtype='datetime64[ns]', freq=None)\n\nIn [181]: s + pd.DateOffset(months=2)\nOut[181]: \n0   2012-03-01\n1   2012-03-02\n2   2012-03-03\ndtype: datetime64[ns]\n\nIn [182]: s - pd.DateOffset(months=2)\nOut[182]: \n0   2011-11-01\n1   2011-11-02\n2   2011-11-03\ndtype: datetime64[ns] \n```", "```py\nIn [183]: s - pd.offsets.Day(2)\nOut[183]: \n0   2011-12-30\n1   2011-12-31\n2   2012-01-01\ndtype: datetime64[ns]\n\nIn [184]: td = s - pd.Series(pd.date_range(\"2011-12-29\", \"2011-12-31\"))\n\nIn [185]: td\nOut[185]: \n0   3 days\n1   3 days\n2   3 days\ndtype: timedelta64[ns]\n\nIn [186]: td + pd.offsets.Minute(15)\nOut[186]: \n0   3 days 00:15:00\n1   3 days 00:15:00\n2   3 days 00:15:00\ndtype: timedelta64[ns] \n```", "```py\nIn [187]: rng + pd.offsets.BQuarterEnd()\nOut[187]: DatetimeIndex(['2012-03-30', '2012-03-30', '2012-03-30'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [188]: weekmask_egypt = \"Sun Mon Tue Wed Thu\"\n\n# They also observe International Workers' Day so let's\n# add that for a couple of years\nIn [189]: holidays = [\n .....:    \"2012-05-01\",\n .....:    datetime.datetime(2013, 5, 1),\n .....:    np.datetime64(\"2014-05-01\"),\n .....: ]\n .....: \n\nIn [190]: bday_egypt = pd.offsets.CustomBusinessDay(\n .....:    holidays=holidays,\n .....:    weekmask=weekmask_egypt,\n .....: )\n .....: \n\nIn [191]: dt = datetime.datetime(2013, 4, 30)\n\nIn [192]: dt + 2 * bday_egypt\nOut[192]: Timestamp('2013-05-05 00:00:00') \n```", "```py\nIn [193]: dts = pd.date_range(dt, periods=5, freq=bday_egypt)\n\nIn [194]: pd.Series(dts.weekday, dts).map(pd.Series(\"Mon Tue Wed Thu Fri Sat Sun\".split()))\nOut[194]: \n2013-04-30    Tue\n2013-05-02    Thu\n2013-05-05    Sun\n2013-05-06    Mon\n2013-05-07    Tue\nFreq: C, dtype: object \n```", "```py\nIn [195]: from pandas.tseries.holiday import USFederalHolidayCalendar\n\nIn [196]: bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n\n# Friday before MLK Day\nIn [197]: dt = datetime.datetime(2014, 1, 17)\n\n# Tuesday after MLK Day (Monday is skipped because it's a holiday)\nIn [198]: dt + bday_us\nOut[198]: Timestamp('2014-01-21 00:00:00') \n```", "```py\nIn [199]: bmth_us = pd.offsets.CustomBusinessMonthBegin(calendar=USFederalHolidayCalendar())\n\n# Skip new years\nIn [200]: dt = datetime.datetime(2013, 12, 17)\n\nIn [201]: dt + bmth_us\nOut[201]: Timestamp('2014-01-02 00:00:00')\n\n# Define date index with custom offset\nIn [202]: pd.date_range(start=\"20100101\", end=\"20120101\", freq=bmth_us)\nOut[202]: \nDatetimeIndex(['2010-01-04', '2010-02-01', '2010-03-01', '2010-04-01',\n '2010-05-03', '2010-06-01', '2010-07-01', '2010-08-02',\n '2010-09-01', '2010-10-01', '2010-11-01', '2010-12-01',\n '2011-01-03', '2011-02-01', '2011-03-01', '2011-04-01',\n '2011-05-02', '2011-06-01', '2011-07-01', '2011-08-01',\n '2011-09-01', '2011-10-03', '2011-11-01', '2011-12-01'],\n dtype='datetime64[ns]', freq='CBMS') \n```", "```py\nIn [203]: bh = pd.offsets.BusinessHour()\n\nIn [204]: bh\nOut[204]: <BusinessHour: bh=09:00-17:00>\n\n# 2014-08-01 is Friday\nIn [205]: pd.Timestamp(\"2014-08-01 10:00\").weekday()\nOut[205]: 4\n\nIn [206]: pd.Timestamp(\"2014-08-01 10:00\") + bh\nOut[206]: Timestamp('2014-08-01 11:00:00')\n\n# Below example is the same as: pd.Timestamp('2014-08-01 09:00') + bh\nIn [207]: pd.Timestamp(\"2014-08-01 08:00\") + bh\nOut[207]: Timestamp('2014-08-01 10:00:00')\n\n# If the results is on the end time, move to the next business day\nIn [208]: pd.Timestamp(\"2014-08-01 16:00\") + bh\nOut[208]: Timestamp('2014-08-04 09:00:00')\n\n# Remainings are added to the next day\nIn [209]: pd.Timestamp(\"2014-08-01 16:30\") + bh\nOut[209]: Timestamp('2014-08-04 09:30:00')\n\n# Adding 2 business hours\nIn [210]: pd.Timestamp(\"2014-08-01 10:00\") + pd.offsets.BusinessHour(2)\nOut[210]: Timestamp('2014-08-01 12:00:00')\n\n# Subtracting 3 business hours\nIn [211]: pd.Timestamp(\"2014-08-01 10:00\") + pd.offsets.BusinessHour(-3)\nOut[211]: Timestamp('2014-07-31 15:00:00') \n```", "```py\nIn [212]: bh = pd.offsets.BusinessHour(start=\"11:00\", end=datetime.time(20, 0))\n\nIn [213]: bh\nOut[213]: <BusinessHour: bh=11:00-20:00>\n\nIn [214]: pd.Timestamp(\"2014-08-01 13:00\") + bh\nOut[214]: Timestamp('2014-08-01 14:00:00')\n\nIn [215]: pd.Timestamp(\"2014-08-01 09:00\") + bh\nOut[215]: Timestamp('2014-08-01 12:00:00')\n\nIn [216]: pd.Timestamp(\"2014-08-01 18:00\") + bh\nOut[216]: Timestamp('2014-08-01 19:00:00') \n```", "```py\nIn [217]: bh = pd.offsets.BusinessHour(start=\"17:00\", end=\"09:00\")\n\nIn [218]: bh\nOut[218]: <BusinessHour: bh=17:00-09:00>\n\nIn [219]: pd.Timestamp(\"2014-08-01 17:00\") + bh\nOut[219]: Timestamp('2014-08-01 18:00:00')\n\nIn [220]: pd.Timestamp(\"2014-08-01 23:00\") + bh\nOut[220]: Timestamp('2014-08-02 00:00:00')\n\n# Although 2014-08-02 is Saturday,\n# it is valid because it starts from 08-01 (Friday).\nIn [221]: pd.Timestamp(\"2014-08-02 04:00\") + bh\nOut[221]: Timestamp('2014-08-02 05:00:00')\n\n# Although 2014-08-04 is Monday,\n# it is out of business hours because it starts from 08-03 (Sunday).\nIn [222]: pd.Timestamp(\"2014-08-04 04:00\") + bh\nOut[222]: Timestamp('2014-08-04 18:00:00') \n```", "```py\n# This adjusts a Timestamp to business hour edge\nIn [223]: pd.offsets.BusinessHour().rollback(pd.Timestamp(\"2014-08-02 15:00\"))\nOut[223]: Timestamp('2014-08-01 17:00:00')\n\nIn [224]: pd.offsets.BusinessHour().rollforward(pd.Timestamp(\"2014-08-02 15:00\"))\nOut[224]: Timestamp('2014-08-04 09:00:00')\n\n# It is the same as BusinessHour() + pd.Timestamp('2014-08-01 17:00').\n# And it is the same as BusinessHour() + pd.Timestamp('2014-08-04 09:00')\nIn [225]: pd.offsets.BusinessHour() + pd.Timestamp(\"2014-08-02 15:00\")\nOut[225]: Timestamp('2014-08-04 10:00:00')\n\n# BusinessDay results (for reference)\nIn [226]: pd.offsets.BusinessHour().rollforward(pd.Timestamp(\"2014-08-02\"))\nOut[226]: Timestamp('2014-08-04 09:00:00')\n\n# It is the same as BusinessDay() + pd.Timestamp('2014-08-01')\n# The result is the same as rollworward because BusinessDay never overlap.\nIn [227]: pd.offsets.BusinessHour() + pd.Timestamp(\"2014-08-02\")\nOut[227]: Timestamp('2014-08-04 10:00:00') \n```", "```py\nIn [228]: from pandas.tseries.holiday import USFederalHolidayCalendar\n\nIn [229]: bhour_us = pd.offsets.CustomBusinessHour(calendar=USFederalHolidayCalendar())\n\n# Friday before MLK Day\nIn [230]: dt = datetime.datetime(2014, 1, 17, 15)\n\nIn [231]: dt + bhour_us\nOut[231]: Timestamp('2014-01-17 16:00:00')\n\n# Tuesday after MLK Day (Monday is skipped because it's a holiday)\nIn [232]: dt + bhour_us * 2\nOut[232]: Timestamp('2014-01-21 09:00:00') \n```", "```py\nIn [233]: bhour_mon = pd.offsets.CustomBusinessHour(start=\"10:00\", weekmask=\"Tue Wed Thu Fri\")\n\n# Monday is skipped because it's a holiday, business hour starts from 10:00\nIn [234]: dt + bhour_mon * 2\nOut[234]: Timestamp('2014-01-21 10:00:00') \n```", "```py\nIn [235]: dates_lst_1 = pd.date_range(\"2020-01-06\", \"2020-04-03\", freq=\"MS\")\n\nIn [236]: dates_lst_1\nOut[236]: DatetimeIndex(['2020-02-01', '2020-03-01', '2020-04-01'], dtype='datetime64[ns]', freq='MS')\n\nIn [237]: dates_lst_2 = pd.date_range(\"2020-01-01\", \"2020-04-01\", freq=\"MS\")\n\nIn [238]: dates_lst_2\nOut[238]: DatetimeIndex(['2020-01-01', '2020-02-01', '2020-03-01', '2020-04-01'], dtype='datetime64[ns]', freq='MS') \n```", "```py\nIn [239]: pd.date_range(start, periods=5, freq=\"B\")\nOut[239]: \nDatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',\n '2011-01-07'],\n dtype='datetime64[ns]', freq='B')\n\nIn [240]: pd.date_range(start, periods=5, freq=pd.offsets.BDay())\nOut[240]: \nDatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',\n '2011-01-07'],\n dtype='datetime64[ns]', freq='B') \n```", "```py\nIn [241]: pd.date_range(start, periods=10, freq=\"2h20min\")\nOut[241]: \nDatetimeIndex(['2011-01-01 00:00:00', '2011-01-01 02:20:00',\n '2011-01-01 04:40:00', '2011-01-01 07:00:00',\n '2011-01-01 09:20:00', '2011-01-01 11:40:00',\n '2011-01-01 14:00:00', '2011-01-01 16:20:00',\n '2011-01-01 18:40:00', '2011-01-01 21:00:00'],\n dtype='datetime64[ns]', freq='140min')\n\nIn [242]: pd.date_range(start, periods=10, freq=\"1D10us\")\nOut[242]: \nDatetimeIndex([       '2011-01-01 00:00:00', '2011-01-02 00:00:00.000010',\n '2011-01-03 00:00:00.000020', '2011-01-04 00:00:00.000030',\n '2011-01-05 00:00:00.000040', '2011-01-06 00:00:00.000050',\n '2011-01-07 00:00:00.000060', '2011-01-08 00:00:00.000070',\n '2011-01-09 00:00:00.000080', '2011-01-10 00:00:00.000090'],\n dtype='datetime64[ns]', freq='86400000010us') \n```", "```py\nIn [243]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthBegin(n=1)\nOut[243]: Timestamp('2014-02-01 00:00:00')\n\nIn [244]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthEnd(n=1)\nOut[244]: Timestamp('2014-01-31 00:00:00')\n\nIn [245]: pd.Timestamp(\"2014-01-02\") - pd.offsets.MonthBegin(n=1)\nOut[245]: Timestamp('2014-01-01 00:00:00')\n\nIn [246]: pd.Timestamp(\"2014-01-02\") - pd.offsets.MonthEnd(n=1)\nOut[246]: Timestamp('2013-12-31 00:00:00')\n\nIn [247]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthBegin(n=4)\nOut[247]: Timestamp('2014-05-01 00:00:00')\n\nIn [248]: pd.Timestamp(\"2014-01-02\") - pd.offsets.MonthBegin(n=4)\nOut[248]: Timestamp('2013-10-01 00:00:00') \n```", "```py\nIn [249]: pd.Timestamp(\"2014-01-01\") + pd.offsets.MonthBegin(n=1)\nOut[249]: Timestamp('2014-02-01 00:00:00')\n\nIn [250]: pd.Timestamp(\"2014-01-31\") + pd.offsets.MonthEnd(n=1)\nOut[250]: Timestamp('2014-02-28 00:00:00')\n\nIn [251]: pd.Timestamp(\"2014-01-01\") - pd.offsets.MonthBegin(n=1)\nOut[251]: Timestamp('2013-12-01 00:00:00')\n\nIn [252]: pd.Timestamp(\"2014-01-31\") - pd.offsets.MonthEnd(n=1)\nOut[252]: Timestamp('2013-12-31 00:00:00')\n\nIn [253]: pd.Timestamp(\"2014-01-01\") + pd.offsets.MonthBegin(n=4)\nOut[253]: Timestamp('2014-05-01 00:00:00')\n\nIn [254]: pd.Timestamp(\"2014-01-31\") - pd.offsets.MonthBegin(n=4)\nOut[254]: Timestamp('2013-10-01 00:00:00') \n```", "```py\nIn [255]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthBegin(n=0)\nOut[255]: Timestamp('2014-02-01 00:00:00')\n\nIn [256]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthEnd(n=0)\nOut[256]: Timestamp('2014-01-31 00:00:00')\n\nIn [257]: pd.Timestamp(\"2014-01-01\") + pd.offsets.MonthBegin(n=0)\nOut[257]: Timestamp('2014-01-01 00:00:00')\n\nIn [258]: pd.Timestamp(\"2014-01-31\") + pd.offsets.MonthEnd(n=0)\nOut[258]: Timestamp('2014-01-31 00:00:00') \n```", "```py\nIn [259]: from pandas.tseries.holiday import (\n .....:    Holiday,\n .....:    USMemorialDay,\n .....:    AbstractHolidayCalendar,\n .....:    nearest_workday,\n .....:    MO,\n .....: )\n .....: \n\nIn [260]: class ExampleCalendar(AbstractHolidayCalendar):\n .....:    rules = [\n .....:        USMemorialDay,\n .....:        Holiday(\"July 4th\", month=7, day=4, observance=nearest_workday),\n .....:        Holiday(\n .....:            \"Columbus Day\",\n .....:            month=10,\n .....:            day=1,\n .....:            offset=pd.DateOffset(weekday=MO(2)),\n .....:        ),\n .....:    ]\n .....: \n\nIn [261]: cal = ExampleCalendar()\n\nIn [262]: cal.holidays(datetime.datetime(2012, 1, 1), datetime.datetime(2012, 12, 31))\nOut[262]: DatetimeIndex(['2012-05-28', '2012-07-04', '2012-10-08'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [263]: pd.date_range(\n .....:    start=\"7/1/2012\", end=\"7/10/2012\", freq=pd.offsets.CDay(calendar=cal)\n .....: ).to_pydatetime()\n .....: \nOut[263]: \narray([datetime.datetime(2012, 7, 2, 0, 0),\n datetime.datetime(2012, 7, 3, 0, 0),\n datetime.datetime(2012, 7, 5, 0, 0),\n datetime.datetime(2012, 7, 6, 0, 0),\n datetime.datetime(2012, 7, 9, 0, 0),\n datetime.datetime(2012, 7, 10, 0, 0)], dtype=object)\n\nIn [264]: offset = pd.offsets.CustomBusinessDay(calendar=cal)\n\nIn [265]: datetime.datetime(2012, 5, 25) + offset\nOut[265]: Timestamp('2012-05-29 00:00:00')\n\nIn [266]: datetime.datetime(2012, 7, 3) + offset\nOut[266]: Timestamp('2012-07-05 00:00:00')\n\nIn [267]: datetime.datetime(2012, 7, 3) + 2 * offset\nOut[267]: Timestamp('2012-07-06 00:00:00')\n\nIn [268]: datetime.datetime(2012, 7, 6) + offset\nOut[268]: Timestamp('2012-07-09 00:00:00') \n```", "```py\nIn [269]: AbstractHolidayCalendar.start_date\nOut[269]: Timestamp('1970-01-01 00:00:00')\n\nIn [270]: AbstractHolidayCalendar.end_date\nOut[270]: Timestamp('2200-12-31 00:00:00') \n```", "```py\nIn [271]: AbstractHolidayCalendar.start_date = datetime.datetime(2012, 1, 1)\n\nIn [272]: AbstractHolidayCalendar.end_date = datetime.datetime(2012, 12, 31)\n\nIn [273]: cal.holidays()\nOut[273]: DatetimeIndex(['2012-05-28', '2012-07-04', '2012-10-08'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [274]: from pandas.tseries.holiday import get_calendar, HolidayCalendarFactory, USLaborDay\n\nIn [275]: cal = get_calendar(\"ExampleCalendar\")\n\nIn [276]: cal.rules\nOut[276]: \n[Holiday: Memorial Day (month=5, day=31, offset=<DateOffset: weekday=MO(-1)>),\n Holiday: July 4th (month=7, day=4, observance=<function nearest_workday at 0x7ff27fdb0b80>),\n Holiday: Columbus Day (month=10, day=1, offset=<DateOffset: weekday=MO(+2)>)]\n\nIn [277]: new_cal = HolidayCalendarFactory(\"NewExampleCalendar\", cal, USLaborDay)\n\nIn [278]: new_cal.rules\nOut[278]: \n[Holiday: Labor Day (month=9, day=1, offset=<DateOffset: weekday=MO(+1)>),\n Holiday: Memorial Day (month=5, day=31, offset=<DateOffset: weekday=MO(-1)>),\n Holiday: July 4th (month=7, day=4, observance=<function nearest_workday at 0x7ff27fdb0b80>),\n Holiday: Columbus Day (month=10, day=1, offset=<DateOffset: weekday=MO(+2)>)] \n```", "```py\nIn [279]: ts = pd.Series(range(len(rng)), index=rng)\n\nIn [280]: ts = ts[:5]\n\nIn [281]: ts.shift(1)\nOut[281]: \n2012-01-01    NaN\n2012-01-02    0.0\n2012-01-03    1.0\nFreq: D, dtype: float64 \n```", "```py\nIn [282]: ts.shift(5, freq=\"D\")\nOut[282]: \n2012-01-06    0\n2012-01-07    1\n2012-01-08    2\nFreq: D, dtype: int64\n\nIn [283]: ts.shift(5, freq=pd.offsets.BDay())\nOut[283]: \n2012-01-06    0\n2012-01-09    1\n2012-01-10    2\ndtype: int64\n\nIn [284]: ts.shift(5, freq=\"BME\")\nOut[284]: \n2012-05-31    0\n2012-05-31    1\n2012-05-31    2\ndtype: int64 \n```", "```py\nIn [285]: dr = pd.date_range(\"1/1/2010\", periods=3, freq=3 * pd.offsets.BDay())\n\nIn [286]: ts = pd.Series(np.random.randn(3), index=dr)\n\nIn [287]: ts\nOut[287]: \n2010-01-01    1.494522\n2010-01-06   -0.778425\n2010-01-11   -0.253355\nFreq: 3B, dtype: float64\n\nIn [288]: ts.asfreq(pd.offsets.BDay())\nOut[288]: \n2010-01-01    1.494522\n2010-01-04         NaN\n2010-01-05         NaN\n2010-01-06   -0.778425\n2010-01-07         NaN\n2010-01-08         NaN\n2010-01-11   -0.253355\nFreq: B, dtype: float64 \n```", "```py\nIn [289]: ts.asfreq(pd.offsets.BDay(), method=\"pad\")\nOut[289]: \n2010-01-01    1.494522\n2010-01-04    1.494522\n2010-01-05    1.494522\n2010-01-06   -0.778425\n2010-01-07   -0.778425\n2010-01-08   -0.778425\n2010-01-11   -0.253355\nFreq: B, dtype: float64 \n```", "```py\nIn [290]: rng = pd.date_range(\"1/1/2012\", periods=100, freq=\"s\")\n\nIn [291]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\n\nIn [292]: ts.resample(\"5Min\").sum()\nOut[292]: \n2012-01-01    25103\nFreq: 5min, dtype: int64 \n```", "```py\nIn [293]: ts.resample(\"5Min\").mean()\nOut[293]: \n2012-01-01    251.03\nFreq: 5min, dtype: float64\n\nIn [294]: ts.resample(\"5Min\").ohlc()\nOut[294]: \n open  high  low  close\n2012-01-01   308   460    9    205\n\nIn [295]: ts.resample(\"5Min\").max()\nOut[295]: \n2012-01-01    460\nFreq: 5min, dtype: int64 \n```", "```py\nIn [296]: ts.resample(\"5Min\", closed=\"right\").mean()\nOut[296]: \n2011-12-31 23:55:00    308.000000\n2012-01-01 00:00:00    250.454545\nFreq: 5min, dtype: float64\n\nIn [297]: ts.resample(\"5Min\", closed=\"left\").mean()\nOut[297]: \n2012-01-01    251.03\nFreq: 5min, dtype: float64 \n```", "```py\nIn [298]: ts.resample(\"5Min\").mean()  # by default label='left'\nOut[298]: \n2012-01-01    251.03\nFreq: 5min, dtype: float64\n\nIn [299]: ts.resample(\"5Min\", label=\"left\").mean()\nOut[299]: \n2012-01-01    251.03\nFreq: 5min, dtype: float64 \n```", "```py\nIn [300]: s = pd.date_range(\"2000-01-01\", \"2000-01-05\").to_series()\n\nIn [301]: s.iloc[2] = pd.NaT\n\nIn [302]: s.dt.day_name()\nOut[302]: \n2000-01-01     Saturday\n2000-01-02       Sunday\n2000-01-03          NaN\n2000-01-04      Tuesday\n2000-01-05    Wednesday\nFreq: D, dtype: object\n\n# default: label='left', closed='left'\nIn [303]: s.resample(\"B\").last().dt.day_name()\nOut[303]: \n1999-12-31       Sunday\n2000-01-03          NaN\n2000-01-04      Tuesday\n2000-01-05    Wednesday\nFreq: B, dtype: object \n```", "```py\nIn [304]: s.resample(\"B\", label=\"right\", closed=\"right\").last().dt.day_name()\nOut[304]: \n2000-01-03       Sunday\n2000-01-04      Tuesday\n2000-01-05    Wednesday\n2000-01-06          NaN\nFreq: B, dtype: object \n```", "```py\n# from secondly to every 250 milliseconds\nIn [305]: ts[:2].resample(\"250ms\").asfreq()\nOut[305]: \n2012-01-01 00:00:00.000    308.0\n2012-01-01 00:00:00.250      NaN\n2012-01-01 00:00:00.500      NaN\n2012-01-01 00:00:00.750      NaN\n2012-01-01 00:00:01.000    204.0\nFreq: 250ms, dtype: float64\n\nIn [306]: ts[:2].resample(\"250ms\").ffill()\nOut[306]: \n2012-01-01 00:00:00.000    308\n2012-01-01 00:00:00.250    308\n2012-01-01 00:00:00.500    308\n2012-01-01 00:00:00.750    308\n2012-01-01 00:00:01.000    204\nFreq: 250ms, dtype: int64\n\nIn [307]: ts[:2].resample(\"250ms\").ffill(limit=2)\nOut[307]: \n2012-01-01 00:00:00.000    308.0\n2012-01-01 00:00:00.250    308.0\n2012-01-01 00:00:00.500    308.0\n2012-01-01 00:00:00.750      NaN\n2012-01-01 00:00:01.000    204.0\nFreq: 250ms, dtype: float64 \n```", "```py\nIn [308]: rng = pd.date_range(\"2014-1-1\", periods=100, freq=\"D\") + pd.Timedelta(\"1s\")\n\nIn [309]: ts = pd.Series(range(100), index=rng) \n```", "```py\nIn [310]: ts.resample(\"3min\").sum()\nOut[310]: \n2014-01-01 00:00:00     0\n2014-01-01 00:03:00     0\n2014-01-01 00:06:00     0\n2014-01-01 00:09:00     0\n2014-01-01 00:12:00     0\n ..\n2014-04-09 23:48:00     0\n2014-04-09 23:51:00     0\n2014-04-09 23:54:00     0\n2014-04-09 23:57:00     0\n2014-04-10 00:00:00    99\nFreq: 3min, Length: 47521, dtype: int64 \n```", "```py\nIn [311]: from functools import partial\n\nIn [312]: from pandas.tseries.frequencies import to_offset\n\nIn [313]: def round(t, freq):\n .....:    freq = to_offset(freq)\n .....:    td = pd.Timedelta(freq)\n .....:    return pd.Timestamp((t.value // td.value) * td.value)\n .....: \n\nIn [314]: ts.groupby(partial(round, freq=\"3min\")).sum()\nOut[314]: \n2014-01-01     0\n2014-01-02     1\n2014-01-03     2\n2014-01-04     3\n2014-01-05     4\n ..\n2014-04-06    95\n2014-04-07    96\n2014-04-08    97\n2014-04-09    98\n2014-04-10    99\nLength: 100, dtype: int64 \n```", "```py\nIn [315]: df = pd.DataFrame(\n .....:    np.random.randn(1000, 3),\n .....:    index=pd.date_range(\"1/1/2012\", freq=\"s\", periods=1000),\n .....:    columns=[\"A\", \"B\", \"C\"],\n .....: )\n .....: \n\nIn [316]: r = df.resample(\"3min\")\n\nIn [317]: r.mean()\nOut[317]: \n A         B         C\n2012-01-01 00:00:00 -0.033823 -0.121514 -0.081447\n2012-01-01 00:03:00  0.056909  0.146731 -0.024320\n2012-01-01 00:06:00 -0.058837  0.047046 -0.052021\n2012-01-01 00:09:00  0.063123 -0.026158 -0.066533\n2012-01-01 00:12:00  0.186340 -0.003144  0.074752\n2012-01-01 00:15:00 -0.085954 -0.016287 -0.050046 \n```", "```py\nIn [318]: r[\"A\"].mean()\nOut[318]: \n2012-01-01 00:00:00   -0.033823\n2012-01-01 00:03:00    0.056909\n2012-01-01 00:06:00   -0.058837\n2012-01-01 00:09:00    0.063123\n2012-01-01 00:12:00    0.186340\n2012-01-01 00:15:00   -0.085954\nFreq: 3min, Name: A, dtype: float64\n\nIn [319]: r[[\"A\", \"B\"]].mean()\nOut[319]: \n A         B\n2012-01-01 00:00:00 -0.033823 -0.121514\n2012-01-01 00:03:00  0.056909  0.146731\n2012-01-01 00:06:00 -0.058837  0.047046\n2012-01-01 00:09:00  0.063123 -0.026158\n2012-01-01 00:12:00  0.186340 -0.003144\n2012-01-01 00:15:00 -0.085954 -0.016287 \n```", "```py\nIn [320]: r[\"A\"].agg([\"sum\", \"mean\", \"std\"])\nOut[320]: \n sum      mean       std\n2012-01-01 00:00:00  -6.088060 -0.033823  1.043263\n2012-01-01 00:03:00  10.243678  0.056909  1.058534\n2012-01-01 00:06:00 -10.590584 -0.058837  0.949264\n2012-01-01 00:09:00  11.362228  0.063123  1.028096\n2012-01-01 00:12:00  33.541257  0.186340  0.884586\n2012-01-01 00:15:00  -8.595393 -0.085954  1.035476 \n```", "```py\nIn [321]: r.agg([\"sum\", \"mean\"])\nOut[321]: \n A            ...          C \n sum      mean  ...        sum      mean\n2012-01-01 00:00:00  -6.088060 -0.033823  ... -14.660515 -0.081447\n2012-01-01 00:03:00  10.243678  0.056909  ...  -4.377642 -0.024320\n2012-01-01 00:06:00 -10.590584 -0.058837  ...  -9.363825 -0.052021\n2012-01-01 00:09:00  11.362228  0.063123  ... -11.975895 -0.066533\n2012-01-01 00:12:00  33.541257  0.186340  ...  13.455299  0.074752\n2012-01-01 00:15:00  -8.595393 -0.085954  ...  -5.004580 -0.050046\n\n[6 rows x 6 columns] \n```", "```py\nIn [322]: r.agg({\"A\": \"sum\", \"B\": lambda x: np.std(x, ddof=1)})\nOut[322]: \n A         B\n2012-01-01 00:00:00  -6.088060  1.001294\n2012-01-01 00:03:00  10.243678  1.074597\n2012-01-01 00:06:00 -10.590584  0.987309\n2012-01-01 00:09:00  11.362228  0.944953\n2012-01-01 00:12:00  33.541257  1.095025\n2012-01-01 00:15:00  -8.595393  1.035312 \n```", "```py\nIn [323]: r.agg({\"A\": \"sum\", \"B\": \"std\"})\nOut[323]: \n A         B\n2012-01-01 00:00:00  -6.088060  1.001294\n2012-01-01 00:03:00  10.243678  1.074597\n2012-01-01 00:06:00 -10.590584  0.987309\n2012-01-01 00:09:00  11.362228  0.944953\n2012-01-01 00:12:00  33.541257  1.095025\n2012-01-01 00:15:00  -8.595393  1.035312 \n```", "```py\nIn [324]: r.agg({\"A\": [\"sum\", \"std\"], \"B\": [\"mean\", \"std\"]})\nOut[324]: \n A                   B \n sum       std      mean       std\n2012-01-01 00:00:00  -6.088060  1.043263 -0.121514  1.001294\n2012-01-01 00:03:00  10.243678  1.058534  0.146731  1.074597\n2012-01-01 00:06:00 -10.590584  0.949264  0.047046  0.987309\n2012-01-01 00:09:00  11.362228  1.028096 -0.026158  0.944953\n2012-01-01 00:12:00  33.541257  0.884586 -0.003144  1.095025\n2012-01-01 00:15:00  -8.595393  1.035476 -0.016287  1.035312 \n```", "```py\nIn [325]: df = pd.DataFrame(\n .....:    {\"date\": pd.date_range(\"2015-01-01\", freq=\"W\", periods=5), \"a\": np.arange(5)},\n .....:    index=pd.MultiIndex.from_arrays(\n .....:        [[1, 2, 3, 4, 5], pd.date_range(\"2015-01-01\", freq=\"W\", periods=5)],\n .....:        names=[\"v\", \"d\"],\n .....:    ),\n .....: )\n .....: \n\nIn [326]: df\nOut[326]: \n date  a\nv d \n1 2015-01-04 2015-01-04  0\n2 2015-01-11 2015-01-11  1\n3 2015-01-18 2015-01-18  2\n4 2015-01-25 2015-01-25  3\n5 2015-02-01 2015-02-01  4\n\nIn [327]: df.resample(\"ME\", on=\"date\")[[\"a\"]].sum()\nOut[327]: \n a\ndate \n2015-01-31  6\n2015-02-28  4 \n```", "```py\nIn [328]: df.resample(\"ME\", level=\"d\")[[\"a\"]].sum()\nOut[328]: \n a\nd \n2015-01-31  6\n2015-02-28  4 \n```", "```py\nIn [329]: small = pd.Series(\n .....:    range(6),\n .....:    index=pd.to_datetime(\n .....:        [\n .....:            \"2017-01-01T00:00:00\",\n .....:            \"2017-01-01T00:30:00\",\n .....:            \"2017-01-01T00:31:00\",\n .....:            \"2017-01-01T01:00:00\",\n .....:            \"2017-01-01T03:00:00\",\n .....:            \"2017-01-01T03:05:00\",\n .....:        ]\n .....:    ),\n .....: )\n .....: \n\nIn [330]: resampled = small.resample(\"h\")\n\nIn [331]: for name, group in resampled:\n .....:    print(\"Group: \", name)\n .....:    print(\"-\" * 27)\n .....:    print(group, end=\"\\n\\n\")\n .....: \nGroup:  2017-01-01 00:00:00\n---------------------------\n2017-01-01 00:00:00    0\n2017-01-01 00:30:00    1\n2017-01-01 00:31:00    2\ndtype: int64\n\nGroup:  2017-01-01 01:00:00\n---------------------------\n2017-01-01 01:00:00    3\ndtype: int64\n\nGroup:  2017-01-01 02:00:00\n---------------------------\nSeries([], dtype: int64)\n\nGroup:  2017-01-01 03:00:00\n---------------------------\n2017-01-01 03:00:00    4\n2017-01-01 03:05:00    5\ndtype: int64 \n```", "```py\nIn [332]: start, end = \"2000-10-01 23:30:00\", \"2000-10-02 00:30:00\"\n\nIn [333]: middle = \"2000-10-02 00:00:00\"\n\nIn [334]: rng = pd.date_range(start, end, freq=\"7min\")\n\nIn [335]: ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n\nIn [336]: ts\nOut[336]: \n2000-10-01 23:30:00     0\n2000-10-01 23:37:00     3\n2000-10-01 23:44:00     6\n2000-10-01 23:51:00     9\n2000-10-01 23:58:00    12\n2000-10-02 00:05:00    15\n2000-10-02 00:12:00    18\n2000-10-02 00:19:00    21\n2000-10-02 00:26:00    24\nFreq: 7min, dtype: int64 \n```", "```py\nIn [337]: ts.resample(\"17min\", origin=\"start_day\").sum()\nOut[337]: \n2000-10-01 23:14:00     0\n2000-10-01 23:31:00     9\n2000-10-01 23:48:00    21\n2000-10-02 00:05:00    54\n2000-10-02 00:22:00    24\nFreq: 17min, dtype: int64\n\nIn [338]: ts[middle:end].resample(\"17min\", origin=\"start_day\").sum()\nOut[338]: \n2000-10-02 00:00:00    33\n2000-10-02 00:17:00    45\nFreq: 17min, dtype: int64 \n```", "```py\nIn [339]: ts.resample(\"17min\", origin=\"epoch\").sum()\nOut[339]: \n2000-10-01 23:18:00     0\n2000-10-01 23:35:00    18\n2000-10-01 23:52:00    27\n2000-10-02 00:09:00    39\n2000-10-02 00:26:00    24\nFreq: 17min, dtype: int64\n\nIn [340]: ts[middle:end].resample(\"17min\", origin=\"epoch\").sum()\nOut[340]: \n2000-10-01 23:52:00    15\n2000-10-02 00:09:00    39\n2000-10-02 00:26:00    24\nFreq: 17min, dtype: int64 \n```", "```py\nIn [341]: ts.resample(\"17min\", origin=\"2001-01-01\").sum()\nOut[341]: \n2000-10-01 23:30:00     9\n2000-10-01 23:47:00    21\n2000-10-02 00:04:00    54\n2000-10-02 00:21:00    24\nFreq: 17min, dtype: int64\n\nIn [342]: ts[middle:end].resample(\"17min\", origin=pd.Timestamp(\"2001-01-01\")).sum()\nOut[342]: \n2000-10-02 00:04:00    54\n2000-10-02 00:21:00    24\nFreq: 17min, dtype: int64 \n```", "```py\nIn [343]: ts.resample(\"17min\", origin=\"start\").sum()\nOut[343]: \n2000-10-01 23:30:00     9\n2000-10-01 23:47:00    21\n2000-10-02 00:04:00    54\n2000-10-02 00:21:00    24\nFreq: 17min, dtype: int64\n\nIn [344]: ts.resample(\"17min\", offset=\"23h30min\").sum()\nOut[344]: \n2000-10-01 23:30:00     9\n2000-10-01 23:47:00    21\n2000-10-02 00:04:00    54\n2000-10-02 00:21:00    24\nFreq: 17min, dtype: int64 \n```", "```py\nIn [345]: ts.resample('17min', origin='end').sum()\nOut[345]: \n2000-10-01 23:35:00     0\n2000-10-01 23:52:00    18\n2000-10-02 00:09:00    27\n2000-10-02 00:26:00    63\nFreq: 17min, dtype: int64 \n```", "```py\nIn [346]: ts.resample('17min', origin='end_day').sum()\nOut[346]: \n2000-10-01 23:38:00     3\n2000-10-01 23:55:00    15\n2000-10-02 00:12:00    45\n2000-10-02 00:29:00    45\nFreq: 17min, dtype: int64 \n```", "```py\nIn [347]: ceil_mid = rng.max().ceil('D')\n\nIn [348]: freq = pd.offsets.Minute(17)\n\nIn [349]: bin_res = ceil_mid - freq * ((ceil_mid - rng.max()) // freq)\n\nIn [350]: bin_res\nOut[350]: Timestamp('2000-10-02 00:29:00') \n```", "```py\nIn [351]: pd.Period(\"2012\", freq=\"Y-DEC\")\nOut[351]: Period('2012', 'Y-DEC')\n\nIn [352]: pd.Period(\"2012-1-1\", freq=\"D\")\nOut[352]: Period('2012-01-01', 'D')\n\nIn [353]: pd.Period(\"2012-1-1 19:00\", freq=\"h\")\nOut[353]: Period('2012-01-01 19:00', 'h')\n\nIn [354]: pd.Period(\"2012-1-1 19:00\", freq=\"5h\")\nOut[354]: Period('2012-01-01 19:00', '5h') \n```", "```py\nIn [355]: p = pd.Period(\"2012\", freq=\"Y-DEC\")\n\nIn [356]: p + 1\nOut[356]: Period('2013', 'Y-DEC')\n\nIn [357]: p - 3\nOut[357]: Period('2009', 'Y-DEC')\n\nIn [358]: p = pd.Period(\"2012-01\", freq=\"2M\")\n\nIn [359]: p + 2\nOut[359]: Period('2012-05', '2M')\n\nIn [360]: p - 1\nOut[360]: Period('2011-11', '2M')\n\nIn [361]: p == pd.Period(\"2012-01\", freq=\"3M\")\nOut[361]: False \n```", "```py\nIn [362]: p = pd.Period(\"2014-07-01 09:00\", freq=\"h\")\n\nIn [363]: p + pd.offsets.Hour(2)\nOut[363]: Period('2014-07-01 11:00', 'h')\n\nIn [364]: p + datetime.timedelta(minutes=120)\nOut[364]: Period('2014-07-01 11:00', 'h')\n\nIn [365]: p + np.timedelta64(7200, \"s\")\nOut[365]: Period('2014-07-01 11:00', 'h') \n```", "```py\nIn [366]: p + pd.offsets.Minute(5)\n---------------------------------------------------------------------------\nValueError  Traceback (most recent call last)\nFile period.pyx:1824, in pandas._libs.tslibs.period._Period._add_timedeltalike_scalar()\n\nFile timedeltas.pyx:278, in pandas._libs.tslibs.timedeltas.delta_to_nanoseconds()\n\nFile np_datetime.pyx:661, in pandas._libs.tslibs.np_datetime.convert_reso()\n\nValueError: Cannot losslessly convert units\n\nThe above exception was the direct cause of the following exception:\n\nIncompatibleFrequency  Traceback (most recent call last)\nCell In[366], line 1\n----> 1 p + pd.offsets.Minute(5)\n\nFile period.pyx:1845, in pandas._libs.tslibs.period._Period.__add__()\n\nFile period.pyx:1826, in pandas._libs.tslibs.period._Period._add_timedeltalike_scalar()\n\nIncompatibleFrequency: Input cannot be converted to Period(freq=h) \n```", "```py\nIn [367]: p = pd.Period(\"2014-07\", freq=\"M\")\n\nIn [368]: p + pd.offsets.MonthEnd(3)\nOut[368]: Period('2014-10', 'M') \n```", "```py\nIn [369]: p + pd.offsets.MonthBegin(3)\n---------------------------------------------------------------------------\nIncompatibleFrequency  Traceback (most recent call last)\nCell In[369], line 1\n----> 1 p + pd.offsets.MonthBegin(3)\n\nFile period.pyx:1847, in pandas._libs.tslibs.period._Period.__add__()\n\nFile period.pyx:1837, in pandas._libs.tslibs.period._Period._add_offset()\n\nFile period.pyx:1732, in pandas._libs.tslibs.period.PeriodMixin._require_matching_freq()\n\nIncompatibleFrequency: Input has different freq=3M from Period(freq=M) \n```", "```py\nIn [370]: pd.Period(\"2012\", freq=\"Y-DEC\") - pd.Period(\"2002\", freq=\"Y-DEC\")\nOut[370]: <10 * YearEnds: month=12> \n```", "```py\nIn [371]: prng = pd.period_range(\"1/1/2011\", \"1/1/2012\", freq=\"M\")\n\nIn [372]: prng\nOut[372]: \nPeriodIndex(['2011-01', '2011-02', '2011-03', '2011-04', '2011-05', '2011-06',\n '2011-07', '2011-08', '2011-09', '2011-10', '2011-11', '2011-12',\n '2012-01'],\n dtype='period[M]') \n```", "```py\nIn [373]: pd.PeriodIndex([\"2011-1\", \"2011-2\", \"2011-3\"], freq=\"M\")\nOut[373]: PeriodIndex(['2011-01', '2011-02', '2011-03'], dtype='period[M]') \n```", "```py\nIn [374]: pd.period_range(start=\"2014-01\", freq=\"3M\", periods=4)\nOut[374]: PeriodIndex(['2014-01', '2014-04', '2014-07', '2014-10'], dtype='period[3M]') \n```", "```py\nIn [375]: pd.period_range(\n .....:    start=pd.Period(\"2017Q1\", freq=\"Q\"), end=pd.Period(\"2017Q2\", freq=\"Q\"), freq=\"M\"\n .....: )\n .....: \nOut[375]: PeriodIndex(['2017-03', '2017-04', '2017-05', '2017-06'], dtype='period[M]') \n```", "```py\nIn [376]: ps = pd.Series(np.random.randn(len(prng)), prng)\n\nIn [377]: ps\nOut[377]: \n2011-01   -2.916901\n2011-02    0.514474\n2011-03    1.346470\n2011-04    0.816397\n2011-05    2.258648\n2011-06    0.494789\n2011-07    0.301239\n2011-08    0.464776\n2011-09   -1.393581\n2011-10    0.056780\n2011-11    0.197035\n2011-12    2.261385\n2012-01   -0.329583\nFreq: M, dtype: float64 \n```", "```py\nIn [378]: idx = pd.period_range(\"2014-07-01 09:00\", periods=5, freq=\"h\")\n\nIn [379]: idx\nOut[379]: \nPeriodIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',\n '2014-07-01 12:00', '2014-07-01 13:00'],\n dtype='period[h]')\n\nIn [380]: idx + pd.offsets.Hour(2)\nOut[380]: \nPeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',\n '2014-07-01 14:00', '2014-07-01 15:00'],\n dtype='period[h]')\n\nIn [381]: idx = pd.period_range(\"2014-07\", periods=5, freq=\"M\")\n\nIn [382]: idx\nOut[382]: PeriodIndex(['2014-07', '2014-08', '2014-09', '2014-10', '2014-11'], dtype='period[M]')\n\nIn [383]: idx + pd.offsets.MonthEnd(3)\nOut[383]: PeriodIndex(['2014-10', '2014-11', '2014-12', '2015-01', '2015-02'], dtype='period[M]') \n```", "```py\nIn [384]: pi = pd.period_range(\"2016-01-01\", periods=3, freq=\"M\")\n\nIn [385]: pi\nOut[385]: PeriodIndex(['2016-01', '2016-02', '2016-03'], dtype='period[M]')\n\nIn [386]: pi.dtype\nOut[386]: period[M] \n```", "```py\n# change monthly freq to daily freq\nIn [387]: pi.astype(\"period[D]\")\nOut[387]: PeriodIndex(['2016-01-31', '2016-02-29', '2016-03-31'], dtype='period[D]')\n\n# convert to DatetimeIndex\nIn [388]: pi.astype(\"datetime64[ns]\")\nOut[388]: DatetimeIndex(['2016-01-01', '2016-02-01', '2016-03-01'], dtype='datetime64[ns]', freq='MS')\n\n# convert to PeriodIndex\nIn [389]: dti = pd.date_range(\"2011-01-01\", freq=\"ME\", periods=3)\n\nIn [390]: dti\nOut[390]: DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31'], dtype='datetime64[ns]', freq='ME')\n\nIn [391]: dti.astype(\"period[M]\")\nOut[391]: PeriodIndex(['2011-01', '2011-02', '2011-03'], dtype='period[M]') \n```", "```py\nIn [392]: ps[\"2011-01\"]\nOut[392]: -2.9169013294054507\n\nIn [393]: ps[datetime.datetime(2011, 12, 25):]\nOut[393]: \n2011-12    2.261385\n2012-01   -0.329583\nFreq: M, dtype: float64\n\nIn [394]: ps[\"10/31/2011\":\"12/31/2011\"]\nOut[394]: \n2011-10    0.056780\n2011-11    0.197035\n2011-12    2.261385\nFreq: M, dtype: float64 \n```", "```py\nIn [395]: ps[\"2011\"]\nOut[395]: \n2011-01   -2.916901\n2011-02    0.514474\n2011-03    1.346470\n2011-04    0.816397\n2011-05    2.258648\n2011-06    0.494789\n2011-07    0.301239\n2011-08    0.464776\n2011-09   -1.393581\n2011-10    0.056780\n2011-11    0.197035\n2011-12    2.261385\nFreq: M, dtype: float64\n\nIn [396]: dfp = pd.DataFrame(\n .....:    np.random.randn(600, 1),\n .....:    columns=[\"A\"],\n .....:    index=pd.period_range(\"2013-01-01 9:00\", periods=600, freq=\"min\"),\n .....: )\n .....: \n\nIn [397]: dfp\nOut[397]: \n A\n2013-01-01 09:00 -0.538468\n2013-01-01 09:01 -1.365819\n2013-01-01 09:02 -0.969051\n2013-01-01 09:03 -0.331152\n2013-01-01 09:04 -0.245334\n...                    ...\n2013-01-01 18:55  0.522460\n2013-01-01 18:56  0.118710\n2013-01-01 18:57  0.167517\n2013-01-01 18:58  0.922883\n2013-01-01 18:59  1.721104\n\n[600 rows x 1 columns]\n\nIn [398]: dfp.loc[\"2013-01-01 10h\"]\nOut[398]: \n A\n2013-01-01 10:00 -0.308975\n2013-01-01 10:01  0.542520\n2013-01-01 10:02  1.061068\n2013-01-01 10:03  0.754005\n2013-01-01 10:04  0.352933\n...                    ...\n2013-01-01 10:55 -0.865621\n2013-01-01 10:56 -1.167818\n2013-01-01 10:57 -2.081748\n2013-01-01 10:58 -0.527146\n2013-01-01 10:59  0.802298\n\n[60 rows x 1 columns] \n```", "```py\nIn [399]: dfp[\"2013-01-01 10h\":\"2013-01-01 11h\"]\nOut[399]: \n A\n2013-01-01 10:00 -0.308975\n2013-01-01 10:01  0.542520\n2013-01-01 10:02  1.061068\n2013-01-01 10:03  0.754005\n2013-01-01 10:04  0.352933\n...                    ...\n2013-01-01 11:55 -0.590204\n2013-01-01 11:56  1.539990\n2013-01-01 11:57 -1.224826\n2013-01-01 11:58  0.578798\n2013-01-01 11:59 -0.685496\n\n[120 rows x 1 columns] \n```", "```py\nIn [400]: p = pd.Period(\"2011\", freq=\"Y-DEC\")\n\nIn [401]: p\nOut[401]: Period('2011', 'Y-DEC') \n```", "```py\nIn [402]: p.asfreq(\"M\", how=\"start\")\nOut[402]: Period('2011-01', 'M')\n\nIn [403]: p.asfreq(\"M\", how=\"end\")\nOut[403]: Period('2011-12', 'M') \n```", "```py\nIn [404]: p.asfreq(\"M\", \"s\")\nOut[404]: Period('2011-01', 'M')\n\nIn [405]: p.asfreq(\"M\", \"e\")\nOut[405]: Period('2011-12', 'M') \n```", "```py\nIn [406]: p = pd.Period(\"2011-12\", freq=\"M\")\n\nIn [407]: p.asfreq(\"Y-NOV\")\nOut[407]: Period('2012', 'Y-NOV') \n```", "```py\nIn [408]: p = pd.Period(\"2012Q1\", freq=\"Q-DEC\")\n\nIn [409]: p.asfreq(\"D\", \"s\")\nOut[409]: Period('2012-01-01', 'D')\n\nIn [410]: p.asfreq(\"D\", \"e\")\nOut[410]: Period('2012-03-31', 'D') \n```", "```py\nIn [411]: p = pd.Period(\"2011Q4\", freq=\"Q-MAR\")\n\nIn [412]: p.asfreq(\"D\", \"s\")\nOut[412]: Period('2011-01-01', 'D')\n\nIn [413]: p.asfreq(\"D\", \"e\")\nOut[413]: Period('2011-03-31', 'D') \n```", "```py\nIn [414]: rng = pd.date_range(\"1/1/2012\", periods=5, freq=\"ME\")\n\nIn [415]: ts = pd.Series(np.random.randn(len(rng)), index=rng)\n\nIn [416]: ts\nOut[416]: \n2012-01-31    1.931253\n2012-02-29   -0.184594\n2012-03-31    0.249656\n2012-04-30   -0.978151\n2012-05-31   -0.873389\nFreq: ME, dtype: float64\n\nIn [417]: ps = ts.to_period()\n\nIn [418]: ps\nOut[418]: \n2012-01    1.931253\n2012-02   -0.184594\n2012-03    0.249656\n2012-04   -0.978151\n2012-05   -0.873389\nFreq: M, dtype: float64\n\nIn [419]: ps.to_timestamp()\nOut[419]: \n2012-01-01    1.931253\n2012-02-01   -0.184594\n2012-03-01    0.249656\n2012-04-01   -0.978151\n2012-05-01   -0.873389\nFreq: MS, dtype: float64 \n```", "```py\nIn [420]: ps.to_timestamp(\"D\", how=\"s\")\nOut[420]: \n2012-01-01    1.931253\n2012-02-01   -0.184594\n2012-03-01    0.249656\n2012-04-01   -0.978151\n2012-05-01   -0.873389\nFreq: MS, dtype: float64 \n```", "```py\nIn [421]: prng = pd.period_range(\"1990Q1\", \"2000Q4\", freq=\"Q-NOV\")\n\nIn [422]: ts = pd.Series(np.random.randn(len(prng)), prng)\n\nIn [423]: ts.index = (prng.asfreq(\"M\", \"e\") + 1).asfreq(\"h\", \"s\") + 9\n\nIn [424]: ts.head()\nOut[424]: \n1990-03-01 09:00   -0.109291\n1990-06-01 09:00   -0.637235\n1990-09-01 09:00   -1.735925\n1990-12-01 09:00    2.096946\n1991-03-01 09:00   -1.039926\nFreq: h, dtype: float64 \n```", "```py\nIn [425]: span = pd.period_range(\"1215-01-01\", \"1381-01-01\", freq=\"D\")\n\nIn [426]: span\nOut[426]: \nPeriodIndex(['1215-01-01', '1215-01-02', '1215-01-03', '1215-01-04',\n '1215-01-05', '1215-01-06', '1215-01-07', '1215-01-08',\n '1215-01-09', '1215-01-10',\n ...\n '1380-12-23', '1380-12-24', '1380-12-25', '1380-12-26',\n '1380-12-27', '1380-12-28', '1380-12-29', '1380-12-30',\n '1380-12-31', '1381-01-01'],\n dtype='period[D]', length=60632) \n```", "```py\nIn [427]: s = pd.Series([20121231, 20141130, 99991231])\n\nIn [428]: s\nOut[428]: \n0    20121231\n1    20141130\n2    99991231\ndtype: int64\n\nIn [429]: def conv(x):\n .....:    return pd.Period(year=x // 10000, month=x // 100 % 100, day=x % 100, freq=\"D\")\n .....: \n\nIn [430]: s.apply(conv)\nOut[430]: \n0    2012-12-31\n1    2014-11-30\n2    9999-12-31\ndtype: period[D]\n\nIn [431]: s.apply(conv)[2]\nOut[431]: Period('9999-12-31', 'D') \n```", "```py\nIn [432]: span = pd.PeriodIndex(s.apply(conv))\n\nIn [433]: span\nOut[433]: PeriodIndex(['2012-12-31', '2014-11-30', '9999-12-31'], dtype='period[D]') \n```", "```py\nIn [434]: rng = pd.date_range(\"3/6/2012 00:00\", periods=15, freq=\"D\")\n\nIn [435]: rng.tz is None\nOut[435]: True \n```", "```py\nIn [436]: import dateutil\n\n# pytz\nIn [437]: rng_pytz = pd.date_range(\"3/6/2012 00:00\", periods=3, freq=\"D\", tz=\"Europe/London\")\n\nIn [438]: rng_pytz.tz\nOut[438]: <DstTzInfo 'Europe/London' LMT-1 day, 23:59:00 STD>\n\n# dateutil\nIn [439]: rng_dateutil = pd.date_range(\"3/6/2012 00:00\", periods=3, freq=\"D\")\n\nIn [440]: rng_dateutil = rng_dateutil.tz_localize(\"dateutil/Europe/London\")\n\nIn [441]: rng_dateutil.tz\nOut[441]: tzfile('/usr/share/zoneinfo/Europe/London')\n\n# dateutil - utc special case\nIn [442]: rng_utc = pd.date_range(\n .....:    \"3/6/2012 00:00\",\n .....:    periods=3,\n .....:    freq=\"D\",\n .....:    tz=dateutil.tz.tzutc(),\n .....: )\n .....: \n\nIn [443]: rng_utc.tz\nOut[443]: tzutc() \n```", "```py\n# datetime.timezone\nIn [444]: rng_utc = pd.date_range(\n .....:    \"3/6/2012 00:00\",\n .....:    periods=3,\n .....:    freq=\"D\",\n .....:    tz=datetime.timezone.utc,\n .....: )\n .....: \n\nIn [445]: rng_utc.tz\nOut[445]: datetime.timezone.utc \n```", "```py\nIn [446]: import pytz\n\n# pytz\nIn [447]: tz_pytz = pytz.timezone(\"Europe/London\")\n\nIn [448]: rng_pytz = pd.date_range(\"3/6/2012 00:00\", periods=3, freq=\"D\")\n\nIn [449]: rng_pytz = rng_pytz.tz_localize(tz_pytz)\n\nIn [450]: rng_pytz.tz == tz_pytz\nOut[450]: True\n\n# dateutil\nIn [451]: tz_dateutil = dateutil.tz.gettz(\"Europe/London\")\n\nIn [452]: rng_dateutil = pd.date_range(\"3/6/2012 00:00\", periods=3, freq=\"D\", tz=tz_dateutil)\n\nIn [453]: rng_dateutil.tz == tz_dateutil\nOut[453]: True \n```", "```py\nIn [454]: rng_pytz.tz_convert(\"US/Eastern\")\nOut[454]: \nDatetimeIndex(['2012-03-05 19:00:00-05:00', '2012-03-06 19:00:00-05:00',\n '2012-03-07 19:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None) \n```", "```py\nIn [455]: dti = pd.date_range(\"2019-01-01\", periods=3, freq=\"D\", tz=\"US/Pacific\")\n\nIn [456]: dti.tz\nOut[456]: <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>\n\nIn [457]: ts = pd.Timestamp(\"2019-01-01\", tz=\"US/Pacific\")\n\nIn [458]: ts.tz\nOut[458]: <DstTzInfo 'US/Pacific' PST-1 day, 16:00:00 STD> \n```", "```py\nIn [459]: d_2037 = \"2037-03-31T010101\"\n\nIn [460]: d_2038 = \"2038-03-31T010101\"\n\nIn [461]: DST = \"Europe/London\"\n\nIn [462]: assert pd.Timestamp(d_2037, tz=DST) != pd.Timestamp(d_2037, tz=\"GMT\")\n\nIn [463]: assert pd.Timestamp(d_2038, tz=DST) == pd.Timestamp(d_2038, tz=\"GMT\") \n```", "```py\nIn [464]: rng_eastern = rng_utc.tz_convert(\"US/Eastern\")\n\nIn [465]: rng_berlin = rng_utc.tz_convert(\"Europe/Berlin\")\n\nIn [466]: rng_eastern[2]\nOut[466]: Timestamp('2012-03-07 19:00:00-0500', tz='US/Eastern')\n\nIn [467]: rng_berlin[2]\nOut[467]: Timestamp('2012-03-08 01:00:00+0100', tz='Europe/Berlin')\n\nIn [468]: rng_eastern[2] == rng_berlin[2]\nOut[468]: True \n```", "```py\nIn [469]: ts_utc = pd.Series(range(3), pd.date_range(\"20130101\", periods=3, tz=\"UTC\"))\n\nIn [470]: eastern = ts_utc.tz_convert(\"US/Eastern\")\n\nIn [471]: berlin = ts_utc.tz_convert(\"Europe/Berlin\")\n\nIn [472]: result = eastern + berlin\n\nIn [473]: result\nOut[473]: \n2013-01-01 00:00:00+00:00    0\n2013-01-02 00:00:00+00:00    2\n2013-01-03 00:00:00+00:00    4\nFreq: D, dtype: int64\n\nIn [474]: result.index\nOut[474]: \nDatetimeIndex(['2013-01-01 00:00:00+00:00', '2013-01-02 00:00:00+00:00',\n '2013-01-03 00:00:00+00:00'],\n dtype='datetime64[ns, UTC]', freq='D') \n```", "```py\nIn [475]: didx = pd.date_range(start=\"2014-08-01 09:00\", freq=\"h\", periods=3, tz=\"US/Eastern\")\n\nIn [476]: didx\nOut[476]: \nDatetimeIndex(['2014-08-01 09:00:00-04:00', '2014-08-01 10:00:00-04:00',\n '2014-08-01 11:00:00-04:00'],\n dtype='datetime64[ns, US/Eastern]', freq='h')\n\nIn [477]: didx.tz_localize(None)\nOut[477]: \nDatetimeIndex(['2014-08-01 09:00:00', '2014-08-01 10:00:00',\n '2014-08-01 11:00:00'],\n dtype='datetime64[ns]', freq=None)\n\nIn [478]: didx.tz_convert(None)\nOut[478]: \nDatetimeIndex(['2014-08-01 13:00:00', '2014-08-01 14:00:00',\n '2014-08-01 15:00:00'],\n dtype='datetime64[ns]', freq='h')\n\n# tz_convert(None) is identical to tz_convert('UTC').tz_localize(None)\nIn [479]: didx.tz_convert(\"UTC\").tz_localize(None)\nOut[479]: \nDatetimeIndex(['2014-08-01 13:00:00', '2014-08-01 14:00:00',\n '2014-08-01 15:00:00'],\n dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [480]: pd.Timestamp(\n .....:    datetime.datetime(2019, 10, 27, 1, 30, 0, 0),\n .....:    tz=\"dateutil/Europe/London\",\n .....:    fold=0,\n .....: )\n .....: \nOut[480]: Timestamp('2019-10-27 01:30:00+0100', tz='dateutil//usr/share/zoneinfo/Europe/London')\n\nIn [481]: pd.Timestamp(\n .....:    year=2019,\n .....:    month=10,\n .....:    day=27,\n .....:    hour=1,\n .....:    minute=30,\n .....:    tz=\"dateutil/Europe/London\",\n .....:    fold=1,\n .....: )\n .....: \nOut[481]: Timestamp('2019-10-27 01:30:00+0000', tz='dateutil//usr/share/zoneinfo/Europe/London') \n```", "```py\nIn [482]: rng_hourly = pd.DatetimeIndex(\n .....:    [\"11/06/2011 00:00\", \"11/06/2011 01:00\", \"11/06/2011 01:00\", \"11/06/2011 02:00\"]\n .....: )\n .....: \n```", "```py\nIn [483]: rng_hourly.tz_localize('US/Eastern')\n---------------------------------------------------------------------------\nAmbiguousTimeError  Traceback (most recent call last)\nCell In[483], line 1\n----> 1 rng_hourly.tz_localize('US/Eastern')\n\nFile ~/work/pandas/pandas/pandas/core/indexes/datetimes.py:293, in DatetimeIndex.tz_localize(self, tz, ambiguous, nonexistent)\n  286 @doc(DatetimeArray.tz_localize)\n  287 def tz_localize(\n  288     self,\n   (...)\n  291     nonexistent: TimeNonexistent = \"raise\",\n  292 ) -> Self:\n--> 293     arr = self._data.tz_localize(tz, ambiguous, nonexistent)\n  294     return type(self)._simple_new(arr, name=self.name)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/_mixins.py:81, in ravel_compat.<locals>.method(self, *args, **kwargs)\n  78 @wraps(meth)\n  79 def method(self, *args, **kwargs):\n  80     if self.ndim == 1:\n---> 81         return meth(self, *args, **kwargs)\n  83     flags = self._ndarray.flags\n  84     flat = self.ravel(\"K\")\n\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimes.py:1088, in DatetimeArray.tz_localize(self, tz, ambiguous, nonexistent)\n  1085     tz = timezones.maybe_get_tz(tz)\n  1086     # Convert to UTC\n-> 1088     new_dates = tzconversion.tz_localize_to_utc(\n  1089         self.asi8,\n  1090         tz,\n  1091         ambiguous=ambiguous,\n  1092         nonexistent=nonexistent,\n  1093         creso=self._creso,\n  1094     )\n  1095 new_dates_dt64 = new_dates.view(f\"M8[{self.unit}]\")\n  1096 dtype = tz_to_dtype(tz, unit=self.unit)\n\nFile tzconversion.pyx:371, in pandas._libs.tslibs.tzconversion.tz_localize_to_utc()\n\nAmbiguousTimeError: Cannot infer dst time from 2011-11-06 01:00:00, try using the 'ambiguous' argument \n```", "```py\nIn [484]: rng_hourly.tz_localize(\"US/Eastern\", ambiguous=\"infer\")\nOut[484]: \nDatetimeIndex(['2011-11-06 00:00:00-04:00', '2011-11-06 01:00:00-04:00',\n '2011-11-06 01:00:00-05:00', '2011-11-06 02:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None)\n\nIn [485]: rng_hourly.tz_localize(\"US/Eastern\", ambiguous=\"NaT\")\nOut[485]: \nDatetimeIndex(['2011-11-06 00:00:00-04:00', 'NaT', 'NaT',\n '2011-11-06 02:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None)\n\nIn [486]: rng_hourly.tz_localize(\"US/Eastern\", ambiguous=[True, True, False, False])\nOut[486]: \nDatetimeIndex(['2011-11-06 00:00:00-04:00', '2011-11-06 01:00:00-04:00',\n '2011-11-06 01:00:00-05:00', '2011-11-06 02:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None) \n```", "```py\nIn [487]: dti = pd.date_range(start=\"2015-03-29 02:30:00\", periods=3, freq=\"h\")\n\n# 2:30 is a nonexistent time \n```", "```py\nIn [488]: dti.tz_localize('Europe/Warsaw')\n---------------------------------------------------------------------------\nNonExistentTimeError  Traceback (most recent call last)\nCell In[488], line 1\n----> 1 dti.tz_localize('Europe/Warsaw')\n\nFile ~/work/pandas/pandas/pandas/core/indexes/datetimes.py:293, in DatetimeIndex.tz_localize(self, tz, ambiguous, nonexistent)\n  286 @doc(DatetimeArray.tz_localize)\n  287 def tz_localize(\n  288     self,\n   (...)\n  291     nonexistent: TimeNonexistent = \"raise\",\n  292 ) -> Self:\n--> 293     arr = self._data.tz_localize(tz, ambiguous, nonexistent)\n  294     return type(self)._simple_new(arr, name=self.name)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/_mixins.py:81, in ravel_compat.<locals>.method(self, *args, **kwargs)\n  78 @wraps(meth)\n  79 def method(self, *args, **kwargs):\n  80     if self.ndim == 1:\n---> 81         return meth(self, *args, **kwargs)\n  83     flags = self._ndarray.flags\n  84     flat = self.ravel(\"K\")\n\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimes.py:1088, in DatetimeArray.tz_localize(self, tz, ambiguous, nonexistent)\n  1085     tz = timezones.maybe_get_tz(tz)\n  1086     # Convert to UTC\n-> 1088     new_dates = tzconversion.tz_localize_to_utc(\n  1089         self.asi8,\n  1090         tz,\n  1091         ambiguous=ambiguous,\n  1092         nonexistent=nonexistent,\n  1093         creso=self._creso,\n  1094     )\n  1095 new_dates_dt64 = new_dates.view(f\"M8[{self.unit}]\")\n  1096 dtype = tz_to_dtype(tz, unit=self.unit)\n\nFile tzconversion.pyx:431, in pandas._libs.tslibs.tzconversion.tz_localize_to_utc()\n\nNonExistentTimeError: 2015-03-29 02:30:00 \n```", "```py\nIn [489]: dti\nOut[489]: \nDatetimeIndex(['2015-03-29 02:30:00', '2015-03-29 03:30:00',\n '2015-03-29 04:30:00'],\n dtype='datetime64[ns]', freq='h')\n\nIn [490]: dti.tz_localize(\"Europe/Warsaw\", nonexistent=\"shift_forward\")\nOut[490]: \nDatetimeIndex(['2015-03-29 03:00:00+02:00', '2015-03-29 03:30:00+02:00',\n '2015-03-29 04:30:00+02:00'],\n dtype='datetime64[ns, Europe/Warsaw]', freq=None)\n\nIn [491]: dti.tz_localize(\"Europe/Warsaw\", nonexistent=\"shift_backward\")\nOut[491]: \nDatetimeIndex(['2015-03-29 01:59:59.999999999+01:00',\n '2015-03-29 03:30:00+02:00',\n '2015-03-29 04:30:00+02:00'],\n dtype='datetime64[ns, Europe/Warsaw]', freq=None)\n\nIn [492]: dti.tz_localize(\"Europe/Warsaw\", nonexistent=pd.Timedelta(1, unit=\"h\"))\nOut[492]: \nDatetimeIndex(['2015-03-29 03:30:00+02:00', '2015-03-29 03:30:00+02:00',\n '2015-03-29 04:30:00+02:00'],\n dtype='datetime64[ns, Europe/Warsaw]', freq=None)\n\nIn [493]: dti.tz_localize(\"Europe/Warsaw\", nonexistent=\"NaT\")\nOut[493]: \nDatetimeIndex(['NaT', '2015-03-29 03:30:00+02:00',\n '2015-03-29 04:30:00+02:00'],\n dtype='datetime64[ns, Europe/Warsaw]', freq=None) \n```", "```py\nIn [494]: s_naive = pd.Series(pd.date_range(\"20130101\", periods=3))\n\nIn [495]: s_naive\nOut[495]: \n0   2013-01-01\n1   2013-01-02\n2   2013-01-03\ndtype: datetime64[ns] \n```", "```py\nIn [496]: s_aware = pd.Series(pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\"))\n\nIn [497]: s_aware\nOut[497]: \n0   2013-01-01 00:00:00-05:00\n1   2013-01-02 00:00:00-05:00\n2   2013-01-03 00:00:00-05:00\ndtype: datetime64[ns, US/Eastern] \n```", "```py\nIn [498]: s_naive.dt.tz_localize(\"UTC\").dt.tz_convert(\"US/Eastern\")\nOut[498]: \n0   2012-12-31 19:00:00-05:00\n1   2013-01-01 19:00:00-05:00\n2   2013-01-02 19:00:00-05:00\ndtype: datetime64[ns, US/Eastern] \n```", "```py\n# convert to a new time zone\nIn [499]: s_aware.astype(\"datetime64[ns, CET]\")\nOut[499]: \n0   2013-01-01 06:00:00+01:00\n1   2013-01-02 06:00:00+01:00\n2   2013-01-03 06:00:00+01:00\ndtype: datetime64[ns, CET] \n```", "```py\nIn [500]: s_naive.to_numpy()\nOut[500]: \narray(['2013-01-01T00:00:00.000000000', '2013-01-02T00:00:00.000000000',\n '2013-01-03T00:00:00.000000000'], dtype='datetime64[ns]')\n\nIn [501]: s_aware.to_numpy()\nOut[501]: \narray([Timestamp('2013-01-01 00:00:00-0500', tz='US/Eastern'),\n Timestamp('2013-01-02 00:00:00-0500', tz='US/Eastern'),\n Timestamp('2013-01-03 00:00:00-0500', tz='US/Eastern')],\n dtype=object) \n```", "```py\nIn [502]: pd.Series(s_aware.to_numpy())\nOut[502]: \n0   2013-01-01 00:00:00-05:00\n1   2013-01-02 00:00:00-05:00\n2   2013-01-03 00:00:00-05:00\ndtype: datetime64[ns, US/Eastern] \n```", "```py\nIn [503]: s_aware.to_numpy(dtype=\"datetime64[ns]\")\nOut[503]: \narray(['2013-01-01T05:00:00.000000000', '2013-01-02T05:00:00.000000000',\n '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]') \n```", "```py\nIn [19]: pd.Series(range(3), index=pd.date_range(\"2000\", freq=\"D\", periods=3))\nOut[19]: \n2000-01-01    0\n2000-01-02    1\n2000-01-03    2\nFreq: D, dtype: int64 \n```", "```py\nIn [20]: pd.Series(pd.date_range(\"2000\", freq=\"D\", periods=3))\nOut[20]: \n0   2000-01-01\n1   2000-01-02\n2   2000-01-03\ndtype: datetime64[ns] \n```", "```py\nIn [21]: pd.Series(pd.period_range(\"1/1/2011\", freq=\"M\", periods=3))\nOut[21]: \n0    2011-01\n1    2011-02\n2    2011-03\ndtype: period[M]\n\nIn [22]: pd.Series([pd.DateOffset(1), pd.DateOffset(2)])\nOut[22]: \n0         <DateOffset>\n1    <2 * DateOffsets>\ndtype: object\n\nIn [23]: pd.Series(pd.date_range(\"1/1/2011\", freq=\"ME\", periods=3))\nOut[23]: \n0   2011-01-31\n1   2011-02-28\n2   2011-03-31\ndtype: datetime64[ns] \n```", "```py\nIn [24]: pd.Timestamp(pd.NaT)\nOut[24]: NaT\n\nIn [25]: pd.Timedelta(pd.NaT)\nOut[25]: NaT\n\nIn [26]: pd.Period(pd.NaT)\nOut[26]: NaT\n\n# Equality acts as np.nan would\nIn [27]: pd.NaT == pd.NaT\nOut[27]: False \n```", "```py\nIn [28]: import datetime\n\nIn [29]: pd.Timestamp(datetime.datetime(2012, 5, 1))\nOut[29]: Timestamp('2012-05-01 00:00:00')\n\nIn [30]: pd.Timestamp(\"2012-05-01\")\nOut[30]: Timestamp('2012-05-01 00:00:00')\n\nIn [31]: pd.Timestamp(2012, 5, 1)\nOut[31]: Timestamp('2012-05-01 00:00:00') \n```", "```py\nIn [32]: pd.Period(\"2011-01\")\nOut[32]: Period('2011-01', 'M')\n\nIn [33]: pd.Period(\"2012-05\", freq=\"D\")\nOut[33]: Period('2012-05-01', 'D') \n```", "```py\nIn [34]: dates = [\n ....:    pd.Timestamp(\"2012-05-01\"),\n ....:    pd.Timestamp(\"2012-05-02\"),\n ....:    pd.Timestamp(\"2012-05-03\"),\n ....: ]\n ....: \n\nIn [35]: ts = pd.Series(np.random.randn(3), dates)\n\nIn [36]: type(ts.index)\nOut[36]: pandas.core.indexes.datetimes.DatetimeIndex\n\nIn [37]: ts.index\nOut[37]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)\n\nIn [38]: ts\nOut[38]: \n2012-05-01    0.469112\n2012-05-02   -0.282863\n2012-05-03   -1.509059\ndtype: float64\n\nIn [39]: periods = [pd.Period(\"2012-01\"), pd.Period(\"2012-02\"), pd.Period(\"2012-03\")]\n\nIn [40]: ts = pd.Series(np.random.randn(3), periods)\n\nIn [41]: type(ts.index)\nOut[41]: pandas.core.indexes.period.PeriodIndex\n\nIn [42]: ts.index\nOut[42]: PeriodIndex(['2012-01', '2012-02', '2012-03'], dtype='period[M]')\n\nIn [43]: ts\nOut[43]: \n2012-01   -1.135632\n2012-02    1.212112\n2012-03   -0.173215\nFreq: M, dtype: float64 \n```", "```py\nIn [44]: pd.to_datetime(pd.Series([\"Jul 31, 2009\", \"Jan 10, 2010\", None]))\nOut[44]: \n0   2009-07-31\n1   2010-01-10\n2          NaT\ndtype: datetime64[ns]\n\nIn [45]: pd.to_datetime([\"2005/11/23\", \"2010/12/31\"])\nOut[45]: DatetimeIndex(['2005-11-23', '2010-12-31'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [46]: pd.to_datetime([\"04-01-2012 10:00\"], dayfirst=True)\nOut[46]: DatetimeIndex(['2012-01-04 10:00:00'], dtype='datetime64[ns]', freq=None)\n\nIn [47]: pd.to_datetime([\"04-14-2012 10:00\"], dayfirst=True)\nOut[47]: DatetimeIndex(['2012-04-14 10:00:00'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [48]: pd.to_datetime(\"2010/11/12\")\nOut[48]: Timestamp('2010-11-12 00:00:00')\n\nIn [49]: pd.Timestamp(\"2010/11/12\")\nOut[49]: Timestamp('2010-11-12 00:00:00') \n```", "```py\nIn [50]: pd.DatetimeIndex([\"2018-01-01\", \"2018-01-03\", \"2018-01-05\"])\nOut[50]: DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [51]: pd.DatetimeIndex([\"2018-01-01\", \"2018-01-03\", \"2018-01-05\"], freq=\"infer\")\nOut[51]: DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], dtype='datetime64[ns]', freq='2D') \n```", "```py\nIn [52]: pd.to_datetime(\"2010/11/12\", format=\"%Y/%m/%d\")\nOut[52]: Timestamp('2010-11-12 00:00:00')\n\nIn [53]: pd.to_datetime(\"12-11-2010 00:00\", format=\"%d-%m-%Y %H:%M\")\nOut[53]: Timestamp('2010-11-12 00:00:00') \n```", "```py\nIn [54]: df = pd.DataFrame(\n ....:    {\"year\": [2015, 2016], \"month\": [2, 3], \"day\": [4, 5], \"hour\": [2, 3]}\n ....: )\n ....: \n\nIn [55]: pd.to_datetime(df)\nOut[55]: \n0   2015-02-04 02:00:00\n1   2016-03-05 03:00:00\ndtype: datetime64[ns] \n```", "```py\nIn [56]: pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\nOut[56]: \n0   2015-02-04\n1   2016-03-05\ndtype: datetime64[ns] \n```", "```py\nIn [57]: pd.to_datetime(['2009/07/31', 'asd'], errors='raise')\n---------------------------------------------------------------------------\nValueError  Traceback (most recent call last)\nCell In[57], line 1\n----> 1 pd.to_datetime(['2009/07/31', 'asd'], errors='raise')\n\nFile ~/work/pandas/pandas/pandas/core/tools/datetimes.py:1099, in to_datetime(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\n  1097         result = _convert_and_box_cache(argc, cache_array)\n  1098     else:\n-> 1099         result = convert_listlike(argc, format)\n  1100 else:\n  1101     result = convert_listlike(np.array([arg]), format)[0]\n\nFile ~/work/pandas/pandas/pandas/core/tools/datetimes.py:433, in _convert_listlike_datetimes(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\n  431 # `format` could be inferred, or user didn't ask for mixed-format parsing.\n  432 if format is not None and format != \"mixed\":\n--> 433     return _array_strptime_with_fallback(arg, name, utc, format, exact, errors)\n  435 result, tz_parsed = objects_to_datetime64(\n  436     arg,\n  437     dayfirst=dayfirst,\n   (...)\n  441     allow_object=True,\n  442 )\n  444 if tz_parsed is not None:\n  445     # We can take a shortcut since the datetime64 numpy array\n  446     # is in UTC\n\nFile ~/work/pandas/pandas/pandas/core/tools/datetimes.py:467, in _array_strptime_with_fallback(arg, name, utc, fmt, exact, errors)\n  456 def _array_strptime_with_fallback(\n  457     arg,\n  458     name,\n   (...)\n  462     errors: str,\n  463 ) -> Index:\n  464  \"\"\"\n  465 Call array_strptime, with fallback behavior depending on 'errors'.\n  466 \"\"\"\n--> 467     result, tz_out = array_strptime(arg, fmt, exact=exact, errors=errors, utc=utc)\n  468     if tz_out is not None:\n  469         unit = np.datetime_data(result.dtype)[0]\n\nFile strptime.pyx:501, in pandas._libs.tslibs.strptime.array_strptime()\n\nFile strptime.pyx:451, in pandas._libs.tslibs.strptime.array_strptime()\n\nFile strptime.pyx:583, in pandas._libs.tslibs.strptime._parse_with_format()\n\nValueError: time data \"asd\" doesn't match format \"%Y/%m/%d\", at position 1\\. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this. \n```", "```py\nIn [58]: pd.to_datetime([\"2009/07/31\", \"asd\"], errors=\"coerce\")\nOut[58]: DatetimeIndex(['2009-07-31', 'NaT'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [59]: pd.to_datetime(\n ....:    [1349720105, 1349806505, 1349892905, 1349979305, 1350065705], unit=\"s\"\n ....: )\n ....: \nOut[59]: \nDatetimeIndex(['2012-10-08 18:15:05', '2012-10-09 18:15:05',\n '2012-10-10 18:15:05', '2012-10-11 18:15:05',\n '2012-10-12 18:15:05'],\n dtype='datetime64[ns]', freq=None)\n\nIn [60]: pd.to_datetime(\n ....:    [1349720105100, 1349720105200, 1349720105300, 1349720105400, 1349720105500],\n ....:    unit=\"ms\",\n ....: )\n ....: \nOut[60]: \nDatetimeIndex(['2012-10-08 18:15:05.100000', '2012-10-08 18:15:05.200000',\n '2012-10-08 18:15:05.300000', '2012-10-08 18:15:05.400000',\n '2012-10-08 18:15:05.500000'],\n dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [61]: pd.Timestamp(1262347200000000000).tz_localize(\"US/Pacific\")\nOut[61]: Timestamp('2010-01-01 12:00:00-0800', tz='US/Pacific')\n\nIn [62]: pd.DatetimeIndex([1262347200000000000]).tz_localize(\"US/Pacific\")\nOut[62]: DatetimeIndex(['2010-01-01 12:00:00-08:00'], dtype='datetime64[ns, US/Pacific]', freq=None) \n```", "```py\nIn [63]: pd.to_datetime([1490195805.433, 1490195805.433502912], unit=\"s\")\nOut[63]: DatetimeIndex(['2017-03-22 15:16:45.433000088', '2017-03-22 15:16:45.433502913'], dtype='datetime64[ns]', freq=None)\n\nIn [64]: pd.to_datetime(1490195805433502912, unit=\"ns\")\nOut[64]: Timestamp('2017-03-22 15:16:45.433502912') \n```", "```py\nIn [65]: stamps = pd.date_range(\"2012-10-08 18:15:05\", periods=4, freq=\"D\")\n\nIn [66]: stamps\nOut[66]: \nDatetimeIndex(['2012-10-08 18:15:05', '2012-10-09 18:15:05',\n '2012-10-10 18:15:05', '2012-10-11 18:15:05'],\n dtype='datetime64[ns]', freq='D') \n```", "```py\nIn [67]: (stamps - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta(\"1s\")\nOut[67]: Index([1349720105, 1349806505, 1349892905, 1349979305], dtype='int64') \n```", "```py\nIn [68]: pd.to_datetime([1, 2, 3], unit=\"D\", origin=pd.Timestamp(\"1960-01-01\"))\nOut[68]: DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [69]: pd.to_datetime([1, 2, 3], unit=\"D\")\nOut[69]: DatetimeIndex(['1970-01-02', '1970-01-03', '1970-01-04'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [52]: pd.to_datetime(\"2010/11/12\", format=\"%Y/%m/%d\")\nOut[52]: Timestamp('2010-11-12 00:00:00')\n\nIn [53]: pd.to_datetime(\"12-11-2010 00:00\", format=\"%d-%m-%Y %H:%M\")\nOut[53]: Timestamp('2010-11-12 00:00:00') \n```", "```py\nIn [54]: df = pd.DataFrame(\n ....:    {\"year\": [2015, 2016], \"month\": [2, 3], \"day\": [4, 5], \"hour\": [2, 3]}\n ....: )\n ....: \n\nIn [55]: pd.to_datetime(df)\nOut[55]: \n0   2015-02-04 02:00:00\n1   2016-03-05 03:00:00\ndtype: datetime64[ns] \n```", "```py\nIn [56]: pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\nOut[56]: \n0   2015-02-04\n1   2016-03-05\ndtype: datetime64[ns] \n```", "```py\nIn [57]: pd.to_datetime(['2009/07/31', 'asd'], errors='raise')\n---------------------------------------------------------------------------\nValueError  Traceback (most recent call last)\nCell In[57], line 1\n----> 1 pd.to_datetime(['2009/07/31', 'asd'], errors='raise')\n\nFile ~/work/pandas/pandas/pandas/core/tools/datetimes.py:1099, in to_datetime(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\n  1097         result = _convert_and_box_cache(argc, cache_array)\n  1098     else:\n-> 1099         result = convert_listlike(argc, format)\n  1100 else:\n  1101     result = convert_listlike(np.array([arg]), format)[0]\n\nFile ~/work/pandas/pandas/pandas/core/tools/datetimes.py:433, in _convert_listlike_datetimes(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\n  431 # `format` could be inferred, or user didn't ask for mixed-format parsing.\n  432 if format is not None and format != \"mixed\":\n--> 433     return _array_strptime_with_fallback(arg, name, utc, format, exact, errors)\n  435 result, tz_parsed = objects_to_datetime64(\n  436     arg,\n  437     dayfirst=dayfirst,\n   (...)\n  441     allow_object=True,\n  442 )\n  444 if tz_parsed is not None:\n  445     # We can take a shortcut since the datetime64 numpy array\n  446     # is in UTC\n\nFile ~/work/pandas/pandas/pandas/core/tools/datetimes.py:467, in _array_strptime_with_fallback(arg, name, utc, fmt, exact, errors)\n  456 def _array_strptime_with_fallback(\n  457     arg,\n  458     name,\n   (...)\n  462     errors: str,\n  463 ) -> Index:\n  464  \"\"\"\n  465 Call array_strptime, with fallback behavior depending on 'errors'.\n  466 \"\"\"\n--> 467     result, tz_out = array_strptime(arg, fmt, exact=exact, errors=errors, utc=utc)\n  468     if tz_out is not None:\n  469         unit = np.datetime_data(result.dtype)[0]\n\nFile strptime.pyx:501, in pandas._libs.tslibs.strptime.array_strptime()\n\nFile strptime.pyx:451, in pandas._libs.tslibs.strptime.array_strptime()\n\nFile strptime.pyx:583, in pandas._libs.tslibs.strptime._parse_with_format()\n\nValueError: time data \"asd\" doesn't match format \"%Y/%m/%d\", at position 1\\. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this. \n```", "```py\nIn [58]: pd.to_datetime([\"2009/07/31\", \"asd\"], errors=\"coerce\")\nOut[58]: DatetimeIndex(['2009-07-31', 'NaT'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [59]: pd.to_datetime(\n ....:    [1349720105, 1349806505, 1349892905, 1349979305, 1350065705], unit=\"s\"\n ....: )\n ....: \nOut[59]: \nDatetimeIndex(['2012-10-08 18:15:05', '2012-10-09 18:15:05',\n '2012-10-10 18:15:05', '2012-10-11 18:15:05',\n '2012-10-12 18:15:05'],\n dtype='datetime64[ns]', freq=None)\n\nIn [60]: pd.to_datetime(\n ....:    [1349720105100, 1349720105200, 1349720105300, 1349720105400, 1349720105500],\n ....:    unit=\"ms\",\n ....: )\n ....: \nOut[60]: \nDatetimeIndex(['2012-10-08 18:15:05.100000', '2012-10-08 18:15:05.200000',\n '2012-10-08 18:15:05.300000', '2012-10-08 18:15:05.400000',\n '2012-10-08 18:15:05.500000'],\n dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [61]: pd.Timestamp(1262347200000000000).tz_localize(\"US/Pacific\")\nOut[61]: Timestamp('2010-01-01 12:00:00-0800', tz='US/Pacific')\n\nIn [62]: pd.DatetimeIndex([1262347200000000000]).tz_localize(\"US/Pacific\")\nOut[62]: DatetimeIndex(['2010-01-01 12:00:00-08:00'], dtype='datetime64[ns, US/Pacific]', freq=None) \n```", "```py\nIn [63]: pd.to_datetime([1490195805.433, 1490195805.433502912], unit=\"s\")\nOut[63]: DatetimeIndex(['2017-03-22 15:16:45.433000088', '2017-03-22 15:16:45.433502913'], dtype='datetime64[ns]', freq=None)\n\nIn [64]: pd.to_datetime(1490195805433502912, unit=\"ns\")\nOut[64]: Timestamp('2017-03-22 15:16:45.433502912') \n```", "```py\nIn [65]: stamps = pd.date_range(\"2012-10-08 18:15:05\", periods=4, freq=\"D\")\n\nIn [66]: stamps\nOut[66]: \nDatetimeIndex(['2012-10-08 18:15:05', '2012-10-09 18:15:05',\n '2012-10-10 18:15:05', '2012-10-11 18:15:05'],\n dtype='datetime64[ns]', freq='D') \n```", "```py\nIn [67]: (stamps - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta(\"1s\")\nOut[67]: Index([1349720105, 1349806505, 1349892905, 1349979305], dtype='int64') \n```", "```py\nIn [68]: pd.to_datetime([1, 2, 3], unit=\"D\", origin=pd.Timestamp(\"1960-01-01\"))\nOut[68]: DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [69]: pd.to_datetime([1, 2, 3], unit=\"D\")\nOut[69]: DatetimeIndex(['1970-01-02', '1970-01-03', '1970-01-04'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [70]: dates = [\n ....:    datetime.datetime(2012, 5, 1),\n ....:    datetime.datetime(2012, 5, 2),\n ....:    datetime.datetime(2012, 5, 3),\n ....: ]\n ....: \n\n# Note the frequency information\nIn [71]: index = pd.DatetimeIndex(dates)\n\nIn [72]: index\nOut[72]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)\n\n# Automatically converted to DatetimeIndex\nIn [73]: index = pd.Index(dates)\n\nIn [74]: index\nOut[74]: DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [75]: start = datetime.datetime(2011, 1, 1)\n\nIn [76]: end = datetime.datetime(2012, 1, 1)\n\nIn [77]: index = pd.date_range(start, end)\n\nIn [78]: index\nOut[78]: \nDatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03', '2011-01-04',\n '2011-01-05', '2011-01-06', '2011-01-07', '2011-01-08',\n '2011-01-09', '2011-01-10',\n ...\n '2011-12-23', '2011-12-24', '2011-12-25', '2011-12-26',\n '2011-12-27', '2011-12-28', '2011-12-29', '2011-12-30',\n '2011-12-31', '2012-01-01'],\n dtype='datetime64[ns]', length=366, freq='D')\n\nIn [79]: index = pd.bdate_range(start, end)\n\nIn [80]: index\nOut[80]: \nDatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',\n '2011-01-07', '2011-01-10', '2011-01-11', '2011-01-12',\n '2011-01-13', '2011-01-14',\n ...\n '2011-12-19', '2011-12-20', '2011-12-21', '2011-12-22',\n '2011-12-23', '2011-12-26', '2011-12-27', '2011-12-28',\n '2011-12-29', '2011-12-30'],\n dtype='datetime64[ns]', length=260, freq='B') \n```", "```py\nIn [81]: pd.date_range(start, periods=1000, freq=\"ME\")\nOut[81]: \nDatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-30',\n '2011-05-31', '2011-06-30', '2011-07-31', '2011-08-31',\n '2011-09-30', '2011-10-31',\n ...\n '2093-07-31', '2093-08-31', '2093-09-30', '2093-10-31',\n '2093-11-30', '2093-12-31', '2094-01-31', '2094-02-28',\n '2094-03-31', '2094-04-30'],\n dtype='datetime64[ns]', length=1000, freq='ME')\n\nIn [82]: pd.bdate_range(start, periods=250, freq=\"BQS\")\nOut[82]: \nDatetimeIndex(['2011-01-03', '2011-04-01', '2011-07-01', '2011-10-03',\n '2012-01-02', '2012-04-02', '2012-07-02', '2012-10-01',\n '2013-01-01', '2013-04-01',\n ...\n '2071-01-01', '2071-04-01', '2071-07-01', '2071-10-01',\n '2072-01-01', '2072-04-01', '2072-07-01', '2072-10-03',\n '2073-01-02', '2073-04-03'],\n dtype='datetime64[ns]', length=250, freq='BQS-JAN') \n```", "```py\nIn [83]: pd.date_range(start, end, freq=\"BME\")\nOut[83]: \nDatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',\n '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',\n '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30'],\n dtype='datetime64[ns]', freq='BME')\n\nIn [84]: pd.date_range(start, end, freq=\"W\")\nOut[84]: \nDatetimeIndex(['2011-01-02', '2011-01-09', '2011-01-16', '2011-01-23',\n '2011-01-30', '2011-02-06', '2011-02-13', '2011-02-20',\n '2011-02-27', '2011-03-06', '2011-03-13', '2011-03-20',\n '2011-03-27', '2011-04-03', '2011-04-10', '2011-04-17',\n '2011-04-24', '2011-05-01', '2011-05-08', '2011-05-15',\n '2011-05-22', '2011-05-29', '2011-06-05', '2011-06-12',\n '2011-06-19', '2011-06-26', '2011-07-03', '2011-07-10',\n '2011-07-17', '2011-07-24', '2011-07-31', '2011-08-07',\n '2011-08-14', '2011-08-21', '2011-08-28', '2011-09-04',\n '2011-09-11', '2011-09-18', '2011-09-25', '2011-10-02',\n '2011-10-09', '2011-10-16', '2011-10-23', '2011-10-30',\n '2011-11-06', '2011-11-13', '2011-11-20', '2011-11-27',\n '2011-12-04', '2011-12-11', '2011-12-18', '2011-12-25',\n '2012-01-01'],\n dtype='datetime64[ns]', freq='W-SUN')\n\nIn [85]: pd.bdate_range(end=end, periods=20)\nOut[85]: \nDatetimeIndex(['2011-12-05', '2011-12-06', '2011-12-07', '2011-12-08',\n '2011-12-09', '2011-12-12', '2011-12-13', '2011-12-14',\n '2011-12-15', '2011-12-16', '2011-12-19', '2011-12-20',\n '2011-12-21', '2011-12-22', '2011-12-23', '2011-12-26',\n '2011-12-27', '2011-12-28', '2011-12-29', '2011-12-30'],\n dtype='datetime64[ns]', freq='B')\n\nIn [86]: pd.bdate_range(start=start, periods=20)\nOut[86]: \nDatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',\n '2011-01-07', '2011-01-10', '2011-01-11', '2011-01-12',\n '2011-01-13', '2011-01-14', '2011-01-17', '2011-01-18',\n '2011-01-19', '2011-01-20', '2011-01-21', '2011-01-24',\n '2011-01-25', '2011-01-26', '2011-01-27', '2011-01-28'],\n dtype='datetime64[ns]', freq='B') \n```", "```py\nIn [87]: pd.date_range(\"2018-01-01\", \"2018-01-05\", periods=5)\nOut[87]: \nDatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n '2018-01-05'],\n dtype='datetime64[ns]', freq=None)\n\nIn [88]: pd.date_range(\"2018-01-01\", \"2018-01-05\", periods=10)\nOut[88]: \nDatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 10:40:00',\n '2018-01-01 21:20:00', '2018-01-02 08:00:00',\n '2018-01-02 18:40:00', '2018-01-03 05:20:00',\n '2018-01-03 16:00:00', '2018-01-04 02:40:00',\n '2018-01-04 13:20:00', '2018-01-05 00:00:00'],\n dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [89]: weekmask = \"Mon Wed Fri\"\n\nIn [90]: holidays = [datetime.datetime(2011, 1, 5), datetime.datetime(2011, 3, 14)]\n\nIn [91]: pd.bdate_range(start, end, freq=\"C\", weekmask=weekmask, holidays=holidays)\nOut[91]: \nDatetimeIndex(['2011-01-03', '2011-01-07', '2011-01-10', '2011-01-12',\n '2011-01-14', '2011-01-17', '2011-01-19', '2011-01-21',\n '2011-01-24', '2011-01-26',\n ...\n '2011-12-09', '2011-12-12', '2011-12-14', '2011-12-16',\n '2011-12-19', '2011-12-21', '2011-12-23', '2011-12-26',\n '2011-12-28', '2011-12-30'],\n dtype='datetime64[ns]', length=154, freq='C')\n\nIn [92]: pd.bdate_range(start, end, freq=\"CBMS\", weekmask=weekmask)\nOut[92]: \nDatetimeIndex(['2011-01-03', '2011-02-02', '2011-03-02', '2011-04-01',\n '2011-05-02', '2011-06-01', '2011-07-01', '2011-08-01',\n '2011-09-02', '2011-10-03', '2011-11-02', '2011-12-02'],\n dtype='datetime64[ns]', freq='CBMS') \n```", "```py\nIn [89]: weekmask = \"Mon Wed Fri\"\n\nIn [90]: holidays = [datetime.datetime(2011, 1, 5), datetime.datetime(2011, 3, 14)]\n\nIn [91]: pd.bdate_range(start, end, freq=\"C\", weekmask=weekmask, holidays=holidays)\nOut[91]: \nDatetimeIndex(['2011-01-03', '2011-01-07', '2011-01-10', '2011-01-12',\n '2011-01-14', '2011-01-17', '2011-01-19', '2011-01-21',\n '2011-01-24', '2011-01-26',\n ...\n '2011-12-09', '2011-12-12', '2011-12-14', '2011-12-16',\n '2011-12-19', '2011-12-21', '2011-12-23', '2011-12-26',\n '2011-12-28', '2011-12-30'],\n dtype='datetime64[ns]', length=154, freq='C')\n\nIn [92]: pd.bdate_range(start, end, freq=\"CBMS\", weekmask=weekmask)\nOut[92]: \nDatetimeIndex(['2011-01-03', '2011-02-02', '2011-03-02', '2011-04-01',\n '2011-05-02', '2011-06-01', '2011-07-01', '2011-08-01',\n '2011-09-02', '2011-10-03', '2011-11-02', '2011-12-02'],\n dtype='datetime64[ns]', freq='CBMS') \n```", "```py\nIn [93]: pd.Timestamp.min\nOut[93]: Timestamp('1677-09-21 00:12:43.145224193')\n\nIn [94]: pd.Timestamp.max\nOut[94]: Timestamp('2262-04-11 23:47:16.854775807') \n```", "```py\nIn [95]: rng = pd.date_range(start, end, freq=\"BME\")\n\nIn [96]: ts = pd.Series(np.random.randn(len(rng)), index=rng)\n\nIn [97]: ts.index\nOut[97]: \nDatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',\n '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',\n '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30'],\n dtype='datetime64[ns]', freq='BME')\n\nIn [98]: ts[:5].index\nOut[98]: \nDatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',\n '2011-05-31'],\n dtype='datetime64[ns]', freq='BME')\n\nIn [99]: ts[::2].index\nOut[99]: \nDatetimeIndex(['2011-01-31', '2011-03-31', '2011-05-31', '2011-07-29',\n '2011-09-30', '2011-11-30'],\n dtype='datetime64[ns]', freq='2BME') \n```", "```py\nIn [100]: ts[\"1/31/2011\"]\nOut[100]: 0.11920871129693428\n\nIn [101]: ts[datetime.datetime(2011, 12, 25):]\nOut[101]: \n2011-12-30    0.56702\nFreq: BME, dtype: float64\n\nIn [102]: ts[\"10/31/2011\":\"12/31/2011\"]\nOut[102]: \n2011-10-31    0.271860\n2011-11-30   -0.424972\n2011-12-30    0.567020\nFreq: BME, dtype: float64 \n```", "```py\nIn [103]: ts[\"2011\"]\nOut[103]: \n2011-01-31    0.119209\n2011-02-28   -1.044236\n2011-03-31   -0.861849\n2011-04-29   -2.104569\n2011-05-31   -0.494929\n2011-06-30    1.071804\n2011-07-29    0.721555\n2011-08-31   -0.706771\n2011-09-30   -1.039575\n2011-10-31    0.271860\n2011-11-30   -0.424972\n2011-12-30    0.567020\nFreq: BME, dtype: float64\n\nIn [104]: ts[\"2011-6\"]\nOut[104]: \n2011-06-30    1.071804\nFreq: BME, dtype: float64 \n```", "```py\nIn [105]: dft = pd.DataFrame(\n .....:    np.random.randn(100000, 1),\n .....:    columns=[\"A\"],\n .....:    index=pd.date_range(\"20130101\", periods=100000, freq=\"min\"),\n .....: )\n .....: \n\nIn [106]: dft\nOut[106]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-03-11 10:35:00 -0.747967\n2013-03-11 10:36:00 -0.034523\n2013-03-11 10:37:00 -0.201754\n2013-03-11 10:38:00 -1.509067\n2013-03-11 10:39:00 -1.693043\n\n[100000 rows x 1 columns]\n\nIn [107]: dft.loc[\"2013\"]\nOut[107]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-03-11 10:35:00 -0.747967\n2013-03-11 10:36:00 -0.034523\n2013-03-11 10:37:00 -0.201754\n2013-03-11 10:38:00 -1.509067\n2013-03-11 10:39:00 -1.693043\n\n[100000 rows x 1 columns] \n```", "```py\nIn [108]: dft[\"2013-1\":\"2013-2\"]\nOut[108]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-02-28 23:55:00  0.850929\n2013-02-28 23:56:00  0.976712\n2013-02-28 23:57:00 -2.693884\n2013-02-28 23:58:00 -1.575535\n2013-02-28 23:59:00 -1.573517\n\n[84960 rows x 1 columns] \n```", "```py\nIn [109]: dft[\"2013-1\":\"2013-2-28\"]\nOut[109]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-02-28 23:55:00  0.850929\n2013-02-28 23:56:00  0.976712\n2013-02-28 23:57:00 -2.693884\n2013-02-28 23:58:00 -1.575535\n2013-02-28 23:59:00 -1.573517\n\n[84960 rows x 1 columns] \n```", "```py\nIn [110]: dft[\"2013-1\":\"2013-2-28 00:00:00\"]\nOut[110]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-02-27 23:56:00  1.197749\n2013-02-27 23:57:00  0.720521\n2013-02-27 23:58:00 -0.072718\n2013-02-27 23:59:00 -0.681192\n2013-02-28 00:00:00 -0.557501\n\n[83521 rows x 1 columns] \n```", "```py\nIn [111]: dft[\"2013-1-15\":\"2013-1-15 12:30:00\"]\nOut[111]: \n A\n2013-01-15 00:00:00 -0.984810\n2013-01-15 00:01:00  0.941451\n2013-01-15 00:02:00  1.559365\n2013-01-15 00:03:00  1.034374\n2013-01-15 00:04:00 -1.480656\n...                       ...\n2013-01-15 12:26:00  0.371454\n2013-01-15 12:27:00 -0.930806\n2013-01-15 12:28:00 -0.069177\n2013-01-15 12:29:00  0.066510\n2013-01-15 12:30:00 -0.003945\n\n[751 rows x 1 columns] \n```", "```py\nIn [112]: dft2 = pd.DataFrame(\n .....:    np.random.randn(20, 1),\n .....:    columns=[\"A\"],\n .....:    index=pd.MultiIndex.from_product(\n .....:        [pd.date_range(\"20130101\", periods=10, freq=\"12h\"), [\"a\", \"b\"]]\n .....:    ),\n .....: )\n .....: \n\nIn [113]: dft2\nOut[113]: \n A\n2013-01-01 00:00:00 a -0.298694\n b  0.823553\n2013-01-01 12:00:00 a  0.943285\n b -1.479399\n2013-01-02 00:00:00 a -1.643342\n...                         ...\n2013-01-04 12:00:00 b  0.069036\n2013-01-05 00:00:00 a  0.122297\n b  1.422060\n2013-01-05 12:00:00 a  0.370079\n b  1.016331\n\n[20 rows x 1 columns]\n\nIn [114]: dft2.loc[\"2013-01-05\"]\nOut[114]: \n A\n2013-01-05 00:00:00 a  0.122297\n b  1.422060\n2013-01-05 12:00:00 a  0.370079\n b  1.016331\n\nIn [115]: idx = pd.IndexSlice\n\nIn [116]: dft2 = dft2.swaplevel(0, 1).sort_index()\n\nIn [117]: dft2.loc[idx[:, \"2013-01-05\"], :]\nOut[117]: \n A\na 2013-01-05 00:00:00  0.122297\n 2013-01-05 12:00:00  0.370079\nb 2013-01-05 00:00:00  1.422060\n 2013-01-05 12:00:00  1.016331 \n```", "```py\nIn [118]: df = pd.DataFrame([0], index=pd.DatetimeIndex([\"2019-01-01\"], tz=\"US/Pacific\"))\n\nIn [119]: df\nOut[119]: \n 0\n2019-01-01 00:00:00-08:00  0\n\nIn [120]: df[\"2019-01-01 12:00:00+04:00\":\"2019-01-01 13:00:00+04:00\"]\nOut[120]: \n 0\n2019-01-01 00:00:00-08:00  0 \n```", "```py\nIn [121]: series_minute = pd.Series(\n .....:    [1, 2, 3],\n .....:    pd.DatetimeIndex(\n .....:        [\"2011-12-31 23:59:00\", \"2012-01-01 00:00:00\", \"2012-01-01 00:02:00\"]\n .....:    ),\n .....: )\n .....: \n\nIn [122]: series_minute.index.resolution\nOut[122]: 'minute' \n```", "```py\nIn [123]: series_minute[\"2011-12-31 23\"]\nOut[123]: \n2011-12-31 23:59:00    1\ndtype: int64 \n```", "```py\nIn [124]: series_minute[\"2011-12-31 23:59\"]\nOut[124]: 1\n\nIn [125]: series_minute[\"2011-12-31 23:59:00\"]\nOut[125]: 1 \n```", "```py\nIn [126]: series_second = pd.Series(\n .....:    [1, 2, 3],\n .....:    pd.DatetimeIndex(\n .....:        [\"2011-12-31 23:59:59\", \"2012-01-01 00:00:00\", \"2012-01-01 00:00:01\"]\n .....:    ),\n .....: )\n .....: \n\nIn [127]: series_second.index.resolution\nOut[127]: 'second'\n\nIn [128]: series_second[\"2011-12-31 23:59\"]\nOut[128]: \n2011-12-31 23:59:59    1\ndtype: int64 \n```", "```py\nIn [129]: dft_minute = pd.DataFrame(\n .....:    {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}, index=series_minute.index\n .....: )\n .....: \n\nIn [130]: dft_minute.loc[\"2011-12-31 23\"]\nOut[130]: \n a  b\n2011-12-31 23:59:00  1  4 \n```", "```py\nIn [131]: dft_minute.loc[\"2011-12-31 23:59\"]\nOut[131]: \na    1\nb    4\nName: 2011-12-31 23:59:00, dtype: int64 \n```", "```py\nIn [132]: series_monthly = pd.Series(\n .....:    [1, 2, 3], pd.DatetimeIndex([\"2011-12\", \"2012-01\", \"2012-02\"])\n .....: )\n .....: \n\nIn [133]: series_monthly.index.resolution\nOut[133]: 'day'\n\nIn [134]: series_monthly[\"2011-12\"]  # returns Series\nOut[134]: \n2011-12-01    1\ndtype: int64 \n```", "```py\nIn [135]: dft[datetime.datetime(2013, 1, 1): datetime.datetime(2013, 2, 28)]\nOut[135]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-02-27 23:56:00  1.197749\n2013-02-27 23:57:00  0.720521\n2013-02-27 23:58:00 -0.072718\n2013-02-27 23:59:00 -0.681192\n2013-02-28 00:00:00 -0.557501\n\n[83521 rows x 1 columns] \n```", "```py\nIn [136]: dft[\n .....:    datetime.datetime(2013, 1, 1, 10, 12, 0): datetime.datetime(\n .....:        2013, 2, 28, 10, 12, 0\n .....:    )\n .....: ]\n .....: \nOut[136]: \n A\n2013-01-01 10:12:00  0.565375\n2013-01-01 10:13:00  0.068184\n2013-01-01 10:14:00  0.788871\n2013-01-01 10:15:00 -0.280343\n2013-01-01 10:16:00  0.931536\n...                       ...\n2013-02-28 10:08:00  0.148098\n2013-02-28 10:09:00 -0.388138\n2013-02-28 10:10:00  0.139348\n2013-02-28 10:11:00  0.085288\n2013-02-28 10:12:00  0.950146\n\n[83521 rows x 1 columns] \n```", "```py\nIn [137]: rng2 = pd.date_range(\"2011-01-01\", \"2012-01-01\", freq=\"W\")\n\nIn [138]: ts2 = pd.Series(np.random.randn(len(rng2)), index=rng2)\n\nIn [139]: ts2.truncate(before=\"2011-11\", after=\"2011-12\")\nOut[139]: \n2011-11-06    0.437823\n2011-11-13   -0.293083\n2011-11-20   -0.059881\n2011-11-27    1.252450\nFreq: W-SUN, dtype: float64\n\nIn [140]: ts2[\"2011-11\":\"2011-12\"]\nOut[140]: \n2011-11-06    0.437823\n2011-11-13   -0.293083\n2011-11-20   -0.059881\n2011-11-27    1.252450\n2011-12-04    0.046611\n2011-12-11    0.059478\n2011-12-18   -0.286539\n2011-12-25    0.841669\nFreq: W-SUN, dtype: float64 \n```", "```py\nIn [141]: ts2.iloc[[0, 2, 6]].index\nOut[141]: DatetimeIndex(['2011-01-02', '2011-01-16', '2011-02-13'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [100]: ts[\"1/31/2011\"]\nOut[100]: 0.11920871129693428\n\nIn [101]: ts[datetime.datetime(2011, 12, 25):]\nOut[101]: \n2011-12-30    0.56702\nFreq: BME, dtype: float64\n\nIn [102]: ts[\"10/31/2011\":\"12/31/2011\"]\nOut[102]: \n2011-10-31    0.271860\n2011-11-30   -0.424972\n2011-12-30    0.567020\nFreq: BME, dtype: float64 \n```", "```py\nIn [103]: ts[\"2011\"]\nOut[103]: \n2011-01-31    0.119209\n2011-02-28   -1.044236\n2011-03-31   -0.861849\n2011-04-29   -2.104569\n2011-05-31   -0.494929\n2011-06-30    1.071804\n2011-07-29    0.721555\n2011-08-31   -0.706771\n2011-09-30   -1.039575\n2011-10-31    0.271860\n2011-11-30   -0.424972\n2011-12-30    0.567020\nFreq: BME, dtype: float64\n\nIn [104]: ts[\"2011-6\"]\nOut[104]: \n2011-06-30    1.071804\nFreq: BME, dtype: float64 \n```", "```py\nIn [105]: dft = pd.DataFrame(\n .....:    np.random.randn(100000, 1),\n .....:    columns=[\"A\"],\n .....:    index=pd.date_range(\"20130101\", periods=100000, freq=\"min\"),\n .....: )\n .....: \n\nIn [106]: dft\nOut[106]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-03-11 10:35:00 -0.747967\n2013-03-11 10:36:00 -0.034523\n2013-03-11 10:37:00 -0.201754\n2013-03-11 10:38:00 -1.509067\n2013-03-11 10:39:00 -1.693043\n\n[100000 rows x 1 columns]\n\nIn [107]: dft.loc[\"2013\"]\nOut[107]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-03-11 10:35:00 -0.747967\n2013-03-11 10:36:00 -0.034523\n2013-03-11 10:37:00 -0.201754\n2013-03-11 10:38:00 -1.509067\n2013-03-11 10:39:00 -1.693043\n\n[100000 rows x 1 columns] \n```", "```py\nIn [108]: dft[\"2013-1\":\"2013-2\"]\nOut[108]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-02-28 23:55:00  0.850929\n2013-02-28 23:56:00  0.976712\n2013-02-28 23:57:00 -2.693884\n2013-02-28 23:58:00 -1.575535\n2013-02-28 23:59:00 -1.573517\n\n[84960 rows x 1 columns] \n```", "```py\nIn [109]: dft[\"2013-1\":\"2013-2-28\"]\nOut[109]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-02-28 23:55:00  0.850929\n2013-02-28 23:56:00  0.976712\n2013-02-28 23:57:00 -2.693884\n2013-02-28 23:58:00 -1.575535\n2013-02-28 23:59:00 -1.573517\n\n[84960 rows x 1 columns] \n```", "```py\nIn [110]: dft[\"2013-1\":\"2013-2-28 00:00:00\"]\nOut[110]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-02-27 23:56:00  1.197749\n2013-02-27 23:57:00  0.720521\n2013-02-27 23:58:00 -0.072718\n2013-02-27 23:59:00 -0.681192\n2013-02-28 00:00:00 -0.557501\n\n[83521 rows x 1 columns] \n```", "```py\nIn [111]: dft[\"2013-1-15\":\"2013-1-15 12:30:00\"]\nOut[111]: \n A\n2013-01-15 00:00:00 -0.984810\n2013-01-15 00:01:00  0.941451\n2013-01-15 00:02:00  1.559365\n2013-01-15 00:03:00  1.034374\n2013-01-15 00:04:00 -1.480656\n...                       ...\n2013-01-15 12:26:00  0.371454\n2013-01-15 12:27:00 -0.930806\n2013-01-15 12:28:00 -0.069177\n2013-01-15 12:29:00  0.066510\n2013-01-15 12:30:00 -0.003945\n\n[751 rows x 1 columns] \n```", "```py\nIn [112]: dft2 = pd.DataFrame(\n .....:    np.random.randn(20, 1),\n .....:    columns=[\"A\"],\n .....:    index=pd.MultiIndex.from_product(\n .....:        [pd.date_range(\"20130101\", periods=10, freq=\"12h\"), [\"a\", \"b\"]]\n .....:    ),\n .....: )\n .....: \n\nIn [113]: dft2\nOut[113]: \n A\n2013-01-01 00:00:00 a -0.298694\n b  0.823553\n2013-01-01 12:00:00 a  0.943285\n b -1.479399\n2013-01-02 00:00:00 a -1.643342\n...                         ...\n2013-01-04 12:00:00 b  0.069036\n2013-01-05 00:00:00 a  0.122297\n b  1.422060\n2013-01-05 12:00:00 a  0.370079\n b  1.016331\n\n[20 rows x 1 columns]\n\nIn [114]: dft2.loc[\"2013-01-05\"]\nOut[114]: \n A\n2013-01-05 00:00:00 a  0.122297\n b  1.422060\n2013-01-05 12:00:00 a  0.370079\n b  1.016331\n\nIn [115]: idx = pd.IndexSlice\n\nIn [116]: dft2 = dft2.swaplevel(0, 1).sort_index()\n\nIn [117]: dft2.loc[idx[:, \"2013-01-05\"], :]\nOut[117]: \n A\na 2013-01-05 00:00:00  0.122297\n 2013-01-05 12:00:00  0.370079\nb 2013-01-05 00:00:00  1.422060\n 2013-01-05 12:00:00  1.016331 \n```", "```py\nIn [118]: df = pd.DataFrame([0], index=pd.DatetimeIndex([\"2019-01-01\"], tz=\"US/Pacific\"))\n\nIn [119]: df\nOut[119]: \n 0\n2019-01-01 00:00:00-08:00  0\n\nIn [120]: df[\"2019-01-01 12:00:00+04:00\":\"2019-01-01 13:00:00+04:00\"]\nOut[120]: \n 0\n2019-01-01 00:00:00-08:00  0 \n```", "```py\nIn [121]: series_minute = pd.Series(\n .....:    [1, 2, 3],\n .....:    pd.DatetimeIndex(\n .....:        [\"2011-12-31 23:59:00\", \"2012-01-01 00:00:00\", \"2012-01-01 00:02:00\"]\n .....:    ),\n .....: )\n .....: \n\nIn [122]: series_minute.index.resolution\nOut[122]: 'minute' \n```", "```py\nIn [123]: series_minute[\"2011-12-31 23\"]\nOut[123]: \n2011-12-31 23:59:00    1\ndtype: int64 \n```", "```py\nIn [124]: series_minute[\"2011-12-31 23:59\"]\nOut[124]: 1\n\nIn [125]: series_minute[\"2011-12-31 23:59:00\"]\nOut[125]: 1 \n```", "```py\nIn [126]: series_second = pd.Series(\n .....:    [1, 2, 3],\n .....:    pd.DatetimeIndex(\n .....:        [\"2011-12-31 23:59:59\", \"2012-01-01 00:00:00\", \"2012-01-01 00:00:01\"]\n .....:    ),\n .....: )\n .....: \n\nIn [127]: series_second.index.resolution\nOut[127]: 'second'\n\nIn [128]: series_second[\"2011-12-31 23:59\"]\nOut[128]: \n2011-12-31 23:59:59    1\ndtype: int64 \n```", "```py\nIn [129]: dft_minute = pd.DataFrame(\n .....:    {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}, index=series_minute.index\n .....: )\n .....: \n\nIn [130]: dft_minute.loc[\"2011-12-31 23\"]\nOut[130]: \n a  b\n2011-12-31 23:59:00  1  4 \n```", "```py\nIn [131]: dft_minute.loc[\"2011-12-31 23:59\"]\nOut[131]: \na    1\nb    4\nName: 2011-12-31 23:59:00, dtype: int64 \n```", "```py\nIn [132]: series_monthly = pd.Series(\n .....:    [1, 2, 3], pd.DatetimeIndex([\"2011-12\", \"2012-01\", \"2012-02\"])\n .....: )\n .....: \n\nIn [133]: series_monthly.index.resolution\nOut[133]: 'day'\n\nIn [134]: series_monthly[\"2011-12\"]  # returns Series\nOut[134]: \n2011-12-01    1\ndtype: int64 \n```", "```py\nIn [135]: dft[datetime.datetime(2013, 1, 1): datetime.datetime(2013, 2, 28)]\nOut[135]: \n A\n2013-01-01 00:00:00  0.276232\n2013-01-01 00:01:00 -1.087401\n2013-01-01 00:02:00 -0.673690\n2013-01-01 00:03:00  0.113648\n2013-01-01 00:04:00 -1.478427\n...                       ...\n2013-02-27 23:56:00  1.197749\n2013-02-27 23:57:00  0.720521\n2013-02-27 23:58:00 -0.072718\n2013-02-27 23:59:00 -0.681192\n2013-02-28 00:00:00 -0.557501\n\n[83521 rows x 1 columns] \n```", "```py\nIn [136]: dft[\n .....:    datetime.datetime(2013, 1, 1, 10, 12, 0): datetime.datetime(\n .....:        2013, 2, 28, 10, 12, 0\n .....:    )\n .....: ]\n .....: \nOut[136]: \n A\n2013-01-01 10:12:00  0.565375\n2013-01-01 10:13:00  0.068184\n2013-01-01 10:14:00  0.788871\n2013-01-01 10:15:00 -0.280343\n2013-01-01 10:16:00  0.931536\n...                       ...\n2013-02-28 10:08:00  0.148098\n2013-02-28 10:09:00 -0.388138\n2013-02-28 10:10:00  0.139348\n2013-02-28 10:11:00  0.085288\n2013-02-28 10:12:00  0.950146\n\n[83521 rows x 1 columns] \n```", "```py\nIn [137]: rng2 = pd.date_range(\"2011-01-01\", \"2012-01-01\", freq=\"W\")\n\nIn [138]: ts2 = pd.Series(np.random.randn(len(rng2)), index=rng2)\n\nIn [139]: ts2.truncate(before=\"2011-11\", after=\"2011-12\")\nOut[139]: \n2011-11-06    0.437823\n2011-11-13   -0.293083\n2011-11-20   -0.059881\n2011-11-27    1.252450\nFreq: W-SUN, dtype: float64\n\nIn [140]: ts2[\"2011-11\":\"2011-12\"]\nOut[140]: \n2011-11-06    0.437823\n2011-11-13   -0.293083\n2011-11-20   -0.059881\n2011-11-27    1.252450\n2011-12-04    0.046611\n2011-12-11    0.059478\n2011-12-18   -0.286539\n2011-12-25    0.841669\nFreq: W-SUN, dtype: float64 \n```", "```py\nIn [141]: ts2.iloc[[0, 2, 6]].index\nOut[141]: DatetimeIndex(['2011-01-02', '2011-01-16', '2011-02-13'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [142]: idx = pd.date_range(start=\"2019-12-29\", freq=\"D\", periods=4)\n\nIn [143]: idx.isocalendar()\nOut[143]: \n year  week  day\n2019-12-29  2019    52    7\n2019-12-30  2020     1    1\n2019-12-31  2020     1    2\n2020-01-01  2020     1    3\n\nIn [144]: idx.to_series().dt.isocalendar()\nOut[144]: \n year  week  day\n2019-12-29  2019    52    7\n2019-12-30  2020     1    1\n2019-12-31  2020     1    2\n2020-01-01  2020     1    3 \n```", "```py\n# This particular day contains a day light savings time transition\nIn [145]: ts = pd.Timestamp(\"2016-10-30 00:00:00\", tz=\"Europe/Helsinki\")\n\n# Respects absolute time\nIn [146]: ts + pd.Timedelta(days=1)\nOut[146]: Timestamp('2016-10-30 23:00:00+0200', tz='Europe/Helsinki')\n\n# Respects calendar time\nIn [147]: ts + pd.DateOffset(days=1)\nOut[147]: Timestamp('2016-10-31 00:00:00+0200', tz='Europe/Helsinki')\n\nIn [148]: friday = pd.Timestamp(\"2018-01-05\")\n\nIn [149]: friday.day_name()\nOut[149]: 'Friday'\n\n# Add 2 business days (Friday --> Tuesday)\nIn [150]: two_business_days = 2 * pd.offsets.BDay()\n\nIn [151]: friday + two_business_days\nOut[151]: Timestamp('2018-01-09 00:00:00')\n\nIn [152]: (friday + two_business_days).day_name()\nOut[152]: 'Tuesday' \n```", "```py\nIn [153]: ts = pd.Timestamp(\"2018-01-06 00:00:00\")\n\nIn [154]: ts.day_name()\nOut[154]: 'Saturday'\n\n# BusinessHour's valid offset dates are Monday through Friday\nIn [155]: offset = pd.offsets.BusinessHour(start=\"09:00\")\n\n# Bring the date to the closest offset date (Monday)\nIn [156]: offset.rollforward(ts)\nOut[156]: Timestamp('2018-01-08 09:00:00')\n\n# Date is brought to the closest offset date first and then the hour is added\nIn [157]: ts + offset\nOut[157]: Timestamp('2018-01-08 10:00:00') \n```", "```py\nIn [158]: ts = pd.Timestamp(\"2014-01-01 09:00\")\n\nIn [159]: day = pd.offsets.Day()\n\nIn [160]: day + ts\nOut[160]: Timestamp('2014-01-02 09:00:00')\n\nIn [161]: (day + ts).normalize()\nOut[161]: Timestamp('2014-01-02 00:00:00')\n\nIn [162]: ts = pd.Timestamp(\"2014-01-01 22:00\")\n\nIn [163]: hour = pd.offsets.Hour()\n\nIn [164]: hour + ts\nOut[164]: Timestamp('2014-01-01 23:00:00')\n\nIn [165]: (hour + ts).normalize()\nOut[165]: Timestamp('2014-01-01 00:00:00')\n\nIn [166]: (hour + pd.Timestamp(\"2014-01-01 23:30\")).normalize()\nOut[166]: Timestamp('2014-01-02 00:00:00') \n```", "```py\nIn [167]: d = datetime.datetime(2008, 8, 18, 9, 0)\n\nIn [168]: d\nOut[168]: datetime.datetime(2008, 8, 18, 9, 0)\n\nIn [169]: d + pd.offsets.Week()\nOut[169]: Timestamp('2008-08-25 09:00:00')\n\nIn [170]: d + pd.offsets.Week(weekday=4)\nOut[170]: Timestamp('2008-08-22 09:00:00')\n\nIn [171]: (d + pd.offsets.Week(weekday=4)).weekday()\nOut[171]: 4\n\nIn [172]: d - pd.offsets.Week()\nOut[172]: Timestamp('2008-08-11 09:00:00') \n```", "```py\nIn [173]: d + pd.offsets.Week(normalize=True)\nOut[173]: Timestamp('2008-08-25 00:00:00')\n\nIn [174]: d - pd.offsets.Week(normalize=True)\nOut[174]: Timestamp('2008-08-11 00:00:00') \n```", "```py\nIn [175]: d + pd.offsets.YearEnd()\nOut[175]: Timestamp('2008-12-31 09:00:00')\n\nIn [176]: d + pd.offsets.YearEnd(month=6)\nOut[176]: Timestamp('2009-06-30 09:00:00') \n```", "```py\nIn [177]: rng = pd.date_range(\"2012-01-01\", \"2012-01-03\")\n\nIn [178]: s = pd.Series(rng)\n\nIn [179]: rng\nOut[179]: DatetimeIndex(['2012-01-01', '2012-01-02', '2012-01-03'], dtype='datetime64[ns]', freq='D')\n\nIn [180]: rng + pd.DateOffset(months=2)\nOut[180]: DatetimeIndex(['2012-03-01', '2012-03-02', '2012-03-03'], dtype='datetime64[ns]', freq=None)\n\nIn [181]: s + pd.DateOffset(months=2)\nOut[181]: \n0   2012-03-01\n1   2012-03-02\n2   2012-03-03\ndtype: datetime64[ns]\n\nIn [182]: s - pd.DateOffset(months=2)\nOut[182]: \n0   2011-11-01\n1   2011-11-02\n2   2011-11-03\ndtype: datetime64[ns] \n```", "```py\nIn [183]: s - pd.offsets.Day(2)\nOut[183]: \n0   2011-12-30\n1   2011-12-31\n2   2012-01-01\ndtype: datetime64[ns]\n\nIn [184]: td = s - pd.Series(pd.date_range(\"2011-12-29\", \"2011-12-31\"))\n\nIn [185]: td\nOut[185]: \n0   3 days\n1   3 days\n2   3 days\ndtype: timedelta64[ns]\n\nIn [186]: td + pd.offsets.Minute(15)\nOut[186]: \n0   3 days 00:15:00\n1   3 days 00:15:00\n2   3 days 00:15:00\ndtype: timedelta64[ns] \n```", "```py\nIn [187]: rng + pd.offsets.BQuarterEnd()\nOut[187]: DatetimeIndex(['2012-03-30', '2012-03-30', '2012-03-30'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [188]: weekmask_egypt = \"Sun Mon Tue Wed Thu\"\n\n# They also observe International Workers' Day so let's\n# add that for a couple of years\nIn [189]: holidays = [\n .....:    \"2012-05-01\",\n .....:    datetime.datetime(2013, 5, 1),\n .....:    np.datetime64(\"2014-05-01\"),\n .....: ]\n .....: \n\nIn [190]: bday_egypt = pd.offsets.CustomBusinessDay(\n .....:    holidays=holidays,\n .....:    weekmask=weekmask_egypt,\n .....: )\n .....: \n\nIn [191]: dt = datetime.datetime(2013, 4, 30)\n\nIn [192]: dt + 2 * bday_egypt\nOut[192]: Timestamp('2013-05-05 00:00:00') \n```", "```py\nIn [193]: dts = pd.date_range(dt, periods=5, freq=bday_egypt)\n\nIn [194]: pd.Series(dts.weekday, dts).map(pd.Series(\"Mon Tue Wed Thu Fri Sat Sun\".split()))\nOut[194]: \n2013-04-30    Tue\n2013-05-02    Thu\n2013-05-05    Sun\n2013-05-06    Mon\n2013-05-07    Tue\nFreq: C, dtype: object \n```", "```py\nIn [195]: from pandas.tseries.holiday import USFederalHolidayCalendar\n\nIn [196]: bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n\n# Friday before MLK Day\nIn [197]: dt = datetime.datetime(2014, 1, 17)\n\n# Tuesday after MLK Day (Monday is skipped because it's a holiday)\nIn [198]: dt + bday_us\nOut[198]: Timestamp('2014-01-21 00:00:00') \n```", "```py\nIn [199]: bmth_us = pd.offsets.CustomBusinessMonthBegin(calendar=USFederalHolidayCalendar())\n\n# Skip new years\nIn [200]: dt = datetime.datetime(2013, 12, 17)\n\nIn [201]: dt + bmth_us\nOut[201]: Timestamp('2014-01-02 00:00:00')\n\n# Define date index with custom offset\nIn [202]: pd.date_range(start=\"20100101\", end=\"20120101\", freq=bmth_us)\nOut[202]: \nDatetimeIndex(['2010-01-04', '2010-02-01', '2010-03-01', '2010-04-01',\n '2010-05-03', '2010-06-01', '2010-07-01', '2010-08-02',\n '2010-09-01', '2010-10-01', '2010-11-01', '2010-12-01',\n '2011-01-03', '2011-02-01', '2011-03-01', '2011-04-01',\n '2011-05-02', '2011-06-01', '2011-07-01', '2011-08-01',\n '2011-09-01', '2011-10-03', '2011-11-01', '2011-12-01'],\n dtype='datetime64[ns]', freq='CBMS') \n```", "```py\nIn [203]: bh = pd.offsets.BusinessHour()\n\nIn [204]: bh\nOut[204]: <BusinessHour: bh=09:00-17:00>\n\n# 2014-08-01 is Friday\nIn [205]: pd.Timestamp(\"2014-08-01 10:00\").weekday()\nOut[205]: 4\n\nIn [206]: pd.Timestamp(\"2014-08-01 10:00\") + bh\nOut[206]: Timestamp('2014-08-01 11:00:00')\n\n# Below example is the same as: pd.Timestamp('2014-08-01 09:00') + bh\nIn [207]: pd.Timestamp(\"2014-08-01 08:00\") + bh\nOut[207]: Timestamp('2014-08-01 10:00:00')\n\n# If the results is on the end time, move to the next business day\nIn [208]: pd.Timestamp(\"2014-08-01 16:00\") + bh\nOut[208]: Timestamp('2014-08-04 09:00:00')\n\n# Remainings are added to the next day\nIn [209]: pd.Timestamp(\"2014-08-01 16:30\") + bh\nOut[209]: Timestamp('2014-08-04 09:30:00')\n\n# Adding 2 business hours\nIn [210]: pd.Timestamp(\"2014-08-01 10:00\") + pd.offsets.BusinessHour(2)\nOut[210]: Timestamp('2014-08-01 12:00:00')\n\n# Subtracting 3 business hours\nIn [211]: pd.Timestamp(\"2014-08-01 10:00\") + pd.offsets.BusinessHour(-3)\nOut[211]: Timestamp('2014-07-31 15:00:00') \n```", "```py\nIn [212]: bh = pd.offsets.BusinessHour(start=\"11:00\", end=datetime.time(20, 0))\n\nIn [213]: bh\nOut[213]: <BusinessHour: bh=11:00-20:00>\n\nIn [214]: pd.Timestamp(\"2014-08-01 13:00\") + bh\nOut[214]: Timestamp('2014-08-01 14:00:00')\n\nIn [215]: pd.Timestamp(\"2014-08-01 09:00\") + bh\nOut[215]: Timestamp('2014-08-01 12:00:00')\n\nIn [216]: pd.Timestamp(\"2014-08-01 18:00\") + bh\nOut[216]: Timestamp('2014-08-01 19:00:00') \n```", "```py\nIn [217]: bh = pd.offsets.BusinessHour(start=\"17:00\", end=\"09:00\")\n\nIn [218]: bh\nOut[218]: <BusinessHour: bh=17:00-09:00>\n\nIn [219]: pd.Timestamp(\"2014-08-01 17:00\") + bh\nOut[219]: Timestamp('2014-08-01 18:00:00')\n\nIn [220]: pd.Timestamp(\"2014-08-01 23:00\") + bh\nOut[220]: Timestamp('2014-08-02 00:00:00')\n\n# Although 2014-08-02 is Saturday,\n# it is valid because it starts from 08-01 (Friday).\nIn [221]: pd.Timestamp(\"2014-08-02 04:00\") + bh\nOut[221]: Timestamp('2014-08-02 05:00:00')\n\n# Although 2014-08-04 is Monday,\n# it is out of business hours because it starts from 08-03 (Sunday).\nIn [222]: pd.Timestamp(\"2014-08-04 04:00\") + bh\nOut[222]: Timestamp('2014-08-04 18:00:00') \n```", "```py\n# This adjusts a Timestamp to business hour edge\nIn [223]: pd.offsets.BusinessHour().rollback(pd.Timestamp(\"2014-08-02 15:00\"))\nOut[223]: Timestamp('2014-08-01 17:00:00')\n\nIn [224]: pd.offsets.BusinessHour().rollforward(pd.Timestamp(\"2014-08-02 15:00\"))\nOut[224]: Timestamp('2014-08-04 09:00:00')\n\n# It is the same as BusinessHour() + pd.Timestamp('2014-08-01 17:00').\n# And it is the same as BusinessHour() + pd.Timestamp('2014-08-04 09:00')\nIn [225]: pd.offsets.BusinessHour() + pd.Timestamp(\"2014-08-02 15:00\")\nOut[225]: Timestamp('2014-08-04 10:00:00')\n\n# BusinessDay results (for reference)\nIn [226]: pd.offsets.BusinessHour().rollforward(pd.Timestamp(\"2014-08-02\"))\nOut[226]: Timestamp('2014-08-04 09:00:00')\n\n# It is the same as BusinessDay() + pd.Timestamp('2014-08-01')\n# The result is the same as rollworward because BusinessDay never overlap.\nIn [227]: pd.offsets.BusinessHour() + pd.Timestamp(\"2014-08-02\")\nOut[227]: Timestamp('2014-08-04 10:00:00') \n```", "```py\nIn [228]: from pandas.tseries.holiday import USFederalHolidayCalendar\n\nIn [229]: bhour_us = pd.offsets.CustomBusinessHour(calendar=USFederalHolidayCalendar())\n\n# Friday before MLK Day\nIn [230]: dt = datetime.datetime(2014, 1, 17, 15)\n\nIn [231]: dt + bhour_us\nOut[231]: Timestamp('2014-01-17 16:00:00')\n\n# Tuesday after MLK Day (Monday is skipped because it's a holiday)\nIn [232]: dt + bhour_us * 2\nOut[232]: Timestamp('2014-01-21 09:00:00') \n```", "```py\nIn [233]: bhour_mon = pd.offsets.CustomBusinessHour(start=\"10:00\", weekmask=\"Tue Wed Thu Fri\")\n\n# Monday is skipped because it's a holiday, business hour starts from 10:00\nIn [234]: dt + bhour_mon * 2\nOut[234]: Timestamp('2014-01-21 10:00:00') \n```", "```py\nIn [235]: dates_lst_1 = pd.date_range(\"2020-01-06\", \"2020-04-03\", freq=\"MS\")\n\nIn [236]: dates_lst_1\nOut[236]: DatetimeIndex(['2020-02-01', '2020-03-01', '2020-04-01'], dtype='datetime64[ns]', freq='MS')\n\nIn [237]: dates_lst_2 = pd.date_range(\"2020-01-01\", \"2020-04-01\", freq=\"MS\")\n\nIn [238]: dates_lst_2\nOut[238]: DatetimeIndex(['2020-01-01', '2020-02-01', '2020-03-01', '2020-04-01'], dtype='datetime64[ns]', freq='MS') \n```", "```py\nIn [239]: pd.date_range(start, periods=5, freq=\"B\")\nOut[239]: \nDatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',\n '2011-01-07'],\n dtype='datetime64[ns]', freq='B')\n\nIn [240]: pd.date_range(start, periods=5, freq=pd.offsets.BDay())\nOut[240]: \nDatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',\n '2011-01-07'],\n dtype='datetime64[ns]', freq='B') \n```", "```py\nIn [241]: pd.date_range(start, periods=10, freq=\"2h20min\")\nOut[241]: \nDatetimeIndex(['2011-01-01 00:00:00', '2011-01-01 02:20:00',\n '2011-01-01 04:40:00', '2011-01-01 07:00:00',\n '2011-01-01 09:20:00', '2011-01-01 11:40:00',\n '2011-01-01 14:00:00', '2011-01-01 16:20:00',\n '2011-01-01 18:40:00', '2011-01-01 21:00:00'],\n dtype='datetime64[ns]', freq='140min')\n\nIn [242]: pd.date_range(start, periods=10, freq=\"1D10us\")\nOut[242]: \nDatetimeIndex([       '2011-01-01 00:00:00', '2011-01-02 00:00:00.000010',\n '2011-01-03 00:00:00.000020', '2011-01-04 00:00:00.000030',\n '2011-01-05 00:00:00.000040', '2011-01-06 00:00:00.000050',\n '2011-01-07 00:00:00.000060', '2011-01-08 00:00:00.000070',\n '2011-01-09 00:00:00.000080', '2011-01-10 00:00:00.000090'],\n dtype='datetime64[ns]', freq='86400000010us') \n```", "```py\nIn [243]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthBegin(n=1)\nOut[243]: Timestamp('2014-02-01 00:00:00')\n\nIn [244]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthEnd(n=1)\nOut[244]: Timestamp('2014-01-31 00:00:00')\n\nIn [245]: pd.Timestamp(\"2014-01-02\") - pd.offsets.MonthBegin(n=1)\nOut[245]: Timestamp('2014-01-01 00:00:00')\n\nIn [246]: pd.Timestamp(\"2014-01-02\") - pd.offsets.MonthEnd(n=1)\nOut[246]: Timestamp('2013-12-31 00:00:00')\n\nIn [247]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthBegin(n=4)\nOut[247]: Timestamp('2014-05-01 00:00:00')\n\nIn [248]: pd.Timestamp(\"2014-01-02\") - pd.offsets.MonthBegin(n=4)\nOut[248]: Timestamp('2013-10-01 00:00:00') \n```", "```py\nIn [249]: pd.Timestamp(\"2014-01-01\") + pd.offsets.MonthBegin(n=1)\nOut[249]: Timestamp('2014-02-01 00:00:00')\n\nIn [250]: pd.Timestamp(\"2014-01-31\") + pd.offsets.MonthEnd(n=1)\nOut[250]: Timestamp('2014-02-28 00:00:00')\n\nIn [251]: pd.Timestamp(\"2014-01-01\") - pd.offsets.MonthBegin(n=1)\nOut[251]: Timestamp('2013-12-01 00:00:00')\n\nIn [252]: pd.Timestamp(\"2014-01-31\") - pd.offsets.MonthEnd(n=1)\nOut[252]: Timestamp('2013-12-31 00:00:00')\n\nIn [253]: pd.Timestamp(\"2014-01-01\") + pd.offsets.MonthBegin(n=4)\nOut[253]: Timestamp('2014-05-01 00:00:00')\n\nIn [254]: pd.Timestamp(\"2014-01-31\") - pd.offsets.MonthBegin(n=4)\nOut[254]: Timestamp('2013-10-01 00:00:00') \n```", "```py\nIn [255]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthBegin(n=0)\nOut[255]: Timestamp('2014-02-01 00:00:00')\n\nIn [256]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthEnd(n=0)\nOut[256]: Timestamp('2014-01-31 00:00:00')\n\nIn [257]: pd.Timestamp(\"2014-01-01\") + pd.offsets.MonthBegin(n=0)\nOut[257]: Timestamp('2014-01-01 00:00:00')\n\nIn [258]: pd.Timestamp(\"2014-01-31\") + pd.offsets.MonthEnd(n=0)\nOut[258]: Timestamp('2014-01-31 00:00:00') \n```", "```py\nIn [259]: from pandas.tseries.holiday import (\n .....:    Holiday,\n .....:    USMemorialDay,\n .....:    AbstractHolidayCalendar,\n .....:    nearest_workday,\n .....:    MO,\n .....: )\n .....: \n\nIn [260]: class ExampleCalendar(AbstractHolidayCalendar):\n .....:    rules = [\n .....:        USMemorialDay,\n .....:        Holiday(\"July 4th\", month=7, day=4, observance=nearest_workday),\n .....:        Holiday(\n .....:            \"Columbus Day\",\n .....:            month=10,\n .....:            day=1,\n .....:            offset=pd.DateOffset(weekday=MO(2)),\n .....:        ),\n .....:    ]\n .....: \n\nIn [261]: cal = ExampleCalendar()\n\nIn [262]: cal.holidays(datetime.datetime(2012, 1, 1), datetime.datetime(2012, 12, 31))\nOut[262]: DatetimeIndex(['2012-05-28', '2012-07-04', '2012-10-08'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [263]: pd.date_range(\n .....:    start=\"7/1/2012\", end=\"7/10/2012\", freq=pd.offsets.CDay(calendar=cal)\n .....: ).to_pydatetime()\n .....: \nOut[263]: \narray([datetime.datetime(2012, 7, 2, 0, 0),\n datetime.datetime(2012, 7, 3, 0, 0),\n datetime.datetime(2012, 7, 5, 0, 0),\n datetime.datetime(2012, 7, 6, 0, 0),\n datetime.datetime(2012, 7, 9, 0, 0),\n datetime.datetime(2012, 7, 10, 0, 0)], dtype=object)\n\nIn [264]: offset = pd.offsets.CustomBusinessDay(calendar=cal)\n\nIn [265]: datetime.datetime(2012, 5, 25) + offset\nOut[265]: Timestamp('2012-05-29 00:00:00')\n\nIn [266]: datetime.datetime(2012, 7, 3) + offset\nOut[266]: Timestamp('2012-07-05 00:00:00')\n\nIn [267]: datetime.datetime(2012, 7, 3) + 2 * offset\nOut[267]: Timestamp('2012-07-06 00:00:00')\n\nIn [268]: datetime.datetime(2012, 7, 6) + offset\nOut[268]: Timestamp('2012-07-09 00:00:00') \n```", "```py\nIn [269]: AbstractHolidayCalendar.start_date\nOut[269]: Timestamp('1970-01-01 00:00:00')\n\nIn [270]: AbstractHolidayCalendar.end_date\nOut[270]: Timestamp('2200-12-31 00:00:00') \n```", "```py\nIn [271]: AbstractHolidayCalendar.start_date = datetime.datetime(2012, 1, 1)\n\nIn [272]: AbstractHolidayCalendar.end_date = datetime.datetime(2012, 12, 31)\n\nIn [273]: cal.holidays()\nOut[273]: DatetimeIndex(['2012-05-28', '2012-07-04', '2012-10-08'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [274]: from pandas.tseries.holiday import get_calendar, HolidayCalendarFactory, USLaborDay\n\nIn [275]: cal = get_calendar(\"ExampleCalendar\")\n\nIn [276]: cal.rules\nOut[276]: \n[Holiday: Memorial Day (month=5, day=31, offset=<DateOffset: weekday=MO(-1)>),\n Holiday: July 4th (month=7, day=4, observance=<function nearest_workday at 0x7ff27fdb0b80>),\n Holiday: Columbus Day (month=10, day=1, offset=<DateOffset: weekday=MO(+2)>)]\n\nIn [277]: new_cal = HolidayCalendarFactory(\"NewExampleCalendar\", cal, USLaborDay)\n\nIn [278]: new_cal.rules\nOut[278]: \n[Holiday: Labor Day (month=9, day=1, offset=<DateOffset: weekday=MO(+1)>),\n Holiday: Memorial Day (month=5, day=31, offset=<DateOffset: weekday=MO(-1)>),\n Holiday: July 4th (month=7, day=4, observance=<function nearest_workday at 0x7ff27fdb0b80>),\n Holiday: Columbus Day (month=10, day=1, offset=<DateOffset: weekday=MO(+2)>)] \n```", "```py\nIn [167]: d = datetime.datetime(2008, 8, 18, 9, 0)\n\nIn [168]: d\nOut[168]: datetime.datetime(2008, 8, 18, 9, 0)\n\nIn [169]: d + pd.offsets.Week()\nOut[169]: Timestamp('2008-08-25 09:00:00')\n\nIn [170]: d + pd.offsets.Week(weekday=4)\nOut[170]: Timestamp('2008-08-22 09:00:00')\n\nIn [171]: (d + pd.offsets.Week(weekday=4)).weekday()\nOut[171]: 4\n\nIn [172]: d - pd.offsets.Week()\nOut[172]: Timestamp('2008-08-11 09:00:00') \n```", "```py\nIn [173]: d + pd.offsets.Week(normalize=True)\nOut[173]: Timestamp('2008-08-25 00:00:00')\n\nIn [174]: d - pd.offsets.Week(normalize=True)\nOut[174]: Timestamp('2008-08-11 00:00:00') \n```", "```py\nIn [175]: d + pd.offsets.YearEnd()\nOut[175]: Timestamp('2008-12-31 09:00:00')\n\nIn [176]: d + pd.offsets.YearEnd(month=6)\nOut[176]: Timestamp('2009-06-30 09:00:00') \n```", "```py\nIn [177]: rng = pd.date_range(\"2012-01-01\", \"2012-01-03\")\n\nIn [178]: s = pd.Series(rng)\n\nIn [179]: rng\nOut[179]: DatetimeIndex(['2012-01-01', '2012-01-02', '2012-01-03'], dtype='datetime64[ns]', freq='D')\n\nIn [180]: rng + pd.DateOffset(months=2)\nOut[180]: DatetimeIndex(['2012-03-01', '2012-03-02', '2012-03-03'], dtype='datetime64[ns]', freq=None)\n\nIn [181]: s + pd.DateOffset(months=2)\nOut[181]: \n0   2012-03-01\n1   2012-03-02\n2   2012-03-03\ndtype: datetime64[ns]\n\nIn [182]: s - pd.DateOffset(months=2)\nOut[182]: \n0   2011-11-01\n1   2011-11-02\n2   2011-11-03\ndtype: datetime64[ns] \n```", "```py\nIn [183]: s - pd.offsets.Day(2)\nOut[183]: \n0   2011-12-30\n1   2011-12-31\n2   2012-01-01\ndtype: datetime64[ns]\n\nIn [184]: td = s - pd.Series(pd.date_range(\"2011-12-29\", \"2011-12-31\"))\n\nIn [185]: td\nOut[185]: \n0   3 days\n1   3 days\n2   3 days\ndtype: timedelta64[ns]\n\nIn [186]: td + pd.offsets.Minute(15)\nOut[186]: \n0   3 days 00:15:00\n1   3 days 00:15:00\n2   3 days 00:15:00\ndtype: timedelta64[ns] \n```", "```py\nIn [187]: rng + pd.offsets.BQuarterEnd()\nOut[187]: DatetimeIndex(['2012-03-30', '2012-03-30', '2012-03-30'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [188]: weekmask_egypt = \"Sun Mon Tue Wed Thu\"\n\n# They also observe International Workers' Day so let's\n# add that for a couple of years\nIn [189]: holidays = [\n .....:    \"2012-05-01\",\n .....:    datetime.datetime(2013, 5, 1),\n .....:    np.datetime64(\"2014-05-01\"),\n .....: ]\n .....: \n\nIn [190]: bday_egypt = pd.offsets.CustomBusinessDay(\n .....:    holidays=holidays,\n .....:    weekmask=weekmask_egypt,\n .....: )\n .....: \n\nIn [191]: dt = datetime.datetime(2013, 4, 30)\n\nIn [192]: dt + 2 * bday_egypt\nOut[192]: Timestamp('2013-05-05 00:00:00') \n```", "```py\nIn [193]: dts = pd.date_range(dt, periods=5, freq=bday_egypt)\n\nIn [194]: pd.Series(dts.weekday, dts).map(pd.Series(\"Mon Tue Wed Thu Fri Sat Sun\".split()))\nOut[194]: \n2013-04-30    Tue\n2013-05-02    Thu\n2013-05-05    Sun\n2013-05-06    Mon\n2013-05-07    Tue\nFreq: C, dtype: object \n```", "```py\nIn [195]: from pandas.tseries.holiday import USFederalHolidayCalendar\n\nIn [196]: bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n\n# Friday before MLK Day\nIn [197]: dt = datetime.datetime(2014, 1, 17)\n\n# Tuesday after MLK Day (Monday is skipped because it's a holiday)\nIn [198]: dt + bday_us\nOut[198]: Timestamp('2014-01-21 00:00:00') \n```", "```py\nIn [199]: bmth_us = pd.offsets.CustomBusinessMonthBegin(calendar=USFederalHolidayCalendar())\n\n# Skip new years\nIn [200]: dt = datetime.datetime(2013, 12, 17)\n\nIn [201]: dt + bmth_us\nOut[201]: Timestamp('2014-01-02 00:00:00')\n\n# Define date index with custom offset\nIn [202]: pd.date_range(start=\"20100101\", end=\"20120101\", freq=bmth_us)\nOut[202]: \nDatetimeIndex(['2010-01-04', '2010-02-01', '2010-03-01', '2010-04-01',\n '2010-05-03', '2010-06-01', '2010-07-01', '2010-08-02',\n '2010-09-01', '2010-10-01', '2010-11-01', '2010-12-01',\n '2011-01-03', '2011-02-01', '2011-03-01', '2011-04-01',\n '2011-05-02', '2011-06-01', '2011-07-01', '2011-08-01',\n '2011-09-01', '2011-10-03', '2011-11-01', '2011-12-01'],\n dtype='datetime64[ns]', freq='CBMS') \n```", "```py\nIn [203]: bh = pd.offsets.BusinessHour()\n\nIn [204]: bh\nOut[204]: <BusinessHour: bh=09:00-17:00>\n\n# 2014-08-01 is Friday\nIn [205]: pd.Timestamp(\"2014-08-01 10:00\").weekday()\nOut[205]: 4\n\nIn [206]: pd.Timestamp(\"2014-08-01 10:00\") + bh\nOut[206]: Timestamp('2014-08-01 11:00:00')\n\n# Below example is the same as: pd.Timestamp('2014-08-01 09:00') + bh\nIn [207]: pd.Timestamp(\"2014-08-01 08:00\") + bh\nOut[207]: Timestamp('2014-08-01 10:00:00')\n\n# If the results is on the end time, move to the next business day\nIn [208]: pd.Timestamp(\"2014-08-01 16:00\") + bh\nOut[208]: Timestamp('2014-08-04 09:00:00')\n\n# Remainings are added to the next day\nIn [209]: pd.Timestamp(\"2014-08-01 16:30\") + bh\nOut[209]: Timestamp('2014-08-04 09:30:00')\n\n# Adding 2 business hours\nIn [210]: pd.Timestamp(\"2014-08-01 10:00\") + pd.offsets.BusinessHour(2)\nOut[210]: Timestamp('2014-08-01 12:00:00')\n\n# Subtracting 3 business hours\nIn [211]: pd.Timestamp(\"2014-08-01 10:00\") + pd.offsets.BusinessHour(-3)\nOut[211]: Timestamp('2014-07-31 15:00:00') \n```", "```py\nIn [212]: bh = pd.offsets.BusinessHour(start=\"11:00\", end=datetime.time(20, 0))\n\nIn [213]: bh\nOut[213]: <BusinessHour: bh=11:00-20:00>\n\nIn [214]: pd.Timestamp(\"2014-08-01 13:00\") + bh\nOut[214]: Timestamp('2014-08-01 14:00:00')\n\nIn [215]: pd.Timestamp(\"2014-08-01 09:00\") + bh\nOut[215]: Timestamp('2014-08-01 12:00:00')\n\nIn [216]: pd.Timestamp(\"2014-08-01 18:00\") + bh\nOut[216]: Timestamp('2014-08-01 19:00:00') \n```", "```py\nIn [217]: bh = pd.offsets.BusinessHour(start=\"17:00\", end=\"09:00\")\n\nIn [218]: bh\nOut[218]: <BusinessHour: bh=17:00-09:00>\n\nIn [219]: pd.Timestamp(\"2014-08-01 17:00\") + bh\nOut[219]: Timestamp('2014-08-01 18:00:00')\n\nIn [220]: pd.Timestamp(\"2014-08-01 23:00\") + bh\nOut[220]: Timestamp('2014-08-02 00:00:00')\n\n# Although 2014-08-02 is Saturday,\n# it is valid because it starts from 08-01 (Friday).\nIn [221]: pd.Timestamp(\"2014-08-02 04:00\") + bh\nOut[221]: Timestamp('2014-08-02 05:00:00')\n\n# Although 2014-08-04 is Monday,\n# it is out of business hours because it starts from 08-03 (Sunday).\nIn [222]: pd.Timestamp(\"2014-08-04 04:00\") + bh\nOut[222]: Timestamp('2014-08-04 18:00:00') \n```", "```py\n# This adjusts a Timestamp to business hour edge\nIn [223]: pd.offsets.BusinessHour().rollback(pd.Timestamp(\"2014-08-02 15:00\"))\nOut[223]: Timestamp('2014-08-01 17:00:00')\n\nIn [224]: pd.offsets.BusinessHour().rollforward(pd.Timestamp(\"2014-08-02 15:00\"))\nOut[224]: Timestamp('2014-08-04 09:00:00')\n\n# It is the same as BusinessHour() + pd.Timestamp('2014-08-01 17:00').\n# And it is the same as BusinessHour() + pd.Timestamp('2014-08-04 09:00')\nIn [225]: pd.offsets.BusinessHour() + pd.Timestamp(\"2014-08-02 15:00\")\nOut[225]: Timestamp('2014-08-04 10:00:00')\n\n# BusinessDay results (for reference)\nIn [226]: pd.offsets.BusinessHour().rollforward(pd.Timestamp(\"2014-08-02\"))\nOut[226]: Timestamp('2014-08-04 09:00:00')\n\n# It is the same as BusinessDay() + pd.Timestamp('2014-08-01')\n# The result is the same as rollworward because BusinessDay never overlap.\nIn [227]: pd.offsets.BusinessHour() + pd.Timestamp(\"2014-08-02\")\nOut[227]: Timestamp('2014-08-04 10:00:00') \n```", "```py\nIn [228]: from pandas.tseries.holiday import USFederalHolidayCalendar\n\nIn [229]: bhour_us = pd.offsets.CustomBusinessHour(calendar=USFederalHolidayCalendar())\n\n# Friday before MLK Day\nIn [230]: dt = datetime.datetime(2014, 1, 17, 15)\n\nIn [231]: dt + bhour_us\nOut[231]: Timestamp('2014-01-17 16:00:00')\n\n# Tuesday after MLK Day (Monday is skipped because it's a holiday)\nIn [232]: dt + bhour_us * 2\nOut[232]: Timestamp('2014-01-21 09:00:00') \n```", "```py\nIn [233]: bhour_mon = pd.offsets.CustomBusinessHour(start=\"10:00\", weekmask=\"Tue Wed Thu Fri\")\n\n# Monday is skipped because it's a holiday, business hour starts from 10:00\nIn [234]: dt + bhour_mon * 2\nOut[234]: Timestamp('2014-01-21 10:00:00') \n```", "```py\nIn [235]: dates_lst_1 = pd.date_range(\"2020-01-06\", \"2020-04-03\", freq=\"MS\")\n\nIn [236]: dates_lst_1\nOut[236]: DatetimeIndex(['2020-02-01', '2020-03-01', '2020-04-01'], dtype='datetime64[ns]', freq='MS')\n\nIn [237]: dates_lst_2 = pd.date_range(\"2020-01-01\", \"2020-04-01\", freq=\"MS\")\n\nIn [238]: dates_lst_2\nOut[238]: DatetimeIndex(['2020-01-01', '2020-02-01', '2020-03-01', '2020-04-01'], dtype='datetime64[ns]', freq='MS') \n```", "```py\nIn [239]: pd.date_range(start, periods=5, freq=\"B\")\nOut[239]: \nDatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',\n '2011-01-07'],\n dtype='datetime64[ns]', freq='B')\n\nIn [240]: pd.date_range(start, periods=5, freq=pd.offsets.BDay())\nOut[240]: \nDatetimeIndex(['2011-01-03', '2011-01-04', '2011-01-05', '2011-01-06',\n '2011-01-07'],\n dtype='datetime64[ns]', freq='B') \n```", "```py\nIn [241]: pd.date_range(start, periods=10, freq=\"2h20min\")\nOut[241]: \nDatetimeIndex(['2011-01-01 00:00:00', '2011-01-01 02:20:00',\n '2011-01-01 04:40:00', '2011-01-01 07:00:00',\n '2011-01-01 09:20:00', '2011-01-01 11:40:00',\n '2011-01-01 14:00:00', '2011-01-01 16:20:00',\n '2011-01-01 18:40:00', '2011-01-01 21:00:00'],\n dtype='datetime64[ns]', freq='140min')\n\nIn [242]: pd.date_range(start, periods=10, freq=\"1D10us\")\nOut[242]: \nDatetimeIndex([       '2011-01-01 00:00:00', '2011-01-02 00:00:00.000010',\n '2011-01-03 00:00:00.000020', '2011-01-04 00:00:00.000030',\n '2011-01-05 00:00:00.000040', '2011-01-06 00:00:00.000050',\n '2011-01-07 00:00:00.000060', '2011-01-08 00:00:00.000070',\n '2011-01-09 00:00:00.000080', '2011-01-10 00:00:00.000090'],\n dtype='datetime64[ns]', freq='86400000010us') \n```", "```py\nIn [243]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthBegin(n=1)\nOut[243]: Timestamp('2014-02-01 00:00:00')\n\nIn [244]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthEnd(n=1)\nOut[244]: Timestamp('2014-01-31 00:00:00')\n\nIn [245]: pd.Timestamp(\"2014-01-02\") - pd.offsets.MonthBegin(n=1)\nOut[245]: Timestamp('2014-01-01 00:00:00')\n\nIn [246]: pd.Timestamp(\"2014-01-02\") - pd.offsets.MonthEnd(n=1)\nOut[246]: Timestamp('2013-12-31 00:00:00')\n\nIn [247]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthBegin(n=4)\nOut[247]: Timestamp('2014-05-01 00:00:00')\n\nIn [248]: pd.Timestamp(\"2014-01-02\") - pd.offsets.MonthBegin(n=4)\nOut[248]: Timestamp('2013-10-01 00:00:00') \n```", "```py\nIn [249]: pd.Timestamp(\"2014-01-01\") + pd.offsets.MonthBegin(n=1)\nOut[249]: Timestamp('2014-02-01 00:00:00')\n\nIn [250]: pd.Timestamp(\"2014-01-31\") + pd.offsets.MonthEnd(n=1)\nOut[250]: Timestamp('2014-02-28 00:00:00')\n\nIn [251]: pd.Timestamp(\"2014-01-01\") - pd.offsets.MonthBegin(n=1)\nOut[251]: Timestamp('2013-12-01 00:00:00')\n\nIn [252]: pd.Timestamp(\"2014-01-31\") - pd.offsets.MonthEnd(n=1)\nOut[252]: Timestamp('2013-12-31 00:00:00')\n\nIn [253]: pd.Timestamp(\"2014-01-01\") + pd.offsets.MonthBegin(n=4)\nOut[253]: Timestamp('2014-05-01 00:00:00')\n\nIn [254]: pd.Timestamp(\"2014-01-31\") - pd.offsets.MonthBegin(n=4)\nOut[254]: Timestamp('2013-10-01 00:00:00') \n```", "```py\nIn [255]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthBegin(n=0)\nOut[255]: Timestamp('2014-02-01 00:00:00')\n\nIn [256]: pd.Timestamp(\"2014-01-02\") + pd.offsets.MonthEnd(n=0)\nOut[256]: Timestamp('2014-01-31 00:00:00')\n\nIn [257]: pd.Timestamp(\"2014-01-01\") + pd.offsets.MonthBegin(n=0)\nOut[257]: Timestamp('2014-01-01 00:00:00')\n\nIn [258]: pd.Timestamp(\"2014-01-31\") + pd.offsets.MonthEnd(n=0)\nOut[258]: Timestamp('2014-01-31 00:00:00') \n```", "```py\nIn [259]: from pandas.tseries.holiday import (\n .....:    Holiday,\n .....:    USMemorialDay,\n .....:    AbstractHolidayCalendar,\n .....:    nearest_workday,\n .....:    MO,\n .....: )\n .....: \n\nIn [260]: class ExampleCalendar(AbstractHolidayCalendar):\n .....:    rules = [\n .....:        USMemorialDay,\n .....:        Holiday(\"July 4th\", month=7, day=4, observance=nearest_workday),\n .....:        Holiday(\n .....:            \"Columbus Day\",\n .....:            month=10,\n .....:            day=1,\n .....:            offset=pd.DateOffset(weekday=MO(2)),\n .....:        ),\n .....:    ]\n .....: \n\nIn [261]: cal = ExampleCalendar()\n\nIn [262]: cal.holidays(datetime.datetime(2012, 1, 1), datetime.datetime(2012, 12, 31))\nOut[262]: DatetimeIndex(['2012-05-28', '2012-07-04', '2012-10-08'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [263]: pd.date_range(\n .....:    start=\"7/1/2012\", end=\"7/10/2012\", freq=pd.offsets.CDay(calendar=cal)\n .....: ).to_pydatetime()\n .....: \nOut[263]: \narray([datetime.datetime(2012, 7, 2, 0, 0),\n datetime.datetime(2012, 7, 3, 0, 0),\n datetime.datetime(2012, 7, 5, 0, 0),\n datetime.datetime(2012, 7, 6, 0, 0),\n datetime.datetime(2012, 7, 9, 0, 0),\n datetime.datetime(2012, 7, 10, 0, 0)], dtype=object)\n\nIn [264]: offset = pd.offsets.CustomBusinessDay(calendar=cal)\n\nIn [265]: datetime.datetime(2012, 5, 25) + offset\nOut[265]: Timestamp('2012-05-29 00:00:00')\n\nIn [266]: datetime.datetime(2012, 7, 3) + offset\nOut[266]: Timestamp('2012-07-05 00:00:00')\n\nIn [267]: datetime.datetime(2012, 7, 3) + 2 * offset\nOut[267]: Timestamp('2012-07-06 00:00:00')\n\nIn [268]: datetime.datetime(2012, 7, 6) + offset\nOut[268]: Timestamp('2012-07-09 00:00:00') \n```", "```py\nIn [269]: AbstractHolidayCalendar.start_date\nOut[269]: Timestamp('1970-01-01 00:00:00')\n\nIn [270]: AbstractHolidayCalendar.end_date\nOut[270]: Timestamp('2200-12-31 00:00:00') \n```", "```py\nIn [271]: AbstractHolidayCalendar.start_date = datetime.datetime(2012, 1, 1)\n\nIn [272]: AbstractHolidayCalendar.end_date = datetime.datetime(2012, 12, 31)\n\nIn [273]: cal.holidays()\nOut[273]: DatetimeIndex(['2012-05-28', '2012-07-04', '2012-10-08'], dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [274]: from pandas.tseries.holiday import get_calendar, HolidayCalendarFactory, USLaborDay\n\nIn [275]: cal = get_calendar(\"ExampleCalendar\")\n\nIn [276]: cal.rules\nOut[276]: \n[Holiday: Memorial Day (month=5, day=31, offset=<DateOffset: weekday=MO(-1)>),\n Holiday: July 4th (month=7, day=4, observance=<function nearest_workday at 0x7ff27fdb0b80>),\n Holiday: Columbus Day (month=10, day=1, offset=<DateOffset: weekday=MO(+2)>)]\n\nIn [277]: new_cal = HolidayCalendarFactory(\"NewExampleCalendar\", cal, USLaborDay)\n\nIn [278]: new_cal.rules\nOut[278]: \n[Holiday: Labor Day (month=9, day=1, offset=<DateOffset: weekday=MO(+1)>),\n Holiday: Memorial Day (month=5, day=31, offset=<DateOffset: weekday=MO(-1)>),\n Holiday: July 4th (month=7, day=4, observance=<function nearest_workday at 0x7ff27fdb0b80>),\n Holiday: Columbus Day (month=10, day=1, offset=<DateOffset: weekday=MO(+2)>)] \n```", "```py\nIn [279]: ts = pd.Series(range(len(rng)), index=rng)\n\nIn [280]: ts = ts[:5]\n\nIn [281]: ts.shift(1)\nOut[281]: \n2012-01-01    NaN\n2012-01-02    0.0\n2012-01-03    1.0\nFreq: D, dtype: float64 \n```", "```py\nIn [282]: ts.shift(5, freq=\"D\")\nOut[282]: \n2012-01-06    0\n2012-01-07    1\n2012-01-08    2\nFreq: D, dtype: int64\n\nIn [283]: ts.shift(5, freq=pd.offsets.BDay())\nOut[283]: \n2012-01-06    0\n2012-01-09    1\n2012-01-10    2\ndtype: int64\n\nIn [284]: ts.shift(5, freq=\"BME\")\nOut[284]: \n2012-05-31    0\n2012-05-31    1\n2012-05-31    2\ndtype: int64 \n```", "```py\nIn [285]: dr = pd.date_range(\"1/1/2010\", periods=3, freq=3 * pd.offsets.BDay())\n\nIn [286]: ts = pd.Series(np.random.randn(3), index=dr)\n\nIn [287]: ts\nOut[287]: \n2010-01-01    1.494522\n2010-01-06   -0.778425\n2010-01-11   -0.253355\nFreq: 3B, dtype: float64\n\nIn [288]: ts.asfreq(pd.offsets.BDay())\nOut[288]: \n2010-01-01    1.494522\n2010-01-04         NaN\n2010-01-05         NaN\n2010-01-06   -0.778425\n2010-01-07         NaN\n2010-01-08         NaN\n2010-01-11   -0.253355\nFreq: B, dtype: float64 \n```", "```py\nIn [289]: ts.asfreq(pd.offsets.BDay(), method=\"pad\")\nOut[289]: \n2010-01-01    1.494522\n2010-01-04    1.494522\n2010-01-05    1.494522\n2010-01-06   -0.778425\n2010-01-07   -0.778425\n2010-01-08   -0.778425\n2010-01-11   -0.253355\nFreq: B, dtype: float64 \n```", "```py\nIn [279]: ts = pd.Series(range(len(rng)), index=rng)\n\nIn [280]: ts = ts[:5]\n\nIn [281]: ts.shift(1)\nOut[281]: \n2012-01-01    NaN\n2012-01-02    0.0\n2012-01-03    1.0\nFreq: D, dtype: float64 \n```", "```py\nIn [282]: ts.shift(5, freq=\"D\")\nOut[282]: \n2012-01-06    0\n2012-01-07    1\n2012-01-08    2\nFreq: D, dtype: int64\n\nIn [283]: ts.shift(5, freq=pd.offsets.BDay())\nOut[283]: \n2012-01-06    0\n2012-01-09    1\n2012-01-10    2\ndtype: int64\n\nIn [284]: ts.shift(5, freq=\"BME\")\nOut[284]: \n2012-05-31    0\n2012-05-31    1\n2012-05-31    2\ndtype: int64 \n```", "```py\nIn [285]: dr = pd.date_range(\"1/1/2010\", periods=3, freq=3 * pd.offsets.BDay())\n\nIn [286]: ts = pd.Series(np.random.randn(3), index=dr)\n\nIn [287]: ts\nOut[287]: \n2010-01-01    1.494522\n2010-01-06   -0.778425\n2010-01-11   -0.253355\nFreq: 3B, dtype: float64\n\nIn [288]: ts.asfreq(pd.offsets.BDay())\nOut[288]: \n2010-01-01    1.494522\n2010-01-04         NaN\n2010-01-05         NaN\n2010-01-06   -0.778425\n2010-01-07         NaN\n2010-01-08         NaN\n2010-01-11   -0.253355\nFreq: B, dtype: float64 \n```", "```py\nIn [289]: ts.asfreq(pd.offsets.BDay(), method=\"pad\")\nOut[289]: \n2010-01-01    1.494522\n2010-01-04    1.494522\n2010-01-05    1.494522\n2010-01-06   -0.778425\n2010-01-07   -0.778425\n2010-01-08   -0.778425\n2010-01-11   -0.253355\nFreq: B, dtype: float64 \n```", "```py\nIn [290]: rng = pd.date_range(\"1/1/2012\", periods=100, freq=\"s\")\n\nIn [291]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\n\nIn [292]: ts.resample(\"5Min\").sum()\nOut[292]: \n2012-01-01    25103\nFreq: 5min, dtype: int64 \n```", "```py\nIn [293]: ts.resample(\"5Min\").mean()\nOut[293]: \n2012-01-01    251.03\nFreq: 5min, dtype: float64\n\nIn [294]: ts.resample(\"5Min\").ohlc()\nOut[294]: \n open  high  low  close\n2012-01-01   308   460    9    205\n\nIn [295]: ts.resample(\"5Min\").max()\nOut[295]: \n2012-01-01    460\nFreq: 5min, dtype: int64 \n```", "```py\nIn [296]: ts.resample(\"5Min\", closed=\"right\").mean()\nOut[296]: \n2011-12-31 23:55:00    308.000000\n2012-01-01 00:00:00    250.454545\nFreq: 5min, dtype: float64\n\nIn [297]: ts.resample(\"5Min\", closed=\"left\").mean()\nOut[297]: \n2012-01-01    251.03\nFreq: 5min, dtype: float64 \n```", "```py\nIn [298]: ts.resample(\"5Min\").mean()  # by default label='left'\nOut[298]: \n2012-01-01    251.03\nFreq: 5min, dtype: float64\n\nIn [299]: ts.resample(\"5Min\", label=\"left\").mean()\nOut[299]: \n2012-01-01    251.03\nFreq: 5min, dtype: float64 \n```", "```py\nIn [300]: s = pd.date_range(\"2000-01-01\", \"2000-01-05\").to_series()\n\nIn [301]: s.iloc[2] = pd.NaT\n\nIn [302]: s.dt.day_name()\nOut[302]: \n2000-01-01     Saturday\n2000-01-02       Sunday\n2000-01-03          NaN\n2000-01-04      Tuesday\n2000-01-05    Wednesday\nFreq: D, dtype: object\n\n# default: label='left', closed='left'\nIn [303]: s.resample(\"B\").last().dt.day_name()\nOut[303]: \n1999-12-31       Sunday\n2000-01-03          NaN\n2000-01-04      Tuesday\n2000-01-05    Wednesday\nFreq: B, dtype: object \n```", "```py\nIn [304]: s.resample(\"B\", label=\"right\", closed=\"right\").last().dt.day_name()\nOut[304]: \n2000-01-03       Sunday\n2000-01-04      Tuesday\n2000-01-05    Wednesday\n2000-01-06          NaN\nFreq: B, dtype: object \n```", "```py\n# from secondly to every 250 milliseconds\nIn [305]: ts[:2].resample(\"250ms\").asfreq()\nOut[305]: \n2012-01-01 00:00:00.000    308.0\n2012-01-01 00:00:00.250      NaN\n2012-01-01 00:00:00.500      NaN\n2012-01-01 00:00:00.750      NaN\n2012-01-01 00:00:01.000    204.0\nFreq: 250ms, dtype: float64\n\nIn [306]: ts[:2].resample(\"250ms\").ffill()\nOut[306]: \n2012-01-01 00:00:00.000    308\n2012-01-01 00:00:00.250    308\n2012-01-01 00:00:00.500    308\n2012-01-01 00:00:00.750    308\n2012-01-01 00:00:01.000    204\nFreq: 250ms, dtype: int64\n\nIn [307]: ts[:2].resample(\"250ms\").ffill(limit=2)\nOut[307]: \n2012-01-01 00:00:00.000    308.0\n2012-01-01 00:00:00.250    308.0\n2012-01-01 00:00:00.500    308.0\n2012-01-01 00:00:00.750      NaN\n2012-01-01 00:00:01.000    204.0\nFreq: 250ms, dtype: float64 \n```", "```py\nIn [308]: rng = pd.date_range(\"2014-1-1\", periods=100, freq=\"D\") + pd.Timedelta(\"1s\")\n\nIn [309]: ts = pd.Series(range(100), index=rng) \n```", "```py\nIn [310]: ts.resample(\"3min\").sum()\nOut[310]: \n2014-01-01 00:00:00     0\n2014-01-01 00:03:00     0\n2014-01-01 00:06:00     0\n2014-01-01 00:09:00     0\n2014-01-01 00:12:00     0\n ..\n2014-04-09 23:48:00     0\n2014-04-09 23:51:00     0\n2014-04-09 23:54:00     0\n2014-04-09 23:57:00     0\n2014-04-10 00:00:00    99\nFreq: 3min, Length: 47521, dtype: int64 \n```", "```py\nIn [311]: from functools import partial\n\nIn [312]: from pandas.tseries.frequencies import to_offset\n\nIn [313]: def round(t, freq):\n .....:    freq = to_offset(freq)\n .....:    td = pd.Timedelta(freq)\n .....:    return pd.Timestamp((t.value // td.value) * td.value)\n .....: \n\nIn [314]: ts.groupby(partial(round, freq=\"3min\")).sum()\nOut[314]: \n2014-01-01     0\n2014-01-02     1\n2014-01-03     2\n2014-01-04     3\n2014-01-05     4\n ..\n2014-04-06    95\n2014-04-07    96\n2014-04-08    97\n2014-04-09    98\n2014-04-10    99\nLength: 100, dtype: int64 \n```", "```py\nIn [315]: df = pd.DataFrame(\n .....:    np.random.randn(1000, 3),\n .....:    index=pd.date_range(\"1/1/2012\", freq=\"s\", periods=1000),\n .....:    columns=[\"A\", \"B\", \"C\"],\n .....: )\n .....: \n\nIn [316]: r = df.resample(\"3min\")\n\nIn [317]: r.mean()\nOut[317]: \n A         B         C\n2012-01-01 00:00:00 -0.033823 -0.121514 -0.081447\n2012-01-01 00:03:00  0.056909  0.146731 -0.024320\n2012-01-01 00:06:00 -0.058837  0.047046 -0.052021\n2012-01-01 00:09:00  0.063123 -0.026158 -0.066533\n2012-01-01 00:12:00  0.186340 -0.003144  0.074752\n2012-01-01 00:15:00 -0.085954 -0.016287 -0.050046 \n```", "```py\nIn [318]: r[\"A\"].mean()\nOut[318]: \n2012-01-01 00:00:00   -0.033823\n2012-01-01 00:03:00    0.056909\n2012-01-01 00:06:00   -0.058837\n2012-01-01 00:09:00    0.063123\n2012-01-01 00:12:00    0.186340\n2012-01-01 00:15:00   -0.085954\nFreq: 3min, Name: A, dtype: float64\n\nIn [319]: r[[\"A\", \"B\"]].mean()\nOut[319]: \n A         B\n2012-01-01 00:00:00 -0.033823 -0.121514\n2012-01-01 00:03:00  0.056909  0.146731\n2012-01-01 00:06:00 -0.058837  0.047046\n2012-01-01 00:09:00  0.063123 -0.026158\n2012-01-01 00:12:00  0.186340 -0.003144\n2012-01-01 00:15:00 -0.085954 -0.016287 \n```", "```py\nIn [320]: r[\"A\"].agg([\"sum\", \"mean\", \"std\"])\nOut[320]: \n sum      mean       std\n2012-01-01 00:00:00  -6.088060 -0.033823  1.043263\n2012-01-01 00:03:00  10.243678  0.056909  1.058534\n2012-01-01 00:06:00 -10.590584 -0.058837  0.949264\n2012-01-01 00:09:00  11.362228  0.063123  1.028096\n2012-01-01 00:12:00  33.541257  0.186340  0.884586\n2012-01-01 00:15:00  -8.595393 -0.085954  1.035476 \n```", "```py\nIn [321]: r.agg([\"sum\", \"mean\"])\nOut[321]: \n A            ...          C \n sum      mean  ...        sum      mean\n2012-01-01 00:00:00  -6.088060 -0.033823  ... -14.660515 -0.081447\n2012-01-01 00:03:00  10.243678  0.056909  ...  -4.377642 -0.024320\n2012-01-01 00:06:00 -10.590584 -0.058837  ...  -9.363825 -0.052021\n2012-01-01 00:09:00  11.362228  0.063123  ... -11.975895 -0.066533\n2012-01-01 00:12:00  33.541257  0.186340  ...  13.455299  0.074752\n2012-01-01 00:15:00  -8.595393 -0.085954  ...  -5.004580 -0.050046\n\n[6 rows x 6 columns] \n```", "```py\nIn [322]: r.agg({\"A\": \"sum\", \"B\": lambda x: np.std(x, ddof=1)})\nOut[322]: \n A         B\n2012-01-01 00:00:00  -6.088060  1.001294\n2012-01-01 00:03:00  10.243678  1.074597\n2012-01-01 00:06:00 -10.590584  0.987309\n2012-01-01 00:09:00  11.362228  0.944953\n2012-01-01 00:12:00  33.541257  1.095025\n2012-01-01 00:15:00  -8.595393  1.035312 \n```", "```py\nIn [323]: r.agg({\"A\": \"sum\", \"B\": \"std\"})\nOut[323]: \n A         B\n2012-01-01 00:00:00  -6.088060  1.001294\n2012-01-01 00:03:00  10.243678  1.074597\n2012-01-01 00:06:00 -10.590584  0.987309\n2012-01-01 00:09:00  11.362228  0.944953\n2012-01-01 00:12:00  33.541257  1.095025\n2012-01-01 00:15:00  -8.595393  1.035312 \n```", "```py\nIn [324]: r.agg({\"A\": [\"sum\", \"std\"], \"B\": [\"mean\", \"std\"]})\nOut[324]: \n A                   B \n sum       std      mean       std\n2012-01-01 00:00:00  -6.088060  1.043263 -0.121514  1.001294\n2012-01-01 00:03:00  10.243678  1.058534  0.146731  1.074597\n2012-01-01 00:06:00 -10.590584  0.949264  0.047046  0.987309\n2012-01-01 00:09:00  11.362228  1.028096 -0.026158  0.944953\n2012-01-01 00:12:00  33.541257  0.884586 -0.003144  1.095025\n2012-01-01 00:15:00  -8.595393  1.035476 -0.016287  1.035312 \n```", "```py\nIn [325]: df = pd.DataFrame(\n .....:    {\"date\": pd.date_range(\"2015-01-01\", freq=\"W\", periods=5), \"a\": np.arange(5)},\n .....:    index=pd.MultiIndex.from_arrays(\n .....:        [[1, 2, 3, 4, 5], pd.date_range(\"2015-01-01\", freq=\"W\", periods=5)],\n .....:        names=[\"v\", \"d\"],\n .....:    ),\n .....: )\n .....: \n\nIn [326]: df\nOut[326]: \n date  a\nv d \n1 2015-01-04 2015-01-04  0\n2 2015-01-11 2015-01-11  1\n3 2015-01-18 2015-01-18  2\n4 2015-01-25 2015-01-25  3\n5 2015-02-01 2015-02-01  4\n\nIn [327]: df.resample(\"ME\", on=\"date\")[[\"a\"]].sum()\nOut[327]: \n a\ndate \n2015-01-31  6\n2015-02-28  4 \n```", "```py\nIn [328]: df.resample(\"ME\", level=\"d\")[[\"a\"]].sum()\nOut[328]: \n a\nd \n2015-01-31  6\n2015-02-28  4 \n```", "```py\nIn [329]: small = pd.Series(\n .....:    range(6),\n .....:    index=pd.to_datetime(\n .....:        [\n .....:            \"2017-01-01T00:00:00\",\n .....:            \"2017-01-01T00:30:00\",\n .....:            \"2017-01-01T00:31:00\",\n .....:            \"2017-01-01T01:00:00\",\n .....:            \"2017-01-01T03:00:00\",\n .....:            \"2017-01-01T03:05:00\",\n .....:        ]\n .....:    ),\n .....: )\n .....: \n\nIn [330]: resampled = small.resample(\"h\")\n\nIn [331]: for name, group in resampled:\n .....:    print(\"Group: \", name)\n .....:    print(\"-\" * 27)\n .....:    print(group, end=\"\\n\\n\")\n .....: \nGroup:  2017-01-01 00:00:00\n---------------------------\n2017-01-01 00:00:00    0\n2017-01-01 00:30:00    1\n2017-01-01 00:31:00    2\ndtype: int64\n\nGroup:  2017-01-01 01:00:00\n---------------------------\n2017-01-01 01:00:00    3\ndtype: int64\n\nGroup:  2017-01-01 02:00:00\n---------------------------\nSeries([], dtype: int64)\n\nGroup:  2017-01-01 03:00:00\n---------------------------\n2017-01-01 03:00:00    4\n2017-01-01 03:05:00    5\ndtype: int64 \n```", "```py\nIn [332]: start, end = \"2000-10-01 23:30:00\", \"2000-10-02 00:30:00\"\n\nIn [333]: middle = \"2000-10-02 00:00:00\"\n\nIn [334]: rng = pd.date_range(start, end, freq=\"7min\")\n\nIn [335]: ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n\nIn [336]: ts\nOut[336]: \n2000-10-01 23:30:00     0\n2000-10-01 23:37:00     3\n2000-10-01 23:44:00     6\n2000-10-01 23:51:00     9\n2000-10-01 23:58:00    12\n2000-10-02 00:05:00    15\n2000-10-02 00:12:00    18\n2000-10-02 00:19:00    21\n2000-10-02 00:26:00    24\nFreq: 7min, dtype: int64 \n```", "```py\nIn [337]: ts.resample(\"17min\", origin=\"start_day\").sum()\nOut[337]: \n2000-10-01 23:14:00     0\n2000-10-01 23:31:00     9\n2000-10-01 23:48:00    21\n2000-10-02 00:05:00    54\n2000-10-02 00:22:00    24\nFreq: 17min, dtype: int64\n\nIn [338]: ts[middle:end].resample(\"17min\", origin=\"start_day\").sum()\nOut[338]: \n2000-10-02 00:00:00    33\n2000-10-02 00:17:00    45\nFreq: 17min, dtype: int64 \n```", "```py\nIn [339]: ts.resample(\"17min\", origin=\"epoch\").sum()\nOut[339]: \n2000-10-01 23:18:00     0\n2000-10-01 23:35:00    18\n2000-10-01 23:52:00    27\n2000-10-02 00:09:00    39\n2000-10-02 00:26:00    24\nFreq: 17min, dtype: int64\n\nIn [340]: ts[middle:end].resample(\"17min\", origin=\"epoch\").sum()\nOut[340]: \n2000-10-01 23:52:00    15\n2000-10-02 00:09:00    39\n2000-10-02 00:26:00    24\nFreq: 17min, dtype: int64 \n```", "```py\nIn [341]: ts.resample(\"17min\", origin=\"2001-01-01\").sum()\nOut[341]: \n2000-10-01 23:30:00     9\n2000-10-01 23:47:00    21\n2000-10-02 00:04:00    54\n2000-10-02 00:21:00    24\nFreq: 17min, dtype: int64\n\nIn [342]: ts[middle:end].resample(\"17min\", origin=pd.Timestamp(\"2001-01-01\")).sum()\nOut[342]: \n2000-10-02 00:04:00    54\n2000-10-02 00:21:00    24\nFreq: 17min, dtype: int64 \n```", "```py\nIn [343]: ts.resample(\"17min\", origin=\"start\").sum()\nOut[343]: \n2000-10-01 23:30:00     9\n2000-10-01 23:47:00    21\n2000-10-02 00:04:00    54\n2000-10-02 00:21:00    24\nFreq: 17min, dtype: int64\n\nIn [344]: ts.resample(\"17min\", offset=\"23h30min\").sum()\nOut[344]: \n2000-10-01 23:30:00     9\n2000-10-01 23:47:00    21\n2000-10-02 00:04:00    54\n2000-10-02 00:21:00    24\nFreq: 17min, dtype: int64 \n```", "```py\nIn [345]: ts.resample('17min', origin='end').sum()\nOut[345]: \n2000-10-01 23:35:00     0\n2000-10-01 23:52:00    18\n2000-10-02 00:09:00    27\n2000-10-02 00:26:00    63\nFreq: 17min, dtype: int64 \n```", "```py\nIn [346]: ts.resample('17min', origin='end_day').sum()\nOut[346]: \n2000-10-01 23:38:00     3\n2000-10-01 23:55:00    15\n2000-10-02 00:12:00    45\n2000-10-02 00:29:00    45\nFreq: 17min, dtype: int64 \n```", "```py\nIn [347]: ceil_mid = rng.max().ceil('D')\n\nIn [348]: freq = pd.offsets.Minute(17)\n\nIn [349]: bin_res = ceil_mid - freq * ((ceil_mid - rng.max()) // freq)\n\nIn [350]: bin_res\nOut[350]: Timestamp('2000-10-02 00:29:00') \n```", "```py\nIn [290]: rng = pd.date_range(\"1/1/2012\", periods=100, freq=\"s\")\n\nIn [291]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\n\nIn [292]: ts.resample(\"5Min\").sum()\nOut[292]: \n2012-01-01    25103\nFreq: 5min, dtype: int64 \n```", "```py\nIn [293]: ts.resample(\"5Min\").mean()\nOut[293]: \n2012-01-01    251.03\nFreq: 5min, dtype: float64\n\nIn [294]: ts.resample(\"5Min\").ohlc()\nOut[294]: \n open  high  low  close\n2012-01-01   308   460    9    205\n\nIn [295]: ts.resample(\"5Min\").max()\nOut[295]: \n2012-01-01    460\nFreq: 5min, dtype: int64 \n```", "```py\nIn [296]: ts.resample(\"5Min\", closed=\"right\").mean()\nOut[296]: \n2011-12-31 23:55:00    308.000000\n2012-01-01 00:00:00    250.454545\nFreq: 5min, dtype: float64\n\nIn [297]: ts.resample(\"5Min\", closed=\"left\").mean()\nOut[297]: \n2012-01-01    251.03\nFreq: 5min, dtype: float64 \n```", "```py\nIn [298]: ts.resample(\"5Min\").mean()  # by default label='left'\nOut[298]: \n2012-01-01    251.03\nFreq: 5min, dtype: float64\n\nIn [299]: ts.resample(\"5Min\", label=\"left\").mean()\nOut[299]: \n2012-01-01    251.03\nFreq: 5min, dtype: float64 \n```", "```py\nIn [300]: s = pd.date_range(\"2000-01-01\", \"2000-01-05\").to_series()\n\nIn [301]: s.iloc[2] = pd.NaT\n\nIn [302]: s.dt.day_name()\nOut[302]: \n2000-01-01     Saturday\n2000-01-02       Sunday\n2000-01-03          NaN\n2000-01-04      Tuesday\n2000-01-05    Wednesday\nFreq: D, dtype: object\n\n# default: label='left', closed='left'\nIn [303]: s.resample(\"B\").last().dt.day_name()\nOut[303]: \n1999-12-31       Sunday\n2000-01-03          NaN\n2000-01-04      Tuesday\n2000-01-05    Wednesday\nFreq: B, dtype: object \n```", "```py\nIn [304]: s.resample(\"B\", label=\"right\", closed=\"right\").last().dt.day_name()\nOut[304]: \n2000-01-03       Sunday\n2000-01-04      Tuesday\n2000-01-05    Wednesday\n2000-01-06          NaN\nFreq: B, dtype: object \n```", "```py\n# from secondly to every 250 milliseconds\nIn [305]: ts[:2].resample(\"250ms\").asfreq()\nOut[305]: \n2012-01-01 00:00:00.000    308.0\n2012-01-01 00:00:00.250      NaN\n2012-01-01 00:00:00.500      NaN\n2012-01-01 00:00:00.750      NaN\n2012-01-01 00:00:01.000    204.0\nFreq: 250ms, dtype: float64\n\nIn [306]: ts[:2].resample(\"250ms\").ffill()\nOut[306]: \n2012-01-01 00:00:00.000    308\n2012-01-01 00:00:00.250    308\n2012-01-01 00:00:00.500    308\n2012-01-01 00:00:00.750    308\n2012-01-01 00:00:01.000    204\nFreq: 250ms, dtype: int64\n\nIn [307]: ts[:2].resample(\"250ms\").ffill(limit=2)\nOut[307]: \n2012-01-01 00:00:00.000    308.0\n2012-01-01 00:00:00.250    308.0\n2012-01-01 00:00:00.500    308.0\n2012-01-01 00:00:00.750      NaN\n2012-01-01 00:00:01.000    204.0\nFreq: 250ms, dtype: float64 \n```", "```py\nIn [308]: rng = pd.date_range(\"2014-1-1\", periods=100, freq=\"D\") + pd.Timedelta(\"1s\")\n\nIn [309]: ts = pd.Series(range(100), index=rng) \n```", "```py\nIn [310]: ts.resample(\"3min\").sum()\nOut[310]: \n2014-01-01 00:00:00     0\n2014-01-01 00:03:00     0\n2014-01-01 00:06:00     0\n2014-01-01 00:09:00     0\n2014-01-01 00:12:00     0\n ..\n2014-04-09 23:48:00     0\n2014-04-09 23:51:00     0\n2014-04-09 23:54:00     0\n2014-04-09 23:57:00     0\n2014-04-10 00:00:00    99\nFreq: 3min, Length: 47521, dtype: int64 \n```", "```py\nIn [311]: from functools import partial\n\nIn [312]: from pandas.tseries.frequencies import to_offset\n\nIn [313]: def round(t, freq):\n .....:    freq = to_offset(freq)\n .....:    td = pd.Timedelta(freq)\n .....:    return pd.Timestamp((t.value // td.value) * td.value)\n .....: \n\nIn [314]: ts.groupby(partial(round, freq=\"3min\")).sum()\nOut[314]: \n2014-01-01     0\n2014-01-02     1\n2014-01-03     2\n2014-01-04     3\n2014-01-05     4\n ..\n2014-04-06    95\n2014-04-07    96\n2014-04-08    97\n2014-04-09    98\n2014-04-10    99\nLength: 100, dtype: int64 \n```", "```py\nIn [315]: df = pd.DataFrame(\n .....:    np.random.randn(1000, 3),\n .....:    index=pd.date_range(\"1/1/2012\", freq=\"s\", periods=1000),\n .....:    columns=[\"A\", \"B\", \"C\"],\n .....: )\n .....: \n\nIn [316]: r = df.resample(\"3min\")\n\nIn [317]: r.mean()\nOut[317]: \n A         B         C\n2012-01-01 00:00:00 -0.033823 -0.121514 -0.081447\n2012-01-01 00:03:00  0.056909  0.146731 -0.024320\n2012-01-01 00:06:00 -0.058837  0.047046 -0.052021\n2012-01-01 00:09:00  0.063123 -0.026158 -0.066533\n2012-01-01 00:12:00  0.186340 -0.003144  0.074752\n2012-01-01 00:15:00 -0.085954 -0.016287 -0.050046 \n```", "```py\nIn [318]: r[\"A\"].mean()\nOut[318]: \n2012-01-01 00:00:00   -0.033823\n2012-01-01 00:03:00    0.056909\n2012-01-01 00:06:00   -0.058837\n2012-01-01 00:09:00    0.063123\n2012-01-01 00:12:00    0.186340\n2012-01-01 00:15:00   -0.085954\nFreq: 3min, Name: A, dtype: float64\n\nIn [319]: r[[\"A\", \"B\"]].mean()\nOut[319]: \n A         B\n2012-01-01 00:00:00 -0.033823 -0.121514\n2012-01-01 00:03:00  0.056909  0.146731\n2012-01-01 00:06:00 -0.058837  0.047046\n2012-01-01 00:09:00  0.063123 -0.026158\n2012-01-01 00:12:00  0.186340 -0.003144\n2012-01-01 00:15:00 -0.085954 -0.016287 \n```", "```py\nIn [320]: r[\"A\"].agg([\"sum\", \"mean\", \"std\"])\nOut[320]: \n sum      mean       std\n2012-01-01 00:00:00  -6.088060 -0.033823  1.043263\n2012-01-01 00:03:00  10.243678  0.056909  1.058534\n2012-01-01 00:06:00 -10.590584 -0.058837  0.949264\n2012-01-01 00:09:00  11.362228  0.063123  1.028096\n2012-01-01 00:12:00  33.541257  0.186340  0.884586\n2012-01-01 00:15:00  -8.595393 -0.085954  1.035476 \n```", "```py\nIn [321]: r.agg([\"sum\", \"mean\"])\nOut[321]: \n A            ...          C \n sum      mean  ...        sum      mean\n2012-01-01 00:00:00  -6.088060 -0.033823  ... -14.660515 -0.081447\n2012-01-01 00:03:00  10.243678  0.056909  ...  -4.377642 -0.024320\n2012-01-01 00:06:00 -10.590584 -0.058837  ...  -9.363825 -0.052021\n2012-01-01 00:09:00  11.362228  0.063123  ... -11.975895 -0.066533\n2012-01-01 00:12:00  33.541257  0.186340  ...  13.455299  0.074752\n2012-01-01 00:15:00  -8.595393 -0.085954  ...  -5.004580 -0.050046\n\n[6 rows x 6 columns] \n```", "```py\nIn [322]: r.agg({\"A\": \"sum\", \"B\": lambda x: np.std(x, ddof=1)})\nOut[322]: \n A         B\n2012-01-01 00:00:00  -6.088060  1.001294\n2012-01-01 00:03:00  10.243678  1.074597\n2012-01-01 00:06:00 -10.590584  0.987309\n2012-01-01 00:09:00  11.362228  0.944953\n2012-01-01 00:12:00  33.541257  1.095025\n2012-01-01 00:15:00  -8.595393  1.035312 \n```", "```py\nIn [323]: r.agg({\"A\": \"sum\", \"B\": \"std\"})\nOut[323]: \n A         B\n2012-01-01 00:00:00  -6.088060  1.001294\n2012-01-01 00:03:00  10.243678  1.074597\n2012-01-01 00:06:00 -10.590584  0.987309\n2012-01-01 00:09:00  11.362228  0.944953\n2012-01-01 00:12:00  33.541257  1.095025\n2012-01-01 00:15:00  -8.595393  1.035312 \n```", "```py\nIn [324]: r.agg({\"A\": [\"sum\", \"std\"], \"B\": [\"mean\", \"std\"]})\nOut[324]: \n A                   B \n sum       std      mean       std\n2012-01-01 00:00:00  -6.088060  1.043263 -0.121514  1.001294\n2012-01-01 00:03:00  10.243678  1.058534  0.146731  1.074597\n2012-01-01 00:06:00 -10.590584  0.949264  0.047046  0.987309\n2012-01-01 00:09:00  11.362228  1.028096 -0.026158  0.944953\n2012-01-01 00:12:00  33.541257  0.884586 -0.003144  1.095025\n2012-01-01 00:15:00  -8.595393  1.035476 -0.016287  1.035312 \n```", "```py\nIn [325]: df = pd.DataFrame(\n .....:    {\"date\": pd.date_range(\"2015-01-01\", freq=\"W\", periods=5), \"a\": np.arange(5)},\n .....:    index=pd.MultiIndex.from_arrays(\n .....:        [[1, 2, 3, 4, 5], pd.date_range(\"2015-01-01\", freq=\"W\", periods=5)],\n .....:        names=[\"v\", \"d\"],\n .....:    ),\n .....: )\n .....: \n\nIn [326]: df\nOut[326]: \n date  a\nv d \n1 2015-01-04 2015-01-04  0\n2 2015-01-11 2015-01-11  1\n3 2015-01-18 2015-01-18  2\n4 2015-01-25 2015-01-25  3\n5 2015-02-01 2015-02-01  4\n\nIn [327]: df.resample(\"ME\", on=\"date\")[[\"a\"]].sum()\nOut[327]: \n a\ndate \n2015-01-31  6\n2015-02-28  4 \n```", "```py\nIn [328]: df.resample(\"ME\", level=\"d\")[[\"a\"]].sum()\nOut[328]: \n a\nd \n2015-01-31  6\n2015-02-28  4 \n```", "```py\nIn [329]: small = pd.Series(\n .....:    range(6),\n .....:    index=pd.to_datetime(\n .....:        [\n .....:            \"2017-01-01T00:00:00\",\n .....:            \"2017-01-01T00:30:00\",\n .....:            \"2017-01-01T00:31:00\",\n .....:            \"2017-01-01T01:00:00\",\n .....:            \"2017-01-01T03:00:00\",\n .....:            \"2017-01-01T03:05:00\",\n .....:        ]\n .....:    ),\n .....: )\n .....: \n\nIn [330]: resampled = small.resample(\"h\")\n\nIn [331]: for name, group in resampled:\n .....:    print(\"Group: \", name)\n .....:    print(\"-\" * 27)\n .....:    print(group, end=\"\\n\\n\")\n .....: \nGroup:  2017-01-01 00:00:00\n---------------------------\n2017-01-01 00:00:00    0\n2017-01-01 00:30:00    1\n2017-01-01 00:31:00    2\ndtype: int64\n\nGroup:  2017-01-01 01:00:00\n---------------------------\n2017-01-01 01:00:00    3\ndtype: int64\n\nGroup:  2017-01-01 02:00:00\n---------------------------\nSeries([], dtype: int64)\n\nGroup:  2017-01-01 03:00:00\n---------------------------\n2017-01-01 03:00:00    4\n2017-01-01 03:05:00    5\ndtype: int64 \n```", "```py\nIn [332]: start, end = \"2000-10-01 23:30:00\", \"2000-10-02 00:30:00\"\n\nIn [333]: middle = \"2000-10-02 00:00:00\"\n\nIn [334]: rng = pd.date_range(start, end, freq=\"7min\")\n\nIn [335]: ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n\nIn [336]: ts\nOut[336]: \n2000-10-01 23:30:00     0\n2000-10-01 23:37:00     3\n2000-10-01 23:44:00     6\n2000-10-01 23:51:00     9\n2000-10-01 23:58:00    12\n2000-10-02 00:05:00    15\n2000-10-02 00:12:00    18\n2000-10-02 00:19:00    21\n2000-10-02 00:26:00    24\nFreq: 7min, dtype: int64 \n```", "```py\nIn [337]: ts.resample(\"17min\", origin=\"start_day\").sum()\nOut[337]: \n2000-10-01 23:14:00     0\n2000-10-01 23:31:00     9\n2000-10-01 23:48:00    21\n2000-10-02 00:05:00    54\n2000-10-02 00:22:00    24\nFreq: 17min, dtype: int64\n\nIn [338]: ts[middle:end].resample(\"17min\", origin=\"start_day\").sum()\nOut[338]: \n2000-10-02 00:00:00    33\n2000-10-02 00:17:00    45\nFreq: 17min, dtype: int64 \n```", "```py\nIn [339]: ts.resample(\"17min\", origin=\"epoch\").sum()\nOut[339]: \n2000-10-01 23:18:00     0\n2000-10-01 23:35:00    18\n2000-10-01 23:52:00    27\n2000-10-02 00:09:00    39\n2000-10-02 00:26:00    24\nFreq: 17min, dtype: int64\n\nIn [340]: ts[middle:end].resample(\"17min\", origin=\"epoch\").sum()\nOut[340]: \n2000-10-01 23:52:00    15\n2000-10-02 00:09:00    39\n2000-10-02 00:26:00    24\nFreq: 17min, dtype: int64 \n```", "```py\nIn [341]: ts.resample(\"17min\", origin=\"2001-01-01\").sum()\nOut[341]: \n2000-10-01 23:30:00     9\n2000-10-01 23:47:00    21\n2000-10-02 00:04:00    54\n2000-10-02 00:21:00    24\nFreq: 17min, dtype: int64\n\nIn [342]: ts[middle:end].resample(\"17min\", origin=pd.Timestamp(\"2001-01-01\")).sum()\nOut[342]: \n2000-10-02 00:04:00    54\n2000-10-02 00:21:00    24\nFreq: 17min, dtype: int64 \n```", "```py\nIn [343]: ts.resample(\"17min\", origin=\"start\").sum()\nOut[343]: \n2000-10-01 23:30:00     9\n2000-10-01 23:47:00    21\n2000-10-02 00:04:00    54\n2000-10-02 00:21:00    24\nFreq: 17min, dtype: int64\n\nIn [344]: ts.resample(\"17min\", offset=\"23h30min\").sum()\nOut[344]: \n2000-10-01 23:30:00     9\n2000-10-01 23:47:00    21\n2000-10-02 00:04:00    54\n2000-10-02 00:21:00    24\nFreq: 17min, dtype: int64 \n```", "```py\nIn [345]: ts.resample('17min', origin='end').sum()\nOut[345]: \n2000-10-01 23:35:00     0\n2000-10-01 23:52:00    18\n2000-10-02 00:09:00    27\n2000-10-02 00:26:00    63\nFreq: 17min, dtype: int64 \n```", "```py\nIn [346]: ts.resample('17min', origin='end_day').sum()\nOut[346]: \n2000-10-01 23:38:00     3\n2000-10-01 23:55:00    15\n2000-10-02 00:12:00    45\n2000-10-02 00:29:00    45\nFreq: 17min, dtype: int64 \n```", "```py\nIn [347]: ceil_mid = rng.max().ceil('D')\n\nIn [348]: freq = pd.offsets.Minute(17)\n\nIn [349]: bin_res = ceil_mid - freq * ((ceil_mid - rng.max()) // freq)\n\nIn [350]: bin_res\nOut[350]: Timestamp('2000-10-02 00:29:00') \n```", "```py\nIn [351]: pd.Period(\"2012\", freq=\"Y-DEC\")\nOut[351]: Period('2012', 'Y-DEC')\n\nIn [352]: pd.Period(\"2012-1-1\", freq=\"D\")\nOut[352]: Period('2012-01-01', 'D')\n\nIn [353]: pd.Period(\"2012-1-1 19:00\", freq=\"h\")\nOut[353]: Period('2012-01-01 19:00', 'h')\n\nIn [354]: pd.Period(\"2012-1-1 19:00\", freq=\"5h\")\nOut[354]: Period('2012-01-01 19:00', '5h') \n```", "```py\nIn [355]: p = pd.Period(\"2012\", freq=\"Y-DEC\")\n\nIn [356]: p + 1\nOut[356]: Period('2013', 'Y-DEC')\n\nIn [357]: p - 3\nOut[357]: Period('2009', 'Y-DEC')\n\nIn [358]: p = pd.Period(\"2012-01\", freq=\"2M\")\n\nIn [359]: p + 2\nOut[359]: Period('2012-05', '2M')\n\nIn [360]: p - 1\nOut[360]: Period('2011-11', '2M')\n\nIn [361]: p == pd.Period(\"2012-01\", freq=\"3M\")\nOut[361]: False \n```", "```py\nIn [362]: p = pd.Period(\"2014-07-01 09:00\", freq=\"h\")\n\nIn [363]: p + pd.offsets.Hour(2)\nOut[363]: Period('2014-07-01 11:00', 'h')\n\nIn [364]: p + datetime.timedelta(minutes=120)\nOut[364]: Period('2014-07-01 11:00', 'h')\n\nIn [365]: p + np.timedelta64(7200, \"s\")\nOut[365]: Period('2014-07-01 11:00', 'h') \n```", "```py\nIn [366]: p + pd.offsets.Minute(5)\n---------------------------------------------------------------------------\nValueError  Traceback (most recent call last)\nFile period.pyx:1824, in pandas._libs.tslibs.period._Period._add_timedeltalike_scalar()\n\nFile timedeltas.pyx:278, in pandas._libs.tslibs.timedeltas.delta_to_nanoseconds()\n\nFile np_datetime.pyx:661, in pandas._libs.tslibs.np_datetime.convert_reso()\n\nValueError: Cannot losslessly convert units\n\nThe above exception was the direct cause of the following exception:\n\nIncompatibleFrequency  Traceback (most recent call last)\nCell In[366], line 1\n----> 1 p + pd.offsets.Minute(5)\n\nFile period.pyx:1845, in pandas._libs.tslibs.period._Period.__add__()\n\nFile period.pyx:1826, in pandas._libs.tslibs.period._Period._add_timedeltalike_scalar()\n\nIncompatibleFrequency: Input cannot be converted to Period(freq=h) \n```", "```py\nIn [367]: p = pd.Period(\"2014-07\", freq=\"M\")\n\nIn [368]: p + pd.offsets.MonthEnd(3)\nOut[368]: Period('2014-10', 'M') \n```", "```py\nIn [369]: p + pd.offsets.MonthBegin(3)\n---------------------------------------------------------------------------\nIncompatibleFrequency  Traceback (most recent call last)\nCell In[369], line 1\n----> 1 p + pd.offsets.MonthBegin(3)\n\nFile period.pyx:1847, in pandas._libs.tslibs.period._Period.__add__()\n\nFile period.pyx:1837, in pandas._libs.tslibs.period._Period._add_offset()\n\nFile period.pyx:1732, in pandas._libs.tslibs.period.PeriodMixin._require_matching_freq()\n\nIncompatibleFrequency: Input has different freq=3M from Period(freq=M) \n```", "```py\nIn [370]: pd.Period(\"2012\", freq=\"Y-DEC\") - pd.Period(\"2002\", freq=\"Y-DEC\")\nOut[370]: <10 * YearEnds: month=12> \n```", "```py\nIn [371]: prng = pd.period_range(\"1/1/2011\", \"1/1/2012\", freq=\"M\")\n\nIn [372]: prng\nOut[372]: \nPeriodIndex(['2011-01', '2011-02', '2011-03', '2011-04', '2011-05', '2011-06',\n '2011-07', '2011-08', '2011-09', '2011-10', '2011-11', '2011-12',\n '2012-01'],\n dtype='period[M]') \n```", "```py\nIn [373]: pd.PeriodIndex([\"2011-1\", \"2011-2\", \"2011-3\"], freq=\"M\")\nOut[373]: PeriodIndex(['2011-01', '2011-02', '2011-03'], dtype='period[M]') \n```", "```py\nIn [374]: pd.period_range(start=\"2014-01\", freq=\"3M\", periods=4)\nOut[374]: PeriodIndex(['2014-01', '2014-04', '2014-07', '2014-10'], dtype='period[3M]') \n```", "```py\nIn [375]: pd.period_range(\n .....:    start=pd.Period(\"2017Q1\", freq=\"Q\"), end=pd.Period(\"2017Q2\", freq=\"Q\"), freq=\"M\"\n .....: )\n .....: \nOut[375]: PeriodIndex(['2017-03', '2017-04', '2017-05', '2017-06'], dtype='period[M]') \n```", "```py\nIn [376]: ps = pd.Series(np.random.randn(len(prng)), prng)\n\nIn [377]: ps\nOut[377]: \n2011-01   -2.916901\n2011-02    0.514474\n2011-03    1.346470\n2011-04    0.816397\n2011-05    2.258648\n2011-06    0.494789\n2011-07    0.301239\n2011-08    0.464776\n2011-09   -1.393581\n2011-10    0.056780\n2011-11    0.197035\n2011-12    2.261385\n2012-01   -0.329583\nFreq: M, dtype: float64 \n```", "```py\nIn [378]: idx = pd.period_range(\"2014-07-01 09:00\", periods=5, freq=\"h\")\n\nIn [379]: idx\nOut[379]: \nPeriodIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',\n '2014-07-01 12:00', '2014-07-01 13:00'],\n dtype='period[h]')\n\nIn [380]: idx + pd.offsets.Hour(2)\nOut[380]: \nPeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',\n '2014-07-01 14:00', '2014-07-01 15:00'],\n dtype='period[h]')\n\nIn [381]: idx = pd.period_range(\"2014-07\", periods=5, freq=\"M\")\n\nIn [382]: idx\nOut[382]: PeriodIndex(['2014-07', '2014-08', '2014-09', '2014-10', '2014-11'], dtype='period[M]')\n\nIn [383]: idx + pd.offsets.MonthEnd(3)\nOut[383]: PeriodIndex(['2014-10', '2014-11', '2014-12', '2015-01', '2015-02'], dtype='period[M]') \n```", "```py\nIn [384]: pi = pd.period_range(\"2016-01-01\", periods=3, freq=\"M\")\n\nIn [385]: pi\nOut[385]: PeriodIndex(['2016-01', '2016-02', '2016-03'], dtype='period[M]')\n\nIn [386]: pi.dtype\nOut[386]: period[M] \n```", "```py\n# change monthly freq to daily freq\nIn [387]: pi.astype(\"period[D]\")\nOut[387]: PeriodIndex(['2016-01-31', '2016-02-29', '2016-03-31'], dtype='period[D]')\n\n# convert to DatetimeIndex\nIn [388]: pi.astype(\"datetime64[ns]\")\nOut[388]: DatetimeIndex(['2016-01-01', '2016-02-01', '2016-03-01'], dtype='datetime64[ns]', freq='MS')\n\n# convert to PeriodIndex\nIn [389]: dti = pd.date_range(\"2011-01-01\", freq=\"ME\", periods=3)\n\nIn [390]: dti\nOut[390]: DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31'], dtype='datetime64[ns]', freq='ME')\n\nIn [391]: dti.astype(\"period[M]\")\nOut[391]: PeriodIndex(['2011-01', '2011-02', '2011-03'], dtype='period[M]') \n```", "```py\nIn [392]: ps[\"2011-01\"]\nOut[392]: -2.9169013294054507\n\nIn [393]: ps[datetime.datetime(2011, 12, 25):]\nOut[393]: \n2011-12    2.261385\n2012-01   -0.329583\nFreq: M, dtype: float64\n\nIn [394]: ps[\"10/31/2011\":\"12/31/2011\"]\nOut[394]: \n2011-10    0.056780\n2011-11    0.197035\n2011-12    2.261385\nFreq: M, dtype: float64 \n```", "```py\nIn [395]: ps[\"2011\"]\nOut[395]: \n2011-01   -2.916901\n2011-02    0.514474\n2011-03    1.346470\n2011-04    0.816397\n2011-05    2.258648\n2011-06    0.494789\n2011-07    0.301239\n2011-08    0.464776\n2011-09   -1.393581\n2011-10    0.056780\n2011-11    0.197035\n2011-12    2.261385\nFreq: M, dtype: float64\n\nIn [396]: dfp = pd.DataFrame(\n .....:    np.random.randn(600, 1),\n .....:    columns=[\"A\"],\n .....:    index=pd.period_range(\"2013-01-01 9:00\", periods=600, freq=\"min\"),\n .....: )\n .....: \n\nIn [397]: dfp\nOut[397]: \n A\n2013-01-01 09:00 -0.538468\n2013-01-01 09:01 -1.365819\n2013-01-01 09:02 -0.969051\n2013-01-01 09:03 -0.331152\n2013-01-01 09:04 -0.245334\n...                    ...\n2013-01-01 18:55  0.522460\n2013-01-01 18:56  0.118710\n2013-01-01 18:57  0.167517\n2013-01-01 18:58  0.922883\n2013-01-01 18:59  1.721104\n\n[600 rows x 1 columns]\n\nIn [398]: dfp.loc[\"2013-01-01 10h\"]\nOut[398]: \n A\n2013-01-01 10:00 -0.308975\n2013-01-01 10:01  0.542520\n2013-01-01 10:02  1.061068\n2013-01-01 10:03  0.754005\n2013-01-01 10:04  0.352933\n...                    ...\n2013-01-01 10:55 -0.865621\n2013-01-01 10:56 -1.167818\n2013-01-01 10:57 -2.081748\n2013-01-01 10:58 -0.527146\n2013-01-01 10:59  0.802298\n\n[60 rows x 1 columns] \n```", "```py\nIn [399]: dfp[\"2013-01-01 10h\":\"2013-01-01 11h\"]\nOut[399]: \n A\n2013-01-01 10:00 -0.308975\n2013-01-01 10:01  0.542520\n2013-01-01 10:02  1.061068\n2013-01-01 10:03  0.754005\n2013-01-01 10:04  0.352933\n...                    ...\n2013-01-01 11:55 -0.590204\n2013-01-01 11:56  1.539990\n2013-01-01 11:57 -1.224826\n2013-01-01 11:58  0.578798\n2013-01-01 11:59 -0.685496\n\n[120 rows x 1 columns] \n```", "```py\nIn [400]: p = pd.Period(\"2011\", freq=\"Y-DEC\")\n\nIn [401]: p\nOut[401]: Period('2011', 'Y-DEC') \n```", "```py\nIn [402]: p.asfreq(\"M\", how=\"start\")\nOut[402]: Period('2011-01', 'M')\n\nIn [403]: p.asfreq(\"M\", how=\"end\")\nOut[403]: Period('2011-12', 'M') \n```", "```py\nIn [404]: p.asfreq(\"M\", \"s\")\nOut[404]: Period('2011-01', 'M')\n\nIn [405]: p.asfreq(\"M\", \"e\")\nOut[405]: Period('2011-12', 'M') \n```", "```py\nIn [406]: p = pd.Period(\"2011-12\", freq=\"M\")\n\nIn [407]: p.asfreq(\"Y-NOV\")\nOut[407]: Period('2012', 'Y-NOV') \n```", "```py\nIn [408]: p = pd.Period(\"2012Q1\", freq=\"Q-DEC\")\n\nIn [409]: p.asfreq(\"D\", \"s\")\nOut[409]: Period('2012-01-01', 'D')\n\nIn [410]: p.asfreq(\"D\", \"e\")\nOut[410]: Period('2012-03-31', 'D') \n```", "```py\nIn [411]: p = pd.Period(\"2011Q4\", freq=\"Q-MAR\")\n\nIn [412]: p.asfreq(\"D\", \"s\")\nOut[412]: Period('2011-01-01', 'D')\n\nIn [413]: p.asfreq(\"D\", \"e\")\nOut[413]: Period('2011-03-31', 'D') \n```", "```py\nIn [351]: pd.Period(\"2012\", freq=\"Y-DEC\")\nOut[351]: Period('2012', 'Y-DEC')\n\nIn [352]: pd.Period(\"2012-1-1\", freq=\"D\")\nOut[352]: Period('2012-01-01', 'D')\n\nIn [353]: pd.Period(\"2012-1-1 19:00\", freq=\"h\")\nOut[353]: Period('2012-01-01 19:00', 'h')\n\nIn [354]: pd.Period(\"2012-1-1 19:00\", freq=\"5h\")\nOut[354]: Period('2012-01-01 19:00', '5h') \n```", "```py\nIn [355]: p = pd.Period(\"2012\", freq=\"Y-DEC\")\n\nIn [356]: p + 1\nOut[356]: Period('2013', 'Y-DEC')\n\nIn [357]: p - 3\nOut[357]: Period('2009', 'Y-DEC')\n\nIn [358]: p = pd.Period(\"2012-01\", freq=\"2M\")\n\nIn [359]: p + 2\nOut[359]: Period('2012-05', '2M')\n\nIn [360]: p - 1\nOut[360]: Period('2011-11', '2M')\n\nIn [361]: p == pd.Period(\"2012-01\", freq=\"3M\")\nOut[361]: False \n```", "```py\nIn [362]: p = pd.Period(\"2014-07-01 09:00\", freq=\"h\")\n\nIn [363]: p + pd.offsets.Hour(2)\nOut[363]: Period('2014-07-01 11:00', 'h')\n\nIn [364]: p + datetime.timedelta(minutes=120)\nOut[364]: Period('2014-07-01 11:00', 'h')\n\nIn [365]: p + np.timedelta64(7200, \"s\")\nOut[365]: Period('2014-07-01 11:00', 'h') \n```", "```py\nIn [366]: p + pd.offsets.Minute(5)\n---------------------------------------------------------------------------\nValueError  Traceback (most recent call last)\nFile period.pyx:1824, in pandas._libs.tslibs.period._Period._add_timedeltalike_scalar()\n\nFile timedeltas.pyx:278, in pandas._libs.tslibs.timedeltas.delta_to_nanoseconds()\n\nFile np_datetime.pyx:661, in pandas._libs.tslibs.np_datetime.convert_reso()\n\nValueError: Cannot losslessly convert units\n\nThe above exception was the direct cause of the following exception:\n\nIncompatibleFrequency  Traceback (most recent call last)\nCell In[366], line 1\n----> 1 p + pd.offsets.Minute(5)\n\nFile period.pyx:1845, in pandas._libs.tslibs.period._Period.__add__()\n\nFile period.pyx:1826, in pandas._libs.tslibs.period._Period._add_timedeltalike_scalar()\n\nIncompatibleFrequency: Input cannot be converted to Period(freq=h) \n```", "```py\nIn [367]: p = pd.Period(\"2014-07\", freq=\"M\")\n\nIn [368]: p + pd.offsets.MonthEnd(3)\nOut[368]: Period('2014-10', 'M') \n```", "```py\nIn [369]: p + pd.offsets.MonthBegin(3)\n---------------------------------------------------------------------------\nIncompatibleFrequency  Traceback (most recent call last)\nCell In[369], line 1\n----> 1 p + pd.offsets.MonthBegin(3)\n\nFile period.pyx:1847, in pandas._libs.tslibs.period._Period.__add__()\n\nFile period.pyx:1837, in pandas._libs.tslibs.period._Period._add_offset()\n\nFile period.pyx:1732, in pandas._libs.tslibs.period.PeriodMixin._require_matching_freq()\n\nIncompatibleFrequency: Input has different freq=3M from Period(freq=M) \n```", "```py\nIn [370]: pd.Period(\"2012\", freq=\"Y-DEC\") - pd.Period(\"2002\", freq=\"Y-DEC\")\nOut[370]: <10 * YearEnds: month=12> \n```", "```py\nIn [371]: prng = pd.period_range(\"1/1/2011\", \"1/1/2012\", freq=\"M\")\n\nIn [372]: prng\nOut[372]: \nPeriodIndex(['2011-01', '2011-02', '2011-03', '2011-04', '2011-05', '2011-06',\n '2011-07', '2011-08', '2011-09', '2011-10', '2011-11', '2011-12',\n '2012-01'],\n dtype='period[M]') \n```", "```py\nIn [373]: pd.PeriodIndex([\"2011-1\", \"2011-2\", \"2011-3\"], freq=\"M\")\nOut[373]: PeriodIndex(['2011-01', '2011-02', '2011-03'], dtype='period[M]') \n```", "```py\nIn [374]: pd.period_range(start=\"2014-01\", freq=\"3M\", periods=4)\nOut[374]: PeriodIndex(['2014-01', '2014-04', '2014-07', '2014-10'], dtype='period[3M]') \n```", "```py\nIn [375]: pd.period_range(\n .....:    start=pd.Period(\"2017Q1\", freq=\"Q\"), end=pd.Period(\"2017Q2\", freq=\"Q\"), freq=\"M\"\n .....: )\n .....: \nOut[375]: PeriodIndex(['2017-03', '2017-04', '2017-05', '2017-06'], dtype='period[M]') \n```", "```py\nIn [376]: ps = pd.Series(np.random.randn(len(prng)), prng)\n\nIn [377]: ps\nOut[377]: \n2011-01   -2.916901\n2011-02    0.514474\n2011-03    1.346470\n2011-04    0.816397\n2011-05    2.258648\n2011-06    0.494789\n2011-07    0.301239\n2011-08    0.464776\n2011-09   -1.393581\n2011-10    0.056780\n2011-11    0.197035\n2011-12    2.261385\n2012-01   -0.329583\nFreq: M, dtype: float64 \n```", "```py\nIn [378]: idx = pd.period_range(\"2014-07-01 09:00\", periods=5, freq=\"h\")\n\nIn [379]: idx\nOut[379]: \nPeriodIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',\n '2014-07-01 12:00', '2014-07-01 13:00'],\n dtype='period[h]')\n\nIn [380]: idx + pd.offsets.Hour(2)\nOut[380]: \nPeriodIndex(['2014-07-01 11:00', '2014-07-01 12:00', '2014-07-01 13:00',\n '2014-07-01 14:00', '2014-07-01 15:00'],\n dtype='period[h]')\n\nIn [381]: idx = pd.period_range(\"2014-07\", periods=5, freq=\"M\")\n\nIn [382]: idx\nOut[382]: PeriodIndex(['2014-07', '2014-08', '2014-09', '2014-10', '2014-11'], dtype='period[M]')\n\nIn [383]: idx + pd.offsets.MonthEnd(3)\nOut[383]: PeriodIndex(['2014-10', '2014-11', '2014-12', '2015-01', '2015-02'], dtype='period[M]') \n```", "```py\nIn [384]: pi = pd.period_range(\"2016-01-01\", periods=3, freq=\"M\")\n\nIn [385]: pi\nOut[385]: PeriodIndex(['2016-01', '2016-02', '2016-03'], dtype='period[M]')\n\nIn [386]: pi.dtype\nOut[386]: period[M] \n```", "```py\n# change monthly freq to daily freq\nIn [387]: pi.astype(\"period[D]\")\nOut[387]: PeriodIndex(['2016-01-31', '2016-02-29', '2016-03-31'], dtype='period[D]')\n\n# convert to DatetimeIndex\nIn [388]: pi.astype(\"datetime64[ns]\")\nOut[388]: DatetimeIndex(['2016-01-01', '2016-02-01', '2016-03-01'], dtype='datetime64[ns]', freq='MS')\n\n# convert to PeriodIndex\nIn [389]: dti = pd.date_range(\"2011-01-01\", freq=\"ME\", periods=3)\n\nIn [390]: dti\nOut[390]: DatetimeIndex(['2011-01-31', '2011-02-28', '2011-03-31'], dtype='datetime64[ns]', freq='ME')\n\nIn [391]: dti.astype(\"period[M]\")\nOut[391]: PeriodIndex(['2011-01', '2011-02', '2011-03'], dtype='period[M]') \n```", "```py\nIn [392]: ps[\"2011-01\"]\nOut[392]: -2.9169013294054507\n\nIn [393]: ps[datetime.datetime(2011, 12, 25):]\nOut[393]: \n2011-12    2.261385\n2012-01   -0.329583\nFreq: M, dtype: float64\n\nIn [394]: ps[\"10/31/2011\":\"12/31/2011\"]\nOut[394]: \n2011-10    0.056780\n2011-11    0.197035\n2011-12    2.261385\nFreq: M, dtype: float64 \n```", "```py\nIn [395]: ps[\"2011\"]\nOut[395]: \n2011-01   -2.916901\n2011-02    0.514474\n2011-03    1.346470\n2011-04    0.816397\n2011-05    2.258648\n2011-06    0.494789\n2011-07    0.301239\n2011-08    0.464776\n2011-09   -1.393581\n2011-10    0.056780\n2011-11    0.197035\n2011-12    2.261385\nFreq: M, dtype: float64\n\nIn [396]: dfp = pd.DataFrame(\n .....:    np.random.randn(600, 1),\n .....:    columns=[\"A\"],\n .....:    index=pd.period_range(\"2013-01-01 9:00\", periods=600, freq=\"min\"),\n .....: )\n .....: \n\nIn [397]: dfp\nOut[397]: \n A\n2013-01-01 09:00 -0.538468\n2013-01-01 09:01 -1.365819\n2013-01-01 09:02 -0.969051\n2013-01-01 09:03 -0.331152\n2013-01-01 09:04 -0.245334\n...                    ...\n2013-01-01 18:55  0.522460\n2013-01-01 18:56  0.118710\n2013-01-01 18:57  0.167517\n2013-01-01 18:58  0.922883\n2013-01-01 18:59  1.721104\n\n[600 rows x 1 columns]\n\nIn [398]: dfp.loc[\"2013-01-01 10h\"]\nOut[398]: \n A\n2013-01-01 10:00 -0.308975\n2013-01-01 10:01  0.542520\n2013-01-01 10:02  1.061068\n2013-01-01 10:03  0.754005\n2013-01-01 10:04  0.352933\n...                    ...\n2013-01-01 10:55 -0.865621\n2013-01-01 10:56 -1.167818\n2013-01-01 10:57 -2.081748\n2013-01-01 10:58 -0.527146\n2013-01-01 10:59  0.802298\n\n[60 rows x 1 columns] \n```", "```py\nIn [399]: dfp[\"2013-01-01 10h\":\"2013-01-01 11h\"]\nOut[399]: \n A\n2013-01-01 10:00 -0.308975\n2013-01-01 10:01  0.542520\n2013-01-01 10:02  1.061068\n2013-01-01 10:03  0.754005\n2013-01-01 10:04  0.352933\n...                    ...\n2013-01-01 11:55 -0.590204\n2013-01-01 11:56  1.539990\n2013-01-01 11:57 -1.224826\n2013-01-01 11:58  0.578798\n2013-01-01 11:59 -0.685496\n\n[120 rows x 1 columns] \n```", "```py\nIn [400]: p = pd.Period(\"2011\", freq=\"Y-DEC\")\n\nIn [401]: p\nOut[401]: Period('2011', 'Y-DEC') \n```", "```py\nIn [402]: p.asfreq(\"M\", how=\"start\")\nOut[402]: Period('2011-01', 'M')\n\nIn [403]: p.asfreq(\"M\", how=\"end\")\nOut[403]: Period('2011-12', 'M') \n```", "```py\nIn [404]: p.asfreq(\"M\", \"s\")\nOut[404]: Period('2011-01', 'M')\n\nIn [405]: p.asfreq(\"M\", \"e\")\nOut[405]: Period('2011-12', 'M') \n```", "```py\nIn [406]: p = pd.Period(\"2011-12\", freq=\"M\")\n\nIn [407]: p.asfreq(\"Y-NOV\")\nOut[407]: Period('2012', 'Y-NOV') \n```", "```py\nIn [408]: p = pd.Period(\"2012Q1\", freq=\"Q-DEC\")\n\nIn [409]: p.asfreq(\"D\", \"s\")\nOut[409]: Period('2012-01-01', 'D')\n\nIn [410]: p.asfreq(\"D\", \"e\")\nOut[410]: Period('2012-03-31', 'D') \n```", "```py\nIn [411]: p = pd.Period(\"2011Q4\", freq=\"Q-MAR\")\n\nIn [412]: p.asfreq(\"D\", \"s\")\nOut[412]: Period('2011-01-01', 'D')\n\nIn [413]: p.asfreq(\"D\", \"e\")\nOut[413]: Period('2011-03-31', 'D') \n```", "```py\nIn [414]: rng = pd.date_range(\"1/1/2012\", periods=5, freq=\"ME\")\n\nIn [415]: ts = pd.Series(np.random.randn(len(rng)), index=rng)\n\nIn [416]: ts\nOut[416]: \n2012-01-31    1.931253\n2012-02-29   -0.184594\n2012-03-31    0.249656\n2012-04-30   -0.978151\n2012-05-31   -0.873389\nFreq: ME, dtype: float64\n\nIn [417]: ps = ts.to_period()\n\nIn [418]: ps\nOut[418]: \n2012-01    1.931253\n2012-02   -0.184594\n2012-03    0.249656\n2012-04   -0.978151\n2012-05   -0.873389\nFreq: M, dtype: float64\n\nIn [419]: ps.to_timestamp()\nOut[419]: \n2012-01-01    1.931253\n2012-02-01   -0.184594\n2012-03-01    0.249656\n2012-04-01   -0.978151\n2012-05-01   -0.873389\nFreq: MS, dtype: float64 \n```", "```py\nIn [420]: ps.to_timestamp(\"D\", how=\"s\")\nOut[420]: \n2012-01-01    1.931253\n2012-02-01   -0.184594\n2012-03-01    0.249656\n2012-04-01   -0.978151\n2012-05-01   -0.873389\nFreq: MS, dtype: float64 \n```", "```py\nIn [421]: prng = pd.period_range(\"1990Q1\", \"2000Q4\", freq=\"Q-NOV\")\n\nIn [422]: ts = pd.Series(np.random.randn(len(prng)), prng)\n\nIn [423]: ts.index = (prng.asfreq(\"M\", \"e\") + 1).asfreq(\"h\", \"s\") + 9\n\nIn [424]: ts.head()\nOut[424]: \n1990-03-01 09:00   -0.109291\n1990-06-01 09:00   -0.637235\n1990-09-01 09:00   -1.735925\n1990-12-01 09:00    2.096946\n1991-03-01 09:00   -1.039926\nFreq: h, dtype: float64 \n```", "```py\nIn [425]: span = pd.period_range(\"1215-01-01\", \"1381-01-01\", freq=\"D\")\n\nIn [426]: span\nOut[426]: \nPeriodIndex(['1215-01-01', '1215-01-02', '1215-01-03', '1215-01-04',\n '1215-01-05', '1215-01-06', '1215-01-07', '1215-01-08',\n '1215-01-09', '1215-01-10',\n ...\n '1380-12-23', '1380-12-24', '1380-12-25', '1380-12-26',\n '1380-12-27', '1380-12-28', '1380-12-29', '1380-12-30',\n '1380-12-31', '1381-01-01'],\n dtype='period[D]', length=60632) \n```", "```py\nIn [427]: s = pd.Series([20121231, 20141130, 99991231])\n\nIn [428]: s\nOut[428]: \n0    20121231\n1    20141130\n2    99991231\ndtype: int64\n\nIn [429]: def conv(x):\n .....:    return pd.Period(year=x // 10000, month=x // 100 % 100, day=x % 100, freq=\"D\")\n .....: \n\nIn [430]: s.apply(conv)\nOut[430]: \n0    2012-12-31\n1    2014-11-30\n2    9999-12-31\ndtype: period[D]\n\nIn [431]: s.apply(conv)[2]\nOut[431]: Period('9999-12-31', 'D') \n```", "```py\nIn [432]: span = pd.PeriodIndex(s.apply(conv))\n\nIn [433]: span\nOut[433]: PeriodIndex(['2012-12-31', '2014-11-30', '9999-12-31'], dtype='period[D]') \n```", "```py\nIn [434]: rng = pd.date_range(\"3/6/2012 00:00\", periods=15, freq=\"D\")\n\nIn [435]: rng.tz is None\nOut[435]: True \n```", "```py\nIn [436]: import dateutil\n\n# pytz\nIn [437]: rng_pytz = pd.date_range(\"3/6/2012 00:00\", periods=3, freq=\"D\", tz=\"Europe/London\")\n\nIn [438]: rng_pytz.tz\nOut[438]: <DstTzInfo 'Europe/London' LMT-1 day, 23:59:00 STD>\n\n# dateutil\nIn [439]: rng_dateutil = pd.date_range(\"3/6/2012 00:00\", periods=3, freq=\"D\")\n\nIn [440]: rng_dateutil = rng_dateutil.tz_localize(\"dateutil/Europe/London\")\n\nIn [441]: rng_dateutil.tz\nOut[441]: tzfile('/usr/share/zoneinfo/Europe/London')\n\n# dateutil - utc special case\nIn [442]: rng_utc = pd.date_range(\n .....:    \"3/6/2012 00:00\",\n .....:    periods=3,\n .....:    freq=\"D\",\n .....:    tz=dateutil.tz.tzutc(),\n .....: )\n .....: \n\nIn [443]: rng_utc.tz\nOut[443]: tzutc() \n```", "```py\n# datetime.timezone\nIn [444]: rng_utc = pd.date_range(\n .....:    \"3/6/2012 00:00\",\n .....:    periods=3,\n .....:    freq=\"D\",\n .....:    tz=datetime.timezone.utc,\n .....: )\n .....: \n\nIn [445]: rng_utc.tz\nOut[445]: datetime.timezone.utc \n```", "```py\nIn [446]: import pytz\n\n# pytz\nIn [447]: tz_pytz = pytz.timezone(\"Europe/London\")\n\nIn [448]: rng_pytz = pd.date_range(\"3/6/2012 00:00\", periods=3, freq=\"D\")\n\nIn [449]: rng_pytz = rng_pytz.tz_localize(tz_pytz)\n\nIn [450]: rng_pytz.tz == tz_pytz\nOut[450]: True\n\n# dateutil\nIn [451]: tz_dateutil = dateutil.tz.gettz(\"Europe/London\")\n\nIn [452]: rng_dateutil = pd.date_range(\"3/6/2012 00:00\", periods=3, freq=\"D\", tz=tz_dateutil)\n\nIn [453]: rng_dateutil.tz == tz_dateutil\nOut[453]: True \n```", "```py\nIn [454]: rng_pytz.tz_convert(\"US/Eastern\")\nOut[454]: \nDatetimeIndex(['2012-03-05 19:00:00-05:00', '2012-03-06 19:00:00-05:00',\n '2012-03-07 19:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None) \n```", "```py\nIn [455]: dti = pd.date_range(\"2019-01-01\", periods=3, freq=\"D\", tz=\"US/Pacific\")\n\nIn [456]: dti.tz\nOut[456]: <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>\n\nIn [457]: ts = pd.Timestamp(\"2019-01-01\", tz=\"US/Pacific\")\n\nIn [458]: ts.tz\nOut[458]: <DstTzInfo 'US/Pacific' PST-1 day, 16:00:00 STD> \n```", "```py\nIn [459]: d_2037 = \"2037-03-31T010101\"\n\nIn [460]: d_2038 = \"2038-03-31T010101\"\n\nIn [461]: DST = \"Europe/London\"\n\nIn [462]: assert pd.Timestamp(d_2037, tz=DST) != pd.Timestamp(d_2037, tz=\"GMT\")\n\nIn [463]: assert pd.Timestamp(d_2038, tz=DST) == pd.Timestamp(d_2038, tz=\"GMT\") \n```", "```py\nIn [464]: rng_eastern = rng_utc.tz_convert(\"US/Eastern\")\n\nIn [465]: rng_berlin = rng_utc.tz_convert(\"Europe/Berlin\")\n\nIn [466]: rng_eastern[2]\nOut[466]: Timestamp('2012-03-07 19:00:00-0500', tz='US/Eastern')\n\nIn [467]: rng_berlin[2]\nOut[467]: Timestamp('2012-03-08 01:00:00+0100', tz='Europe/Berlin')\n\nIn [468]: rng_eastern[2] == rng_berlin[2]\nOut[468]: True \n```", "```py\nIn [469]: ts_utc = pd.Series(range(3), pd.date_range(\"20130101\", periods=3, tz=\"UTC\"))\n\nIn [470]: eastern = ts_utc.tz_convert(\"US/Eastern\")\n\nIn [471]: berlin = ts_utc.tz_convert(\"Europe/Berlin\")\n\nIn [472]: result = eastern + berlin\n\nIn [473]: result\nOut[473]: \n2013-01-01 00:00:00+00:00    0\n2013-01-02 00:00:00+00:00    2\n2013-01-03 00:00:00+00:00    4\nFreq: D, dtype: int64\n\nIn [474]: result.index\nOut[474]: \nDatetimeIndex(['2013-01-01 00:00:00+00:00', '2013-01-02 00:00:00+00:00',\n '2013-01-03 00:00:00+00:00'],\n dtype='datetime64[ns, UTC]', freq='D') \n```", "```py\nIn [475]: didx = pd.date_range(start=\"2014-08-01 09:00\", freq=\"h\", periods=3, tz=\"US/Eastern\")\n\nIn [476]: didx\nOut[476]: \nDatetimeIndex(['2014-08-01 09:00:00-04:00', '2014-08-01 10:00:00-04:00',\n '2014-08-01 11:00:00-04:00'],\n dtype='datetime64[ns, US/Eastern]', freq='h')\n\nIn [477]: didx.tz_localize(None)\nOut[477]: \nDatetimeIndex(['2014-08-01 09:00:00', '2014-08-01 10:00:00',\n '2014-08-01 11:00:00'],\n dtype='datetime64[ns]', freq=None)\n\nIn [478]: didx.tz_convert(None)\nOut[478]: \nDatetimeIndex(['2014-08-01 13:00:00', '2014-08-01 14:00:00',\n '2014-08-01 15:00:00'],\n dtype='datetime64[ns]', freq='h')\n\n# tz_convert(None) is identical to tz_convert('UTC').tz_localize(None)\nIn [479]: didx.tz_convert(\"UTC\").tz_localize(None)\nOut[479]: \nDatetimeIndex(['2014-08-01 13:00:00', '2014-08-01 14:00:00',\n '2014-08-01 15:00:00'],\n dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [480]: pd.Timestamp(\n .....:    datetime.datetime(2019, 10, 27, 1, 30, 0, 0),\n .....:    tz=\"dateutil/Europe/London\",\n .....:    fold=0,\n .....: )\n .....: \nOut[480]: Timestamp('2019-10-27 01:30:00+0100', tz='dateutil//usr/share/zoneinfo/Europe/London')\n\nIn [481]: pd.Timestamp(\n .....:    year=2019,\n .....:    month=10,\n .....:    day=27,\n .....:    hour=1,\n .....:    minute=30,\n .....:    tz=\"dateutil/Europe/London\",\n .....:    fold=1,\n .....: )\n .....: \nOut[481]: Timestamp('2019-10-27 01:30:00+0000', tz='dateutil//usr/share/zoneinfo/Europe/London') \n```", "```py\nIn [482]: rng_hourly = pd.DatetimeIndex(\n .....:    [\"11/06/2011 00:00\", \"11/06/2011 01:00\", \"11/06/2011 01:00\", \"11/06/2011 02:00\"]\n .....: )\n .....: \n```", "```py\nIn [483]: rng_hourly.tz_localize('US/Eastern')\n---------------------------------------------------------------------------\nAmbiguousTimeError  Traceback (most recent call last)\nCell In[483], line 1\n----> 1 rng_hourly.tz_localize('US/Eastern')\n\nFile ~/work/pandas/pandas/pandas/core/indexes/datetimes.py:293, in DatetimeIndex.tz_localize(self, tz, ambiguous, nonexistent)\n  286 @doc(DatetimeArray.tz_localize)\n  287 def tz_localize(\n  288     self,\n   (...)\n  291     nonexistent: TimeNonexistent = \"raise\",\n  292 ) -> Self:\n--> 293     arr = self._data.tz_localize(tz, ambiguous, nonexistent)\n  294     return type(self)._simple_new(arr, name=self.name)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/_mixins.py:81, in ravel_compat.<locals>.method(self, *args, **kwargs)\n  78 @wraps(meth)\n  79 def method(self, *args, **kwargs):\n  80     if self.ndim == 1:\n---> 81         return meth(self, *args, **kwargs)\n  83     flags = self._ndarray.flags\n  84     flat = self.ravel(\"K\")\n\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimes.py:1088, in DatetimeArray.tz_localize(self, tz, ambiguous, nonexistent)\n  1085     tz = timezones.maybe_get_tz(tz)\n  1086     # Convert to UTC\n-> 1088     new_dates = tzconversion.tz_localize_to_utc(\n  1089         self.asi8,\n  1090         tz,\n  1091         ambiguous=ambiguous,\n  1092         nonexistent=nonexistent,\n  1093         creso=self._creso,\n  1094     )\n  1095 new_dates_dt64 = new_dates.view(f\"M8[{self.unit}]\")\n  1096 dtype = tz_to_dtype(tz, unit=self.unit)\n\nFile tzconversion.pyx:371, in pandas._libs.tslibs.tzconversion.tz_localize_to_utc()\n\nAmbiguousTimeError: Cannot infer dst time from 2011-11-06 01:00:00, try using the 'ambiguous' argument \n```", "```py\nIn [484]: rng_hourly.tz_localize(\"US/Eastern\", ambiguous=\"infer\")\nOut[484]: \nDatetimeIndex(['2011-11-06 00:00:00-04:00', '2011-11-06 01:00:00-04:00',\n '2011-11-06 01:00:00-05:00', '2011-11-06 02:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None)\n\nIn [485]: rng_hourly.tz_localize(\"US/Eastern\", ambiguous=\"NaT\")\nOut[485]: \nDatetimeIndex(['2011-11-06 00:00:00-04:00', 'NaT', 'NaT',\n '2011-11-06 02:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None)\n\nIn [486]: rng_hourly.tz_localize(\"US/Eastern\", ambiguous=[True, True, False, False])\nOut[486]: \nDatetimeIndex(['2011-11-06 00:00:00-04:00', '2011-11-06 01:00:00-04:00',\n '2011-11-06 01:00:00-05:00', '2011-11-06 02:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None) \n```", "```py\nIn [487]: dti = pd.date_range(start=\"2015-03-29 02:30:00\", periods=3, freq=\"h\")\n\n# 2:30 is a nonexistent time \n```", "```py\nIn [488]: dti.tz_localize('Europe/Warsaw')\n---------------------------------------------------------------------------\nNonExistentTimeError  Traceback (most recent call last)\nCell In[488], line 1\n----> 1 dti.tz_localize('Europe/Warsaw')\n\nFile ~/work/pandas/pandas/pandas/core/indexes/datetimes.py:293, in DatetimeIndex.tz_localize(self, tz, ambiguous, nonexistent)\n  286 @doc(DatetimeArray.tz_localize)\n  287 def tz_localize(\n  288     self,\n   (...)\n  291     nonexistent: TimeNonexistent = \"raise\",\n  292 ) -> Self:\n--> 293     arr = self._data.tz_localize(tz, ambiguous, nonexistent)\n  294     return type(self)._simple_new(arr, name=self.name)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/_mixins.py:81, in ravel_compat.<locals>.method(self, *args, **kwargs)\n  78 @wraps(meth)\n  79 def method(self, *args, **kwargs):\n  80     if self.ndim == 1:\n---> 81         return meth(self, *args, **kwargs)\n  83     flags = self._ndarray.flags\n  84     flat = self.ravel(\"K\")\n\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimes.py:1088, in DatetimeArray.tz_localize(self, tz, ambiguous, nonexistent)\n  1085     tz = timezones.maybe_get_tz(tz)\n  1086     # Convert to UTC\n-> 1088     new_dates = tzconversion.tz_localize_to_utc(\n  1089         self.asi8,\n  1090         tz,\n  1091         ambiguous=ambiguous,\n  1092         nonexistent=nonexistent,\n  1093         creso=self._creso,\n  1094     )\n  1095 new_dates_dt64 = new_dates.view(f\"M8[{self.unit}]\")\n  1096 dtype = tz_to_dtype(tz, unit=self.unit)\n\nFile tzconversion.pyx:431, in pandas._libs.tslibs.tzconversion.tz_localize_to_utc()\n\nNonExistentTimeError: 2015-03-29 02:30:00 \n```", "```py\nIn [489]: dti\nOut[489]: \nDatetimeIndex(['2015-03-29 02:30:00', '2015-03-29 03:30:00',\n '2015-03-29 04:30:00'],\n dtype='datetime64[ns]', freq='h')\n\nIn [490]: dti.tz_localize(\"Europe/Warsaw\", nonexistent=\"shift_forward\")\nOut[490]: \nDatetimeIndex(['2015-03-29 03:00:00+02:00', '2015-03-29 03:30:00+02:00',\n '2015-03-29 04:30:00+02:00'],\n dtype='datetime64[ns, Europe/Warsaw]', freq=None)\n\nIn [491]: dti.tz_localize(\"Europe/Warsaw\", nonexistent=\"shift_backward\")\nOut[491]: \nDatetimeIndex(['2015-03-29 01:59:59.999999999+01:00',\n '2015-03-29 03:30:00+02:00',\n '2015-03-29 04:30:00+02:00'],\n dtype='datetime64[ns, Europe/Warsaw]', freq=None)\n\nIn [492]: dti.tz_localize(\"Europe/Warsaw\", nonexistent=pd.Timedelta(1, unit=\"h\"))\nOut[492]: \nDatetimeIndex(['2015-03-29 03:30:00+02:00', '2015-03-29 03:30:00+02:00',\n '2015-03-29 04:30:00+02:00'],\n dtype='datetime64[ns, Europe/Warsaw]', freq=None)\n\nIn [493]: dti.tz_localize(\"Europe/Warsaw\", nonexistent=\"NaT\")\nOut[493]: \nDatetimeIndex(['NaT', '2015-03-29 03:30:00+02:00',\n '2015-03-29 04:30:00+02:00'],\n dtype='datetime64[ns, Europe/Warsaw]', freq=None) \n```", "```py\nIn [494]: s_naive = pd.Series(pd.date_range(\"20130101\", periods=3))\n\nIn [495]: s_naive\nOut[495]: \n0   2013-01-01\n1   2013-01-02\n2   2013-01-03\ndtype: datetime64[ns] \n```", "```py\nIn [496]: s_aware = pd.Series(pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\"))\n\nIn [497]: s_aware\nOut[497]: \n0   2013-01-01 00:00:00-05:00\n1   2013-01-02 00:00:00-05:00\n2   2013-01-03 00:00:00-05:00\ndtype: datetime64[ns, US/Eastern] \n```", "```py\nIn [498]: s_naive.dt.tz_localize(\"UTC\").dt.tz_convert(\"US/Eastern\")\nOut[498]: \n0   2012-12-31 19:00:00-05:00\n1   2013-01-01 19:00:00-05:00\n2   2013-01-02 19:00:00-05:00\ndtype: datetime64[ns, US/Eastern] \n```", "```py\n# convert to a new time zone\nIn [499]: s_aware.astype(\"datetime64[ns, CET]\")\nOut[499]: \n0   2013-01-01 06:00:00+01:00\n1   2013-01-02 06:00:00+01:00\n2   2013-01-03 06:00:00+01:00\ndtype: datetime64[ns, CET] \n```", "```py\nIn [500]: s_naive.to_numpy()\nOut[500]: \narray(['2013-01-01T00:00:00.000000000', '2013-01-02T00:00:00.000000000',\n '2013-01-03T00:00:00.000000000'], dtype='datetime64[ns]')\n\nIn [501]: s_aware.to_numpy()\nOut[501]: \narray([Timestamp('2013-01-01 00:00:00-0500', tz='US/Eastern'),\n Timestamp('2013-01-02 00:00:00-0500', tz='US/Eastern'),\n Timestamp('2013-01-03 00:00:00-0500', tz='US/Eastern')],\n dtype=object) \n```", "```py\nIn [502]: pd.Series(s_aware.to_numpy())\nOut[502]: \n0   2013-01-01 00:00:00-05:00\n1   2013-01-02 00:00:00-05:00\n2   2013-01-03 00:00:00-05:00\ndtype: datetime64[ns, US/Eastern] \n```", "```py\nIn [503]: s_aware.to_numpy(dtype=\"datetime64[ns]\")\nOut[503]: \narray(['2013-01-01T05:00:00.000000000', '2013-01-02T05:00:00.000000000',\n '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]') \n```", "```py\nIn [434]: rng = pd.date_range(\"3/6/2012 00:00\", periods=15, freq=\"D\")\n\nIn [435]: rng.tz is None\nOut[435]: True \n```", "```py\nIn [436]: import dateutil\n\n# pytz\nIn [437]: rng_pytz = pd.date_range(\"3/6/2012 00:00\", periods=3, freq=\"D\", tz=\"Europe/London\")\n\nIn [438]: rng_pytz.tz\nOut[438]: <DstTzInfo 'Europe/London' LMT-1 day, 23:59:00 STD>\n\n# dateutil\nIn [439]: rng_dateutil = pd.date_range(\"3/6/2012 00:00\", periods=3, freq=\"D\")\n\nIn [440]: rng_dateutil = rng_dateutil.tz_localize(\"dateutil/Europe/London\")\n\nIn [441]: rng_dateutil.tz\nOut[441]: tzfile('/usr/share/zoneinfo/Europe/London')\n\n# dateutil - utc special case\nIn [442]: rng_utc = pd.date_range(\n .....:    \"3/6/2012 00:00\",\n .....:    periods=3,\n .....:    freq=\"D\",\n .....:    tz=dateutil.tz.tzutc(),\n .....: )\n .....: \n\nIn [443]: rng_utc.tz\nOut[443]: tzutc() \n```", "```py\n# datetime.timezone\nIn [444]: rng_utc = pd.date_range(\n .....:    \"3/6/2012 00:00\",\n .....:    periods=3,\n .....:    freq=\"D\",\n .....:    tz=datetime.timezone.utc,\n .....: )\n .....: \n\nIn [445]: rng_utc.tz\nOut[445]: datetime.timezone.utc \n```", "```py\nIn [446]: import pytz\n\n# pytz\nIn [447]: tz_pytz = pytz.timezone(\"Europe/London\")\n\nIn [448]: rng_pytz = pd.date_range(\"3/6/2012 00:00\", periods=3, freq=\"D\")\n\nIn [449]: rng_pytz = rng_pytz.tz_localize(tz_pytz)\n\nIn [450]: rng_pytz.tz == tz_pytz\nOut[450]: True\n\n# dateutil\nIn [451]: tz_dateutil = dateutil.tz.gettz(\"Europe/London\")\n\nIn [452]: rng_dateutil = pd.date_range(\"3/6/2012 00:00\", periods=3, freq=\"D\", tz=tz_dateutil)\n\nIn [453]: rng_dateutil.tz == tz_dateutil\nOut[453]: True \n```", "```py\nIn [454]: rng_pytz.tz_convert(\"US/Eastern\")\nOut[454]: \nDatetimeIndex(['2012-03-05 19:00:00-05:00', '2012-03-06 19:00:00-05:00',\n '2012-03-07 19:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None) \n```", "```py\nIn [455]: dti = pd.date_range(\"2019-01-01\", periods=3, freq=\"D\", tz=\"US/Pacific\")\n\nIn [456]: dti.tz\nOut[456]: <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>\n\nIn [457]: ts = pd.Timestamp(\"2019-01-01\", tz=\"US/Pacific\")\n\nIn [458]: ts.tz\nOut[458]: <DstTzInfo 'US/Pacific' PST-1 day, 16:00:00 STD> \n```", "```py\nIn [459]: d_2037 = \"2037-03-31T010101\"\n\nIn [460]: d_2038 = \"2038-03-31T010101\"\n\nIn [461]: DST = \"Europe/London\"\n\nIn [462]: assert pd.Timestamp(d_2037, tz=DST) != pd.Timestamp(d_2037, tz=\"GMT\")\n\nIn [463]: assert pd.Timestamp(d_2038, tz=DST) == pd.Timestamp(d_2038, tz=\"GMT\") \n```", "```py\nIn [464]: rng_eastern = rng_utc.tz_convert(\"US/Eastern\")\n\nIn [465]: rng_berlin = rng_utc.tz_convert(\"Europe/Berlin\")\n\nIn [466]: rng_eastern[2]\nOut[466]: Timestamp('2012-03-07 19:00:00-0500', tz='US/Eastern')\n\nIn [467]: rng_berlin[2]\nOut[467]: Timestamp('2012-03-08 01:00:00+0100', tz='Europe/Berlin')\n\nIn [468]: rng_eastern[2] == rng_berlin[2]\nOut[468]: True \n```", "```py\nIn [469]: ts_utc = pd.Series(range(3), pd.date_range(\"20130101\", periods=3, tz=\"UTC\"))\n\nIn [470]: eastern = ts_utc.tz_convert(\"US/Eastern\")\n\nIn [471]: berlin = ts_utc.tz_convert(\"Europe/Berlin\")\n\nIn [472]: result = eastern + berlin\n\nIn [473]: result\nOut[473]: \n2013-01-01 00:00:00+00:00    0\n2013-01-02 00:00:00+00:00    2\n2013-01-03 00:00:00+00:00    4\nFreq: D, dtype: int64\n\nIn [474]: result.index\nOut[474]: \nDatetimeIndex(['2013-01-01 00:00:00+00:00', '2013-01-02 00:00:00+00:00',\n '2013-01-03 00:00:00+00:00'],\n dtype='datetime64[ns, UTC]', freq='D') \n```", "```py\nIn [475]: didx = pd.date_range(start=\"2014-08-01 09:00\", freq=\"h\", periods=3, tz=\"US/Eastern\")\n\nIn [476]: didx\nOut[476]: \nDatetimeIndex(['2014-08-01 09:00:00-04:00', '2014-08-01 10:00:00-04:00',\n '2014-08-01 11:00:00-04:00'],\n dtype='datetime64[ns, US/Eastern]', freq='h')\n\nIn [477]: didx.tz_localize(None)\nOut[477]: \nDatetimeIndex(['2014-08-01 09:00:00', '2014-08-01 10:00:00',\n '2014-08-01 11:00:00'],\n dtype='datetime64[ns]', freq=None)\n\nIn [478]: didx.tz_convert(None)\nOut[478]: \nDatetimeIndex(['2014-08-01 13:00:00', '2014-08-01 14:00:00',\n '2014-08-01 15:00:00'],\n dtype='datetime64[ns]', freq='h')\n\n# tz_convert(None) is identical to tz_convert('UTC').tz_localize(None)\nIn [479]: didx.tz_convert(\"UTC\").tz_localize(None)\nOut[479]: \nDatetimeIndex(['2014-08-01 13:00:00', '2014-08-01 14:00:00',\n '2014-08-01 15:00:00'],\n dtype='datetime64[ns]', freq=None) \n```", "```py\nIn [480]: pd.Timestamp(\n .....:    datetime.datetime(2019, 10, 27, 1, 30, 0, 0),\n .....:    tz=\"dateutil/Europe/London\",\n .....:    fold=0,\n .....: )\n .....: \nOut[480]: Timestamp('2019-10-27 01:30:00+0100', tz='dateutil//usr/share/zoneinfo/Europe/London')\n\nIn [481]: pd.Timestamp(\n .....:    year=2019,\n .....:    month=10,\n .....:    day=27,\n .....:    hour=1,\n .....:    minute=30,\n .....:    tz=\"dateutil/Europe/London\",\n .....:    fold=1,\n .....: )\n .....: \nOut[481]: Timestamp('2019-10-27 01:30:00+0000', tz='dateutil//usr/share/zoneinfo/Europe/London') \n```", "```py\nIn [482]: rng_hourly = pd.DatetimeIndex(\n .....:    [\"11/06/2011 00:00\", \"11/06/2011 01:00\", \"11/06/2011 01:00\", \"11/06/2011 02:00\"]\n .....: )\n .....: \n```", "```py\nIn [483]: rng_hourly.tz_localize('US/Eastern')\n---------------------------------------------------------------------------\nAmbiguousTimeError  Traceback (most recent call last)\nCell In[483], line 1\n----> 1 rng_hourly.tz_localize('US/Eastern')\n\nFile ~/work/pandas/pandas/pandas/core/indexes/datetimes.py:293, in DatetimeIndex.tz_localize(self, tz, ambiguous, nonexistent)\n  286 @doc(DatetimeArray.tz_localize)\n  287 def tz_localize(\n  288     self,\n   (...)\n  291     nonexistent: TimeNonexistent = \"raise\",\n  292 ) -> Self:\n--> 293     arr = self._data.tz_localize(tz, ambiguous, nonexistent)\n  294     return type(self)._simple_new(arr, name=self.name)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/_mixins.py:81, in ravel_compat.<locals>.method(self, *args, **kwargs)\n  78 @wraps(meth)\n  79 def method(self, *args, **kwargs):\n  80     if self.ndim == 1:\n---> 81         return meth(self, *args, **kwargs)\n  83     flags = self._ndarray.flags\n  84     flat = self.ravel(\"K\")\n\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimes.py:1088, in DatetimeArray.tz_localize(self, tz, ambiguous, nonexistent)\n  1085     tz = timezones.maybe_get_tz(tz)\n  1086     # Convert to UTC\n-> 1088     new_dates = tzconversion.tz_localize_to_utc(\n  1089         self.asi8,\n  1090         tz,\n  1091         ambiguous=ambiguous,\n  1092         nonexistent=nonexistent,\n  1093         creso=self._creso,\n  1094     )\n  1095 new_dates_dt64 = new_dates.view(f\"M8[{self.unit}]\")\n  1096 dtype = tz_to_dtype(tz, unit=self.unit)\n\nFile tzconversion.pyx:371, in pandas._libs.tslibs.tzconversion.tz_localize_to_utc()\n\nAmbiguousTimeError: Cannot infer dst time from 2011-11-06 01:00:00, try using the 'ambiguous' argument \n```", "```py\nIn [484]: rng_hourly.tz_localize(\"US/Eastern\", ambiguous=\"infer\")\nOut[484]: \nDatetimeIndex(['2011-11-06 00:00:00-04:00', '2011-11-06 01:00:00-04:00',\n '2011-11-06 01:00:00-05:00', '2011-11-06 02:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None)\n\nIn [485]: rng_hourly.tz_localize(\"US/Eastern\", ambiguous=\"NaT\")\nOut[485]: \nDatetimeIndex(['2011-11-06 00:00:00-04:00', 'NaT', 'NaT',\n '2011-11-06 02:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None)\n\nIn [486]: rng_hourly.tz_localize(\"US/Eastern\", ambiguous=[True, True, False, False])\nOut[486]: \nDatetimeIndex(['2011-11-06 00:00:00-04:00', '2011-11-06 01:00:00-04:00',\n '2011-11-06 01:00:00-05:00', '2011-11-06 02:00:00-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None) \n```", "```py\nIn [487]: dti = pd.date_range(start=\"2015-03-29 02:30:00\", periods=3, freq=\"h\")\n\n# 2:30 is a nonexistent time \n```", "```py\nIn [488]: dti.tz_localize('Europe/Warsaw')\n---------------------------------------------------------------------------\nNonExistentTimeError  Traceback (most recent call last)\nCell In[488], line 1\n----> 1 dti.tz_localize('Europe/Warsaw')\n\nFile ~/work/pandas/pandas/pandas/core/indexes/datetimes.py:293, in DatetimeIndex.tz_localize(self, tz, ambiguous, nonexistent)\n  286 @doc(DatetimeArray.tz_localize)\n  287 def tz_localize(\n  288     self,\n   (...)\n  291     nonexistent: TimeNonexistent = \"raise\",\n  292 ) -> Self:\n--> 293     arr = self._data.tz_localize(tz, ambiguous, nonexistent)\n  294     return type(self)._simple_new(arr, name=self.name)\n\nFile ~/work/pandas/pandas/pandas/core/arrays/_mixins.py:81, in ravel_compat.<locals>.method(self, *args, **kwargs)\n  78 @wraps(meth)\n  79 def method(self, *args, **kwargs):\n  80     if self.ndim == 1:\n---> 81         return meth(self, *args, **kwargs)\n  83     flags = self._ndarray.flags\n  84     flat = self.ravel(\"K\")\n\nFile ~/work/pandas/pandas/pandas/core/arrays/datetimes.py:1088, in DatetimeArray.tz_localize(self, tz, ambiguous, nonexistent)\n  1085     tz = timezones.maybe_get_tz(tz)\n  1086     # Convert to UTC\n-> 1088     new_dates = tzconversion.tz_localize_to_utc(\n  1089         self.asi8,\n  1090         tz,\n  1091         ambiguous=ambiguous,\n  1092         nonexistent=nonexistent,\n  1093         creso=self._creso,\n  1094     )\n  1095 new_dates_dt64 = new_dates.view(f\"M8[{self.unit}]\")\n  1096 dtype = tz_to_dtype(tz, unit=self.unit)\n\nFile tzconversion.pyx:431, in pandas._libs.tslibs.tzconversion.tz_localize_to_utc()\n\nNonExistentTimeError: 2015-03-29 02:30:00 \n```", "```py\nIn [489]: dti\nOut[489]: \nDatetimeIndex(['2015-03-29 02:30:00', '2015-03-29 03:30:00',\n '2015-03-29 04:30:00'],\n dtype='datetime64[ns]', freq='h')\n\nIn [490]: dti.tz_localize(\"Europe/Warsaw\", nonexistent=\"shift_forward\")\nOut[490]: \nDatetimeIndex(['2015-03-29 03:00:00+02:00', '2015-03-29 03:30:00+02:00',\n '2015-03-29 04:30:00+02:00'],\n dtype='datetime64[ns, Europe/Warsaw]', freq=None)\n\nIn [491]: dti.tz_localize(\"Europe/Warsaw\", nonexistent=\"shift_backward\")\nOut[491]: \nDatetimeIndex(['2015-03-29 01:59:59.999999999+01:00',\n '2015-03-29 03:30:00+02:00',\n '2015-03-29 04:30:00+02:00'],\n dtype='datetime64[ns, Europe/Warsaw]', freq=None)\n\nIn [492]: dti.tz_localize(\"Europe/Warsaw\", nonexistent=pd.Timedelta(1, unit=\"h\"))\nOut[492]: \nDatetimeIndex(['2015-03-29 03:30:00+02:00', '2015-03-29 03:30:00+02:00',\n '2015-03-29 04:30:00+02:00'],\n dtype='datetime64[ns, Europe/Warsaw]', freq=None)\n\nIn [493]: dti.tz_localize(\"Europe/Warsaw\", nonexistent=\"NaT\")\nOut[493]: \nDatetimeIndex(['NaT', '2015-03-29 03:30:00+02:00',\n '2015-03-29 04:30:00+02:00'],\n dtype='datetime64[ns, Europe/Warsaw]', freq=None) \n```", "```py\nIn [494]: s_naive = pd.Series(pd.date_range(\"20130101\", periods=3))\n\nIn [495]: s_naive\nOut[495]: \n0   2013-01-01\n1   2013-01-02\n2   2013-01-03\ndtype: datetime64[ns] \n```", "```py\nIn [496]: s_aware = pd.Series(pd.date_range(\"20130101\", periods=3, tz=\"US/Eastern\"))\n\nIn [497]: s_aware\nOut[497]: \n0   2013-01-01 00:00:00-05:00\n1   2013-01-02 00:00:00-05:00\n2   2013-01-03 00:00:00-05:00\ndtype: datetime64[ns, US/Eastern] \n```", "```py\nIn [498]: s_naive.dt.tz_localize(\"UTC\").dt.tz_convert(\"US/Eastern\")\nOut[498]: \n0   2012-12-31 19:00:00-05:00\n1   2013-01-01 19:00:00-05:00\n2   2013-01-02 19:00:00-05:00\ndtype: datetime64[ns, US/Eastern] \n```", "```py\n# convert to a new time zone\nIn [499]: s_aware.astype(\"datetime64[ns, CET]\")\nOut[499]: \n0   2013-01-01 06:00:00+01:00\n1   2013-01-02 06:00:00+01:00\n2   2013-01-03 06:00:00+01:00\ndtype: datetime64[ns, CET] \n```", "```py\nIn [500]: s_naive.to_numpy()\nOut[500]: \narray(['2013-01-01T00:00:00.000000000', '2013-01-02T00:00:00.000000000',\n '2013-01-03T00:00:00.000000000'], dtype='datetime64[ns]')\n\nIn [501]: s_aware.to_numpy()\nOut[501]: \narray([Timestamp('2013-01-01 00:00:00-0500', tz='US/Eastern'),\n Timestamp('2013-01-02 00:00:00-0500', tz='US/Eastern'),\n Timestamp('2013-01-03 00:00:00-0500', tz='US/Eastern')],\n dtype=object) \n```", "```py\nIn [502]: pd.Series(s_aware.to_numpy())\nOut[502]: \n0   2013-01-01 00:00:00-05:00\n1   2013-01-02 00:00:00-05:00\n2   2013-01-03 00:00:00-05:00\ndtype: datetime64[ns, US/Eastern] \n```", "```py\nIn [503]: s_aware.to_numpy(dtype=\"datetime64[ns]\")\nOut[503]: \narray(['2013-01-01T05:00:00.000000000', '2013-01-02T05:00:00.000000000',\n '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]') \n```"]