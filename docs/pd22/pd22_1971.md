# 版本 0.12.0（2013 年 7 月 24 日）

> 原文：[`pandas.pydata.org/docs/whatsnew/v0.12.0.html`](https://pandas.pydata.org/docs/whatsnew/v0.12.0.html)

这是从 0.11.0 开始的一个重大发布，包括几个新功能和增强功能，以及大量的错误修复。

重点包括一致的 I/O API 命名方案，用于读取 html、将 MultiIndexes 写入 csv 文件、读取和写入 STATA 数据文件、读取和写入 JSON 格式文件的例程，Python 3 对 `HDFStore` 的支持，通过 `filter` 进行 groupby 表达式的过滤，以及接受正则表达式的经过改进的 `replace` 例程。

## API 变更

> +   现在 I/O API 与一组顶级 `reader` 函数更加一致，可以像 `pd.read_csv()` 一样访问，通常返回一个 `pandas` 对象。
> +   
>     +   `read_csv`
>     +   
>     +   `read_excel`
>     +   
>     +   `read_hdf`
>     +   
>     +   `read_sql`
>     +   
>     +   `read_json`
>     +   
>     +   `read_html`
>     +   
>     +   `read_stata`
>     +   
>     +   `read_clipboard`
>     +   
>     相应的 `writer` 函数是对象方法，可以像 `df.to_csv()` 一样访问。
>     
>     +   `to_csv`
>     +   
>     +   `to_excel`
>     +   
>     +   `to_hdf`
>     +   
>     +   `to_sql`
>     +   
>     +   `to_json`
>     +   
>     +   `to_html`
>     +   
>     +   `to_stata`
>     +   
>     +   `to_clipboard`
>     +   
> +   修复 Series、DataFrame 上的取模和整数除法，使其表现类似于 `float` dtypes，根据需要返回 `np.nan` 或 `np.inf`（[GH 3590](https://github.com/pandas-dev/pandas/issues/3590)）。这修正了一个 numpy 的 bug，即将 `integer` 和 `float` dtypes 视为不同。
> +   
>     ```py
>     In [1]: p = pd.DataFrame({"first": [4, 5, 8], "second": [0, 0, 3]})
>     
>     In [2]: p % 0
>     Out[2]: 
>      first  second
>     0    NaN     NaN
>     1    NaN     NaN
>     2    NaN     NaN
>     
>     In [3]: p % p
>     Out[3]: 
>      first  second
>     0    0.0     NaN
>     1    0.0     NaN
>     2    0.0     0.0
>     
>     In [4]: p / p
>     Out[4]: 
>      first  second
>     0    1.0     NaN
>     1    1.0     NaN
>     2    1.0     1.0
>     
>     In [5]: p / 0
>     Out[5]: 
>      first  second
>     0    inf     NaN
>     1    inf     NaN
>     2    inf     inf 
>     ```
>     
> +   向 `groupby` 添加 `squeeze` 关键字，以允许从 DataFrame -> Series 的缩减，如果组是唯一的话。这是从 0.10.1 开始的一个回归。我们正在恢复到之前的行为。这意味着 groupby 将返回相同形状的对象，无论组是否唯一。回滚此问题（[GH 2893](https://github.com/pandas-dev/pandas/issues/2893)）与（[GH 3596](https://github.com/pandas-dev/pandas/issues/3596)）。
> +   
>     ```py
>     In [2]: df2 = pd.DataFrame([{"val1": 1, "val2": 20},
>      ...:                    {"val1": 1, "val2": 19},
>      ...:                    {"val1": 1, "val2": 27},
>      ...:                    {"val1": 1, "val2": 12}])
>     
>     In [3]: def func(dataf):
>      ...:    return dataf["val2"] - dataf["val2"].mean()
>      ...:
>     
>     In [4]: # squeezing the result frame to a series (because we have unique groups)
>      ...: df2.groupby("val1", squeeze=True).apply(func)
>     Out[4]:
>     0    0.5
>     1   -0.5
>     2    7.5
>     3   -7.5
>     Name: 1, dtype: float64
>     
>     In [5]: # no squeezing (the default, and behavior in 0.10.1)
>      ...: df2.groupby("val1").apply(func)
>     Out[5]:
>     val2    0    1    2    3
>     val1
>     1     0.5 -0.5  7.5 -7.5 
>     ```
>     
> +   使用基于标签的索引器掩码进行布尔索引时引发 `iloc`，例如，布尔 Series，即使具有整数标签，也会引发。由于 `iloc` 是纯粹基于位置的，因此 Series 上的标签是不可对齐的（[GH 3631](https://github.com/pandas-dev/pandas/issues/3631)）
> +   
>     这种情况很少见，有很多替代方案。这保留了 `iloc` API 的*纯*基于位置的特性。
>     
>     ```py
>     In [6]: df = pd.DataFrame(range(5), index=list("ABCDE"), columns=["a"])
>     
>     In [7]: mask = df.a % 2 == 0
>     
>     In [8]: mask
>     Out[8]: 
>     A     True
>     B    False
>     C     True
>     D    False
>     E     True
>     Name: a, dtype: bool
>     
>     # this is what you should use
>     In [9]: df.loc[mask]
>     Out[9]: 
>      a
>     A  0
>     C  2
>     E  4
>     
>     # this will work as well
>     In [10]: df.iloc[mask.values]
>     Out[10]: 
>      a
>     A  0
>     C  2
>     E  4 
>     ```
>     
>     `df.iloc[mask]` 将引发 `ValueError`
>     
> +   绘图函数的 `raise_on_error` 参数已移除。相反，当对象的 `dtype` 是 `object` 时，绘图函数会引发 `TypeError`，以提醒您尽量避免使用 `object` 数组，因此如果需要绘制某些内容，则应将其转换为适当的数值 dtype。
> +   
> +   向 DataFrame 绘图方法添加 `colormap` 关键字。接受 matplotlib colormap 对象（例如，matplotlib.cm.jet）或此类对象的字符串名称（例如，'jet'）。对于每列，将从 colormap 中进行采样以选择颜色。请参阅 Colormaps 以获取更多信息。([GH 3860](https://github.com/pandas-dev/pandas/issues/3860))
> +   
> +   `DataFrame.interpolate()` 现在已被弃用。请改用 `DataFrame.fillna()` 和 `DataFrame.replace()`（[GH 3582](https://github.com/pandas-dev/pandas/issues/3582)，[GH 3675](https://github.com/pandas-dev/pandas/issues/3675)，[GH 3676](https://github.com/pandas-dev/pandas/issues/3676)）
> +   
> +   `DataFrame.replace()` 的 `method` 和 `axis` 参数已弃用
> +   
> +   `DataFrame.replace` 的 `infer_types` 参数已删除，并且现在默认执行转换（[GH 3907](https://github.com/pandas-dev/pandas/issues/3907)）
> +   
> +   在 `DataFrame.insert` 中添加了关键字 `allow_duplicates`，如果为 `True`，则允许插入重复列，默认为 `False`（与 0.12 之前相同）（[GH 3679](https://github.com/pandas-dev/pandas/issues/3679)）
> +   
> +   为 `NDFrame` 对象实现 `__nonzero__`（[GH 3691](https://github.com/pandas-dev/pandas/issues/3691)，[GH 3696](https://github.com/pandas-dev/pandas/issues/3696)）
> +   
> +   IO API
> +   
>     +   添加了顶层函数 `read_excel` 来替代以下内容，原始 API 已被弃用并将在将来的版本中删除
>     +   
>         ```py
>         from pandas.io.parsers import ExcelFile
>         
>         xls = ExcelFile("path_to_file.xls")
>         xls.parse("Sheet1", index_col=None, na_values=["NA"]) 
>         ```
>         
>         通过
>         
>         ```py
>         import pandas as pd
>         
>         pd.read_excel("path_to_file.xls", "Sheet1", index_col=None, na_values=["NA"]) 
>         ```
>         
>     +   添加了顶层函数 `read_sql`，它等效于以下内容
>     +   
>         ```py
>         from pandas.io.sql import read_frame
>         
>         read_frame(...) 
>         ```
>         
> +   `DataFrame.to_html` 和 `DataFrame.to_latex` 现在接受路径作为它们的第一个参数（[GH 3702](https://github.com/pandas-dev/pandas/issues/3702)）
> +   
> +   不允许在 `datetime64[ns]` 上进行 astypes，除了转换为 `object`，以及在 `timedelta64[ns]` 上进行 astypes，转换为 `object/int`（[GH 3425](https://github.com/pandas-dev/pandas/issues/3425)）
> +   
> +   对于某些所谓的缩减操作，`datetime64` 类型的行为发生了变化（[GH 3726](https://github.com/pandas-dev/pandas/issues/3726)）。现在，在 `Series` 上执行以下操作会引发 `TypeError`，在 `DataFrame` 上执行这些操作会返回一个*空* `Series`，类似于在例如 `slice` 对象的 `DataFrame` 上执行这些操作：
> +   
>     +   sum、prod、mean、std、var、skew、kurt、corr 和 cov
>     +   
> +   `read_html` 在读取时现在默认为 `None`，当 lxml 无法解析时，将回退到 `bs4` + `html5lib`。也可以尝试一系列解析器直到成功
> +   
> +   内部 `pandas` 类层次结构已发生变化（轻微）。以前的 `PandasObject` 现在称为 `PandasContainer`，而新的 `PandasObject` 已成为 `PandasContainer` 以及 `Index`、`Categorical`、`GroupBy`、`SparseList` 和 `SparseArray`（及其基类）的基类。目前，`PandasObject` 提供字符串方法（来自 `StringMixin`）（[GH 4090](https://github.com/pandas-dev/pandas/issues/4090)，[GH 4092](https://github.com/pandas-dev/pandas/issues/4092)）
> +   
> +   新的 `StringMixin`，给定一个 `__unicode__` 方法，获得 Python 2 和 Python 3 兼容的字符串方法（`__str__`、`__bytes__` 和 `__repr__`）。加上字符串安全性。现在在 pandas 库的许多地方使用。（[GH 4090](https://github.com/pandas-dev/pandas/issues/4090)，[GH 4092](https://github.com/pandas-dev/pandas/issues/4092)）

## IO 增强

> +   `pd.read_html()` 现在可以解析 HTML 字符串、文件或 URL 并返回 DataFrame，由 @cpcloud 提供。 ([GH 3477](https://github.com/pandas-dev/pandas/issues/3477), [GH 3605](https://github.com/pandas-dev/pandas/issues/3605), [GH 3606](https://github.com/pandas-dev/pandas/issues/3606), [GH 3616](https://github.com/pandas-dev/pandas/issues/3616))。它与一个 *单一* 解析器后端配合使用：BeautifulSoup4 + html5lib 查看文档
> +   
>     您可以使用 `pd.read_html()` 来读取从 `DataFrame.to_html()` 输出的内容，如下所示
>     
>     ```py
>     In [11]: df = pd.DataFrame({"a": range(3), "b": list("abc")})
>     
>     In [12]: print(df)
>      a  b
>     0  0  a
>     1  1  b
>     2  2  c
>     
>     In [13]: html = df.to_html()
>     
>     In [14]: alist = pd.read_html(html, index_col=0)
>     
>     In [15]: print(df == alist[0])
>      a     b
>     0  True  True
>     1  True  True
>     2  True  True 
>     ```
>     
>     请注意，此处的 `alist` 是 Python 的 `list`，因此 `pd.read_html()` 和 `DataFrame.to_html()` 不是逆过程。
>     
>     +   `pd.read_html()` 不再对日期字符串进行强制转换（[GH 3656](https://github.com/pandas-dev/pandas/issues/3656)）。
>     +   
>     警告
>     
>     您可能需要安装旧版本的 BeautifulSoup4，查看安装文档
>     
> +   添加了用于读取和写入 Stata 文件的模块：`pandas.io.stata`（[GH 1512](https://github.com/pandas-dev/pandas/issues/1512)）通过`read_stata`顶级函数进行读取，通过`to_stata`DataFrame 方法进行写入，查看文档
> +   
> +   添加了用于读取和写入 json 格式文件的模块：`pandas.io.json` 通过 `read_json` 顶级函数进行读取，并通过 `to_json` DataFrame 方法进行写入，查看文档 各种问题 ([GH 1226](https://github.com/pandas-dev/pandas/issues/1226), [GH 3804](https://github.com/pandas-dev/pandas/issues/3804), [GH 3876](https://github.com/pandas-dev/pandas/issues/3876), [GH 3867](https://github.com/pandas-dev/pandas/issues/3867), [GH 1305](https://github.com/pandas-dev/pandas/issues/1305))
> +   
> +   读取和写入 csv 格式文件的 `MultiIndex` 列支持
> +   
>     +   `read_csv` 中的 `header` 选项现在接受要从中读取索引的行列表。
>     +   
>     +   现在可以在 `to_csv` 和 `read_csv` 中指定选项 `tupleize_cols`，以提供对通过元组列表写入和读取 `MultIndex` 列的 0.12 版行为的兼容性。在 0.12 中的默认行为是写入元组列表并 *不* 将元组列表解释为 `MultiIndex` 列。
>     +   
>         注意：0.12 版的默认行为与以前的版本保持不变，但从 0.13 开始，默认的 *写入* 和 *读取* `MultiIndex` 列的格式将是新的格式。 ([GH 3571](https://github.com/pandas-dev/pandas/issues/3571), [GH 1651](https://github.com/pandas-dev/pandas/issues/1651), [GH 3141](https://github.com/pandas-dev/pandas/issues/3141))
>         
>     +   如果未指定 `index_col`（例如，您没有索引，或者使用 `df.to_csv(..., index=False` 写入了索引），则列索引上的任何 `names` 将丢失。
>     +   
>         ```py
>         In [16]: mi_idx = pd.MultiIndex.from_arrays([[1, 2, 3, 4], list("abcd")], names=list("ab"))
>         
>         In [17]: mi_col = pd.MultiIndex.from_arrays([[1, 2], list("ab")], names=list("cd"))
>         
>         In [18]: df = pd.DataFrame(np.ones((4, 2)), index=mi_idx, columns=mi_col)
>         
>         In [19]: df.to_csv("mi.csv")
>         
>         In [20]: print(open("mi.csv").read())
>         c,,1,2
>         d,,a,b
>         a,b,,
>         1,a,1.0,1.0
>         2,b,1.0,1.0
>         3,c,1.0,1.0
>         4,d,1.0,1.0
>         
>         
>         In [21]: pd.read_csv("mi.csv", header=[0, 1, 2, 3], index_col=[0, 1])
>         Out[21]: 
>         c                    1                  2
>         d                    a                  b
>         a   Unnamed: 2_level_2 Unnamed: 3_level_2
>         1                  1.0                1.0
>         2 b                1.0                1.0
>         3 c                1.0                1.0
>         4 d                1.0                1.0 
>         ```
>         
> +   对 Python3 的`HDFStore`（通过`PyTables 3.0.0`）的支持
> +   
> +   通过 `read_hdf` 支持迭代器，当迭代完成时自动打开和关闭存储。这仅适用于 *tables*
> +   
>     ```py
>     In [25]: path = 'store_iterator.h5'
>     
>     In [26]: pd.DataFrame(np.random.randn(10, 2)).to_hdf(path, 'df', table=True)
>     
>     In [27]: for df in pd.read_hdf(path, 'df', chunksize=3):
>      ....:    print(df)
>      ....:
>      0         1
>     0  0.713216 -0.778461
>     1 -0.661062  0.862877
>     2  0.344342  0.149565
>      0         1
>     3 -0.626968 -0.875772
>     4 -0.930687 -0.218983
>     5  0.949965 -0.442354
>      0         1
>     6 -0.402985  1.111358
>     7 -0.241527 -0.670477
>     8  0.049355  0.632633
>      0         1
>     9 -1.502767 -1.225492 
>     ```
>     
> +   当文件不包含任何列时，例如，所有换行符时，`read_csv`现在将抛出更具信息性的错误消息

## 其他增强功能

> +   `DataFrame.replace()`现在允许在包含对象 dtype 的`Series`上使用正则表达式。请参阅常规文档中的示例部分通过字符串表达式替换
> +   
>     例如，你可以这样做
>     
>     ```py
>     In [22]: df = pd.DataFrame({"a": list("ab.."), "b": [1, 2, 3, 4]})
>     
>     In [23]: df.replace(regex=r"\s*\.\s*", value=np.nan)
>     Out[23]: 
>      a  b
>     0    a  1
>     1    b  2
>     2  NaN  3
>     3  NaN  4 
>     ```
>     
>     将字符串`'.'`的所有出现替换为零个或多个周围空格的实例为`NaN`。
>     
>     常规字符串替换仍然按预期工作。例如，你可以这样做
>     
>     ```py
>     In [24]: df.replace(".", np.nan)
>     Out[24]: 
>      a  b
>     0    a  1
>     1    b  2
>     2  NaN  3
>     3  NaN  4 
>     ```
>     
>     将字符串`'.'`的所有出现替换为`NaN`。
>     
> +   `pd.melt()`现在接受可选参数`var_name`和`value_name`，以指定返回的 DataFrame 的自定义列名。
> +   
> +   `pd.set_option()`现在允许 N 个选项，值对([GH 3667](https://github.com/pandas-dev/pandas/issues/3667))。
> +   
>     假设我们有一个选项`'a.b'`和另一个选项`'b.c'`。我们可以同时设置它们：
>     
>     ```py
>     In [31]: pd.get_option('a.b')
>     Out[31]: 2
>     
>     In [32]: pd.get_option('b.c')
>     Out[32]: 3
>     
>     In [33]: pd.set_option('a.b', 1, 'b.c', 4)
>     
>     In [34]: pd.get_option('a.b')
>     Out[34]: 1
>     
>     In [35]: pd.get_option('b.c')
>     Out[35]: 4 
>     ```
>     
> +   对于分组对象的`filter`方法返回原始对象的子集。假设我们只想取属于组总和大于 2 的组的元素。
> +   
>     ```py
>     In [25]: sf = pd.Series([1, 1, 2, 3, 3, 3])
>     
>     In [26]: sf.groupby(sf).filter(lambda x: x.sum() > 2)
>     Out[26]: 
>     3    3
>     4    3
>     5    3
>     dtype: int64 
>     ```
>     
>     `filter`的参数必须是一个函数，应用于整个组，返回`True`或`False`。
>     
>     另一个有用的操作是过滤出只属于只有几个成员的组的元素。
>     
>     ```py
>     In [27]: dff = pd.DataFrame({"A": np.arange(8), "B": list("aabbbbcc")})
>     
>     In [28]: dff.groupby("B").filter(lambda x: len(x) > 2)
>     Out[28]: 
>      A  B
>     2  2  b
>     3  3  b
>     4  4  b
>     5  5  b 
>     ```
>     
>     或者，而不是丢弃有问题的组，我们可以返回一个类似索引的对象，其中未通过过滤器的组填充为 NaN。
>     
>     ```py
>     In [29]: dff.groupby("B").filter(lambda x: len(x) > 2, dropna=False)
>     Out[29]: 
>      A    B
>     0  NaN  NaN
>     1  NaN  NaN
>     2  2.0    b
>     3  3.0    b
>     4  4.0    b
>     5  5.0    b
>     6  NaN  NaN
>     7  NaN  NaN 
>     ```
>     
> +   Series 和 DataFrame hist 方法现在接受`figsize`参数([GH 3834](https://github.com/pandas-dev/pandas/issues/3834))
> +   
> +   在连接操作期间，DatetimeIndexes 不再尝试转换混合整数索引([GH 3877](https://github.com/pandas-dev/pandas/issues/3877))
> +   
> +   Timestamp.min 和 Timestamp.max 现在表示有效的 Timestamp 实例，而不是默认的 datetime.min 和 datetime.max（分别），感谢@SleepingPills
> +   
> +   当未找到表格且检测到 BeautifulSoup==4.2.0 时，`read_html`现在会引发异常([GH 4214](https://github.com/pandas-dev/pandas/issues/4214))

## 实验性功能

> +   添加了实验性的`CustomBusinessDay`类，以支持具有自定义假日日历和自定义周掩码的`DateOffsets`。([GH 2301](https://github.com/pandas-dev/pandas/issues/2301))
> +   
>     注意
>     
>     这使用了 Numpy 1.7 中引入的`numpy.busdaycalendar` API，因此需要 Numpy 1.7.0 或更新版本。
>     
>     ```py
>     In [30]: from pandas.tseries.offsets import CustomBusinessDay
>     
>     In [31]: from datetime import datetime
>     
>     # As an interesting example, let's look at Egypt where
>     # a Friday-Saturday weekend is observed.
>     In [32]: weekmask_egypt = "Sun Mon Tue Wed Thu"
>     
>     # They also observe International Workers' Day so let's
>     # add that for a couple of years
>     In [33]: holidays = ["2012-05-01", datetime(2013, 5, 1), np.datetime64("2014-05-01")]
>     
>     In [34]: bday_egypt = CustomBusinessDay(holidays=holidays, weekmask=weekmask_egypt)
>     
>     In [35]: dt = datetime(2013, 4, 30)
>     
>     In [36]: print(dt + 2 * bday_egypt)
>     2013-05-05 00:00:00
>     
>     In [37]: dts = pd.date_range(dt, periods=5, freq=bday_egypt)
>     
>     In [38]: print(pd.Series(dts.weekday, dts).map(pd.Series("Mon Tue Wed Thu Fri Sat Sun".split())))
>     2013-04-30    Tue
>     2013-05-02    Thu
>     2013-05-05    Sun
>     2013-05-06    Mon
>     2013-05-07    Tue
>     Freq: C, dtype: object 
>     ```

## Bug 修复

> +   绘图函数现在在尝试绘制任何内容之前会引发`TypeError`，如果相关对象的`dtype`为`object`（[GH 1818](https://github.com/pandas-dev/pandas/issues/1818)，[GH 3572](https://github.com/pandas-dev/pandas/issues/3572)，[GH 3911](https://github.com/pandas-dev/pandas/issues/3911)，[GH 3912](https://github.com/pandas-dev/pandas/issues/3912)），但如果可能的话，它们将尝试将对象数组转换为数值数组，以便您仍然可以绘制，例如，具有浮点数的对象数组。这发生在任何绘图发生之前，消除了任何不必要的绘图显示。
> +   
> +   如果`value`参数是列表或元组，则`fillna`方法现在��引发`TypeError`。
> +   
> +   `Series.str`现在支持迭代（[GH 3638](https://github.com/pandas-dev/pandas/issues/3638)）。您可以迭代`Series`中每个字符串的各个元素。每次迭代都会产生一个`Series`，原始`Series`的每个索引处要么是单个字符，要么是`NaN`。例如，
> +   
>     ```py
>     In [38]: strs = "go", "bow", "joe", "slow"
>     
>     In [32]: ds = pd.Series(strs)
>     
>     In [33]: for s in ds.str:
>      ...:     print(s)
>     
>     0    g
>     1    b
>     2    j
>     3    s
>     dtype: object
>     0    o
>     1    o
>     2    o
>     3    l
>     dtype: object
>     0    NaN
>     1      w
>     2      e
>     3      o
>     dtype: object
>     0    NaN
>     1    NaN
>     2    NaN
>     3      w
>     dtype: object
>     
>     In [41]: s
>     Out[41]:
>     0    NaN
>     1    NaN
>     2    NaN
>     3      w
>     dtype: object
>     
>     In [42]: s.dropna().values.item() == "w"
>     Out[42]: True 
>     ```
>     
>     迭代器产生的最后一个元素将是包含`Series`的`Series`，其中包含`Series`中最长字符串的最后一个元素，所有其他元素均为`NaN`。在这里，由于`'slow'`是最长的字符串，且没有其他长度相同的字符串，因此在生成的`Series`中，`'w'`是唯一的非空字符串。
>     
> +   `HDFStore`
> +   
>     +   将在重新创建时保留索引属性（freq，tz，name）（[GH 3499](https://github.com/pandas-dev/pandas/issues/3499)）
>     +   
>     +   如果尝试附加具有不同频率或不同名称的索引，则会发出`AttributeConflictWarning`警告
>     +   
>     +   支持具有时区的日期列作为`data_columns`（[GH 2852](https://github.com/pandas-dev/pandas/issues/2852)）
>     +   
> +   非唯一索引支持已澄清（[GH 3468](https://github.com/pandas-dev/pandas/issues/3468)）。
> +   
>     +   修复将新索引分配给 DataFrame 中的重复索引将失败（[GH 3468](https://github.com/pandas-dev/pandas/issues/3468)）
>     +   
>     +   修复具有重复索引的 DataFrame 的构建
>     +   
>     +   `ref_locs`支持允许跨数据类型重复索引，允许`iget`支持始终找到索引（即使跨数据类型）（[GH 2194](https://github.com/pandas-dev/pandas/issues/2194)）
>     +   
>     +   在具有非唯一索引的 DataFrame 上应用`applymap`现在可以正常工作（已删除警告）（[GH 2786](https://github.com/pandas-dev/pandas/issues/2786)），并修复（[GH 3230](https://github.com/pandas-dev/pandas/issues/3230)）
>     +   
>     +   修复`to_csv`以处理非唯一列（[GH 3495](https://github.com/pandas-dev/pandas/issues/3495)）
>     +   
>     +   具有`getitem`的重复索引将按正确顺序返回项目（[GH 3455](https://github.com/pandas-dev/pandas/issues/3455)，[GH 3457](https://github.com/pandas-dev/pandas/issues/3457)），并处理缺失元素，如唯一索引（[GH 3561](https://github.com/pandas-dev/pandas/issues/3561)）
>     +   
>     +   具有重复索引且空 DataFrame.from_records 将返回正确的框架 ([GH 3562](https://github.com/pandas-dev/pandas/issues/3562))
>     +   
>     +   修复了当跨数据类型存在重复时，Concat 产生非唯一列的问题 ([GH 3602](https://github.com/pandas-dev/pandas/issues/3602))
>     +   
>     +   允许对非唯一列进行插入/删除 ([GH 3679](https://github.com/pandas-dev/pandas/issues/3679))
>     +   
>     +   通过 `loc` 和相关方法修复了使用切片的非唯一索引 ([GH 3659](https://github.com/pandas-dev/pandas/issues/3659))
>     +   
>     +   允许对非唯一列进行插入/删除 ([GH 3679](https://github.com/pandas-dev/pandas/issues/3679))
>     +   
>     +   扩展 `reindex` 以正确处理非唯一索引 ([GH 3679](https://github.com/pandas-dev/pandas/issues/3679))
>     +   
>     +   `DataFrame.itertuples()` 现在可以处理具有重复列名的框架 ([GH 3873](https://github.com/pandas-dev/pandas/issues/3873))
>     +   
>     +   通过 `iloc` 进行非唯一索引的错误 ([GH 4017](https://github.com/pandas-dev/pandas/issues/4017)); 为基于位置的获取添加了 `takeable` 参数
>     +   
>     +   通过`.ix/.loc`和`__getitem__`允许在系列中进行非唯一索引 ([GH 4246](https://github.com/pandas-dev/pandas/issues/4246))
>     +   
>     +   通过`.ix/.loc`修复了非唯一索引内存分配问题 ([GH 4280](https://github.com/pandas-dev/pandas/issues/4280))
>     +   
> +   `DataFrame.from_records` 不接受空的记录数组 ([GH 3682](https://github.com/pandas-dev/pandas/issues/3682))
> +   
> +   `read_html` 现在正确跳过测试 ([GH 3741](https://github.com/pandas-dev/pandas/issues/3741))
> +   
> +   修复了在 `DataFrame.replace` 中 `to_replace` 参数中使用编译的正则表达式时无效的 bug ([GH 3907](https://github.com/pandas-dev/pandas/issues/3907))
> +   
> +   改进了 `network` 测试装饰器以捕获 `IOError`（因此也捕获了 `URLError`）。 添加了 `with_connectivity_check` 装饰器，以允许显式检查网站作为查看网络连接性的代理。 另外，为装饰器添加了新的 `optional_args` 工厂。 ([GH 3910](https://github.com/pandas-dev/pandas/issues/3910), [GH 3914](https://github.com/pandas-dev/pandas/issues/3914))
> +   
> +   修复了测试问题，其中打开了太多的套接字，导致连接重置问题 ([GH 3982](https://github.com/pandas-dev/pandas/issues/3982), [GH 3985](https://github.com/pandas-dev/pandas/issues/3985), [GH 4028](https://github.com/pandas-dev/pandas/issues/4028), [GH 4054](https://github.com/pandas-dev/pandas/issues/4054))
> +   
> +   修复了 test_yahoo、test_google 中失败的测试，其中未检索到符号但正在被访问 ([GH 3982](https://github.com/pandas-dev/pandas/issues/3982), [GH 3985](https://github.com/pandas-dev/pandas/issues/3985), [GH 4028](https://github.com/pandas-dev/pandas/issues/4028), [GH 4054](https://github.com/pandas-dev/pandas/issues/4054))
> +   
> +   如果未传递当前环境的图形，则`Series.hist` 现在将获取图形
> +   
> +   修复了 1xN DataFrame 在 1xN 掩码上出错的错误（[GH 4071](https://github.com/pandas-dev/pandas/issues/4071)）
> +   
> +   修复了在 python3 下运行`tox`时 pickle 导入被不兼容地重写的 bug（[GH 4062](https://github.com/pandas-dev/pandas/issues/4062), [GH 4063](https://github.com/pandas-dev/pandas/issues/4063)）
> +   
> +   修复了 sharex 和 sharey 未传递给 grouped_hist 的 bug（[GH 4089](https://github.com/pandas-dev/pandas/issues/4089)）
> +   
> +   修复了`DataFrame.replace`中当 regex=False 时未迭代嵌套字典的 bug（[GH 4115](https://github.com/pandas-dev/pandas/issues/4115)）
> +   
> +   修复了在`to_datetime`中使用`format`参数时微秒解析错误的 bug（[GH 4152](https://github.com/pandas-dev/pandas/issues/4152)）
> +   
> +   修复了`PandasAutoDateLocator`中`invert_xaxis`错误触发`MilliSecondLocator`的 bug（[GH 3990](https://github.com/pandas-dev/pandas/issues/3990)）
> +   
> +   修复了绘图中对于 matplotlib 1.1.1 无效颜色映射未引发异常的 bug（[GH 4215](https://github.com/pandas-dev/pandas/issues/4215)）
> +   
> +   修复了在`DataFrame.plot(kind='kde')`中显示图例的 bug（[GH 4216](https://github.com/pandas-dev/pandas/issues/4216)）
> +   
> +   修复了索引切片未携带名称属性的错误（[GH 4226](https://github.com/pandas-dev/pandas/issues/4226)）
> +   
> +   修复了在特定时区使用字符串数组初始化`DatetimeIndex`时的错误（[GH 4229](https://github.com/pandas-dev/pandas/issues/4229)）
> +   
> +   修复了 html5lib 未正确跳过的 bug（[GH 4265](https://github.com/pandas-dev/pandas/issues/4265)）
> +   
> +   修复了`get_data_famafrench`未使用正确文件边缘的错误（[GH 4281](https://github.com/pandas-dev/pandas/issues/4281)）

查看完整发布说明或 GitHub 上的问题跟踪器获取完整列表。

## 贡献者

总共有 50 人为此版本贡献了补丁。名字后面带有“+”的人第一次贡献了补丁。

+   Andy Hayden

+   Chang She

+   Christopher Whelan

+   Damien Garaud

+   Dan Allan

+   Dan Birken

+   Dieter Vandenbussche

+   Dražen Lučanin

+   Gábor Lipták +

+   Jeff Mellen +

+   Jeff Tratner +

+   Jeffrey Tratner +

+   Jonathan deWerd +

+   Joris Van den Bossche +

+   Juraj Niznan +

+   Karmel Allison

+   Kelsey Jordahl

+   Kevin Stone +

+   Kieran O’Mahony

+   Kyle Meyer +

+   Mike Kelly +

+   PKEuS +

+   Patrick O’Brien +

+   Phillip Cloud

+   Richard Höchenberger +

+   Skipper Seabold

+   SleepingPills +

+   Tobias Brandt

+   Tom Farnbauer +

+   TomAugspurger +

+   Trent Hauck +

+   Wes McKinney

+   Wouter Overmeire

+   Yaroslav Halchenko

+   conmai +

+   danielballan +

+   davidshinn +

+   dieterv77

+   duozhang +

+   ejnens +

+   gliptak +

+   jniznan +

+   jreback

+   lexual

+   nipunreddevil +

+   ogiaquino +

+   stonebig +

+   tim smith +

+   timmie

+   y-p

## API 更改

> +   现在 I/O API 与一组顶级`reader`函数更加一致，可以像`pd.read_csv()`这样访问，通常返回一个`pandas`对象。
> +   
>     +   `read_csv`
>     +   
>     +   `read_excel`
>     +   
>     +   `read_hdf`
>     +   
>     +   `read_sql`
>     +   
>     +   `read_json`
>     +   
>     +   `read_html`
>     +   
>     +   `read_stata`
>     +   
>     +   `read_clipboard`
>     +   
>     相应的`writer`函数是作为对象方法访问的，如`df.to_csv()`
>     
>     +   `to_csv`
>     +   
>     +   `to_excel`
>     +   
>     +   `to_hdf`
>     +   
>     +   `to_sql`
>     +   
>     +   `to_json`
>     +   
>     +   `to_html`
>     +   
>     +   `to_stata`
>     +   
>     +   `to_clipboard`
>     +   
> +   修复 Series，DataFrames 上的模数和整数除法，使其类似于`float` dtypes 以返回适当的`np.nan`或`np.inf`（[GH 3590](https://github.com/pandas-dev/pandas/issues/3590)）。这纠正了一个 numpy 处理`integer`和`float` dtypes 不同的 bug。
> +   
>     ```py
>     In [1]: p = pd.DataFrame({"first": [4, 5, 8], "second": [0, 0, 3]})
>     
>     In [2]: p % 0
>     Out[2]: 
>      first  second
>     0    NaN     NaN
>     1    NaN     NaN
>     2    NaN     NaN
>     
>     In [3]: p % p
>     Out[3]: 
>      first  second
>     0    0.0     NaN
>     1    0.0     NaN
>     2    0.0     0.0
>     
>     In [4]: p / p
>     Out[4]: 
>      first  second
>     0    1.0     NaN
>     1    1.0     NaN
>     2    1.0     1.0
>     
>     In [5]: p / 0
>     Out[5]: 
>      first  second
>     0    inf     NaN
>     1    inf     NaN
>     2    inf     inf 
>     ```
>     
> +   向`groupby`添加`squeeze`关键字，以允许从 DataFrame -> Series 的减少，如果组是唯一的。这是从 0.10.1 开始的一个回归。我们正在恢复到以前的行为。这意味着 groupby 将返回相同形状的对象，无论组是否唯一。通过([GH 3596](https://github.com/pandas-dev/pandas/issues/3596))撤销此问题([GH 2893](https://github.com/pandas-dev/pandas/issues/2893))。
> +   
>     ```py
>     In [2]: df2 = pd.DataFrame([{"val1": 1, "val2": 20},
>      ...:                    {"val1": 1, "val2": 19},
>      ...:                    {"val1": 1, "val2": 27},
>      ...:                    {"val1": 1, "val2": 12}])
>     
>     In [3]: def func(dataf):
>      ...:    return dataf["val2"] - dataf["val2"].mean()
>      ...:
>     
>     In [4]: # squeezing the result frame to a series (because we have unique groups)
>      ...: df2.groupby("val1", squeeze=True).apply(func)
>     Out[4]:
>     0    0.5
>     1   -0.5
>     2    7.5
>     3   -7.5
>     Name: 1, dtype: float64
>     
>     In [5]: # no squeezing (the default, and behavior in 0.10.1)
>      ...: df2.groupby("val1").apply(func)
>     Out[5]:
>     val2    0    1    2    3
>     val1
>     1     0.5 -0.5  7.5 -7.5 
>     ```
>     
> +   当使用基于标签的索引器掩码进行布尔索引时，例如布尔 Series，即使具有整数标签，也会在`iloc`上引发。由于`iloc`是纯粹基于位置的，Series 上的标签是不可对齐的（[GH 3631](https://github.com/pandas-dev/pandas/issues/3631)）
> +   
>     这种情况很少见，而且有很多替代方案。这样做保留了`iloc` API 的*纯粹*基于位置的特性。
>     
>     ```py
>     In [6]: df = pd.DataFrame(range(5), index=list("ABCDE"), columns=["a"])
>     
>     In [7]: mask = df.a % 2 == 0
>     
>     In [8]: mask
>     Out[8]: 
>     A     True
>     B    False
>     C     True
>     D    False
>     E     True
>     Name: a, dtype: bool
>     
>     # this is what you should use
>     In [9]: df.loc[mask]
>     Out[9]: 
>      a
>     A  0
>     C  2
>     E  4
>     
>     # this will work as well
>     In [10]: df.iloc[mask.values]
>     Out[10]: 
>      a
>     A  0
>     C  2
>     E  4 
>     ```
>     
>     `df.iloc[mask]`会引发`ValueError`
>     
> +   绘图函数的`raise_on_error`参数已移除。相反，当对象的`dtype`为`object`时，绘图函数会引发`TypeError`，以提醒您尽量避免`object`数组，如果需要绘制某些内容，则应将其转换为适当的数值 dtype。
> +   
> +   向 DataFrame 绘图方法添加`colormap`关键字。接受 matplotlib colormap 对象（例如，matplotlib.cm.jet）或此类对象的字符串名称（例如，‘jet’）。对 colormap 进行采样以为每列选择颜色。请参阅 Colormaps 了解更多信息。([GH 3860](https://github.com/pandas-dev/pandas/issues/3860))
> +   
> +   `DataFrame.interpolate()`现在已弃用。请改用`DataFrame.fillna()`和`DataFrame.replace()`（[GH 3582](https://github.com/pandas-dev/pandas/issues/3582), [GH 3675](https://github.com/pandas-dev/pandas/issues/3675), [GH 3676](https://github.com/pandas-dev/pandas/issues/3676)）
> +   
> +   `DataFrame.replace()`的`method`和`axis`参数已废弃
> +   
> +   `DataFrame.replace`的`infer_types`参数已移除，默认现在会执行转换（[GH 3907](https://github.com/pandas-dev/pandas/issues/3907)）
> +   
> +   向`DataFrame.insert`添加关键字`allow_duplicates`，如果为`True`，则允许插入重复列，默认为`False`（与 0.12 之前的行为相同）（[GH 3679](https://github.com/pandas-dev/pandas/issues/3679)）
> +   
> +   实现`NDFrame`对象的`__nonzero__`方法（[GH 3691](https://github.com/pandas-dev/pandas/issues/3691), [GH 3696](https://github.com/pandas-dev/pandas/issues/3696)）
> +   
> +   IO api
> +   
>     +   添加了顶层函数 `read_excel` 以替换以下操作，原始 API 已弃用，并将在将来的版本中删除
>     +   
>         ```py
>         from pandas.io.parsers import ExcelFile
>         
>         xls = ExcelFile("path_to_file.xls")
>         xls.parse("Sheet1", index_col=None, na_values=["NA"]) 
>         ```
>         
>         使用
>         
>         ```py
>         import pandas as pd
>         
>         pd.read_excel("path_to_file.xls", "Sheet1", index_col=None, na_values=["NA"]) 
>         ```
>         
>     +   添加了顶层函数 `read_sql`，等同于以下操作
>     +   
>         ```py
>         from pandas.io.sql import read_frame
>         
>         read_frame(...) 
>         ```
>         
> +   `DataFrame.to_html` 和 `DataFrame.to_latex` 现在接受路径作为它们的第一个参数 ([GH 3702](https://github.com/pandas-dev/pandas/issues/3702))
> +   
> +   不允许对 `datetime64[ns]` 执行除了到 `object` 的 astypes 外的操作，也不允许对 `timedelta64[ns]` 执行到 `object/int` 的操作 ([GH 3425](https://github.com/pandas-dev/pandas/issues/3425))
> +   
> +   关于某些所谓的减少操作，`datetime64` dtypes 的行为已更改 ([GH 3726](https://github.com/pandas-dev/pandas/issues/3726)). 当在 `Series` 上执行以下操作时，现在会引发 `TypeError`，并在 `DataFrame` 上执行时返回一个*空* `Series`，类似于在 `slice` 对象的 `DataFrame` 上执行这些操作：
> +   
>     +   sum、prod、mean、std、var、skew、kurt、corr 和 cov
>     +   
> +   `read_html` 现在在读取时默认为 `None`，当 lxml 解析失败时回退到 `bs4` + `html5lib`。也可以尝试一系列解析器直到成功为止
> +   
> +   内部的 `pandas` 类层次结构已经改变（略）。以前的 `PandasObject` 现在被称为 `PandasContainer`，而新的 `PandasObject` 已成为 `PandasContainer` 以及 `Index`、`Categorical`、`GroupBy`、`SparseList` 和 `SparseArray`（+它们的基类）的基类。当前，`PandasObject` 提供了字符串方法（来自 `StringMixin`）。 ([GH 4090](https://github.com/pandas-dev/pandas/issues/4090), [GH 4092](https://github.com/pandas-dev/pandas/issues/4092))
> +   
> +   新的 `StringMixin`，给定一个 `__unicode__` 方法，获取兼容 Python 2 和 Python 3 的字符串方法 (`__str__`, `__bytes__`, 和 `__repr__`)。加上整个 pandas 库中的字符串安全。现在在 pandas 库的许多地方都使用了它。 ([GH 4090](https://github.com/pandas-dev/pandas/issues/4090), [GH 4092](https://github.com/pandas-dev/pandas/issues/4092))

## IO 增强

> +   `pd.read_html()` 现在可以解析 HTML 字符串、文件或网址，并返回 DataFrames，感谢 @cpcloud。 ([GH 3477](https://github.com/pandas-dev/pandas/issues/3477), [GH 3605](https://github.com/pandas-dev/pandas/issues/3605), [GH 3606](https://github.com/pandas-dev/pandas/issues/3606), [GH 3616](https://github.com/pandas-dev/pandas/issues/3616)). 它只与一个*单一*解析器后端兼容：BeautifulSoup4 + html5lib 查看文档
> +   
>     你可以使用 `pd.read_html()` 来读取 `DataFrame.to_html()` 的输出，就像这样
>     
>     ```py
>     In [11]: df = pd.DataFrame({"a": range(3), "b": list("abc")})
>     
>     In [12]: print(df)
>      a  b
>     0  0  a
>     1  1  b
>     2  2  c
>     
>     In [13]: html = df.to_html()
>     
>     In [14]: alist = pd.read_html(html, index_col=0)
>     
>     In [15]: print(df == alist[0])
>      a     b
>     0  True  True
>     1  True  True
>     2  True  True 
>     ```
>     
>     注意这里的 `alist` 是一个 Python `list`，所以 `pd.read_html()` 和 `DataFrame.to_html()` 不是逆操作。
>     
>     +   `pd.read_html()` 不再对日期字符串执行强制转换 ([GH 3656](https://github.com/pandas-dev/pandas/issues/3656)).
>     +   
>     警告
>     
>     你可能需要安装一个较旧版本的 BeautifulSoup4，查看安装文档
>     
> +   添加了用于读写 Stata 文件的模块：`pandas.io.stata`([GH 1512](https://github.com/pandas-dev/pandas/issues/1512))，可通过`read_stata`顶级函数进行读取，通过`to_stata` DataFrame 方法进行写入，查看文档
> +   
> +   添加了用于读写 json 格式文件的模块：`pandas.io.json`，可通过`read_json`顶级函数进行读取，通过`to_json` DataFrame 方法进行写入，查看文档各种问题（[GH 1226](https://github.com/pandas-dev/pandas/issues/1226)，[GH 3804](https://github.com/pandas-dev/pandas/issues/3804)，[GH 3876](https://github.com/pandas-dev/pandas/issues/3876)，[GH 3867](https://github.com/pandas-dev/pandas/issues/3867)，[GH 1305](https://github.com/pandas-dev/pandas/issues/1305))
> +   
> +   支持读写 csv 格式文件的`MultiIndex`列
> +   
>     +   `read_csv`中的`header`选项现在接受要读取索引的行列表
>     +   
>     +   现在可以在`to_csv`和`read_csv`中指定`tupleize_cols`选项，以提供对通过元组列表写入和读取`MultIndex`列的 0.12 之前行为的兼容性。0.12 中的默认行为是写入元组列表，*不*将元组列表解释为`MultiIndex`列。
>     +   
>         注意：0.12 版本中的默认行为与之前的版本保持不变，但从 0.13 开始，默认*写入*和读取`MultiIndex`列的格式将采用新格式。([GH 3571](https://github.com/pandas-dev/pandas/issues/3571)，[GH 1651](https://github.com/pandas-dev/pandas/issues/1651)，[GH 3141](https://github.com/pandas-dev/pandas/issues/3141))
>         
>     +   如果未指定`index_col`（例如，您没有索引，或者使用`df.to_csv(..., index=False`写入），则列索引上的任何`names`将*丢失*
>     +   
>         ```py
>         In [16]: mi_idx = pd.MultiIndex.from_arrays([[1, 2, 3, 4], list("abcd")], names=list("ab"))
>         
>         In [17]: mi_col = pd.MultiIndex.from_arrays([[1, 2], list("ab")], names=list("cd"))
>         
>         In [18]: df = pd.DataFrame(np.ones((4, 2)), index=mi_idx, columns=mi_col)
>         
>         In [19]: df.to_csv("mi.csv")
>         
>         In [20]: print(open("mi.csv").read())
>         c,,1,2
>         d,,a,b
>         a,b,,
>         1,a,1.0,1.0
>         2,b,1.0,1.0
>         3,c,1.0,1.0
>         4,d,1.0,1.0
>         
>         
>         In [21]: pd.read_csv("mi.csv", header=[0, 1, 2, 3], index_col=[0, 1])
>         Out[21]: 
>         c                    1                  2
>         d                    a                  b
>         a   Unnamed: 2_level_2 Unnamed: 3_level_2
>         1                  1.0                1.0
>         2 b                1.0                1.0
>         3 c                1.0                1.0
>         4 d                1.0                1.0 
>         ```
>         
> +   支持在 Python3 上通过`PyTables 3.0.0`实现对`HDFStore`的支持
> +   
> +   通过`read_hdf`实现迭代器支持，当迭代完成时自动打开和关闭存储。这仅适用于*表*
> +   
>     ```py
>     In [25]: path = 'store_iterator.h5'
>     
>     In [26]: pd.DataFrame(np.random.randn(10, 2)).to_hdf(path, 'df', table=True)
>     
>     In [27]: for df in pd.read_hdf(path, 'df', chunksize=3):
>      ....:    print(df)
>      ....:
>      0         1
>     0  0.713216 -0.778461
>     1 -0.661062  0.862877
>     2  0.344342  0.149565
>      0         1
>     3 -0.626968 -0.875772
>     4 -0.930687 -0.218983
>     5  0.949965 -0.442354
>      0         1
>     6 -0.402985  1.111358
>     7 -0.241527 -0.670477
>     8  0.049355  0.632633
>      0         1
>     9 -1.502767 -1.225492 
>     ```
>     
> +   当文件不包含任何列时，例如所有换行符时，`read_csv`现在将抛出更具信息性的错误消息

## 其他增强功能

> +   `DataFrame.replace()`现在允许在包含对象 dtype 的`Series`上使用正则表达式。请参阅常规文档中的示例部分通过字符串表达式替换
> +   
>     例如，您可以执行
>     
>     ```py
>     In [22]: df = pd.DataFrame({"a": list("ab.."), "b": [1, 2, 3, 4]})
>     
>     In [23]: df.replace(regex=r"\s*\.\s*", value=np.nan)
>     Out[23]: 
>      a  b
>     0    a  1
>     1    b  2
>     2  NaN  3
>     3  NaN  4 
>     ```
>     
>     将所有字符串`'.'`替换为零个或多个周围空格的实例为`NaN`
>     
>     常规字符串替换仍然按预期工作。例如，您可以执行
>     
>     ```py
>     In [24]: df.replace(".", np.nan)
>     Out[24]: 
>      a  b
>     0    a  1
>     1    b  2
>     2  NaN  3
>     3  NaN  4 
>     ```
>     
>     将所有字符串`'.'`替换为`NaN`
>     
> +   `pd.melt()`现在接受可选参数`var_name`和`value_name`，以指定返回的 DataFrame 的自定义列名
> +   
> +   `pd.set_option()`现在允许 N 个选项，值对([GH 3667](https://github.com/pandas-dev/pandas/issues/3667))
> +   
>     假设我们有一个选项 `'a.b'` 和另一个选项 `'b.c'`。我们可以同时设置它们：
>     
>     ```py
>     In [31]: pd.get_option('a.b')
>     Out[31]: 2
>     
>     In [32]: pd.get_option('b.c')
>     Out[32]: 3
>     
>     In [33]: pd.set_option('a.b', 1, 'b.c', 4)
>     
>     In [34]: pd.get_option('a.b')
>     Out[34]: 1
>     
>     In [35]: pd.get_option('b.c')
>     Out[35]: 4 
>     ```
>     
> +   组对象的 `filter` 方法返回原始对象的子集。假设我们只想取属于具有总组和大于 2 的组的元素。
> +   
>     ```py
>     In [25]: sf = pd.Series([1, 1, 2, 3, 3, 3])
>     
>     In [26]: sf.groupby(sf).filter(lambda x: x.sum() > 2)
>     Out[26]: 
>     3    3
>     4    3
>     5    3
>     dtype: int64 
>     ```
>     
>     `filter` 的参数必须是一个函数，该函数作用于整个组，返回 `True` 或 `False`。
>     
>     另一个有用的操作是过滤掉属于仅有几个成员的组的元素。
>     
>     ```py
>     In [27]: dff = pd.DataFrame({"A": np.arange(8), "B": list("aabbbbcc")})
>     
>     In [28]: dff.groupby("B").filter(lambda x: len(x) > 2)
>     Out[28]: 
>      A  B
>     2  2  b
>     3  3  b
>     4  4  b
>     5  5  b 
>     ```
>     
>     或者，我们可以返回一个类似索引的对象，其中未通过过滤器的组填充为 NaN。
>     
>     ```py
>     In [29]: dff.groupby("B").filter(lambda x: len(x) > 2, dropna=False)
>     Out[29]: 
>      A    B
>     0  NaN  NaN
>     1  NaN  NaN
>     2  2.0    b
>     3  3.0    b
>     4  4.0    b
>     5  5.0    b
>     6  NaN  NaN
>     7  NaN  NaN 
>     ```
>     
> +   系列和数据框的 `hist` 方法现在接受一个 `figsize` 参数（[GH 3834](https://github.com/pandas-dev/pandas/issues/3834)）
> +   
> +   在连接操作期间，DatetimeIndexes 不再尝试转换混合整数索引（[GH 3877](https://github.com/pandas-dev/pandas/issues/3877)）
> +   
> +   `Timestamp.min` 和 `Timestamp.max` 现在代表有效的 `Timestamp` 实例，而不是默认的 `datetime.min` 和 `datetime.max`（分别），感谢 @SleepingPills
> +   
> +   当未找到任何表格且检测到 BeautifulSoup==4.2.0 时，`read_html` 现在会引发异常（[GH 4214](https://github.com/pandas-dev/pandas/issues/4214)）

## 实验性功能

> +   添加了实验性的 `CustomBusinessDay` 类，支持具有自定义假日日历和自定义周掩码的 `DateOffsets`。（[GH 2301](https://github.com/pandas-dev/pandas/issues/2301)）
> +   
>     注意
>     
>     这使用了在 Numpy 1.7 中引入的 `numpy.busdaycalendar` API，因此需要 Numpy 1.7.0 或更新版本。
>     
>     ```py
>     In [30]: from pandas.tseries.offsets import CustomBusinessDay
>     
>     In [31]: from datetime import datetime
>     
>     # As an interesting example, let's look at Egypt where
>     # a Friday-Saturday weekend is observed.
>     In [32]: weekmask_egypt = "Sun Mon Tue Wed Thu"
>     
>     # They also observe International Workers' Day so let's
>     # add that for a couple of years
>     In [33]: holidays = ["2012-05-01", datetime(2013, 5, 1), np.datetime64("2014-05-01")]
>     
>     In [34]: bday_egypt = CustomBusinessDay(holidays=holidays, weekmask=weekmask_egypt)
>     
>     In [35]: dt = datetime(2013, 4, 30)
>     
>     In [36]: print(dt + 2 * bday_egypt)
>     2013-05-05 00:00:00
>     
>     In [37]: dts = pd.date_range(dt, periods=5, freq=bday_egypt)
>     
>     In [38]: print(pd.Series(dts.weekday, dts).map(pd.Series("Mon Tue Wed Thu Fri Sat Sun".split())))
>     2013-04-30    Tue
>     2013-05-02    Thu
>     2013-05-05    Sun
>     2013-05-06    Mon
>     2013-05-07    Tue
>     Freq: C, dtype: object 
>     ```

## 错误修复

> +   如果关联对象的 dtype 为 `object`，则绘图函数现在会在尝试绘制任何内容之前引发 `TypeError`（[GH 1818](https://github.com/pandas-dev/pandas/issues/1818), [GH 3572](https://github.com/pandas-dev/pandas/issues/3572), [GH 3911](https://github.com/pandas-dev/pandas/issues/3911), [GH 3912](https://github.com/pandas-dev/pandas/issues/3912)），但如果可能的话，它们会尝试将对象数组转换为数字数组，以便您仍然可以绘制，例如，具有浮点数的对象数组。这在任何绘图发生之前发生，从而消除了任何错误绘图的可能性。
> +   
> +   如果 `value` 参数是列表或元组，则 `fillna` 方法现在会引发 `TypeError`。
> +   
> +   `Series.str` 现在支持迭代（[GH 3638](https://github.com/pandas-dev/pandas/issues/3638)）。您可以迭代 `Series` 中每个字符串的各个元素。每次迭代都会产生一个 `Series`，原始 `Series` 中每个索引处要么是单个字符，要么是 `NaN`。例如，
> +   
>     ```py
>     In [38]: strs = "go", "bow", "joe", "slow"
>     
>     In [32]: ds = pd.Series(strs)
>     
>     In [33]: for s in ds.str:
>      ...:     print(s)
>     
>     0    g
>     1    b
>     2    j
>     3    s
>     dtype: object
>     0    o
>     1    o
>     2    o
>     3    l
>     dtype: object
>     0    NaN
>     1      w
>     2      e
>     3      o
>     dtype: object
>     0    NaN
>     1    NaN
>     2    NaN
>     3      w
>     dtype: object
>     
>     In [41]: s
>     Out[41]:
>     0    NaN
>     1    NaN
>     2    NaN
>     3      w
>     dtype: object
>     
>     In [42]: s.dropna().values.item() == "w"
>     Out[42]: True 
>     ```
>     
>     迭代器生成的最后一个元素将是一个 `Series`，其中包含 `Series` 中最长字符串的最后一个元素，所有其他元素都为 `NaN`。在这里，由于 `'slow'` 是最长的字符串，并且没有其他长度相同的字符串，因此 `'w'` 是生成的 `Series` 中唯一的非空字符串。
>     
> +   `HDFStore`
> +   
>     +   重新创建时将保留索引属性（freq，tz，name）（[GH 3499](https://github.com/pandas-dev/pandas/issues/3499)）。
>     +   
>     +   如果您尝试附加具有不同频率的索引，或者尝试附加具有不同名称的索引，将会发出`AttributeConflictWarning`警告。
>     +   
>     +   支持具有时区的日期列作为 data_columns（[GH 2852](https://github.com/pandas-dev/pandas/issues/2852)）。
>     +   
> +   澄清非唯一索引支持（[GH 3468](https://github.com/pandas-dev/pandas/issues/3468)）。
> +   
>     +   修复将新索引分配给 DataFrame 中的重复索引会失败的问题（[GH 3468](https://github.com/pandas-dev/pandas/issues/3468)）。
>     +   
>     +   修复使用重复索引构建 DataFrame 的问题。
>     +   
>     +   ref_locs 支持允许在不同数据类型之间具有重复索引，允许 iget 支持始终找到索引（即使在不同数据类型之间）（[GH 2194](https://github.com/pandas-dev/pandas/issues/2194)）。
>     +   
>     +   在具有非唯一索引的 DataFrame 上应用 applymap 现在可以正常工作（已删除警告）（[GH 2786](https://github.com/pandas-dev/pandas/issues/2786)），并修复（[GH 3230](https://github.com/pandas-dev/pandas/issues/3230)）。
>     +   
>     +   修复 to_csv 处理非唯一列的问题（[GH 3495](https://github.com/pandas-dev/pandas/issues/3495)）。
>     +   
>     +   具有 getitem 的重复索引将按正确顺序返回项目（[GH 3455](https://github.com/pandas-dev/pandas/issues/3455)，[GH 3457](https://github.com/pandas-dev/pandas/issues/3457)），并处理缺失元素，如唯一索引（[GH 3561](https://github.com/pandas-dev/pandas/issues/3561)）。
>     +   
>     +   具有重复索引的空 DataFrame.from_records 将返回一个正确的框架（[GH 3562](https://github.com/pandas-dev/pandas/issues/3562)）。
>     +   
>     +   修复当重复跨数据类型时产生非唯一列的 Concat 问题（[GH 3602](https://github.com/pandas-dev/pandas/issues/3602)）。
>     +   
>     +   允许对非唯一列进行插入/删除操作（[GH 3679](https://github.com/pandas-dev/pandas/issues/3679)）。
>     +   
>     +   通过`loc`和相关方法修复使用切片进行非唯一索引的问题（[GH 3659](https://github.com/pandas-dev/pandas/issues/3659)）。
>     +   
>     +   允许对非唯一列进行插入/删除操作（[GH 3679](https://github.com/pandas-dev/pandas/issues/3679)）。
>     +   
>     +   扩展`reindex`以正确处理非唯一索引（[GH 3679](https://github.com/pandas-dev/pandas/issues/3679)）。
>     +   
>     +   `DataFrame.itertuples()`现在可以处理具有重复列名的框架（[GH 3873](https://github.com/pandas-dev/pandas/issues/3873)）。
>     +   
>     +   通过`iloc`进行非唯一索引的 bug 修复（[GH 4017](https://github.com/pandas-dev/pandas/issues/4017）；为`reindex`添加了`takeable`参数以进行基于位置的取值。
>     +   
>     +   通过`.ix/.loc`和`__getitem__`在系列中允许非唯一索引（[GH 4246](https://github.com/pandas-dev/pandas/issues/4246)）。
>     +   
>     +   修复使用`.ix/.loc`进行非唯一索引的内存分配问题（[GH 4280](https://github.com/pandas-dev/pandas/issues/4280)）。
>     +   
> +   `DataFrame.from_records`不接受空 recarrays（[GH 3682](https://github.com/pandas-dev/pandas/issues/3682)）。
> +   
> +   `read_html` 现在正确跳过测试了 ([GH 3741](https://github.com/pandas-dev/pandas/issues/3741))
> +   
> +   修复了使用 `DataFrame.replace` 中编译的正则表达式在 `to_replace` 参数中不起作用的 bug ([GH 3907](https://github.com/pandas-dev/pandas/issues/3907))
> +   
> +   改进了 `network` 测试修饰符以捕获 `IOError`（因此也是 `URLError`）。添加了 `with_connectivity_check` 修饰符，允许显式检查网站作为检查网络连接性的代理。此外，为修饰符添加了新的 `optional_args` 修饰符工厂 ([GH 3910](https://github.com/pandas-dev/pandas/issues/3910), [GH 3914](https://github.com/pandas-dev/pandas/issues/3914))
> +   
> +   修复了测试问题，其中打开了太多的套接字，导致连接重置问题 ([GH 3982](https://github.com/pandas-dev/pandas/issues/3982), [GH 3985](https://github.com/pandas-dev/pandas/issues/3985), [GH 4028](https://github.com/pandas-dev/pandas/issues/4028), [GH 4054](https://github.com/pandas-dev/pandas/issues/4054))
> +   
> +   修复了 test_yahoo、test_google 中的测试失败问题，其中未检索到符号但正在访问 ([GH 3982](https://github.com/pandas-dev/pandas/issues/3982), [GH 3985](https://github.com/pandas-dev/pandas/issues/3985), [GH 4028](https://github.com/pandas-dev/pandas/issues/4028), [GH 4054](https://github.com/pandas-dev/pandas/issues/4054))
> +   
> +   `Series.hist` 现在会在当前环境中获取图形（如果未传递）
> +   
> +   修复了 1xN DataFrame 在 1xN 掩码上报错的 bug ([GH 4071](https://github.com/pandas-dev/pandas/issues/4071))
> +   
> +   修复了在 python3 下运行 `tox` 时，pickle 导入以不兼容的方式重写的 bug ([GH 4062](https://github.com/pandas-dev/pandas/issues/4062), [GH 4063](https://github.com/pandas-dev/pandas/issues/4063))
> +   
> +   修复了未传递 sharex 和 sharey 到 grouped_hist 中的 bug ([GH 4089](https://github.com/pandas-dev/pandas/issues/4089))
> +   
> +   修复了 `DataFrame.replace` 中的 bug，其中嵌套字典在 regex=False 时未被迭代 ([GH 4115](https://github.com/pandas-dev/pandas/issues/4115))
> +   
> +   修复了在使用 `to_datetime` 中的 `format` 参数时微秒解析的 bug ([GH 4152](https://github.com/pandas-dev/pandas/issues/4152))
> +   
> +   修复了 `PandasAutoDateLocator` 中的 bug，其中 `invert_xaxis` 错误地触发了 `MilliSecondLocator` ([GH 3990](https://github.com/pandas-dev/pandas/issues/3990))
> +   
> +   修复了绘图中无效色图未触发异常的 bug ([GH 4215](https://github.com/pandas-dev/pandas/issues/4215))
> +   
> +   修复了在 `DataFrame.plot(kind='kde')` 中显示图例的问题 ([GH 4216](https://github.com/pandas-dev/pandas/issues/4216))
> +   
> +   修复了索引切片没有携带 name 属性的 bug ([GH 4226](https://github.com/pandas-dev/pandas/issues/4226))
> +   
> +   修复了在特定时区中使用字符串数组初始化 `DatetimeIndex` 中的 bug ([GH 4229](https://github.com/pandas-dev/pandas/issues/4229))
> +   
> +   修复了 html5lib 没有被正确跳过的 bug（[GH 4265](https://github.com/pandas-dev/pandas/issues/4265)）
> +   
> +   修复了 get_data_famafrench 没有使用正确文件边缘的 bug（[GH 4281](https://github.com/pandas-dev/pandas/issues/4281)）

查看完整的发行说明或 GitHub 上的问题跟踪器获取完整列表。

## 贡献者

总共有 50 人为这个版本提供了补丁。名字后面带有“+”的人是第一次贡献补丁的。

+   Andy Hayden

+   Chang She

+   Christopher Whelan

+   Damien Garaud

+   Dan Allan

+   Dan Birken

+   Dieter Vandenbussche

+   Dražen Lučanin

+   Gábor Lipták +

+   Jeff Mellen +

+   Jeff Tratner +

+   Jeffrey Tratner +

+   Jonathan deWerd +

+   Joris Van den Bossche +

+   Juraj Niznan +

+   Karmel Allison

+   Kelsey Jordahl

+   Kevin Stone +

+   Kieran O’Mahony

+   Kyle Meyer +

+   Mike Kelly +

+   PKEuS +

+   Patrick O’Brien +

+   Phillip Cloud

+   Richard Höchenberger +

+   Skipper Seabold

+   SleepingPills +

+   Tobias Brandt

+   Tom Farnbauer +

+   TomAugspurger +

+   Trent Hauck +

+   Wes McKinney

+   Wouter Overmeire

+   Yaroslav Halchenko

+   conmai +

+   danielballan +

+   davidshinn +

+   dieterv77

+   duozhang +

+   ejnens +

+   gliptak +

+   jniznan +

+   jreback

+   lexual

+   nipunreddevil +

+   ogiaquino +

+   stonebig +

+   tim smith +

+   timmie

+   y-p
