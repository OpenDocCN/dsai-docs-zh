- en: scipy.special.xlogy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.special.xlogy.html#scipy.special.xlogy](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.special.xlogy.html#scipy.special.xlogy)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Compute `x*log(y)` so that the result is 0 if `x = 0`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**x**array_like'
  prefs: []
  type: TYPE_NORMAL
- en: Multiplier
  prefs: []
  type: TYPE_NORMAL
- en: '**y**array_like'
  prefs: []
  type: TYPE_NORMAL
- en: Argument
  prefs: []
  type: TYPE_NORMAL
- en: '**out**ndarray, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Optional output array for the function results
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: '**z**scalar or ndarray'
  prefs: []
  type: TYPE_NORMAL
- en: Computed x*log(y)
  prefs: []
  type: TYPE_NORMAL
- en: Notes
  prefs: []
  type: TYPE_NORMAL
- en: The log function used in the computation is the natural log.
  prefs: []
  type: TYPE_NORMAL
- en: New in version 0.13.0.
  prefs: []
  type: TYPE_NORMAL
- en: Examples
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use this function to calculate the binary logistic loss also known as
    the binary cross entropy. This loss function is used for binary classification
    problems and is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: \[L = 1/n * \sum_{i=0}^n -(y_i*log(y\_pred_i) + (1-y_i)*log(1-y\_pred_i))\]
  prefs: []
  type: TYPE_NORMAL
- en: We can define the parameters *x* and *y* as y and y_pred respectively. y is
    the array of the actual labels which over here can be either 0 or 1. y_pred is
    the array of the predicted probabilities with respect to the positive class (1).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: A lower loss is usually better as it indicates that the predictions are similar
    to the actual labels. In this example since our predicted probabilities are close
    to the actual labels, we get an overall loss that is reasonably low and appropriate.
  prefs: []
  type: TYPE_NORMAL
