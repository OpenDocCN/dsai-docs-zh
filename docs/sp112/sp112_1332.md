# scipy.stats.ks_2samp

> 原文：[https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.stats.ks_2samp.html#scipy.stats.ks_2samp](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.stats.ks_2samp.html#scipy.stats.ks_2samp)

```py
scipy.stats.ks_2samp(data1, data2, alternative='two-sided', method='auto', *, axis=0, nan_policy='propagate', keepdims=False)
```

执行两样本 Kolmogorov-Smirnov 拟合优度检验。

此检验比较两个独立样本的底层连续分布 F(x) 和 G(x)。请参阅注释以了解可用的零假设和备择假设描述。

参数：

**data1, data2**array_like，1维

假设两个样本观察结果数组来自连续分布，样本大小可能不同。

**alternative**{‘two-sided’, ‘less’, ‘greater’}，可选

定义零假设和备择假设。默认为 ‘two-sided’。请参阅下方注释中的解释。

**method**{‘auto’, ‘exact’, ‘asymp’}，可选

定义了计算 p 值所用的方法。以下选项可供选择（默认为 ‘auto’）：

> +   ‘auto’：对于小数组大小使用 ‘exact’，对于大数组使用 ‘asymp’
> +   
> +   ‘exact’：使用检验统计量的确切分布
> +   
> +   ‘asymp’：使用检验统计量的渐近分布

**axis**int 或 None，默认为 0

如果是整数，则是沿着其计算统计量的输入轴。输入的每个轴切片（例如行）的统计量将出现在输出的相应元素中。如果为 `None`，则在计算统计量之前会被展平。

**nan_policy**{‘propagate’, ‘omit’, ‘raise’}

定义如何处理输入的 NaN 值。

+   `propagate`：如果沿着计算统计量的轴切片（例如行）存在 NaN，则输出的相应条目将为 NaN。

+   `omit`：在执行计算时将省略 NaN。如果沿着计算统计量的轴切片中剩余的数据不足，则输出的相应条目将为 NaN。

+   `raise`：如果存在 NaN，则会引发 `ValueError`。

**keepdims**bool，默认为 False

如果设置为 True，则会将被减少的轴保留在结果中作为尺寸为一的维度。使用此选项，结果将正确传播至输入数组。

返回：

res：KstestResult

一个包含属性的对象：

statisticfloat

KS 检验统计量。

pvaluefloat

单尾或双尾 p 值。

statistic_locationfloat

来自 *data1* 或 *data2* 与 KS 统计量对应的值；即，在此观察值处度量经验分布函数之间的距离。

statistic_signint

如果 *data1* 的经验分布函数在 *statistic_location* 处超过 *data2* 的经验分布函数，则为 +1，否则为 -1。

另请参见

[`kstest`](scipy.stats.kstest.html#scipy.stats.kstest "scipy.stats.kstest"), [`ks_1samp`](scipy.stats.ks_1samp.html#scipy.stats.ks_1samp "scipy.stats.ks_1samp"), [`epps_singleton_2samp`](scipy.stats.epps_singleton_2samp.html#scipy.stats.epps_singleton_2samp "scipy.stats.epps_singleton_2samp"), [`anderson_ksamp`](scipy.stats.anderson_ksamp.html#scipy.stats.anderson_ksamp "scipy.stats.anderson_ksamp")

注意

可以使用*alternative*参数选择三种零假设及其对应的备择假设。

+   *less*: 零假设是对于所有的x，F(x) >= G(x)；备择假设是至少有一个x使得F(x) < G(x)。统计量是样本的经验分布函数之间最小（最负）差异的大小。

+   *greater*: 零假设是对于所有的x，F(x) <= G(x)；备择假设是至少有一个x使得F(x) > G(x)。统计量是样本的经验分布函数之间的最大（最正）差异。

+   *two-sided*: 零假设是两个分布是相同的，即对于所有的x，F(x)=G(x)；备择假设是它们不相同。统计量是样本的经验分布函数之间的最大绝对差异。

注意备择假设描述了基础分布的*CDFs*，而不是数据的观察值。例如，假设x1 ~ F和x2 ~ G。如果对于所有的x，F(x) > G(x)，则x1中的值倾向于小于x2中的值。

如果KS统计量很大，则p值很小，这可能表明零假设被否定，支持备择假设。

如果`method='exact'`，[`ks_2samp`](#scipy.stats.ks_2samp "scipy.stats.ks_2samp") 试图计算一个精确的p值，即在零假设下获得与从数据计算出的测试统计值一样极端的概率。如果`method='asymp'`，则使用渐近的Kolmogorov-Smirnov分布来计算近似p值。如果`method='auto'`，则如果两个样本量均小于10000，则尝试精确p值计算；否则，使用渐近方法。无论如何，如果尝试并失败了精确p值计算，将发出警告，并返回渐近p值。

‘two-sided’ ‘exact’ 计算计算补充概率，然后从1中减去。因此，它能返回的最小概率约为1e-16。虽然算法本身是精确的，但对于大样本量，数值误差可能会累积。它最适用于其中一个样本量仅为几千的情况。

我们通常遵循Hodges对Drion/Gnedenko/Korolyuk的处理[[1]](#r2a7d47e1a68b-1)。

从 SciPy 1.9 开始，`np.matrix` 输入（不建议在新代码中使用）在执行计算之前会转换为 `np.ndarray`。在这种情况下，输出将是适当形状的标量或`np.ndarray`，而不是 2D 的`np.matrix`。同样地，虽然忽略掩码数组的掩码元素，但输出将是标量或`np.ndarray`，而不是具有`mask=False`的掩码数组。

参考文献

[[1](#id1)]

Hodges, J.L. Jr., “斯米尔诺夫双样本检验的显著性概率”，《数学档案》，3，No. 43（1958），469-486。

示例

假设我们希望检验两个样本是否来自同一分布的零假设。我们选择 95% 的置信水平；也就是说，如果 p 值小于 0.05，我们将拒绝零假设，支持备选假设。

如果第一个样本是从均匀分布抽取的，而第二个样本是从标准正态分布抽取的，我们预期将拒绝零假设。

```py
>>> import numpy as np
>>> from scipy import stats
>>> rng = np.random.default_rng()
>>> sample1 = stats.uniform.rvs(size=100, random_state=rng)
>>> sample2 = stats.norm.rvs(size=110, random_state=rng)
>>> stats.ks_2samp(sample1, sample2)
KstestResult(statistic=0.5454545454545454, pvalue=7.37417839555191e-15) 
```

实际上，p 值低于我们的阈值 0.05，因此我们拒绝零假设，支持“双边”替代假设：数据*不是*来自同一分布。

当两个样本来自相同分布时，我们期望数据大部分时间与零假设一致。

```py
>>> sample1 = stats.norm.rvs(size=105, random_state=rng)
>>> sample2 = stats.norm.rvs(size=95, random_state=rng)
>>> stats.ks_2samp(sample1, sample2)
KstestResult(statistic=0.10927318295739348, pvalue=0.5438289009927495) 
```

正如预期的那样，p 值为 0.54 不低于我们的阈值 0.05，因此我们无法拒绝零假设。

然而，假设第一个样本是从向更大值偏移的正态分布中抽取的。在这种情况下，底层分布的累积密度函数（CDF）倾向于*小于*第二个样本的CDF。因此，我们预计将拒绝零假设，采用`alternative='less'`：

```py
>>> sample1 = stats.norm.rvs(size=105, loc=0.5, random_state=rng)
>>> stats.ks_2samp(sample1, sample2, alternative='less')
KstestResult(statistic=0.4055137844611529, pvalue=3.5474563068855554e-08) 
```

而且，确实，p 值小于我们的阈值，我们拒绝零假设，支持备选假设。
