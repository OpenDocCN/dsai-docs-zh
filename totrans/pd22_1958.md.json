["```py\nIn [1]: np.random.seed(1234)\n\nIn [2]: df = pd.DataFrame({'A': range(10), 'B': np.random.randn(10)})\n\nIn [3]: df\nOut[3]: \n A         B\n0  0  0.471435\n1  1 -1.190976\n2  2  1.432707\n3  3 -0.312652\n4  4 -0.720589\n5  5  0.887163\n6  6  0.859588\n7  7 -0.636524\n8  8  0.015696\n9  9 -2.242685\n\n[10 rows x 2 columns] \n```", "```py\nIn [8]: pd.rolling_mean(df, window=3)\n FutureWarning: pd.rolling_mean is deprecated for DataFrame and will be removed in a future version, replace with\n DataFrame.rolling(window=3,center=False).mean()\nOut[8]:\n A         B\n0 NaN       NaN\n1 NaN       NaN\n2   1  0.237722\n3   2 -0.023640\n4   3  0.133155\n5   4 -0.048693\n6   5  0.342054\n7   6  0.370076\n8   7  0.079587\n9   8 -0.954504 \n```", "```py\nIn [4]: r = df.rolling(window=3) \n```", "```py\nIn [5]: r\nOut[5]: Rolling [window=3,center=False,axis=0,method=single] \n```", "```py\nIn [9]: r.<TAB>  # noqa E225, E999\nr.A           r.agg         r.apply       r.count       r.exclusions  r.max         r.median      r.name        r.skew        r.sum\nr.B           r.aggregate   r.corr        r.cov         r.kurt        r.mean        r.min         r.quantile    r.std         r.var \n```", "```py\nIn [6]: r.mean()\nOut[6]: \n A         B\n0  NaN       NaN\n1  NaN       NaN\n2  1.0  0.237722\n3  2.0 -0.023640\n4  3.0  0.133155\n5  4.0 -0.048693\n6  5.0  0.342054\n7  6.0  0.370076\n8  7.0  0.079587\n9  8.0 -0.954504\n\n[10 rows x 2 columns] \n```", "```py\nIn [7]: r['A'].mean()\nOut[7]: \n0    NaN\n1    NaN\n2    1.0\n3    2.0\n4    3.0\n5    4.0\n6    5.0\n7    6.0\n8    7.0\n9    8.0\nName: A, Length: 10, dtype: float64 \n```", "```py\nIn [8]: r.agg({'A': ['mean', 'std'],\n ...:       'B': ['mean', 'std']})\n ...: \nOut[8]: \n A              B \n mean  std      mean       std\n0  NaN  NaN       NaN       NaN\n1  NaN  NaN       NaN       NaN\n2  1.0  1.0  0.237722  1.327364\n3  2.0  1.0 -0.023640  1.335505\n4  3.0  1.0  0.133155  1.143778\n5  4.0  1.0 -0.048693  0.835747\n6  5.0  1.0  0.342054  0.920379\n7  6.0  1.0  0.370076  0.871850\n8  7.0  1.0  0.079587  0.750099\n9  8.0  1.0 -0.954504  1.162285\n\n[10 rows x 4 columns] \n```", "```py\nIn [9]: s = pd.Series(np.random.randn(5))\n\nIn [10]: s.rename('newname')\nOut[10]: \n0    1.150036\n1    0.991946\n2    0.953324\n3   -2.021255\n4   -0.334077\nName: newname, Length: 5, dtype: float64 \n```", "```py\nIn [11]: df = pd.DataFrame(np.random.randn(5, 2))\n\nIn [12]: (df.rename_axis(\"indexname\")\n ....:   .rename_axis(\"columns_name\", axis=\"columns\"))\n ....: \nOut[12]: \ncolumns_name         0         1\nindexname \n0             0.002118  0.405453\n1             0.289092  1.321158\n2            -1.546906 -0.202646\n3            -0.655969  0.193421\n4             0.553439  1.318152\n\n[5 rows x 2 columns] \n```", "```py\nIn [3]: s = pd.Series(range(1000))\n\nIn [4]: s.index\nOut[4]:\nInt64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n ...\n 990, 991, 992, 993, 994, 995, 996, 997, 998, 999], dtype='int64', length=1000)\n\nIn [6]: s.index.nbytes\nOut[6]: 8000 \n```", "```py\nIn [13]: s = pd.Series(range(1000))\n\nIn [14]: s.index\nOut[14]: RangeIndex(start=0, stop=1000, step=1)\n\nIn [15]: s.index.nbytes\nOut[15]: 128 \n```", "```py\nIn [1]: pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=None)\nFutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame)\nbut in a future version of pandas this will be changed to expand=True (return DataFrame)\n\nOut[1]:\n0      1\n1      2\n2    NaN\ndtype: object \n```", "```py\nIn [16]: pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=False)\nOut[16]: \n0      1\n1      2\n2    NaN\nLength: 3, dtype: object \n```", "```py\nIn [17]: pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=True)\nOut[17]: \n 0\n0    1\n1    2\n2  NaN\n\n[3 rows x 1 columns] \n```", "```py\nIn [18]: s = pd.Series([\"a1\", \"b2\", \"c3\"], [\"A11\", \"B22\", \"C33\"])\n\nIn [19]: s.index\nOut[19]: Index(['A11', 'B22', 'C33'], dtype='object')\n\nIn [20]: s.index.str.extract(\"(?P<letter>[a-zA-Z])\", expand=False)\nOut[20]: Index(['A', 'B', 'C'], dtype='object', name='letter') \n```", "```py\nIn [21]: s.index.str.extract(\"(?P<letter>[a-zA-Z])\", expand=True)\nOut[21]: \n letter\n0      A\n1      B\n2      C\n\n[3 rows x 1 columns] \n```", "```py\n>>> s.index.str.extract(\"(?P<letter>[a-zA-Z])([0-9]+)\", expand=False)\nValueError: only one regex group is supported with Index \n```", "```py\nIn [22]: s.index.str.extract(\"(?P<letter>[a-zA-Z])([0-9]+)\", expand=True)\nOut[22]: \n letter   1\n0      A  11\n1      B  22\n2      C  33\n\n[3 rows x 2 columns] \n```", "```py\nIn [23]: s = pd.Series([\"a1a2\", \"b1\", \"c1\"], [\"A\", \"B\", \"C\"])\n\nIn [24]: s\nOut[24]: \nA    a1a2\nB      b1\nC      c1\nLength: 3, dtype: object\n\nIn [25]: s.str.extract(r\"(?P<letter>[ab])(?P<digit>\\d)\", expand=False)\nOut[25]: \n letter digit\nA      a     1\nB      b     1\nC    NaN   NaN\n\n[3 rows x 2 columns] \n```", "```py\nIn [26]: s.str.extractall(r\"(?P<letter>[ab])(?P<digit>\\d)\")\nOut[26]: \n letter digit\n match \nA 0          a     1\n 1          a     2\nB 0          b     1\n\n[3 rows x 2 columns] \n```", "```py\nIn [27]: pd.Series(['a', 'b', np.nan, 'c']).str.cat(sep=' ')\nOut[27]: 'a b c'\n\nIn [28]: pd.Series(['a', 'b', np.nan, 'c']).str.cat(sep=' ', na_rep='?')\nOut[28]: 'a b ? c' \n```", "```py\nIn [2]: pd.Series(['a', 'b', np.nan, 'c']).str.cat(' ')\nValueError: Did you mean to supply a ``sep`` keyword? \n```", "```py\nIn [29]: dr = pd.date_range('20130101 09:12:56.1234', periods=3)\n\nIn [30]: dr\nOut[30]: \nDatetimeIndex(['2013-01-01 09:12:56.123400', '2013-01-02 09:12:56.123400',\n '2013-01-03 09:12:56.123400'],\n dtype='datetime64[ns]', freq='D')\n\nIn [31]: dr.round('s')\nOut[31]: \nDatetimeIndex(['2013-01-01 09:12:56', '2013-01-02 09:12:56',\n '2013-01-03 09:12:56'],\n dtype='datetime64[ns]', freq=None)\n\n# Timestamp scalar\nIn [32]: dr[0]\nOut[32]: Timestamp('2013-01-01 09:12:56.123400')\n\nIn [33]: dr[0].round('10s')\nOut[33]: Timestamp('2013-01-01 09:13:00') \n```", "```py\nIn [34]: dr = dr.tz_localize('US/Eastern')\n\nIn [35]: dr\nOut[35]: \nDatetimeIndex(['2013-01-01 09:12:56.123400-05:00',\n '2013-01-02 09:12:56.123400-05:00',\n '2013-01-03 09:12:56.123400-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None)\n\nIn [36]: dr.round('s')\nOut[36]: \nDatetimeIndex(['2013-01-01 09:12:56-05:00', '2013-01-02 09:12:56-05:00',\n '2013-01-03 09:12:56-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None) \n```", "```py\nIn [37]: t = pd.timedelta_range('1 days 2 hr 13 min 45 us', periods=3, freq='d')\n\nIn [38]: t\nOut[38]: \nTimedeltaIndex(['1 days 02:13:00.000045', '2 days 02:13:00.000045',\n '3 days 02:13:00.000045'],\n dtype='timedelta64[ns]', freq='D')\n\nIn [39]: t.round('10min')\nOut[39]: TimedeltaIndex(['1 days 02:10:00', '2 days 02:10:00', '3 days 02:10:00'], dtype='timedelta64[ns]', freq=None)\n\n# Timedelta scalar\nIn [40]: t[0]\nOut[40]: Timedelta('1 days 02:13:00.000045')\n\nIn [41]: t[0].round('2h')\nOut[41]: Timedelta('1 days 02:00:00') \n```", "```py\nIn [42]: s = pd.Series(dr)\n\nIn [43]: s\nOut[43]: \n0   2013-01-01 09:12:56.123400-05:00\n1   2013-01-02 09:12:56.123400-05:00\n2   2013-01-03 09:12:56.123400-05:00\nLength: 3, dtype: datetime64[ns, US/Eastern]\n\nIn [44]: s.dt.round('D')\nOut[44]: \n0   2013-01-01 00:00:00-05:00\n1   2013-01-02 00:00:00-05:00\n2   2013-01-03 00:00:00-05:00\nLength: 3, dtype: datetime64[ns, US/Eastern] \n```", "```py\nIn [2]: s = pd.Series([1, 2, 3], index=np.arange(3.))\n\nIn [3]: s\nOut[3]:\n0    1\n1    2\n2    3\ndtype: int64\n\nIn [4]: s.index\nOut[4]: Float64Index([0.0, 1.0, 2.0], dtype='float64')\n\nIn [5]: print(s.to_csv(path=None))\n0,1\n1,2\n2,3 \n```", "```py\nIn [45]: s = pd.Series([1, 2, 3], index=np.arange(3.))\n\nIn [46]: s\nOut[46]: \n0.0    1\n1.0    2\n2.0    3\nLength: 3, dtype: int64\n\nIn [47]: s.index\nOut[47]: Index([0.0, 1.0, 2.0], dtype='float64')\n\nIn [48]: print(s.to_csv(path_or_buf=None, header=False))\n0.0,1\n1.0,2\n2.0,3 \n```", "```py\nIn [5]: df = pd.DataFrame({'a': [0, 1, 1],\n 'b': pd.Series([100, 200, 300], dtype='uint32')})\n\nIn [7]: df.dtypes\nOut[7]:\na     int64\nb    uint32\ndtype: object\n\nIn [8]: ix = df['a'] == 1\n\nIn [9]: df.loc[ix, 'b'] = df.loc[ix, 'b']\n\nIn [11]: df.dtypes\nOut[11]:\na    int64\nb    int64\ndtype: object \n```", "```py\nIn [49]: df = pd.DataFrame({'a': [0, 1, 1],\n ....:                   'b': pd.Series([100, 200, 300], dtype='uint32')})\n ....: \n\nIn [50]: df.dtypes\nOut[50]: \na     int64\nb    uint32\nLength: 2, dtype: object\n\nIn [51]: ix = df['a'] == 1\n\nIn [52]: df.loc[ix, 'b'] = df.loc[ix, 'b']\n\nIn [53]: df.dtypes\nOut[53]: \na     int64\nb    uint32\nLength: 2, dtype: object \n```", "```py\nIn [4]: df = pd.DataFrame(np.array(range(1,10)).reshape(3,3),\n columns=list('abc'),\n index=[[4,4,8], [8,10,12]])\n\nIn [5]: df\nOut[5]:\n a  b  c\n4 8   1  2  3\n 10  4  5  6\n8 12  7  8  9\n\nIn [7]: df.ix[4, 'c'] = np.array([0., 1.])\n\nIn [8]: df\nOut[8]:\n a  b  c\n4 8   1  2  0\n 10  4  5  1\n8 12  7  8  9 \n```", "```py\nIn [54]: df = pd.DataFrame(np.array(range(1,10)).reshape(3,3),\n ....:                  columns=list('abc'),\n ....:                  index=[[4,4,8], [8,10,12]])\n ....: \n\nIn [55]: df\nOut[55]: \n a  b  c\n4 8   1  2  3\n 10  4  5  6\n8 12  7  8  9\n\n[3 rows x 3 columns]\n\nIn [56]: df.loc[4, 'c'] = np.array([0., 1.])\n\nIn [57]: df\nOut[57]: \n a  b  c\n4 8   1  2  0\n 10  4  5  1\n8 12  7  8  9\n\n[3 rows x 3 columns] \n```", "```py\nIn [1]: p = Panel(np.arange(2*3*4).reshape(2,3,4))\n\nIn [2]: p.to_xarray()\nOut[2]:\n<xarray.DataArray (items: 2, major_axis: 3, minor_axis: 4)>\narray([[[ 0,  1,  2,  3],\n [ 4,  5,  6,  7],\n [ 8,  9, 10, 11]],\n\n [[12, 13, 14, 15],\n [16, 17, 18, 19],\n [20, 21, 22, 23]]])\nCoordinates:\n * items       (items) int64 0 1\n * major_axis  (major_axis) int64 0 1 2\n * minor_axis  (minor_axis) int64 0 1 2 3 \n```", "```py\nIn [58]: pd.NaT * 1\nOut[58]: NaT\n\nIn [59]: pd.NaT * 1.5\nOut[59]: NaT\n\nIn [60]: pd.NaT / 2\nOut[60]: NaT\n\nIn [61]: pd.NaT * np.nan\nOut[61]: NaT \n```", "```py\nIn [62]: pd.NaT / pd.NaT\nOut[62]: nan\n\nIn [63]: pd.Timedelta('1s') / pd.NaT\nOut[63]: nan \n```", "```py\nIn [64]: pd.NaT + pd.NaT\nOut[64]: NaT\n\n# same as\nIn [65]: pd.Timedelta('1s') + pd.Timedelta('1s')\nOut[65]: Timedelta('0 days 00:00:02') \n```", "```py\nIn [3]: pd.Timestamp('19900315') + pd.Timestamp('19900315')\nTypeError: unsupported operand type(s) for +: 'Timestamp' and 'Timestamp' \n```", "```py\nIn [1]: pd.Series([pd.NaT], dtype='<M8[ns]') + pd.Series([pd.NaT], dtype='<M8[ns]')\nTypeError: can only operate on a datetimes for subtraction,\n but the operator [__add__] was passed \n```", "```py\nIn [66]: pd.Series([pd.NaT], dtype='<m8[ns]') + pd.Series([pd.NaT], dtype='<m8[ns]')\nOut[66]: \n0   NaT\nLength: 1, dtype: timedelta64[ns] \n```", "```py\nIn [67]: pd.Timedelta('1s') / 2.0\nOut[67]: Timedelta('0 days 00:00:00.500000') \n```", "```py\nIn [68]: ser = pd.Series(pd.timedelta_range('1 day', periods=3))\n\nIn [69]: ser\nOut[69]: \n0   1 days\n1   2 days\n2   3 days\nLength: 3, dtype: timedelta64[ns]\n\nIn [70]: pd.Timestamp('2012-01-01') - ser\nOut[70]: \n0   2011-12-31\n1   2011-12-30\n2   2011-12-29\nLength: 3, dtype: datetime64[ns] \n```", "```py\nIn [3]: pd.Series([0,1]).rank(method='average', na_option='keep',\n ascending=True, pct=False)\nOut[3]:\n0    1\n1    2\ndtype: float64\n\nIn [4]: pd.DataFrame([0,1]).rank(axis=0, numeric_only=None,\n method='average', na_option='keep',\n ascending=True, pct=False)\nOut[4]:\n 0\n0  1\n1  2 \n```", "```py\nIn [71]: pd.Series([0,1]).rank(axis=0, method='average', numeric_only=False,\n ....:                      na_option='keep', ascending=True, pct=False)\n ....: \nOut[71]: \n0    1.0\n1    2.0\nLength: 2, dtype: float64\n\nIn [72]: pd.DataFrame([0,1]).rank(axis=0, method='average', numeric_only=False,\n ....:                         na_option='keep', ascending=True, pct=False)\n ....: \nOut[72]: \n 0\n0  1.0\n1  2.0\n\n[2 rows x 1 columns] \n```", "```py\nIn [73]: d = pd.Timestamp('2014-02-01')\n\nIn [74]: d\nOut[74]: Timestamp('2014-02-01 00:00:00')\n\nIn [75]: d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\nOut[75]: Timestamp('2014-02-01 00:00:00')\n\nIn [76]: d + pd.offsets.QuarterBegin(n=0, startingMonth=1)\nOut[76]: Timestamp('2014-04-01 00:00:00') \n```", "```py\nIn [3]: d = pd.Timestamp('2014-02-15')\n\nIn [4]: d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\nOut[4]: Timestamp('2014-02-01 00:00:00') \n```", "```py\nIn [77]: d = pd.Timestamp('2014-02-15')\n\nIn [78]: d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\nOut[78]: Timestamp('2014-05-01 00:00:00') \n```", "```py\nIn [79]: np.random.seed(1234)\n\nIn [80]: df = pd.DataFrame(np.random.rand(10,4),\n ....:                  columns=list('ABCD'),\n ....:                  index=pd.date_range('2010-01-01 09:00:00',\n ....:                                      periods=10, freq='s'))\n ....: \n\nIn [81]: df\nOut[81]: \n A         B         C         D\n2010-01-01 09:00:00  0.191519  0.622109  0.437728  0.785359\n2010-01-01 09:00:01  0.779976  0.272593  0.276464  0.801872\n2010-01-01 09:00:02  0.958139  0.875933  0.357817  0.500995\n2010-01-01 09:00:03  0.683463  0.712702  0.370251  0.561196\n2010-01-01 09:00:04  0.503083  0.013768  0.772827  0.882641\n2010-01-01 09:00:05  0.364886  0.615396  0.075381  0.368824\n2010-01-01 09:00:06  0.933140  0.651378  0.397203  0.788730\n2010-01-01 09:00:07  0.316836  0.568099  0.869127  0.436173\n2010-01-01 09:00:08  0.802148  0.143767  0.704261  0.704581\n2010-01-01 09:00:09  0.218792  0.924868  0.442141  0.909316\n\n[10 rows x 4 columns] \n```", "```py\nIn [6]: df.resample('2s')\nOut[6]:\n A         B         C         D\n2010-01-01 09:00:00  0.485748  0.447351  0.357096  0.793615\n2010-01-01 09:00:02  0.820801  0.794317  0.364034  0.531096\n2010-01-01 09:00:04  0.433985  0.314582  0.424104  0.625733\n2010-01-01 09:00:06  0.624988  0.609738  0.633165  0.612452\n2010-01-01 09:00:08  0.510470  0.534317  0.573201  0.806949 \n```", "```py\nIn [7]: df.resample('2s', how='sum')\nOut[7]:\n A         B         C         D\n2010-01-01 09:00:00  0.971495  0.894701  0.714192  1.587231\n2010-01-01 09:00:02  1.641602  1.588635  0.728068  1.062191\n2010-01-01 09:00:04  0.867969  0.629165  0.848208  1.251465\n2010-01-01 09:00:06  1.249976  1.219477  1.266330  1.224904\n2010-01-01 09:00:08  1.020940  1.068634  1.146402  1.613897 \n```", "```py\nIn [82]: r = df.resample('2s')\n\nIn [83]: r\nOut[83]: <pandas.core.resample.DatetimeIndexResampler object at 0x7ff230e71c30> \n```", "```py\nIn [84]: r.mean()\nOut[84]: \n A         B         C         D\n2010-01-01 09:00:00  0.485748  0.447351  0.357096  0.793615\n2010-01-01 09:00:02  0.820801  0.794317  0.364034  0.531096\n2010-01-01 09:00:04  0.433985  0.314582  0.424104  0.625733\n2010-01-01 09:00:06  0.624988  0.609738  0.633165  0.612452\n2010-01-01 09:00:08  0.510470  0.534317  0.573201  0.806949\n\n[5 rows x 4 columns] \n```", "```py\nIn [85]: r.sum()\nOut[85]: \n A         B         C         D\n2010-01-01 09:00:00  0.971495  0.894701  0.714192  1.587231\n2010-01-01 09:00:02  1.641602  1.588635  0.728068  1.062191\n2010-01-01 09:00:04  0.867969  0.629165  0.848208  1.251465\n2010-01-01 09:00:06  1.249976  1.219477  1.266330  1.224904\n2010-01-01 09:00:08  1.020940  1.068634  1.146402  1.613897\n\n[5 rows x 4 columns] \n```", "```py\nIn [86]: r[['A','C']].mean()\nOut[86]: \n A         C\n2010-01-01 09:00:00  0.485748  0.357096\n2010-01-01 09:00:02  0.820801  0.364034\n2010-01-01 09:00:04  0.433985  0.424104\n2010-01-01 09:00:06  0.624988  0.633165\n2010-01-01 09:00:08  0.510470  0.573201\n\n[5 rows x 2 columns] \n```", "```py\nIn [87]: r.agg({'A' : 'mean', 'B' : 'sum'})\nOut[87]: \n A         B\n2010-01-01 09:00:00  0.485748  0.894701\n2010-01-01 09:00:02  0.820801  1.588635\n2010-01-01 09:00:04  0.433985  0.629165\n2010-01-01 09:00:06  0.624988  1.219477\n2010-01-01 09:00:08  0.510470  1.068634\n\n[5 rows x 2 columns] \n```", "```py\nIn [88]: r[['A','B']].agg(['mean','sum'])\nOut[88]: \n A                   B \n mean       sum      mean       sum\n2010-01-01 09:00:00  0.485748  0.971495  0.447351  0.894701\n2010-01-01 09:00:02  0.820801  1.641602  0.794317  1.588635\n2010-01-01 09:00:04  0.433985  0.867969  0.314582  0.629165\n2010-01-01 09:00:06  0.624988  1.249976  0.609738  1.219477\n2010-01-01 09:00:08  0.510470  1.020940  0.534317  1.068634\n\n[5 rows x 4 columns] \n```", "```py\nIn [89]: s = pd.Series(np.arange(5, dtype='int64'),\n index=pd.date_range('2010-01-01', periods=5, freq='Q'))\n\nIn [90]: s\nOut[90]:\n2010-03-31    0\n2010-06-30    1\n2010-09-30    2\n2010-12-31    3\n2011-03-31    4\nFreq: Q-DEC, Length: 5, dtype: int64 \n```", "```py\nIn [6]: s.resample('M', fill_method='ffill')\nOut[6]:\n2010-03-31    0\n2010-04-30    0\n2010-05-31    0\n2010-06-30    1\n2010-07-31    1\n2010-08-31    1\n2010-09-30    2\n2010-10-31    2\n2010-11-30    2\n2010-12-31    3\n2011-01-31    3\n2011-02-28    3\n2011-03-31    4\nFreq: M, dtype: int64 \n```", "```py\nIn [91]: s.resample('M').ffill()\nOut[91]:\n2010-03-31    0\n2010-04-30    0\n2010-05-31    0\n2010-06-30    1\n2010-07-31    1\n2010-08-31    1\n2010-09-30    2\n2010-10-31    2\n2010-11-30    2\n2010-12-31    3\n2011-01-31    3\n2011-02-28    3\n2011-03-31    4\nFreq: M, Length: 13, dtype: int64 \n```", "```py\nIn [4]: r = df.resample('2s')\n\nIn [6]: r*10\npandas/tseries/resample.py:80: FutureWarning: .resample() is now a deferred operation\nuse .resample(...).mean() instead of .resample(...)\n\nOut[6]:\n A         B         C         D\n2010-01-01 09:00:00  4.857476  4.473507  3.570960  7.936154\n2010-01-01 09:00:02  8.208011  7.943173  3.640340  5.310957\n2010-01-01 09:00:04  4.339846  3.145823  4.241039  6.257326\n2010-01-01 09:00:06  6.249881  6.097384  6.331650  6.124518\n2010-01-01 09:00:08  5.104699  5.343172  5.732009  8.069486 \n```", "```py\nIn [7]: r.iloc[0] = 5\nValueError: .resample() is now a deferred operation\nuse .resample(...).mean() instead of .resample(...) \n```", "```py\nIn [4]: df.resample('2s').min()\nOut[4]:\nA    0.433985\nB    0.314582\nC    0.357096\nD    0.531096\ndtype: float64 \n```", "```py\nIn [89]: df.resample('2s').min()\nOut[89]: \n A         B         C         D\n2010-01-01 09:00:00  0.191519  0.272593  0.276464  0.785359\n2010-01-01 09:00:02  0.683463  0.712702  0.357817  0.500995\n2010-01-01 09:00:04  0.364886  0.013768  0.075381  0.368824\n2010-01-01 09:00:06  0.316836  0.568099  0.397203  0.436173\n2010-01-01 09:00:08  0.218792  0.143767  0.442141  0.704581\n\n[5 rows x 4 columns] \n```", "```py\nIn [90]: df.resample('2s').mean().min()\nOut[90]: \nA    0.433985\nB    0.314582\nC    0.357096\nD    0.531096\nLength: 4, dtype: float64 \n```", "```py\nIn [91]: df = pd.DataFrame({'a': np.linspace(0, 10, 5), 'b': range(5)})\n\nIn [92]: df\nOut[92]: \n a  b\n0   0.0  0\n1   2.5  1\n2   5.0  2\n3   7.5  3\n4  10.0  4\n\n[5 rows x 2 columns] \n```", "```py\nIn [12]: df.eval('c = a + b')\nFutureWarning: eval expressions containing an assignment currentlydefault to operating inplace.\nThis will change in a future version of pandas, use inplace=True to avoid this warning.\n\nIn [13]: df\nOut[13]:\n a  b     c\n0   0.0  0   0.0\n1   2.5  1   3.5\n2   5.0  2   7.0\n3   7.5  3  10.5\n4  10.0  4  14.0 \n```", "```py\nIn [93]: df\nOut[93]: \n a  b     c\n0   0.0  0   0.0\n1   2.5  1   3.5\n2   5.0  2   7.0\n3   7.5  3  10.5\n4  10.0  4  14.0\n\n[5 rows x 3 columns]\n\nIn [94]: df.eval('d = c - b', inplace=False)\nOut[94]: \n a  b     c     d\n0   0.0  0   0.0   0.0\n1   2.5  1   3.5   2.5\n2   5.0  2   7.0   5.0\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[5 rows x 4 columns]\n\nIn [95]: df\nOut[95]: \n a  b     c\n0   0.0  0   0.0\n1   2.5  1   3.5\n2   5.0  2   7.0\n3   7.5  3  10.5\n4  10.0  4  14.0\n\n[5 rows x 3 columns]\n\nIn [96]: df.eval('d = c - b', inplace=True)\n\nIn [97]: df\nOut[97]: \n a  b     c     d\n0   0.0  0   0.0   0.0\n1   2.5  1   3.5   2.5\n2   5.0  2   7.0   5.0\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[5 rows x 4 columns] \n```", "```py\nIn [98]: df.query('a > 5')\nOut[98]: \n a  b     c     d\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[2 rows x 4 columns]\n\nIn [99]: df.query('a > 5', inplace=True)\n\nIn [100]: df\nOut[100]: \n a  b     c     d\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[2 rows x 4 columns] \n```", "```py\nIn [101]: df\nOut[101]: \n a  b     c     d\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[2 rows x 4 columns]\n\nIn [102]: df.eval(\"\"\"\n .....: e = d + a\n .....: f = e - 22\n .....: g = f / 2.0\"\"\", inplace=True)\n .....: \n\nIn [103]: df\nOut[103]: \n a  b     c     d     e    f    g\n3   7.5  3  10.5   7.5  15.0 -7.0 -3.5\n4  10.0  4  14.0  10.0  20.0 -2.0 -1.0\n\n[2 rows x 7 columns] \n```", "```py\n    In [107]: s = pd.Series(range(10), pd.date_range('2015-01-01', freq='H', periods=10))\n\n    In [108]: s.between_time(\"7:00am\", \"9:00am\")\n    Out[108]:\n    2015-01-01 07:00:00    7\n    2015-01-01 08:00:00    8\n    2015-01-01 09:00:00    9\n    Freq: H, Length: 3, dtype: int64 \n    ```", "```py\n    In [2]: s.between_time('20150101 07:00:00','20150101 09:00:00')\n    ValueError: Cannot convert arg ['20150101 07:00:00'] to a time. \n    ```", "```py\n    In [1]: s = pd.Series(range(3))\n\n    In [2]: pd.rolling_mean(s,window=2,min_periods=1)\n     FutureWarning: pd.rolling_mean is deprecated for Series and\n     will be removed in a future version, replace with\n     Series.rolling(min_periods=1,window=2,center=False).mean()\n    Out[2]:\n     0    0.0\n     1    0.5\n     2    1.5\n     dtype: float64\n\n    In [3]: pd.rolling_cov(s, s, window=2)\n     FutureWarning: pd.rolling_cov is deprecated for Series and\n     will be removed in a future version, replace with\n     Series.rolling(window=2).cov(other=<Series>)\n    Out[3]:\n     0    NaN\n     1    0.5\n     2    0.5\n     dtype: float64 \n    ```", "```py\nIn [104]: s = pd.Series([1, 2, 3], index=[4, 5, 6])\n\nIn [105]: s\nOut[105]: \n4    1\n5    2\n6    3\nLength: 3, dtype: int64\n\nIn [106]: s2 = pd.Series([1, 2, 3], index=list('abc'))\n\nIn [107]: s2\nOut[107]: \na    1\nb    2\nc    3\nLength: 3, dtype: int64 \n```", "```py\n# this is label indexing\nIn [2]: s[5.0]\nFutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\nOut[2]: 2\n\n# this is positional indexing\nIn [3]: s.iloc[1.0]\nFutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\nOut[3]: 2\n\n# this is label indexing\nIn [4]: s.loc[5.0]\nFutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\nOut[4]: 2\n\n# .ix would coerce 1.0 to the positional 1, and index\nIn [5]: s2.ix[1.0] = 10\nFutureWarning: scalar indexers for index type Index should be integers and not floating point\n\nIn [6]: s2\nOut[6]:\na     1\nb    10\nc     3\ndtype: int64 \n```", "```py\nIn [3]: s.iloc[2.0]\nTypeError: cannot do label indexing on <class 'pandas.indexes.numeric.Int64Index'> with these indexers [2.0] of <type 'float'> \n```", "```py\nIn [108]: s[5.0]\nOut[108]: 2\n\nIn [109]: s.loc[5.0]\nOut[109]: 2 \n```", "```py\nIn [110]: s_copy = s.copy()\n\nIn [111]: s_copy[5.0] = 10\n\nIn [112]: s_copy\nOut[112]: \n4     1\n5    10\n6     3\nLength: 3, dtype: int64\n\nIn [113]: s_copy = s.copy()\n\nIn [114]: s_copy.loc[5.0] = 10\n\nIn [115]: s_copy\nOut[115]: \n4     1\n5    10\n6     3\nLength: 3, dtype: int64 \n```", "```py\nIn [3]: s2.ix[1.0] = 10\nIn [4]: s2\nOut[4]:\na       1\nb       2\nc       3\n1.0    10\ndtype: int64 \n```", "```py\nIn [116]: s.loc[5.0:6]\nOut[116]: \n5    2\n6    3\nLength: 2, dtype: int64 \n```", "```py\nIn [117]: s.loc[5.1:6]\nOut[117]: \n6    3\nLength: 1, dtype: int64 \n```", "```py\nIn [118]: s = pd.Series([1, 2, 3], index=np.arange(3.))\n\nIn [119]: s[1.0]\nOut[119]: 2\n\nIn [120]: s[1.0:2.5]\nOut[120]: \n1.0    2\n2.0    3\nLength: 2, dtype: int64 \n```", "```py\nIn [1]: np.random.seed(1234)\n\nIn [2]: df = pd.DataFrame({'A': range(10), 'B': np.random.randn(10)})\n\nIn [3]: df\nOut[3]: \n A         B\n0  0  0.471435\n1  1 -1.190976\n2  2  1.432707\n3  3 -0.312652\n4  4 -0.720589\n5  5  0.887163\n6  6  0.859588\n7  7 -0.636524\n8  8  0.015696\n9  9 -2.242685\n\n[10 rows x 2 columns] \n```", "```py\nIn [8]: pd.rolling_mean(df, window=3)\n FutureWarning: pd.rolling_mean is deprecated for DataFrame and will be removed in a future version, replace with\n DataFrame.rolling(window=3,center=False).mean()\nOut[8]:\n A         B\n0 NaN       NaN\n1 NaN       NaN\n2   1  0.237722\n3   2 -0.023640\n4   3  0.133155\n5   4 -0.048693\n6   5  0.342054\n7   6  0.370076\n8   7  0.079587\n9   8 -0.954504 \n```", "```py\nIn [4]: r = df.rolling(window=3) \n```", "```py\nIn [5]: r\nOut[5]: Rolling [window=3,center=False,axis=0,method=single] \n```", "```py\nIn [9]: r.<TAB>  # noqa E225, E999\nr.A           r.agg         r.apply       r.count       r.exclusions  r.max         r.median      r.name        r.skew        r.sum\nr.B           r.aggregate   r.corr        r.cov         r.kurt        r.mean        r.min         r.quantile    r.std         r.var \n```", "```py\nIn [6]: r.mean()\nOut[6]: \n A         B\n0  NaN       NaN\n1  NaN       NaN\n2  1.0  0.237722\n3  2.0 -0.023640\n4  3.0  0.133155\n5  4.0 -0.048693\n6  5.0  0.342054\n7  6.0  0.370076\n8  7.0  0.079587\n9  8.0 -0.954504\n\n[10 rows x 2 columns] \n```", "```py\nIn [7]: r['A'].mean()\nOut[7]: \n0    NaN\n1    NaN\n2    1.0\n3    2.0\n4    3.0\n5    4.0\n6    5.0\n7    6.0\n8    7.0\n9    8.0\nName: A, Length: 10, dtype: float64 \n```", "```py\nIn [8]: r.agg({'A': ['mean', 'std'],\n ...:       'B': ['mean', 'std']})\n ...: \nOut[8]: \n A              B \n mean  std      mean       std\n0  NaN  NaN       NaN       NaN\n1  NaN  NaN       NaN       NaN\n2  1.0  1.0  0.237722  1.327364\n3  2.0  1.0 -0.023640  1.335505\n4  3.0  1.0  0.133155  1.143778\n5  4.0  1.0 -0.048693  0.835747\n6  5.0  1.0  0.342054  0.920379\n7  6.0  1.0  0.370076  0.871850\n8  7.0  1.0  0.079587  0.750099\n9  8.0  1.0 -0.954504  1.162285\n\n[10 rows x 4 columns] \n```", "```py\nIn [9]: s = pd.Series(np.random.randn(5))\n\nIn [10]: s.rename('newname')\nOut[10]: \n0    1.150036\n1    0.991946\n2    0.953324\n3   -2.021255\n4   -0.334077\nName: newname, Length: 5, dtype: float64 \n```", "```py\nIn [11]: df = pd.DataFrame(np.random.randn(5, 2))\n\nIn [12]: (df.rename_axis(\"indexname\")\n ....:   .rename_axis(\"columns_name\", axis=\"columns\"))\n ....: \nOut[12]: \ncolumns_name         0         1\nindexname \n0             0.002118  0.405453\n1             0.289092  1.321158\n2            -1.546906 -0.202646\n3            -0.655969  0.193421\n4             0.553439  1.318152\n\n[5 rows x 2 columns] \n```", "```py\nIn [3]: s = pd.Series(range(1000))\n\nIn [4]: s.index\nOut[4]:\nInt64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n ...\n 990, 991, 992, 993, 994, 995, 996, 997, 998, 999], dtype='int64', length=1000)\n\nIn [6]: s.index.nbytes\nOut[6]: 8000 \n```", "```py\nIn [13]: s = pd.Series(range(1000))\n\nIn [14]: s.index\nOut[14]: RangeIndex(start=0, stop=1000, step=1)\n\nIn [15]: s.index.nbytes\nOut[15]: 128 \n```", "```py\nIn [1]: pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=None)\nFutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame)\nbut in a future version of pandas this will be changed to expand=True (return DataFrame)\n\nOut[1]:\n0      1\n1      2\n2    NaN\ndtype: object \n```", "```py\nIn [16]: pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=False)\nOut[16]: \n0      1\n1      2\n2    NaN\nLength: 3, dtype: object \n```", "```py\nIn [17]: pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=True)\nOut[17]: \n 0\n0    1\n1    2\n2  NaN\n\n[3 rows x 1 columns] \n```", "```py\nIn [18]: s = pd.Series([\"a1\", \"b2\", \"c3\"], [\"A11\", \"B22\", \"C33\"])\n\nIn [19]: s.index\nOut[19]: Index(['A11', 'B22', 'C33'], dtype='object')\n\nIn [20]: s.index.str.extract(\"(?P<letter>[a-zA-Z])\", expand=False)\nOut[20]: Index(['A', 'B', 'C'], dtype='object', name='letter') \n```", "```py\nIn [21]: s.index.str.extract(\"(?P<letter>[a-zA-Z])\", expand=True)\nOut[21]: \n letter\n0      A\n1      B\n2      C\n\n[3 rows x 1 columns] \n```", "```py\n>>> s.index.str.extract(\"(?P<letter>[a-zA-Z])([0-9]+)\", expand=False)\nValueError: only one regex group is supported with Index \n```", "```py\nIn [22]: s.index.str.extract(\"(?P<letter>[a-zA-Z])([0-9]+)\", expand=True)\nOut[22]: \n letter   1\n0      A  11\n1      B  22\n2      C  33\n\n[3 rows x 2 columns] \n```", "```py\nIn [23]: s = pd.Series([\"a1a2\", \"b1\", \"c1\"], [\"A\", \"B\", \"C\"])\n\nIn [24]: s\nOut[24]: \nA    a1a2\nB      b1\nC      c1\nLength: 3, dtype: object\n\nIn [25]: s.str.extract(r\"(?P<letter>[ab])(?P<digit>\\d)\", expand=False)\nOut[25]: \n letter digit\nA      a     1\nB      b     1\nC    NaN   NaN\n\n[3 rows x 2 columns] \n```", "```py\nIn [26]: s.str.extractall(r\"(?P<letter>[ab])(?P<digit>\\d)\")\nOut[26]: \n letter digit\n match \nA 0          a     1\n 1          a     2\nB 0          b     1\n\n[3 rows x 2 columns] \n```", "```py\nIn [27]: pd.Series(['a', 'b', np.nan, 'c']).str.cat(sep=' ')\nOut[27]: 'a b c'\n\nIn [28]: pd.Series(['a', 'b', np.nan, 'c']).str.cat(sep=' ', na_rep='?')\nOut[28]: 'a b ? c' \n```", "```py\nIn [2]: pd.Series(['a', 'b', np.nan, 'c']).str.cat(' ')\nValueError: Did you mean to supply a ``sep`` keyword? \n```", "```py\nIn [29]: dr = pd.date_range('20130101 09:12:56.1234', periods=3)\n\nIn [30]: dr\nOut[30]: \nDatetimeIndex(['2013-01-01 09:12:56.123400', '2013-01-02 09:12:56.123400',\n '2013-01-03 09:12:56.123400'],\n dtype='datetime64[ns]', freq='D')\n\nIn [31]: dr.round('s')\nOut[31]: \nDatetimeIndex(['2013-01-01 09:12:56', '2013-01-02 09:12:56',\n '2013-01-03 09:12:56'],\n dtype='datetime64[ns]', freq=None)\n\n# Timestamp scalar\nIn [32]: dr[0]\nOut[32]: Timestamp('2013-01-01 09:12:56.123400')\n\nIn [33]: dr[0].round('10s')\nOut[33]: Timestamp('2013-01-01 09:13:00') \n```", "```py\nIn [34]: dr = dr.tz_localize('US/Eastern')\n\nIn [35]: dr\nOut[35]: \nDatetimeIndex(['2013-01-01 09:12:56.123400-05:00',\n '2013-01-02 09:12:56.123400-05:00',\n '2013-01-03 09:12:56.123400-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None)\n\nIn [36]: dr.round('s')\nOut[36]: \nDatetimeIndex(['2013-01-01 09:12:56-05:00', '2013-01-02 09:12:56-05:00',\n '2013-01-03 09:12:56-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None) \n```", "```py\nIn [37]: t = pd.timedelta_range('1 days 2 hr 13 min 45 us', periods=3, freq='d')\n\nIn [38]: t\nOut[38]: \nTimedeltaIndex(['1 days 02:13:00.000045', '2 days 02:13:00.000045',\n '3 days 02:13:00.000045'],\n dtype='timedelta64[ns]', freq='D')\n\nIn [39]: t.round('10min')\nOut[39]: TimedeltaIndex(['1 days 02:10:00', '2 days 02:10:00', '3 days 02:10:00'], dtype='timedelta64[ns]', freq=None)\n\n# Timedelta scalar\nIn [40]: t[0]\nOut[40]: Timedelta('1 days 02:13:00.000045')\n\nIn [41]: t[0].round('2h')\nOut[41]: Timedelta('1 days 02:00:00') \n```", "```py\nIn [42]: s = pd.Series(dr)\n\nIn [43]: s\nOut[43]: \n0   2013-01-01 09:12:56.123400-05:00\n1   2013-01-02 09:12:56.123400-05:00\n2   2013-01-03 09:12:56.123400-05:00\nLength: 3, dtype: datetime64[ns, US/Eastern]\n\nIn [44]: s.dt.round('D')\nOut[44]: \n0   2013-01-01 00:00:00-05:00\n1   2013-01-02 00:00:00-05:00\n2   2013-01-03 00:00:00-05:00\nLength: 3, dtype: datetime64[ns, US/Eastern] \n```", "```py\nIn [2]: s = pd.Series([1, 2, 3], index=np.arange(3.))\n\nIn [3]: s\nOut[3]:\n0    1\n1    2\n2    3\ndtype: int64\n\nIn [4]: s.index\nOut[4]: Float64Index([0.0, 1.0, 2.0], dtype='float64')\n\nIn [5]: print(s.to_csv(path=None))\n0,1\n1,2\n2,3 \n```", "```py\nIn [45]: s = pd.Series([1, 2, 3], index=np.arange(3.))\n\nIn [46]: s\nOut[46]: \n0.0    1\n1.0    2\n2.0    3\nLength: 3, dtype: int64\n\nIn [47]: s.index\nOut[47]: Index([0.0, 1.0, 2.0], dtype='float64')\n\nIn [48]: print(s.to_csv(path_or_buf=None, header=False))\n0.0,1\n1.0,2\n2.0,3 \n```", "```py\nIn [5]: df = pd.DataFrame({'a': [0, 1, 1],\n 'b': pd.Series([100, 200, 300], dtype='uint32')})\n\nIn [7]: df.dtypes\nOut[7]:\na     int64\nb    uint32\ndtype: object\n\nIn [8]: ix = df['a'] == 1\n\nIn [9]: df.loc[ix, 'b'] = df.loc[ix, 'b']\n\nIn [11]: df.dtypes\nOut[11]:\na    int64\nb    int64\ndtype: object \n```", "```py\nIn [49]: df = pd.DataFrame({'a': [0, 1, 1],\n ....:                   'b': pd.Series([100, 200, 300], dtype='uint32')})\n ....: \n\nIn [50]: df.dtypes\nOut[50]: \na     int64\nb    uint32\nLength: 2, dtype: object\n\nIn [51]: ix = df['a'] == 1\n\nIn [52]: df.loc[ix, 'b'] = df.loc[ix, 'b']\n\nIn [53]: df.dtypes\nOut[53]: \na     int64\nb    uint32\nLength: 2, dtype: object \n```", "```py\nIn [4]: df = pd.DataFrame(np.array(range(1,10)).reshape(3,3),\n columns=list('abc'),\n index=[[4,4,8], [8,10,12]])\n\nIn [5]: df\nOut[5]:\n a  b  c\n4 8   1  2  3\n 10  4  5  6\n8 12  7  8  9\n\nIn [7]: df.ix[4, 'c'] = np.array([0., 1.])\n\nIn [8]: df\nOut[8]:\n a  b  c\n4 8   1  2  0\n 10  4  5  1\n8 12  7  8  9 \n```", "```py\nIn [54]: df = pd.DataFrame(np.array(range(1,10)).reshape(3,3),\n ....:                  columns=list('abc'),\n ....:                  index=[[4,4,8], [8,10,12]])\n ....: \n\nIn [55]: df\nOut[55]: \n a  b  c\n4 8   1  2  3\n 10  4  5  6\n8 12  7  8  9\n\n[3 rows x 3 columns]\n\nIn [56]: df.loc[4, 'c'] = np.array([0., 1.])\n\nIn [57]: df\nOut[57]: \n a  b  c\n4 8   1  2  0\n 10  4  5  1\n8 12  7  8  9\n\n[3 rows x 3 columns] \n```", "```py\nIn [1]: p = Panel(np.arange(2*3*4).reshape(2,3,4))\n\nIn [2]: p.to_xarray()\nOut[2]:\n<xarray.DataArray (items: 2, major_axis: 3, minor_axis: 4)>\narray([[[ 0,  1,  2,  3],\n [ 4,  5,  6,  7],\n [ 8,  9, 10, 11]],\n\n [[12, 13, 14, 15],\n [16, 17, 18, 19],\n [20, 21, 22, 23]]])\nCoordinates:\n * items       (items) int64 0 1\n * major_axis  (major_axis) int64 0 1 2\n * minor_axis  (minor_axis) int64 0 1 2 3 \n```", "```py\nIn [1]: np.random.seed(1234)\n\nIn [2]: df = pd.DataFrame({'A': range(10), 'B': np.random.randn(10)})\n\nIn [3]: df\nOut[3]: \n A         B\n0  0  0.471435\n1  1 -1.190976\n2  2  1.432707\n3  3 -0.312652\n4  4 -0.720589\n5  5  0.887163\n6  6  0.859588\n7  7 -0.636524\n8  8  0.015696\n9  9 -2.242685\n\n[10 rows x 2 columns] \n```", "```py\nIn [8]: pd.rolling_mean(df, window=3)\n FutureWarning: pd.rolling_mean is deprecated for DataFrame and will be removed in a future version, replace with\n DataFrame.rolling(window=3,center=False).mean()\nOut[8]:\n A         B\n0 NaN       NaN\n1 NaN       NaN\n2   1  0.237722\n3   2 -0.023640\n4   3  0.133155\n5   4 -0.048693\n6   5  0.342054\n7   6  0.370076\n8   7  0.079587\n9   8 -0.954504 \n```", "```py\nIn [4]: r = df.rolling(window=3) \n```", "```py\nIn [5]: r\nOut[5]: Rolling [window=3,center=False,axis=0,method=single] \n```", "```py\nIn [9]: r.<TAB>  # noqa E225, E999\nr.A           r.agg         r.apply       r.count       r.exclusions  r.max         r.median      r.name        r.skew        r.sum\nr.B           r.aggregate   r.corr        r.cov         r.kurt        r.mean        r.min         r.quantile    r.std         r.var \n```", "```py\nIn [6]: r.mean()\nOut[6]: \n A         B\n0  NaN       NaN\n1  NaN       NaN\n2  1.0  0.237722\n3  2.0 -0.023640\n4  3.0  0.133155\n5  4.0 -0.048693\n6  5.0  0.342054\n7  6.0  0.370076\n8  7.0  0.079587\n9  8.0 -0.954504\n\n[10 rows x 2 columns] \n```", "```py\nIn [7]: r['A'].mean()\nOut[7]: \n0    NaN\n1    NaN\n2    1.0\n3    2.0\n4    3.0\n5    4.0\n6    5.0\n7    6.0\n8    7.0\n9    8.0\nName: A, Length: 10, dtype: float64 \n```", "```py\nIn [8]: r.agg({'A': ['mean', 'std'],\n ...:       'B': ['mean', 'std']})\n ...: \nOut[8]: \n A              B \n mean  std      mean       std\n0  NaN  NaN       NaN       NaN\n1  NaN  NaN       NaN       NaN\n2  1.0  1.0  0.237722  1.327364\n3  2.0  1.0 -0.023640  1.335505\n4  3.0  1.0  0.133155  1.143778\n5  4.0  1.0 -0.048693  0.835747\n6  5.0  1.0  0.342054  0.920379\n7  6.0  1.0  0.370076  0.871850\n8  7.0  1.0  0.079587  0.750099\n9  8.0  1.0 -0.954504  1.162285\n\n[10 rows x 4 columns] \n```", "```py\nIn [9]: s = pd.Series(np.random.randn(5))\n\nIn [10]: s.rename('newname')\nOut[10]: \n0    1.150036\n1    0.991946\n2    0.953324\n3   -2.021255\n4   -0.334077\nName: newname, Length: 5, dtype: float64 \n```", "```py\nIn [11]: df = pd.DataFrame(np.random.randn(5, 2))\n\nIn [12]: (df.rename_axis(\"indexname\")\n ....:   .rename_axis(\"columns_name\", axis=\"columns\"))\n ....: \nOut[12]: \ncolumns_name         0         1\nindexname \n0             0.002118  0.405453\n1             0.289092  1.321158\n2            -1.546906 -0.202646\n3            -0.655969  0.193421\n4             0.553439  1.318152\n\n[5 rows x 2 columns] \n```", "```py\nIn [3]: s = pd.Series(range(1000))\n\nIn [4]: s.index\nOut[4]:\nInt64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n ...\n 990, 991, 992, 993, 994, 995, 996, 997, 998, 999], dtype='int64', length=1000)\n\nIn [6]: s.index.nbytes\nOut[6]: 8000 \n```", "```py\nIn [13]: s = pd.Series(range(1000))\n\nIn [14]: s.index\nOut[14]: RangeIndex(start=0, stop=1000, step=1)\n\nIn [15]: s.index.nbytes\nOut[15]: 128 \n```", "```py\nIn [1]: pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=None)\nFutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame)\nbut in a future version of pandas this will be changed to expand=True (return DataFrame)\n\nOut[1]:\n0      1\n1      2\n2    NaN\ndtype: object \n```", "```py\nIn [16]: pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=False)\nOut[16]: \n0      1\n1      2\n2    NaN\nLength: 3, dtype: object \n```", "```py\nIn [17]: pd.Series(['a1', 'b2', 'c3']).str.extract(r'[ab](\\d)', expand=True)\nOut[17]: \n 0\n0    1\n1    2\n2  NaN\n\n[3 rows x 1 columns] \n```", "```py\nIn [18]: s = pd.Series([\"a1\", \"b2\", \"c3\"], [\"A11\", \"B22\", \"C33\"])\n\nIn [19]: s.index\nOut[19]: Index(['A11', 'B22', 'C33'], dtype='object')\n\nIn [20]: s.index.str.extract(\"(?P<letter>[a-zA-Z])\", expand=False)\nOut[20]: Index(['A', 'B', 'C'], dtype='object', name='letter') \n```", "```py\nIn [21]: s.index.str.extract(\"(?P<letter>[a-zA-Z])\", expand=True)\nOut[21]: \n letter\n0      A\n1      B\n2      C\n\n[3 rows x 1 columns] \n```", "```py\n>>> s.index.str.extract(\"(?P<letter>[a-zA-Z])([0-9]+)\", expand=False)\nValueError: only one regex group is supported with Index \n```", "```py\nIn [22]: s.index.str.extract(\"(?P<letter>[a-zA-Z])([0-9]+)\", expand=True)\nOut[22]: \n letter   1\n0      A  11\n1      B  22\n2      C  33\n\n[3 rows x 2 columns] \n```", "```py\nIn [23]: s = pd.Series([\"a1a2\", \"b1\", \"c1\"], [\"A\", \"B\", \"C\"])\n\nIn [24]: s\nOut[24]: \nA    a1a2\nB      b1\nC      c1\nLength: 3, dtype: object\n\nIn [25]: s.str.extract(r\"(?P<letter>[ab])(?P<digit>\\d)\", expand=False)\nOut[25]: \n letter digit\nA      a     1\nB      b     1\nC    NaN   NaN\n\n[3 rows x 2 columns] \n```", "```py\nIn [26]: s.str.extractall(r\"(?P<letter>[ab])(?P<digit>\\d)\")\nOut[26]: \n letter digit\n match \nA 0          a     1\n 1          a     2\nB 0          b     1\n\n[3 rows x 2 columns] \n```", "```py\nIn [27]: pd.Series(['a', 'b', np.nan, 'c']).str.cat(sep=' ')\nOut[27]: 'a b c'\n\nIn [28]: pd.Series(['a', 'b', np.nan, 'c']).str.cat(sep=' ', na_rep='?')\nOut[28]: 'a b ? c' \n```", "```py\nIn [2]: pd.Series(['a', 'b', np.nan, 'c']).str.cat(' ')\nValueError: Did you mean to supply a ``sep`` keyword? \n```", "```py\nIn [29]: dr = pd.date_range('20130101 09:12:56.1234', periods=3)\n\nIn [30]: dr\nOut[30]: \nDatetimeIndex(['2013-01-01 09:12:56.123400', '2013-01-02 09:12:56.123400',\n '2013-01-03 09:12:56.123400'],\n dtype='datetime64[ns]', freq='D')\n\nIn [31]: dr.round('s')\nOut[31]: \nDatetimeIndex(['2013-01-01 09:12:56', '2013-01-02 09:12:56',\n '2013-01-03 09:12:56'],\n dtype='datetime64[ns]', freq=None)\n\n# Timestamp scalar\nIn [32]: dr[0]\nOut[32]: Timestamp('2013-01-01 09:12:56.123400')\n\nIn [33]: dr[0].round('10s')\nOut[33]: Timestamp('2013-01-01 09:13:00') \n```", "```py\nIn [34]: dr = dr.tz_localize('US/Eastern')\n\nIn [35]: dr\nOut[35]: \nDatetimeIndex(['2013-01-01 09:12:56.123400-05:00',\n '2013-01-02 09:12:56.123400-05:00',\n '2013-01-03 09:12:56.123400-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None)\n\nIn [36]: dr.round('s')\nOut[36]: \nDatetimeIndex(['2013-01-01 09:12:56-05:00', '2013-01-02 09:12:56-05:00',\n '2013-01-03 09:12:56-05:00'],\n dtype='datetime64[ns, US/Eastern]', freq=None) \n```", "```py\nIn [37]: t = pd.timedelta_range('1 days 2 hr 13 min 45 us', periods=3, freq='d')\n\nIn [38]: t\nOut[38]: \nTimedeltaIndex(['1 days 02:13:00.000045', '2 days 02:13:00.000045',\n '3 days 02:13:00.000045'],\n dtype='timedelta64[ns]', freq='D')\n\nIn [39]: t.round('10min')\nOut[39]: TimedeltaIndex(['1 days 02:10:00', '2 days 02:10:00', '3 days 02:10:00'], dtype='timedelta64[ns]', freq=None)\n\n# Timedelta scalar\nIn [40]: t[0]\nOut[40]: Timedelta('1 days 02:13:00.000045')\n\nIn [41]: t[0].round('2h')\nOut[41]: Timedelta('1 days 02:00:00') \n```", "```py\nIn [42]: s = pd.Series(dr)\n\nIn [43]: s\nOut[43]: \n0   2013-01-01 09:12:56.123400-05:00\n1   2013-01-02 09:12:56.123400-05:00\n2   2013-01-03 09:12:56.123400-05:00\nLength: 3, dtype: datetime64[ns, US/Eastern]\n\nIn [44]: s.dt.round('D')\nOut[44]: \n0   2013-01-01 00:00:00-05:00\n1   2013-01-02 00:00:00-05:00\n2   2013-01-03 00:00:00-05:00\nLength: 3, dtype: datetime64[ns, US/Eastern] \n```", "```py\nIn [2]: s = pd.Series([1, 2, 3], index=np.arange(3.))\n\nIn [3]: s\nOut[3]:\n0    1\n1    2\n2    3\ndtype: int64\n\nIn [4]: s.index\nOut[4]: Float64Index([0.0, 1.0, 2.0], dtype='float64')\n\nIn [5]: print(s.to_csv(path=None))\n0,1\n1,2\n2,3 \n```", "```py\nIn [45]: s = pd.Series([1, 2, 3], index=np.arange(3.))\n\nIn [46]: s\nOut[46]: \n0.0    1\n1.0    2\n2.0    3\nLength: 3, dtype: int64\n\nIn [47]: s.index\nOut[47]: Index([0.0, 1.0, 2.0], dtype='float64')\n\nIn [48]: print(s.to_csv(path_or_buf=None, header=False))\n0.0,1\n1.0,2\n2.0,3 \n```", "```py\nIn [5]: df = pd.DataFrame({'a': [0, 1, 1],\n 'b': pd.Series([100, 200, 300], dtype='uint32')})\n\nIn [7]: df.dtypes\nOut[7]:\na     int64\nb    uint32\ndtype: object\n\nIn [8]: ix = df['a'] == 1\n\nIn [9]: df.loc[ix, 'b'] = df.loc[ix, 'b']\n\nIn [11]: df.dtypes\nOut[11]:\na    int64\nb    int64\ndtype: object \n```", "```py\nIn [49]: df = pd.DataFrame({'a': [0, 1, 1],\n ....:                   'b': pd.Series([100, 200, 300], dtype='uint32')})\n ....: \n\nIn [50]: df.dtypes\nOut[50]: \na     int64\nb    uint32\nLength: 2, dtype: object\n\nIn [51]: ix = df['a'] == 1\n\nIn [52]: df.loc[ix, 'b'] = df.loc[ix, 'b']\n\nIn [53]: df.dtypes\nOut[53]: \na     int64\nb    uint32\nLength: 2, dtype: object \n```", "```py\nIn [4]: df = pd.DataFrame(np.array(range(1,10)).reshape(3,3),\n columns=list('abc'),\n index=[[4,4,8], [8,10,12]])\n\nIn [5]: df\nOut[5]:\n a  b  c\n4 8   1  2  3\n 10  4  5  6\n8 12  7  8  9\n\nIn [7]: df.ix[4, 'c'] = np.array([0., 1.])\n\nIn [8]: df\nOut[8]:\n a  b  c\n4 8   1  2  0\n 10  4  5  1\n8 12  7  8  9 \n```", "```py\nIn [54]: df = pd.DataFrame(np.array(range(1,10)).reshape(3,3),\n ....:                  columns=list('abc'),\n ....:                  index=[[4,4,8], [8,10,12]])\n ....: \n\nIn [55]: df\nOut[55]: \n a  b  c\n4 8   1  2  3\n 10  4  5  6\n8 12  7  8  9\n\n[3 rows x 3 columns]\n\nIn [56]: df.loc[4, 'c'] = np.array([0., 1.])\n\nIn [57]: df\nOut[57]: \n a  b  c\n4 8   1  2  0\n 10  4  5  1\n8 12  7  8  9\n\n[3 rows x 3 columns] \n```", "```py\nIn [1]: p = Panel(np.arange(2*3*4).reshape(2,3,4))\n\nIn [2]: p.to_xarray()\nOut[2]:\n<xarray.DataArray (items: 2, major_axis: 3, minor_axis: 4)>\narray([[[ 0,  1,  2,  3],\n [ 4,  5,  6,  7],\n [ 8,  9, 10, 11]],\n\n [[12, 13, 14, 15],\n [16, 17, 18, 19],\n [20, 21, 22, 23]]])\nCoordinates:\n * items       (items) int64 0 1\n * major_axis  (major_axis) int64 0 1 2\n * minor_axis  (minor_axis) int64 0 1 2 3 \n```", "```py\nIn [58]: pd.NaT * 1\nOut[58]: NaT\n\nIn [59]: pd.NaT * 1.5\nOut[59]: NaT\n\nIn [60]: pd.NaT / 2\nOut[60]: NaT\n\nIn [61]: pd.NaT * np.nan\nOut[61]: NaT \n```", "```py\nIn [62]: pd.NaT / pd.NaT\nOut[62]: nan\n\nIn [63]: pd.Timedelta('1s') / pd.NaT\nOut[63]: nan \n```", "```py\nIn [64]: pd.NaT + pd.NaT\nOut[64]: NaT\n\n# same as\nIn [65]: pd.Timedelta('1s') + pd.Timedelta('1s')\nOut[65]: Timedelta('0 days 00:00:02') \n```", "```py\nIn [3]: pd.Timestamp('19900315') + pd.Timestamp('19900315')\nTypeError: unsupported operand type(s) for +: 'Timestamp' and 'Timestamp' \n```", "```py\nIn [1]: pd.Series([pd.NaT], dtype='<M8[ns]') + pd.Series([pd.NaT], dtype='<M8[ns]')\nTypeError: can only operate on a datetimes for subtraction,\n but the operator [__add__] was passed \n```", "```py\nIn [66]: pd.Series([pd.NaT], dtype='<m8[ns]') + pd.Series([pd.NaT], dtype='<m8[ns]')\nOut[66]: \n0   NaT\nLength: 1, dtype: timedelta64[ns] \n```", "```py\nIn [67]: pd.Timedelta('1s') / 2.0\nOut[67]: Timedelta('0 days 00:00:00.500000') \n```", "```py\nIn [68]: ser = pd.Series(pd.timedelta_range('1 day', periods=3))\n\nIn [69]: ser\nOut[69]: \n0   1 days\n1   2 days\n2   3 days\nLength: 3, dtype: timedelta64[ns]\n\nIn [70]: pd.Timestamp('2012-01-01') - ser\nOut[70]: \n0   2011-12-31\n1   2011-12-30\n2   2011-12-29\nLength: 3, dtype: datetime64[ns] \n```", "```py\nIn [3]: pd.Series([0,1]).rank(method='average', na_option='keep',\n ascending=True, pct=False)\nOut[3]:\n0    1\n1    2\ndtype: float64\n\nIn [4]: pd.DataFrame([0,1]).rank(axis=0, numeric_only=None,\n method='average', na_option='keep',\n ascending=True, pct=False)\nOut[4]:\n 0\n0  1\n1  2 \n```", "```py\nIn [71]: pd.Series([0,1]).rank(axis=0, method='average', numeric_only=False,\n ....:                      na_option='keep', ascending=True, pct=False)\n ....: \nOut[71]: \n0    1.0\n1    2.0\nLength: 2, dtype: float64\n\nIn [72]: pd.DataFrame([0,1]).rank(axis=0, method='average', numeric_only=False,\n ....:                         na_option='keep', ascending=True, pct=False)\n ....: \nOut[72]: \n 0\n0  1.0\n1  2.0\n\n[2 rows x 1 columns] \n```", "```py\nIn [73]: d = pd.Timestamp('2014-02-01')\n\nIn [74]: d\nOut[74]: Timestamp('2014-02-01 00:00:00')\n\nIn [75]: d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\nOut[75]: Timestamp('2014-02-01 00:00:00')\n\nIn [76]: d + pd.offsets.QuarterBegin(n=0, startingMonth=1)\nOut[76]: Timestamp('2014-04-01 00:00:00') \n```", "```py\nIn [3]: d = pd.Timestamp('2014-02-15')\n\nIn [4]: d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\nOut[4]: Timestamp('2014-02-01 00:00:00') \n```", "```py\nIn [77]: d = pd.Timestamp('2014-02-15')\n\nIn [78]: d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\nOut[78]: Timestamp('2014-05-01 00:00:00') \n```", "```py\nIn [79]: np.random.seed(1234)\n\nIn [80]: df = pd.DataFrame(np.random.rand(10,4),\n ....:                  columns=list('ABCD'),\n ....:                  index=pd.date_range('2010-01-01 09:00:00',\n ....:                                      periods=10, freq='s'))\n ....: \n\nIn [81]: df\nOut[81]: \n A         B         C         D\n2010-01-01 09:00:00  0.191519  0.622109  0.437728  0.785359\n2010-01-01 09:00:01  0.779976  0.272593  0.276464  0.801872\n2010-01-01 09:00:02  0.958139  0.875933  0.357817  0.500995\n2010-01-01 09:00:03  0.683463  0.712702  0.370251  0.561196\n2010-01-01 09:00:04  0.503083  0.013768  0.772827  0.882641\n2010-01-01 09:00:05  0.364886  0.615396  0.075381  0.368824\n2010-01-01 09:00:06  0.933140  0.651378  0.397203  0.788730\n2010-01-01 09:00:07  0.316836  0.568099  0.869127  0.436173\n2010-01-01 09:00:08  0.802148  0.143767  0.704261  0.704581\n2010-01-01 09:00:09  0.218792  0.924868  0.442141  0.909316\n\n[10 rows x 4 columns] \n```", "```py\nIn [6]: df.resample('2s')\nOut[6]:\n A         B         C         D\n2010-01-01 09:00:00  0.485748  0.447351  0.357096  0.793615\n2010-01-01 09:00:02  0.820801  0.794317  0.364034  0.531096\n2010-01-01 09:00:04  0.433985  0.314582  0.424104  0.625733\n2010-01-01 09:00:06  0.624988  0.609738  0.633165  0.612452\n2010-01-01 09:00:08  0.510470  0.534317  0.573201  0.806949 \n```", "```py\nIn [7]: df.resample('2s', how='sum')\nOut[7]:\n A         B         C         D\n2010-01-01 09:00:00  0.971495  0.894701  0.714192  1.587231\n2010-01-01 09:00:02  1.641602  1.588635  0.728068  1.062191\n2010-01-01 09:00:04  0.867969  0.629165  0.848208  1.251465\n2010-01-01 09:00:06  1.249976  1.219477  1.266330  1.224904\n2010-01-01 09:00:08  1.020940  1.068634  1.146402  1.613897 \n```", "```py\nIn [82]: r = df.resample('2s')\n\nIn [83]: r\nOut[83]: <pandas.core.resample.DatetimeIndexResampler object at 0x7ff230e71c30> \n```", "```py\nIn [84]: r.mean()\nOut[84]: \n A         B         C         D\n2010-01-01 09:00:00  0.485748  0.447351  0.357096  0.793615\n2010-01-01 09:00:02  0.820801  0.794317  0.364034  0.531096\n2010-01-01 09:00:04  0.433985  0.314582  0.424104  0.625733\n2010-01-01 09:00:06  0.624988  0.609738  0.633165  0.612452\n2010-01-01 09:00:08  0.510470  0.534317  0.573201  0.806949\n\n[5 rows x 4 columns] \n```", "```py\nIn [85]: r.sum()\nOut[85]: \n A         B         C         D\n2010-01-01 09:00:00  0.971495  0.894701  0.714192  1.587231\n2010-01-01 09:00:02  1.641602  1.588635  0.728068  1.062191\n2010-01-01 09:00:04  0.867969  0.629165  0.848208  1.251465\n2010-01-01 09:00:06  1.249976  1.219477  1.266330  1.224904\n2010-01-01 09:00:08  1.020940  1.068634  1.146402  1.613897\n\n[5 rows x 4 columns] \n```", "```py\nIn [86]: r[['A','C']].mean()\nOut[86]: \n A         C\n2010-01-01 09:00:00  0.485748  0.357096\n2010-01-01 09:00:02  0.820801  0.364034\n2010-01-01 09:00:04  0.433985  0.424104\n2010-01-01 09:00:06  0.624988  0.633165\n2010-01-01 09:00:08  0.510470  0.573201\n\n[5 rows x 2 columns] \n```", "```py\nIn [87]: r.agg({'A' : 'mean', 'B' : 'sum'})\nOut[87]: \n A         B\n2010-01-01 09:00:00  0.485748  0.894701\n2010-01-01 09:00:02  0.820801  1.588635\n2010-01-01 09:00:04  0.433985  0.629165\n2010-01-01 09:00:06  0.624988  1.219477\n2010-01-01 09:00:08  0.510470  1.068634\n\n[5 rows x 2 columns] \n```", "```py\nIn [88]: r[['A','B']].agg(['mean','sum'])\nOut[88]: \n A                   B \n mean       sum      mean       sum\n2010-01-01 09:00:00  0.485748  0.971495  0.447351  0.894701\n2010-01-01 09:00:02  0.820801  1.641602  0.794317  1.588635\n2010-01-01 09:00:04  0.433985  0.867969  0.314582  0.629165\n2010-01-01 09:00:06  0.624988  1.249976  0.609738  1.219477\n2010-01-01 09:00:08  0.510470  1.020940  0.534317  1.068634\n\n[5 rows x 4 columns] \n```", "```py\nIn [89]: s = pd.Series(np.arange(5, dtype='int64'),\n index=pd.date_range('2010-01-01', periods=5, freq='Q'))\n\nIn [90]: s\nOut[90]:\n2010-03-31    0\n2010-06-30    1\n2010-09-30    2\n2010-12-31    3\n2011-03-31    4\nFreq: Q-DEC, Length: 5, dtype: int64 \n```", "```py\nIn [6]: s.resample('M', fill_method='ffill')\nOut[6]:\n2010-03-31    0\n2010-04-30    0\n2010-05-31    0\n2010-06-30    1\n2010-07-31    1\n2010-08-31    1\n2010-09-30    2\n2010-10-31    2\n2010-11-30    2\n2010-12-31    3\n2011-01-31    3\n2011-02-28    3\n2011-03-31    4\nFreq: M, dtype: int64 \n```", "```py\nIn [91]: s.resample('M').ffill()\nOut[91]:\n2010-03-31    0\n2010-04-30    0\n2010-05-31    0\n2010-06-30    1\n2010-07-31    1\n2010-08-31    1\n2010-09-30    2\n2010-10-31    2\n2010-11-30    2\n2010-12-31    3\n2011-01-31    3\n2011-02-28    3\n2011-03-31    4\nFreq: M, Length: 13, dtype: int64 \n```", "```py\nIn [4]: r = df.resample('2s')\n\nIn [6]: r*10\npandas/tseries/resample.py:80: FutureWarning: .resample() is now a deferred operation\nuse .resample(...).mean() instead of .resample(...)\n\nOut[6]:\n A         B         C         D\n2010-01-01 09:00:00  4.857476  4.473507  3.570960  7.936154\n2010-01-01 09:00:02  8.208011  7.943173  3.640340  5.310957\n2010-01-01 09:00:04  4.339846  3.145823  4.241039  6.257326\n2010-01-01 09:00:06  6.249881  6.097384  6.331650  6.124518\n2010-01-01 09:00:08  5.104699  5.343172  5.732009  8.069486 \n```", "```py\nIn [7]: r.iloc[0] = 5\nValueError: .resample() is now a deferred operation\nuse .resample(...).mean() instead of .resample(...) \n```", "```py\nIn [4]: df.resample('2s').min()\nOut[4]:\nA    0.433985\nB    0.314582\nC    0.357096\nD    0.531096\ndtype: float64 \n```", "```py\nIn [89]: df.resample('2s').min()\nOut[89]: \n A         B         C         D\n2010-01-01 09:00:00  0.191519  0.272593  0.276464  0.785359\n2010-01-01 09:00:02  0.683463  0.712702  0.357817  0.500995\n2010-01-01 09:00:04  0.364886  0.013768  0.075381  0.368824\n2010-01-01 09:00:06  0.316836  0.568099  0.397203  0.436173\n2010-01-01 09:00:08  0.218792  0.143767  0.442141  0.704581\n\n[5 rows x 4 columns] \n```", "```py\nIn [90]: df.resample('2s').mean().min()\nOut[90]: \nA    0.433985\nB    0.314582\nC    0.357096\nD    0.531096\nLength: 4, dtype: float64 \n```", "```py\nIn [91]: df = pd.DataFrame({'a': np.linspace(0, 10, 5), 'b': range(5)})\n\nIn [92]: df\nOut[92]: \n a  b\n0   0.0  0\n1   2.5  1\n2   5.0  2\n3   7.5  3\n4  10.0  4\n\n[5 rows x 2 columns] \n```", "```py\nIn [12]: df.eval('c = a + b')\nFutureWarning: eval expressions containing an assignment currentlydefault to operating inplace.\nThis will change in a future version of pandas, use inplace=True to avoid this warning.\n\nIn [13]: df\nOut[13]:\n a  b     c\n0   0.0  0   0.0\n1   2.5  1   3.5\n2   5.0  2   7.0\n3   7.5  3  10.5\n4  10.0  4  14.0 \n```", "```py\nIn [93]: df\nOut[93]: \n a  b     c\n0   0.0  0   0.0\n1   2.5  1   3.5\n2   5.0  2   7.0\n3   7.5  3  10.5\n4  10.0  4  14.0\n\n[5 rows x 3 columns]\n\nIn [94]: df.eval('d = c - b', inplace=False)\nOut[94]: \n a  b     c     d\n0   0.0  0   0.0   0.0\n1   2.5  1   3.5   2.5\n2   5.0  2   7.0   5.0\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[5 rows x 4 columns]\n\nIn [95]: df\nOut[95]: \n a  b     c\n0   0.0  0   0.0\n1   2.5  1   3.5\n2   5.0  2   7.0\n3   7.5  3  10.5\n4  10.0  4  14.0\n\n[5 rows x 3 columns]\n\nIn [96]: df.eval('d = c - b', inplace=True)\n\nIn [97]: df\nOut[97]: \n a  b     c     d\n0   0.0  0   0.0   0.0\n1   2.5  1   3.5   2.5\n2   5.0  2   7.0   5.0\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[5 rows x 4 columns] \n```", "```py\nIn [98]: df.query('a > 5')\nOut[98]: \n a  b     c     d\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[2 rows x 4 columns]\n\nIn [99]: df.query('a > 5', inplace=True)\n\nIn [100]: df\nOut[100]: \n a  b     c     d\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[2 rows x 4 columns] \n```", "```py\nIn [101]: df\nOut[101]: \n a  b     c     d\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[2 rows x 4 columns]\n\nIn [102]: df.eval(\"\"\"\n .....: e = d + a\n .....: f = e - 22\n .....: g = f / 2.0\"\"\", inplace=True)\n .....: \n\nIn [103]: df\nOut[103]: \n a  b     c     d     e    f    g\n3   7.5  3  10.5   7.5  15.0 -7.0 -3.5\n4  10.0  4  14.0  10.0  20.0 -2.0 -1.0\n\n[2 rows x 7 columns] \n```", "```py\n    In [107]: s = pd.Series(range(10), pd.date_range('2015-01-01', freq='H', periods=10))\n\n    In [108]: s.between_time(\"7:00am\", \"9:00am\")\n    Out[108]:\n    2015-01-01 07:00:00    7\n    2015-01-01 08:00:00    8\n    2015-01-01 09:00:00    9\n    Freq: H, Length: 3, dtype: int64 \n    ```", "```py\n    In [2]: s.between_time('20150101 07:00:00','20150101 09:00:00')\n    ValueError: Cannot convert arg ['20150101 07:00:00'] to a time. \n    ```", "```py\n    In [1]: s = pd.Series(range(3))\n\n    In [2]: pd.rolling_mean(s,window=2,min_periods=1)\n     FutureWarning: pd.rolling_mean is deprecated for Series and\n     will be removed in a future version, replace with\n     Series.rolling(min_periods=1,window=2,center=False).mean()\n    Out[2]:\n     0    0.0\n     1    0.5\n     2    1.5\n     dtype: float64\n\n    In [3]: pd.rolling_cov(s, s, window=2)\n     FutureWarning: pd.rolling_cov is deprecated for Series and\n     will be removed in a future version, replace with\n     Series.rolling(window=2).cov(other=<Series>)\n    Out[3]:\n     0    NaN\n     1    0.5\n     2    0.5\n     dtype: float64 \n    ```", "```py\nIn [104]: s = pd.Series([1, 2, 3], index=[4, 5, 6])\n\nIn [105]: s\nOut[105]: \n4    1\n5    2\n6    3\nLength: 3, dtype: int64\n\nIn [106]: s2 = pd.Series([1, 2, 3], index=list('abc'))\n\nIn [107]: s2\nOut[107]: \na    1\nb    2\nc    3\nLength: 3, dtype: int64 \n```", "```py\n# this is label indexing\nIn [2]: s[5.0]\nFutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\nOut[2]: 2\n\n# this is positional indexing\nIn [3]: s.iloc[1.0]\nFutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\nOut[3]: 2\n\n# this is label indexing\nIn [4]: s.loc[5.0]\nFutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\nOut[4]: 2\n\n# .ix would coerce 1.0 to the positional 1, and index\nIn [5]: s2.ix[1.0] = 10\nFutureWarning: scalar indexers for index type Index should be integers and not floating point\n\nIn [6]: s2\nOut[6]:\na     1\nb    10\nc     3\ndtype: int64 \n```", "```py\nIn [3]: s.iloc[2.0]\nTypeError: cannot do label indexing on <class 'pandas.indexes.numeric.Int64Index'> with these indexers [2.0] of <type 'float'> \n```", "```py\nIn [108]: s[5.0]\nOut[108]: 2\n\nIn [109]: s.loc[5.0]\nOut[109]: 2 \n```", "```py\nIn [110]: s_copy = s.copy()\n\nIn [111]: s_copy[5.0] = 10\n\nIn [112]: s_copy\nOut[112]: \n4     1\n5    10\n6     3\nLength: 3, dtype: int64\n\nIn [113]: s_copy = s.copy()\n\nIn [114]: s_copy.loc[5.0] = 10\n\nIn [115]: s_copy\nOut[115]: \n4     1\n5    10\n6     3\nLength: 3, dtype: int64 \n```", "```py\nIn [3]: s2.ix[1.0] = 10\nIn [4]: s2\nOut[4]:\na       1\nb       2\nc       3\n1.0    10\ndtype: int64 \n```", "```py\nIn [116]: s.loc[5.0:6]\nOut[116]: \n5    2\n6    3\nLength: 2, dtype: int64 \n```", "```py\nIn [117]: s.loc[5.1:6]\nOut[117]: \n6    3\nLength: 1, dtype: int64 \n```", "```py\nIn [118]: s = pd.Series([1, 2, 3], index=np.arange(3.))\n\nIn [119]: s[1.0]\nOut[119]: 2\n\nIn [120]: s[1.0:2.5]\nOut[120]: \n1.0    2\n2.0    3\nLength: 2, dtype: int64 \n```", "```py\nIn [58]: pd.NaT * 1\nOut[58]: NaT\n\nIn [59]: pd.NaT * 1.5\nOut[59]: NaT\n\nIn [60]: pd.NaT / 2\nOut[60]: NaT\n\nIn [61]: pd.NaT * np.nan\nOut[61]: NaT \n```", "```py\nIn [62]: pd.NaT / pd.NaT\nOut[62]: nan\n\nIn [63]: pd.Timedelta('1s') / pd.NaT\nOut[63]: nan \n```", "```py\nIn [64]: pd.NaT + pd.NaT\nOut[64]: NaT\n\n# same as\nIn [65]: pd.Timedelta('1s') + pd.Timedelta('1s')\nOut[65]: Timedelta('0 days 00:00:02') \n```", "```py\nIn [3]: pd.Timestamp('19900315') + pd.Timestamp('19900315')\nTypeError: unsupported operand type(s) for +: 'Timestamp' and 'Timestamp' \n```", "```py\nIn [1]: pd.Series([pd.NaT], dtype='<M8[ns]') + pd.Series([pd.NaT], dtype='<M8[ns]')\nTypeError: can only operate on a datetimes for subtraction,\n but the operator [__add__] was passed \n```", "```py\nIn [66]: pd.Series([pd.NaT], dtype='<m8[ns]') + pd.Series([pd.NaT], dtype='<m8[ns]')\nOut[66]: \n0   NaT\nLength: 1, dtype: timedelta64[ns] \n```", "```py\nIn [67]: pd.Timedelta('1s') / 2.0\nOut[67]: Timedelta('0 days 00:00:00.500000') \n```", "```py\nIn [68]: ser = pd.Series(pd.timedelta_range('1 day', periods=3))\n\nIn [69]: ser\nOut[69]: \n0   1 days\n1   2 days\n2   3 days\nLength: 3, dtype: timedelta64[ns]\n\nIn [70]: pd.Timestamp('2012-01-01') - ser\nOut[70]: \n0   2011-12-31\n1   2011-12-30\n2   2011-12-29\nLength: 3, dtype: datetime64[ns] \n```", "```py\nIn [3]: pd.Series([0,1]).rank(method='average', na_option='keep',\n ascending=True, pct=False)\nOut[3]:\n0    1\n1    2\ndtype: float64\n\nIn [4]: pd.DataFrame([0,1]).rank(axis=0, numeric_only=None,\n method='average', na_option='keep',\n ascending=True, pct=False)\nOut[4]:\n 0\n0  1\n1  2 \n```", "```py\nIn [71]: pd.Series([0,1]).rank(axis=0, method='average', numeric_only=False,\n ....:                      na_option='keep', ascending=True, pct=False)\n ....: \nOut[71]: \n0    1.0\n1    2.0\nLength: 2, dtype: float64\n\nIn [72]: pd.DataFrame([0,1]).rank(axis=0, method='average', numeric_only=False,\n ....:                         na_option='keep', ascending=True, pct=False)\n ....: \nOut[72]: \n 0\n0  1.0\n1  2.0\n\n[2 rows x 1 columns] \n```", "```py\nIn [73]: d = pd.Timestamp('2014-02-01')\n\nIn [74]: d\nOut[74]: Timestamp('2014-02-01 00:00:00')\n\nIn [75]: d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\nOut[75]: Timestamp('2014-02-01 00:00:00')\n\nIn [76]: d + pd.offsets.QuarterBegin(n=0, startingMonth=1)\nOut[76]: Timestamp('2014-04-01 00:00:00') \n```", "```py\nIn [3]: d = pd.Timestamp('2014-02-15')\n\nIn [4]: d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\nOut[4]: Timestamp('2014-02-01 00:00:00') \n```", "```py\nIn [77]: d = pd.Timestamp('2014-02-15')\n\nIn [78]: d + pd.offsets.QuarterBegin(n=0, startingMonth=2)\nOut[78]: Timestamp('2014-05-01 00:00:00') \n```", "```py\nIn [79]: np.random.seed(1234)\n\nIn [80]: df = pd.DataFrame(np.random.rand(10,4),\n ....:                  columns=list('ABCD'),\n ....:                  index=pd.date_range('2010-01-01 09:00:00',\n ....:                                      periods=10, freq='s'))\n ....: \n\nIn [81]: df\nOut[81]: \n A         B         C         D\n2010-01-01 09:00:00  0.191519  0.622109  0.437728  0.785359\n2010-01-01 09:00:01  0.779976  0.272593  0.276464  0.801872\n2010-01-01 09:00:02  0.958139  0.875933  0.357817  0.500995\n2010-01-01 09:00:03  0.683463  0.712702  0.370251  0.561196\n2010-01-01 09:00:04  0.503083  0.013768  0.772827  0.882641\n2010-01-01 09:00:05  0.364886  0.615396  0.075381  0.368824\n2010-01-01 09:00:06  0.933140  0.651378  0.397203  0.788730\n2010-01-01 09:00:07  0.316836  0.568099  0.869127  0.436173\n2010-01-01 09:00:08  0.802148  0.143767  0.704261  0.704581\n2010-01-01 09:00:09  0.218792  0.924868  0.442141  0.909316\n\n[10 rows x 4 columns] \n```", "```py\nIn [6]: df.resample('2s')\nOut[6]:\n A         B         C         D\n2010-01-01 09:00:00  0.485748  0.447351  0.357096  0.793615\n2010-01-01 09:00:02  0.820801  0.794317  0.364034  0.531096\n2010-01-01 09:00:04  0.433985  0.314582  0.424104  0.625733\n2010-01-01 09:00:06  0.624988  0.609738  0.633165  0.612452\n2010-01-01 09:00:08  0.510470  0.534317  0.573201  0.806949 \n```", "```py\nIn [7]: df.resample('2s', how='sum')\nOut[7]:\n A         B         C         D\n2010-01-01 09:00:00  0.971495  0.894701  0.714192  1.587231\n2010-01-01 09:00:02  1.641602  1.588635  0.728068  1.062191\n2010-01-01 09:00:04  0.867969  0.629165  0.848208  1.251465\n2010-01-01 09:00:06  1.249976  1.219477  1.266330  1.224904\n2010-01-01 09:00:08  1.020940  1.068634  1.146402  1.613897 \n```", "```py\nIn [82]: r = df.resample('2s')\n\nIn [83]: r\nOut[83]: <pandas.core.resample.DatetimeIndexResampler object at 0x7ff230e71c30> \n```", "```py\nIn [84]: r.mean()\nOut[84]: \n A         B         C         D\n2010-01-01 09:00:00  0.485748  0.447351  0.357096  0.793615\n2010-01-01 09:00:02  0.820801  0.794317  0.364034  0.531096\n2010-01-01 09:00:04  0.433985  0.314582  0.424104  0.625733\n2010-01-01 09:00:06  0.624988  0.609738  0.633165  0.612452\n2010-01-01 09:00:08  0.510470  0.534317  0.573201  0.806949\n\n[5 rows x 4 columns] \n```", "```py\nIn [85]: r.sum()\nOut[85]: \n A         B         C         D\n2010-01-01 09:00:00  0.971495  0.894701  0.714192  1.587231\n2010-01-01 09:00:02  1.641602  1.588635  0.728068  1.062191\n2010-01-01 09:00:04  0.867969  0.629165  0.848208  1.251465\n2010-01-01 09:00:06  1.249976  1.219477  1.266330  1.224904\n2010-01-01 09:00:08  1.020940  1.068634  1.146402  1.613897\n\n[5 rows x 4 columns] \n```", "```py\nIn [86]: r[['A','C']].mean()\nOut[86]: \n A         C\n2010-01-01 09:00:00  0.485748  0.357096\n2010-01-01 09:00:02  0.820801  0.364034\n2010-01-01 09:00:04  0.433985  0.424104\n2010-01-01 09:00:06  0.624988  0.633165\n2010-01-01 09:00:08  0.510470  0.573201\n\n[5 rows x 2 columns] \n```", "```py\nIn [87]: r.agg({'A' : 'mean', 'B' : 'sum'})\nOut[87]: \n A         B\n2010-01-01 09:00:00  0.485748  0.894701\n2010-01-01 09:00:02  0.820801  1.588635\n2010-01-01 09:00:04  0.433985  0.629165\n2010-01-01 09:00:06  0.624988  1.219477\n2010-01-01 09:00:08  0.510470  1.068634\n\n[5 rows x 2 columns] \n```", "```py\nIn [88]: r[['A','B']].agg(['mean','sum'])\nOut[88]: \n A                   B \n mean       sum      mean       sum\n2010-01-01 09:00:00  0.485748  0.971495  0.447351  0.894701\n2010-01-01 09:00:02  0.820801  1.641602  0.794317  1.588635\n2010-01-01 09:00:04  0.433985  0.867969  0.314582  0.629165\n2010-01-01 09:00:06  0.624988  1.249976  0.609738  1.219477\n2010-01-01 09:00:08  0.510470  1.020940  0.534317  1.068634\n\n[5 rows x 4 columns] \n```", "```py\nIn [89]: s = pd.Series(np.arange(5, dtype='int64'),\n index=pd.date_range('2010-01-01', periods=5, freq='Q'))\n\nIn [90]: s\nOut[90]:\n2010-03-31    0\n2010-06-30    1\n2010-09-30    2\n2010-12-31    3\n2011-03-31    4\nFreq: Q-DEC, Length: 5, dtype: int64 \n```", "```py\nIn [6]: s.resample('M', fill_method='ffill')\nOut[6]:\n2010-03-31    0\n2010-04-30    0\n2010-05-31    0\n2010-06-30    1\n2010-07-31    1\n2010-08-31    1\n2010-09-30    2\n2010-10-31    2\n2010-11-30    2\n2010-12-31    3\n2011-01-31    3\n2011-02-28    3\n2011-03-31    4\nFreq: M, dtype: int64 \n```", "```py\nIn [91]: s.resample('M').ffill()\nOut[91]:\n2010-03-31    0\n2010-04-30    0\n2010-05-31    0\n2010-06-30    1\n2010-07-31    1\n2010-08-31    1\n2010-09-30    2\n2010-10-31    2\n2010-11-30    2\n2010-12-31    3\n2011-01-31    3\n2011-02-28    3\n2011-03-31    4\nFreq: M, Length: 13, dtype: int64 \n```", "```py\nIn [4]: r = df.resample('2s')\n\nIn [6]: r*10\npandas/tseries/resample.py:80: FutureWarning: .resample() is now a deferred operation\nuse .resample(...).mean() instead of .resample(...)\n\nOut[6]:\n A         B         C         D\n2010-01-01 09:00:00  4.857476  4.473507  3.570960  7.936154\n2010-01-01 09:00:02  8.208011  7.943173  3.640340  5.310957\n2010-01-01 09:00:04  4.339846  3.145823  4.241039  6.257326\n2010-01-01 09:00:06  6.249881  6.097384  6.331650  6.124518\n2010-01-01 09:00:08  5.104699  5.343172  5.732009  8.069486 \n```", "```py\nIn [7]: r.iloc[0] = 5\nValueError: .resample() is now a deferred operation\nuse .resample(...).mean() instead of .resample(...) \n```", "```py\nIn [4]: df.resample('2s').min()\nOut[4]:\nA    0.433985\nB    0.314582\nC    0.357096\nD    0.531096\ndtype: float64 \n```", "```py\nIn [89]: df.resample('2s').min()\nOut[89]: \n A         B         C         D\n2010-01-01 09:00:00  0.191519  0.272593  0.276464  0.785359\n2010-01-01 09:00:02  0.683463  0.712702  0.357817  0.500995\n2010-01-01 09:00:04  0.364886  0.013768  0.075381  0.368824\n2010-01-01 09:00:06  0.316836  0.568099  0.397203  0.436173\n2010-01-01 09:00:08  0.218792  0.143767  0.442141  0.704581\n\n[5 rows x 4 columns] \n```", "```py\nIn [90]: df.resample('2s').mean().min()\nOut[90]: \nA    0.433985\nB    0.314582\nC    0.357096\nD    0.531096\nLength: 4, dtype: float64 \n```", "```py\nIn [84]: r.mean()\nOut[84]: \n A         B         C         D\n2010-01-01 09:00:00  0.485748  0.447351  0.357096  0.793615\n2010-01-01 09:00:02  0.820801  0.794317  0.364034  0.531096\n2010-01-01 09:00:04  0.433985  0.314582  0.424104  0.625733\n2010-01-01 09:00:06  0.624988  0.609738  0.633165  0.612452\n2010-01-01 09:00:08  0.510470  0.534317  0.573201  0.806949\n\n[5 rows x 4 columns] \n```", "```py\nIn [85]: r.sum()\nOut[85]: \n A         B         C         D\n2010-01-01 09:00:00  0.971495  0.894701  0.714192  1.587231\n2010-01-01 09:00:02  1.641602  1.588635  0.728068  1.062191\n2010-01-01 09:00:04  0.867969  0.629165  0.848208  1.251465\n2010-01-01 09:00:06  1.249976  1.219477  1.266330  1.224904\n2010-01-01 09:00:08  1.020940  1.068634  1.146402  1.613897\n\n[5 rows x 4 columns] \n```", "```py\nIn [86]: r[['A','C']].mean()\nOut[86]: \n A         C\n2010-01-01 09:00:00  0.485748  0.357096\n2010-01-01 09:00:02  0.820801  0.364034\n2010-01-01 09:00:04  0.433985  0.424104\n2010-01-01 09:00:06  0.624988  0.633165\n2010-01-01 09:00:08  0.510470  0.573201\n\n[5 rows x 2 columns] \n```", "```py\nIn [87]: r.agg({'A' : 'mean', 'B' : 'sum'})\nOut[87]: \n A         B\n2010-01-01 09:00:00  0.485748  0.894701\n2010-01-01 09:00:02  0.820801  1.588635\n2010-01-01 09:00:04  0.433985  0.629165\n2010-01-01 09:00:06  0.624988  1.219477\n2010-01-01 09:00:08  0.510470  1.068634\n\n[5 rows x 2 columns] \n```", "```py\nIn [88]: r[['A','B']].agg(['mean','sum'])\nOut[88]: \n A                   B \n mean       sum      mean       sum\n2010-01-01 09:00:00  0.485748  0.971495  0.447351  0.894701\n2010-01-01 09:00:02  0.820801  1.641602  0.794317  1.588635\n2010-01-01 09:00:04  0.433985  0.867969  0.314582  0.629165\n2010-01-01 09:00:06  0.624988  1.249976  0.609738  1.219477\n2010-01-01 09:00:08  0.510470  1.020940  0.534317  1.068634\n\n[5 rows x 4 columns] \n```", "```py\nIn [89]: s = pd.Series(np.arange(5, dtype='int64'),\n index=pd.date_range('2010-01-01', periods=5, freq='Q'))\n\nIn [90]: s\nOut[90]:\n2010-03-31    0\n2010-06-30    1\n2010-09-30    2\n2010-12-31    3\n2011-03-31    4\nFreq: Q-DEC, Length: 5, dtype: int64 \n```", "```py\nIn [6]: s.resample('M', fill_method='ffill')\nOut[6]:\n2010-03-31    0\n2010-04-30    0\n2010-05-31    0\n2010-06-30    1\n2010-07-31    1\n2010-08-31    1\n2010-09-30    2\n2010-10-31    2\n2010-11-30    2\n2010-12-31    3\n2011-01-31    3\n2011-02-28    3\n2011-03-31    4\nFreq: M, dtype: int64 \n```", "```py\nIn [91]: s.resample('M').ffill()\nOut[91]:\n2010-03-31    0\n2010-04-30    0\n2010-05-31    0\n2010-06-30    1\n2010-07-31    1\n2010-08-31    1\n2010-09-30    2\n2010-10-31    2\n2010-11-30    2\n2010-12-31    3\n2011-01-31    3\n2011-02-28    3\n2011-03-31    4\nFreq: M, Length: 13, dtype: int64 \n```", "```py\nIn [4]: r = df.resample('2s')\n\nIn [6]: r*10\npandas/tseries/resample.py:80: FutureWarning: .resample() is now a deferred operation\nuse .resample(...).mean() instead of .resample(...)\n\nOut[6]:\n A         B         C         D\n2010-01-01 09:00:00  4.857476  4.473507  3.570960  7.936154\n2010-01-01 09:00:02  8.208011  7.943173  3.640340  5.310957\n2010-01-01 09:00:04  4.339846  3.145823  4.241039  6.257326\n2010-01-01 09:00:06  6.249881  6.097384  6.331650  6.124518\n2010-01-01 09:00:08  5.104699  5.343172  5.732009  8.069486 \n```", "```py\nIn [7]: r.iloc[0] = 5\nValueError: .resample() is now a deferred operation\nuse .resample(...).mean() instead of .resample(...) \n```", "```py\nIn [4]: df.resample('2s').min()\nOut[4]:\nA    0.433985\nB    0.314582\nC    0.357096\nD    0.531096\ndtype: float64 \n```", "```py\nIn [89]: df.resample('2s').min()\nOut[89]: \n A         B         C         D\n2010-01-01 09:00:00  0.191519  0.272593  0.276464  0.785359\n2010-01-01 09:00:02  0.683463  0.712702  0.357817  0.500995\n2010-01-01 09:00:04  0.364886  0.013768  0.075381  0.368824\n2010-01-01 09:00:06  0.316836  0.568099  0.397203  0.436173\n2010-01-01 09:00:08  0.218792  0.143767  0.442141  0.704581\n\n[5 rows x 4 columns] \n```", "```py\nIn [90]: df.resample('2s').mean().min()\nOut[90]: \nA    0.433985\nB    0.314582\nC    0.357096\nD    0.531096\nLength: 4, dtype: float64 \n```", "```py\nIn [91]: df = pd.DataFrame({'a': np.linspace(0, 10, 5), 'b': range(5)})\n\nIn [92]: df\nOut[92]: \n a  b\n0   0.0  0\n1   2.5  1\n2   5.0  2\n3   7.5  3\n4  10.0  4\n\n[5 rows x 2 columns] \n```", "```py\nIn [12]: df.eval('c = a + b')\nFutureWarning: eval expressions containing an assignment currentlydefault to operating inplace.\nThis will change in a future version of pandas, use inplace=True to avoid this warning.\n\nIn [13]: df\nOut[13]:\n a  b     c\n0   0.0  0   0.0\n1   2.5  1   3.5\n2   5.0  2   7.0\n3   7.5  3  10.5\n4  10.0  4  14.0 \n```", "```py\nIn [93]: df\nOut[93]: \n a  b     c\n0   0.0  0   0.0\n1   2.5  1   3.5\n2   5.0  2   7.0\n3   7.5  3  10.5\n4  10.0  4  14.0\n\n[5 rows x 3 columns]\n\nIn [94]: df.eval('d = c - b', inplace=False)\nOut[94]: \n a  b     c     d\n0   0.0  0   0.0   0.0\n1   2.5  1   3.5   2.5\n2   5.0  2   7.0   5.0\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[5 rows x 4 columns]\n\nIn [95]: df\nOut[95]: \n a  b     c\n0   0.0  0   0.0\n1   2.5  1   3.5\n2   5.0  2   7.0\n3   7.5  3  10.5\n4  10.0  4  14.0\n\n[5 rows x 3 columns]\n\nIn [96]: df.eval('d = c - b', inplace=True)\n\nIn [97]: df\nOut[97]: \n a  b     c     d\n0   0.0  0   0.0   0.0\n1   2.5  1   3.5   2.5\n2   5.0  2   7.0   5.0\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[5 rows x 4 columns] \n```", "```py\nIn [98]: df.query('a > 5')\nOut[98]: \n a  b     c     d\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[2 rows x 4 columns]\n\nIn [99]: df.query('a > 5', inplace=True)\n\nIn [100]: df\nOut[100]: \n a  b     c     d\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[2 rows x 4 columns] \n```", "```py\nIn [101]: df\nOut[101]: \n a  b     c     d\n3   7.5  3  10.5   7.5\n4  10.0  4  14.0  10.0\n\n[2 rows x 4 columns]\n\nIn [102]: df.eval(\"\"\"\n .....: e = d + a\n .....: f = e - 22\n .....: g = f / 2.0\"\"\", inplace=True)\n .....: \n\nIn [103]: df\nOut[103]: \n a  b     c     d     e    f    g\n3   7.5  3  10.5   7.5  15.0 -7.0 -3.5\n4  10.0  4  14.0  10.0  20.0 -2.0 -1.0\n\n[2 rows x 7 columns] \n```", "```py\n    In [107]: s = pd.Series(range(10), pd.date_range('2015-01-01', freq='H', periods=10))\n\n    In [108]: s.between_time(\"7:00am\", \"9:00am\")\n    Out[108]:\n    2015-01-01 07:00:00    7\n    2015-01-01 08:00:00    8\n    2015-01-01 09:00:00    9\n    Freq: H, Length: 3, dtype: int64 \n    ```", "```py\n    In [2]: s.between_time('20150101 07:00:00','20150101 09:00:00')\n    ValueError: Cannot convert arg ['20150101 07:00:00'] to a time. \n    ```", "```py\n    In [1]: s = pd.Series(range(3))\n\n    In [2]: pd.rolling_mean(s,window=2,min_periods=1)\n     FutureWarning: pd.rolling_mean is deprecated for Series and\n     will be removed in a future version, replace with\n     Series.rolling(min_periods=1,window=2,center=False).mean()\n    Out[2]:\n     0    0.0\n     1    0.5\n     2    1.5\n     dtype: float64\n\n    In [3]: pd.rolling_cov(s, s, window=2)\n     FutureWarning: pd.rolling_cov is deprecated for Series and\n     will be removed in a future version, replace with\n     Series.rolling(window=2).cov(other=<Series>)\n    Out[3]:\n     0    NaN\n     1    0.5\n     2    0.5\n     dtype: float64 \n    ```", "```py\nIn [104]: s = pd.Series([1, 2, 3], index=[4, 5, 6])\n\nIn [105]: s\nOut[105]: \n4    1\n5    2\n6    3\nLength: 3, dtype: int64\n\nIn [106]: s2 = pd.Series([1, 2, 3], index=list('abc'))\n\nIn [107]: s2\nOut[107]: \na    1\nb    2\nc    3\nLength: 3, dtype: int64 \n```", "```py\n# this is label indexing\nIn [2]: s[5.0]\nFutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\nOut[2]: 2\n\n# this is positional indexing\nIn [3]: s.iloc[1.0]\nFutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\nOut[3]: 2\n\n# this is label indexing\nIn [4]: s.loc[5.0]\nFutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\nOut[4]: 2\n\n# .ix would coerce 1.0 to the positional 1, and index\nIn [5]: s2.ix[1.0] = 10\nFutureWarning: scalar indexers for index type Index should be integers and not floating point\n\nIn [6]: s2\nOut[6]:\na     1\nb    10\nc     3\ndtype: int64 \n```", "```py\nIn [3]: s.iloc[2.0]\nTypeError: cannot do label indexing on <class 'pandas.indexes.numeric.Int64Index'> with these indexers [2.0] of <type 'float'> \n```", "```py\nIn [108]: s[5.0]\nOut[108]: 2\n\nIn [109]: s.loc[5.0]\nOut[109]: 2 \n```", "```py\nIn [110]: s_copy = s.copy()\n\nIn [111]: s_copy[5.0] = 10\n\nIn [112]: s_copy\nOut[112]: \n4     1\n5    10\n6     3\nLength: 3, dtype: int64\n\nIn [113]: s_copy = s.copy()\n\nIn [114]: s_copy.loc[5.0] = 10\n\nIn [115]: s_copy\nOut[115]: \n4     1\n5    10\n6     3\nLength: 3, dtype: int64 \n```", "```py\nIn [3]: s2.ix[1.0] = 10\nIn [4]: s2\nOut[4]:\na       1\nb       2\nc       3\n1.0    10\ndtype: int64 \n```", "```py\nIn [116]: s.loc[5.0:6]\nOut[116]: \n5    2\n6    3\nLength: 2, dtype: int64 \n```", "```py\nIn [117]: s.loc[5.1:6]\nOut[117]: \n6    3\nLength: 1, dtype: int64 \n```", "```py\nIn [118]: s = pd.Series([1, 2, 3], index=np.arange(3.))\n\nIn [119]: s[1.0]\nOut[119]: 2\n\nIn [120]: s[1.0:2.5]\nOut[120]: \n1.0    2\n2.0    3\nLength: 2, dtype: int64 \n```"]