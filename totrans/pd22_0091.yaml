- en: pandas.read_parquet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html](https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Load a parquet object from the file path, returning a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**path**str, path object or file-like object'
  prefs: []
  type: TYPE_NORMAL
- en: 'String, path object (implementing `os.PathLike[str]`), or file-like object
    implementing a binary `read()` function. The string could be a URL. Valid URL
    schemes include http, ftp, s3, gs, and file. For file URLs, a host is expected.
    A local file could be: `file://localhost/path/to/table.parquet`. A file URL can
    also be a path to a directory that contains multiple partitioned parquet files.
    Both pyarrow and fastparquet support paths to directories as well as file URLs.
    A directory path could be: `file://localhost/path/to/tables` or `s3://bucket/partition_dir`.'
  prefs: []
  type: TYPE_NORMAL
- en: '**engine**{‘auto’, ‘pyarrow’, ‘fastparquet’}, default ‘auto’'
  prefs: []
  type: TYPE_NORMAL
- en: Parquet library to use. If ‘auto’, then the option `io.parquet.engine` is used.
    The default `io.parquet.engine` behavior is to try ‘pyarrow’, falling back to
    ‘fastparquet’ if ‘pyarrow’ is unavailable.
  prefs: []
  type: TYPE_NORMAL
- en: When using the `'pyarrow'` engine and no storage options are provided and a
    filesystem is implemented by both `pyarrow.fs` and `fsspec` (e.g. “s3://”), then
    the `pyarrow.fs` filesystem is attempted first. Use the filesystem keyword with
    an instantiated fsspec filesystem if you wish to use its implementation.
  prefs: []
  type: TYPE_NORMAL
- en: '**columns**list, default=None'
  prefs: []
  type: TYPE_NORMAL
- en: If not None, only these columns will be read from the file.
  prefs: []
  type: TYPE_NORMAL
- en: '**storage_options**dict, optional'
  prefs: []
  type: TYPE_NORMAL
- en: Extra options that make sense for a particular storage connection, e.g. host,
    port, username, password, etc. For HTTP(S) URLs the key-value pairs are forwarded
    to `urllib.request.Request` as header options. For other URLs (e.g. starting with
    “s3://”, and “gcs://”) the key-value pairs are forwarded to `fsspec.open`. Please
    see `fsspec` and `urllib` for more details, and for more examples on storage options
    refer [here](https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files).
  prefs: []
  type: TYPE_NORMAL
- en: New in version 1.3.0.
  prefs: []
  type: TYPE_NORMAL
- en: '**use_nullable_dtypes**bool, default False'
  prefs: []
  type: TYPE_NORMAL
- en: 'If True, use dtypes that use `pd.NA` as missing value indicator for the resulting
    DataFrame. (only applicable for the `pyarrow` engine) As new dtypes are added
    that support `pd.NA` in the future, the output with this option will change to
    use those dtypes. Note: this is an experimental option, and behaviour (e.g. additional
    support dtypes) may change without notice.'
  prefs: []
  type: TYPE_NORMAL
- en: Deprecated since version 2.0.
  prefs: []
  type: TYPE_NORMAL
- en: '**dtype_backend**{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’'
  prefs: []
  type: TYPE_NORMAL
- en: 'Back-end data type applied to the resultant [`DataFrame`](pandas.DataFrame.html#pandas.DataFrame
    "pandas.DataFrame") (still experimental). Behaviour is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`"numpy_nullable"`: returns nullable-dtype-backed [`DataFrame`](pandas.DataFrame.html#pandas.DataFrame
    "pandas.DataFrame") (default).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"pyarrow"`: returns pyarrow-backed nullable [`ArrowDtype`](pandas.ArrowDtype.html#pandas.ArrowDtype
    "pandas.ArrowDtype") DataFrame.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: New in version 2.0.
  prefs: []
  type: TYPE_NORMAL
- en: '**filesystem**fsspec or pyarrow filesystem, default None'
  prefs: []
  type: TYPE_NORMAL
- en: Filesystem object to use when reading the parquet file. Only implemented for
    `engine="pyarrow"`.
  prefs: []
  type: TYPE_NORMAL
- en: New in version 2.1.0.
  prefs: []
  type: TYPE_NORMAL
- en: '**filters**List[Tuple] or List[List[Tuple]], default None'
  prefs: []
  type: TYPE_NORMAL
- en: 'To filter out data. Filter syntax: [[(column, op, val), …],…] where op is [==,
    =, >, >=, <, <=, !=, in, not in] The innermost tuples are transposed into a set
    of filters applied through an AND operation. The outer list combines these sets
    of filters through an OR operation. A single list of tuples can also be used,
    meaning that no OR operation between set of filters is to be conducted.'
  prefs: []
  type: TYPE_NORMAL
- en: Using this argument will NOT result in row-wise filtering of the final partitions
    unless `engine="pyarrow"` is also specified. For other engines, filtering is only
    performed at the partition level, that is, to prevent the loading of some row-groups
    and/or files.
  prefs: []
  type: TYPE_NORMAL
- en: New in version 2.1.0.
  prefs: []
  type: TYPE_NORMAL
- en: '****kwargs**'
  prefs: []
  type: TYPE_NORMAL
- en: Any additional kwargs are passed to the engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Returns:'
  prefs: []
  type: TYPE_NORMAL
- en: DataFrame
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs: []
  type: TYPE_NORMAL
- en: '[`DataFrame.to_parquet`](pandas.DataFrame.to_parquet.html#pandas.DataFrame.to_parquet
    "pandas.DataFrame.to_parquet")'
  prefs: []
  type: TYPE_NORMAL
- en: Create a parquet object that serializes a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Examples
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The function uses kwargs that are passed directly to the engine. In the following
    example, we use the filters argument of the pyarrow engine to filter the rows
    of the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Since pyarrow is the default engine, we can omit the engine argument. Note that
    the filters argument is implemented by the pyarrow engine, which can benefit from
    multithreading and also potentially be more economical in terms of memory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
