["```py\n`from ultralytics import YOLO  # Load a model model = YOLO(\"yolov8n.pt\")  # pretrained YOLOv8n model  # Run batched inference on a list of images results = model([\"im1.jpg\", \"im2.jpg\"])  # return a list of Results objects  # Process results list for result in results:     boxes = result.boxes  # Boxes object for bounding box outputs     masks = result.masks  # Masks object for segmentation masks outputs     keypoints = result.keypoints  # Keypoints object for pose outputs     probs = result.probs  # Probs object for classification outputs     obb = result.obb  # Oriented boxes object for OBB outputs     result.show()  # display to screen     result.save(filename=\"result.jpg\")  # save to disk` \n```", "```py\n`from ultralytics import YOLO  # Load a model model = YOLO(\"yolov8n.pt\")  # pretrained YOLOv8n model  # Run batched inference on a list of images results = model([\"im1.jpg\", \"im2.jpg\"], stream=True)  # return a generator of Results objects  # Process results generator for result in results:     boxes = result.boxes  # Boxes object for bounding box outputs     masks = result.masks  # Masks object for segmentation masks outputs     keypoints = result.keypoints  # Keypoints object for pose outputs     probs = result.probs  # Probs object for classification outputs     obb = result.obb  # Oriented boxes object for OBB outputs     result.show()  # display to screen     result.save(filename=\"result.jpg\")  # save to disk` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Define path to the image file source = \"path/to/image.jpg\"  # Run inference on the source results = model(source)  # list of Results objects` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Define current screenshot as source source = \"screen\"  # Run inference on the source results = model(source)  # list of Results objects` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Define remote image or video URL source = \"https://ultralytics.com/images/bus.jpg\"  # Run inference on the source results = model(source)  # list of Results objects` \n```", "```py\n`from PIL import Image  from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Open an image using PIL source = Image.open(\"path/to/image.jpg\")  # Run inference on the source results = model(source)  # list of Results objects` \n```", "```py\n`import cv2  from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Read an image using OpenCV source = cv2.imread(\"path/to/image.jpg\")  # Run inference on the source results = model(source)  # list of Results objects` \n```", "```py\n`import numpy as np  from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Create a random numpy array of HWC shape (640, 640, 3) with values in range [0, 255] and type uint8 source = np.random.randint(low=0, high=255, size=(640, 640, 3), dtype=\"uint8\")  # Run inference on the source results = model(source)  # list of Results objects` \n```", "```py\n`import torch  from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Create a random torch tensor of BCHW shape (1, 3, 640, 640) with values in range [0, 1] and type float32 source = torch.rand(1, 3, 640, 640, dtype=torch.float32)  # Run inference on the source results = model(source)  # list of Results objects` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Define a path to a CSV file with images, URLs, videos and directories source = \"path/to/file.csv\"  # Run inference on the source results = model(source)  # list of Results objects` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Define path to video file source = \"path/to/video.mp4\"  # Run inference on the source results = model(source, stream=True)  # generator of Results objects` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Define path to directory containing images and videos for inference source = \"path/to/dir\"  # Run inference on the source results = model(source, stream=True)  # generator of Results objects` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Define a glob search for all JPG files in a directory source = \"path/to/dir/*.jpg\"  # OR define a recursive glob search for all JPG files including subdirectories source = \"path/to/dir/**/*.jpg\"  # Run inference on the source results = model(source, stream=True)  # generator of Results objects` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Define source as YouTube video URL source = \"https://youtu.be/LNwODJXcvt4\"  # Run inference on the source results = model(source, stream=True)  # generator of Results objects` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Single stream with batch-size 1 inference source = \"rtsp://example.com/media.mp4\"  # RTSP, RTMP, TCP or IP streaming address  # Multiple streams with batched inference (i.e. batch-size 8 for 8 streams) source = \"path/to/list.streams\"  # *.streams text file with one streaming address per row  # Run inference on the source results = model(source, stream=True)  # generator of Results objects` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Run inference on 'bus.jpg' with arguments model.predict(\"bus.jpg\", save=True, imgsz=320, conf=0.5)` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Run inference on an image results = model(\"bus.jpg\")  # list of 1 Results object results = model([\"bus.jpg\", \"zidane.jpg\"])  # list of 2 Results objects` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Run inference on an image results = model(\"bus.jpg\")  # results list  # View results for r in results:     print(r.boxes)  # print the Boxes object containing the detection bounding boxes` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n-seg Segment model model = YOLO(\"yolov8n-seg.pt\")  # Run inference on an image results = model(\"bus.jpg\")  # results list  # View results for r in results:     print(r.masks)  # print the Masks object containing the detected instance masks` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n-pose Pose model model = YOLO(\"yolov8n-pose.pt\")  # Run inference on an image results = model(\"bus.jpg\")  # results list  # View results for r in results:     print(r.keypoints)  # print the Keypoints object containing the detected keypoints` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n-cls Classify model model = YOLO(\"yolov8n-cls.pt\")  # Run inference on an image results = model(\"bus.jpg\")  # results list  # View results for r in results:     print(r.probs)  # print the Probs object containing the detected class probabilities` \n```", "```py\n`from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n-obb.pt\")  # Run inference on an image results = model(\"bus.jpg\")  # results list  # View results for r in results:     print(r.obb)  # print the OBB object containing the oriented detection bounding boxes` \n```", "```py\n`from PIL import Image  from ultralytics import YOLO  # Load a pretrained YOLOv8n model model = YOLO(\"yolov8n.pt\")  # Run inference on 'bus.jpg' results = model([\"bus.jpg\", \"zidane.jpg\"])  # results list  # Visualize the results for i, r in enumerate(results):     # Plot results image     im_bgr = r.plot()  # BGR-order numpy array     im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image      # Show results to screen (in supported environments)     r.show()      # Save results to disk     r.save(filename=f\"results{i}.jpg\")` \n```", "```py\n`from threading import Thread  from ultralytics import YOLO   def thread_safe_predict(image_path):   \"\"\"Performs thread-safe prediction on an image using a locally instantiated YOLO model.\"\"\"     local_model = YOLO(\"yolov8n.pt\")     results = local_model.predict(image_path)     # Process results   # Starting threads that each have their own model instance Thread(target=thread_safe_predict, args=(\"image1.jpg\",)).start() Thread(target=thread_safe_predict, args=(\"image2.jpg\",)).start()` \n```", "```py\n`import cv2  from ultralytics import YOLO  # Load the YOLOv8 model model = YOLO(\"yolov8n.pt\")  # Open the video file video_path = \"path/to/your/video/file.mp4\" cap = cv2.VideoCapture(video_path)  # Loop through the video frames while cap.isOpened():     # Read a frame from the video     success, frame = cap.read()      if success:         # Run YOLOv8 inference on the frame         results = model(frame)          # Visualize the results on the frame         annotated_frame = results[0].plot()          # Display the annotated frame         cv2.imshow(\"YOLOv8 Inference\", annotated_frame)          # Break the loop if 'q' is pressed         if cv2.waitKey(1) & 0xFF == ord(\"q\"):             break     else:         # Break the loop if the end of the video is reached         break  # Release the video capture object and close the display window cap.release() cv2.destroyAllWindows()` \n```"]