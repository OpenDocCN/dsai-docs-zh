# pandas.read_html

> 译文：[`pandas.pydata.org/docs/reference/api/pandas.read_html.html`](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html)

```py
pandas.read_html(io, *, match='.+', flavor=None, header=None, index_col=None, skiprows=None, attrs=None, parse_dates=False, thousands=',', encoding=None, decimal='.', converters=None, na_values=None, keep_default_na=True, displayed_only=True, extract_links=None, dtype_backend=_NoDefault.no_default, storage_options=None)
```

将 HTML 表格读取为`DataFrame`对象的`list`。

参数：

**io**str、路径对象或类文件对象

字符串、实现`os.PathLike[str]`的路径对象，或实现字符串`read()`函数的类文件对象。该字符串可以表示 URL 或 HTML 本身。请注意，lxml 仅接受 http、ftp 和 file URL 协议。如果您有一个以 `'https'` 开头的 URL，您可以尝试删除 `'s'`。

自版本 2.1.0 起已弃用：传递 html 文本字符串已弃用。请改用`io.StringIO`/`io.BytesIO`包装文本字符串/字节输入。

**match**str 或编译的正则表达式，可选

包含与此正则表达式或字符串匹配的文本的表将被返回。除非 HTML 非常简单，否则您可能需要传递一个非空字符串。默认为‘.+’（匹配任何非空字符串）。默认值将返回页面上包含的所有表。该值被转换为正则表达式，以便在 Beautiful Soup 和 lxml 之间有一致的行为。

**flavor**{“lxml”, “html5lib”, “bs4”} 或类似列表，可选

要使用的解析引擎（或解析引擎列表）。`bs4` 和 `html5lib` 是互为同义词，它们都是为了向后兼容而存在的。默认值为`None`，尝试使用`lxml`进行解析，如果失败则退回到`bs4` + `html5lib`。

**header**int 或类似列表，可选

用于将行（或用于使列标题的`MultiIndex`的行列表）的行。

**index_col**int 或类似列表，可选

用于创建索引的列（或列列表）。

**skiprows**int、类似列表或切片，可选

在解析列整数后要跳过的行数。基于 0。如果给定整数序列或切片，将跳过由该序列索引的行。请注意，单个元素序列意味着‘跳过第 n 行’，而整数意味着‘跳过 n 行’。

**attrs**dict，可选

这是一个属性字典，您可以传递以用于在 HTML 中识别表。在传递给 lxml 或 Beautiful Soup 之前，这些属性不会被检查是否有效。但是，这些属性必须是有效的 HTML 表属性才能正常工作。例如，

```py
attrs = {'id': 'table'} 
```

是一个有效的属性字典，因为‘id’ HTML 标签属性是根据[此文档](https://html.spec.whatwg.org/multipage/dom.html#global-attributes)对于*任何* HTML 标签都是有效的 HTML 属性。

```py
attrs = {'asdf': 'table'} 
```

*不*是有效的属性字典，因为‘asdf’不是有效的 HTML 属性，即使它是有效的 XML 属性。可以在[这里](http://www.w3.org/TR/REC-html40/struct/tables.html#h-11.2)找到有效的 HTML 4.01 表属性。HTML 5 规范的工作草案可以在[这里](https://html.spec.whatwg.org/multipage/tables.html)找到。它包含了现代 Web 的表属性的最新信息。

**parse_dates**布尔值，可选

有关更多详细信息，请参阅`read_csv()`。

**thousands**字符串，可选

用于解析千位分隔符的分隔符。默认为`','`。

**encoding**字符串，可选

用于解码网页的编码。默认为`None`。``None``保留了先前的编码行为，这取决于底层解析器库（例如，解析器库将尝试使用文档提供的编码）。

**decimal**字符串，默认为‘.’

用作小数点识别的字符（例如，对于欧洲数据使用‘,’）。

**converters**字典，默认为 None

用于转换特定列中的值的函数字典。键可以是整数或列标签，值是一个接受一个输入��数（单元格内容而不是列）的函数，并返回转换后的内容。

**na_values**可迭代对象，默认为 None

自定义 NA 值。

**keep_default_na**布尔值，默认为 True

如果指定了 na_values 并且 keep_default_na 为 False，则默认的 NaN 值将被覆盖，否则它们将被追加。

**displayed_only**布尔值，默认为 True

是否应解析具有“display: none”的元素。

**extract_links**{None, “all”, “header”, “body”, “footer”}

在指定部分中带有<a>标签的表元素将提取其 href。

版本 1.5.0 中新增。

**dtype_backend**{‘numpy_nullable’, ‘pyarrow’}，默认为‘numpy_nullable’

应用于生成的`DataFrame`的后端数据类型（仍处于实验阶段）。行为如下：

+   `"numpy_nullable"`：返回支持可空数据类型的`DataFrame`（默认）。

+   `"pyarrow"`：返回支持 pyarrow 的可空`ArrowDtype` DataFrame。

版本 2.0 中新增。

**storage_options**字典，可选

针对特定存储连接有意义的额外选项，例如主机、端口、用户名、密码等。对于 HTTP(S) URL，键值对将作为标头选项转发给`urllib.request.Request`。对于其他 URL（例如以“s3://”和“gcs://”开头的 URL），键值对将转发给`fsspec.open`。请参阅`fsspec`和`urllib`以获取更多详细信息，并参考[这里](https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files)获取有关存储选项的更多示例。

版本 2.1.0 中新增。

返回：

dfs

一个 DataFrames 列表。

另请参阅

`read_csv`

将逗号分隔值（csv）文件读入 DataFrame。

注意

在使用此功能之前，您应该阅读关于 HTML 解析库的注意事项。

在调用此函数后，需要进行一些清理工作。例如，如果在传递 header=0 参数时，列名被转换为 NaN，则可能需要手动分配列名。我们尽量不对表格的结构做过多假设，并将表格中包含的 HTML 的特殊性推给用户。

此函数搜索`<table>`元素，仅搜索每个`<tr>`和`<th>`行以及表格中每个`<tr>`或`<th>`元素中的`<td>`元素。`<td>`代表“表格数据”。此函数尝试正确处理`colspan`和`rowspan`属性。如果函数有一个`<thead>`参数，则用于构建标题，否则函数尝试在主体中找到标题（将只包含`<th>`元素的行放入标题中）。

与`read_csv()`类似，header 参数在应用 skiprows 之后**再**应用。

此函数将*始终*返回一个`DataFrame`列表，否则将失败，例如，它*不会*返回空列表。

示例

查看文档中 IO 部分的 read_html 文档以查看一些读取 HTML 表格的示例。
