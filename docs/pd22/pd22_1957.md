# 版本 0.18.1（2016 年 5 月 3 日）

> 原文：[`pandas.pydata.org/docs/whatsnew/v0.18.1.html`](https://pandas.pydata.org/docs/whatsnew/v0.18.1.html)

这是从 0.18.0 的次要 bug 修复版本，包括大量的 bug 修复以及一些新功能、增强功能和性能改进。我们建议所有用户升级到此版本。

主要亮点包括：

+   `.groupby(...)` 已得到加强，以提供与 `.rolling(..)`、`.expanding(..)` 和 `.resample(..)` 每个组的方便语法，参见此处

+   `pd.to_datetime()` 现在可以从 `DataFrame` 组装日期，请参阅此处

+   方法链改进，请参阅此处。

+   自定义工作时间偏移，请参阅此处。

+   在处理 `sparse` 时进行了许多 bug 修复，请参阅此处

+   [通过@TomAugsburger](https://twitter.com/TomAugspurger)提供的现代 pandas 功能，扩展了 Tutorials section。 ([GH 13045](https://github.com/pandas-dev/pandas/issues/13045)).

v0.18.1 中的新功能

+   新特性

    +   自定义工作时间

    +   方法`.groupby(..)`语法与窗口和重采样操作

    +   方法链改进

        +   方法 `.where()` 和 `.mask()`

        +   [方法 `.loc[]`, `.iloc[]`, `.ix[]`](#methods-loc-iloc-ix)

        +   [`[]` 索引](#indexing-with)

    +   在 `DatetimeIndex` 的部分字符串索引时，作为 `MultiIndex` 的一部分

    +   组装日期时间

    +   其他增强功能

+   稀疏更改

+   API 更改

    +   方法 `.groupby(..).nth()` 更改

    +   NumPy 函数兼容性

    +   在 GroupBy 重采样上使用 `.apply`

    +   `read_csv` 异常的更改

    +   方法 `to_datetime` 错误更改

    +   其他 API 更改

    +   弃用

+   性能改进

+   错误修复

+   贡献者

## 新特性

### 自定义工作时间

`CustomBusinessHour` 是 `BusinessHour` 和 `CustomBusinessDay` 的混合，允许您指定任意假期。详情请参阅自定义工作时间 ([GH 11514](https://github.com/pandas-dev/pandas/issues/11514))

```py
In [1]: from pandas.tseries.offsets import CustomBusinessHour

In [2]: from pandas.tseries.holiday import USFederalHolidayCalendar

In [3]: bhour_us = CustomBusinessHour(calendar=USFederalHolidayCalendar()) 
```

MLK Day 前的星期五

```py
In [4]: import datetime

In [5]: dt = datetime.datetime(2014, 1, 17, 15)

In [6]: dt + bhour_us
Out[6]: Timestamp('2014-01-17 16:00:00') 
```

MLK Day 后的星期二（星期一因为是假日而跳过）

```py
In [7]: dt + bhour_us * 2
Out[7]: Timestamp('2014-01-20 09:00:00') 
```  ### 方法 `.groupby(..)` 语法与窗口和重采样操作

`.groupby(...)` 已增强以提供方便的语法，用于处理每个组的`.rolling(..)`、`.expanding(..)`和`.resample(..)`，请参阅 ([GH 12486](https://github.com/pandas-dev/pandas/issues/12486), [GH 12738](https://github.com/pandas-dev/pandas/issues/12738))。

现在你可以在 groupbys 上将`.rolling(..)`和`.expanding(..)`作为方法使用。 这些会返回另一个延迟对象（类似于在未分组的 pandas 对象上所做的`.rolling()`和`.expanding()`）。 然后，您可以以类似的方式操作这些`RollingGroupby`对象。

以前，要按组获得滚动窗口平均值，您必须执行以下操作：

```py
In [8]: df = pd.DataFrame({"A": [1] * 20 + [2] * 12 + [3] * 8, "B": np.arange(40)})

In [9]: df
Out[9]: 
 A   B
0   1   0
1   1   1
2   1   2
3   1   3
4   1   4
.. ..  ..
35  3  35
36  3  36
37  3  37
38  3  38
39  3  39

[40 rows x 2 columns] 
```

```py
In [1]: df.groupby("A").apply(lambda x: x.rolling(4).B.mean())
Out[1]:
A
1  0      NaN
 1      NaN
 2      NaN
 3      1.5
 4      2.5
 5      3.5
 6      4.5
 7      5.5
 8      6.5
 9      7.5
 10     8.5
 11     9.5
 12    10.5
 13    11.5
 14    12.5
 15    13.5
 16    14.5
 17    15.5
 18    16.5
 19    17.5
2  20     NaN
 21     NaN
 22     NaN
 23    21.5
 24    22.5
 25    23.5
 26    24.5
 27    25.5
 28    26.5
 29    27.5
 30    28.5
 31    29.5
3  32     NaN
 33     NaN
 34     NaN
 35    33.5
 36    34.5
 37    35.5
 38    36.5
 39    37.5
Name: B, dtype: float64 
```

现在你可以这样做：

```py
In [10]: df.groupby("A").rolling(4).B.mean()
Out[10]: 
A 
1  0      NaN
 1      NaN
 2      NaN
 3      1.5
 4      2.5
 ... 
3  35    33.5
 36    34.5
 37    35.5
 38    36.5
 39    37.5
Name: B, Length: 40, dtype: float64 
```

对于`.resample(..)`类型的操作，以前您必须执行：

```py
In [11]: df = pd.DataFrame(
 ....:    {
 ....:        "date": pd.date_range(start="2016-01-01", periods=4, freq="W"),
 ....:        "group": [1, 1, 2, 2],
 ....:        "val": [5, 6, 7, 8],
 ....:    }
 ....: ).set_index("date")
 ....: 

In [12]: df
Out[12]: 
 group  val
date 
2016-01-03      1    5
2016-01-10      1    6
2016-01-17      2    7
2016-01-24      2    8

[4 rows x 2 columns] 
```

```py
In[1]: df.groupby("group").apply(lambda x: x.resample("1D").ffill())
Out[1]:
                  group  val
group date
1     2016-01-03      1    5
      2016-01-04      1    5
      2016-01-05      1    5
      2016-01-06      1    5
      2016-01-07      1    5
      2016-01-08      1    5
      2016-01-09      1    5
      2016-01-10      1    6
2     2016-01-17      2    7
      2016-01-18      2    7
      2016-01-19      2    7
      2016-01-20      2    7
      2016-01-21      2    7
      2016-01-22      2    7
      2016-01-23      2    7
      2016-01-24      2    8 
```

现在你可以这样做：

```py
In[1]: df.groupby("group").resample("1D").ffill()
Out[1]:
                  group  val
group date
1     2016-01-03      1    5
      2016-01-04      1    5
      2016-01-05      1    5
      2016-01-06      1    5
      2016-01-07      1    5
      2016-01-08      1    5
      2016-01-09      1    5
      2016-01-10      1    6
2     2016-01-17      2    7
      2016-01-18      2    7
      2016-01-19      2    7
      2016-01-20      2    7
      2016-01-21      2    7
      2016-01-22      2    7
      2016-01-23      2    7
      2016-01-24      2    8 
```  ### 方法链改进

以下方法/索引器现在接受一个`callable`。 旨在使这些在方法链中更有用，请参阅文档。 ([GH 11485](https://github.com/pandas-dev/pandas/issues/11485), [GH 12533](https://github.com/pandas-dev/pandas/issues/12533))

+   `.where()`和`.mask()`

+   `.loc[]`、`iloc[]`和`.ix[]`

+   `[]` 索引

#### 方法`.where()`和`.mask()`

这些可以接受条件和`other`参数的可调用对象。

```py
In [13]: df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})

In [14]: df.where(lambda x: x > 4, lambda x: x + 10)
Out[14]: 
 A   B  C
0  11  14  7
1  12   5  8
2  13   6  9

[3 rows x 3 columns] 
```

#### 方法`.loc[]`、`.iloc[]`、`.ix[]`

这些可以接受一个可调用对象和一个切片器的元组。 可调用对象可以返回有效的布尔索引器或任何对这些索引器的输入有效的内容。

```py
# callable returns bool indexer
In [15]: df.loc[lambda x: x.A >= 2, lambda x: x.sum() > 10]
Out[15]: 
 B  C
1  5  8
2  6  9

[2 rows x 2 columns]

# callable returns list of labels
In [16]: df.loc[lambda x: [1, 2], lambda x: ["A", "B"]]
Out[16]: 
 A  B
1  2  5
2  3  6

[2 rows x 2 columns] 
```

#### 使用`[]`进行索引

最后，您可以在 Series、DataFrame 和 Panel 的`[]`索引中使用可调用对象。 可调用对象必须根据其类和索引类型返回`[]`索引的有效输入。

```py
In [17]: df[lambda x: "A"]
Out[17]: 
0    1
1    2
2    3
Name: A, Length: 3, dtype: int64 
```

使用这些方法/索引器，您可以在不使用临时变量的情况下链接数据选择操作。

```py
In [18]: bb = pd.read_csv("data/baseball.csv", index_col="id")

In [19]: (bb.groupby(["year", "team"]).sum(numeric_only=True).loc[lambda df: df.r > 100])
Out[19]: 
 stint    g    ab    r    h  X2b  ...     so   ibb   hbp    sh    sf  gidp
year team                                   ... 
2007 CIN       6  379   745  101  203   35  ...  127.0  14.0   1.0   1.0  15.0  18.0
 DET       5  301  1062  162  283   54  ...  176.0   3.0  10.0   4.0   8.0  28.0
 HOU       4  311   926  109  218   47  ...  212.0   3.0   9.0  16.0   6.0  17.0
 LAN      11  413  1021  153  293   61  ...  141.0   8.0   9.0   3.0   8.0  29.0
 NYN      13  622  1854  240  509  101  ...  310.0  24.0  23.0  18.0  15.0  48.0
 SFN       5  482  1305  198  337   67  ...  188.0  51.0   8.0  16.0   6.0  41.0
 TEX       2  198   729  115  200   40  ...  140.0   4.0   5.0   2.0   8.0  16.0
 TOR       4  459  1408  187  378   96  ...  265.0  16.0  12.0   4.0  16.0  38.0

[8 rows x 18 columns] 
```  ### 部分字符串索引在`MultiIndex`中的部分`DatetimeIndex`

部分字符串索引现在在`MultiIndex`的一部分`DateTimeIndex`上匹配 ([GH 10331](https://github.com/pandas-dev/pandas/issues/10331))

```py
In [20]: dft2 = pd.DataFrame(
 ....:    np.random.randn(20, 1),
 ....:    columns=["A"],
 ....:    index=pd.MultiIndex.from_product(
 ....:        [pd.date_range("20130101", periods=10, freq="12H"), ["a", "b"]]
 ....:    ),
 ....: )
 ....:

In [21]: dft2
Out[21]:
 A
2013-01-01 00:00:00 a  0.469112
 b -0.282863
2013-01-01 12:00:00 a -1.509059
 b -1.135632
2013-01-02 00:00:00 a  1.212112
...                         ...
2013-01-04 12:00:00 b  0.271860
2013-01-05 00:00:00 a -0.424972
 b  0.567020
2013-01-05 12:00:00 a  0.276232
 b -1.087401

[20 rows x 1 columns]

In [22]: dft2.loc["2013-01-05"]
Out[22]:
 A
2013-01-05 00:00:00 a -0.424972
 b  0.567020
2013-01-05 12:00:00 a  0.276232
 b -1.087401

[4 rows x 1 columns] 
```

在其他级别

```py
In [26]: idx = pd.IndexSlice

In [27]: dft2 = dft2.swaplevel(0, 1).sort_index()

In [28]: dft2
Out[28]:
 A
a 2013-01-01 00:00:00  0.469112
 2013-01-01 12:00:00 -1.509059
 2013-01-02 00:00:00  1.212112
 2013-01-02 12:00:00  0.119209
 2013-01-03 00:00:00 -0.861849
...                         ...
b 2013-01-03 12:00:00  1.071804
 2013-01-04 00:00:00 -0.706771
 2013-01-04 12:00:00  0.271860
 2013-01-05 00:00:00  0.567020
 2013-01-05 12:00:00 -1.087401

[20 rows x 1 columns]

In [29]: dft2.loc[idx[:, "2013-01-05"], :]
Out[29]:
 A
a 2013-01-05 00:00:00 -0.424972
 2013-01-05 12:00:00  0.276232
b 2013-01-05 00:00:00  0.567020
 2013-01-05 12:00:00 -1.087401

[4 rows x 1 columns] 
```  ### 组装日期时间

`pd.to_datetime()` 已经具备了从传递的`DataFrame`或字典中组装日期时间的能力。 ([GH 8158](https://github.com/pandas-dev/pandas/issues/8158))。

```py
In [20]: df = pd.DataFrame(
 ....:    {"year": [2015, 2016], "month": [2, 3], "day": [4, 5], "hour": [2, 3]}
 ....: )
 ....: 

In [21]: df
Out[21]: 
 year  month  day  hour
0  2015      2    4     2
1  2016      3    5     3

[2 rows x 4 columns] 
```

使用传递的框架进行组装。

```py
In [22]: pd.to_datetime(df)
Out[22]: 
0   2015-02-04 02:00:00
1   2016-03-05 03:00:00
Length: 2, dtype: datetime64[ns] 
```

您只需传递您需要组装的列。

```py
In [23]: pd.to_datetime(df[["year", "month", "day"]])
Out[23]: 
0   2015-02-04
1   2016-03-05
Length: 2, dtype: datetime64[ns] 
```  ### 其他增强

+   `pd.read_csv()` 现在支持`delim_whitespace=True`用于 Python 引擎 ([GH 12958](https://github.com/pandas-dev/pandas/issues/12958))

+   `pd.read_csv()` 现在支持打开包含单个 CSV 的 ZIP 文件，通过扩展推断或显式`compression='zip'` ([GH 12175](https://github.com/pandas-dev/pandas/issues/12175))

+   `pd.read_csv()` 现在支持使用 xz 压缩打开文件，通过扩展推断或明确指定`compression='xz'`； `xz` 压缩也通过相同的方式由`DataFrame.to_csv`支持 ([GH 11852](https://github.com/pandas-dev/pandas/issues/11852))

+   `pd.read_msgpack()` 现在即使使用压缩，也始终提供可写的 ndarrays（[GH 12359](https://github.com/pandas-dev/pandas/issues/12359)）

+   `pd.read_msgpack()` 现在支持使用 msgpack 序列化和反序列化分类变量（[GH 12573](https://github.com/pandas-dev/pandas/issues/12573))

+   `.to_json()` 现在支持包含分类和稀疏数据的 `NDFrames`（[GH 10778](https://github.com/pandas-dev/pandas/issues/10778)）

+   `interpolate()` 现在支持 `method='akima'`（[GH 7588](https://github.com/pandas-dev/pandas/issues/7588)）。

+   `pd.read_excel()` 现在接受路径对象（例如 `pathlib.Path`, `py.path.local`）作为文件路径，与其他 `read_*` 函数一致（[GH 12655](https://github.com/pandas-dev/pandas/issues/12655)）

+   已添加 `.weekday_name` 属性作为 `DatetimeIndex` 和 `.dt` 访问器的组成部分（[GH 11128](https://github.com/pandas-dev/pandas/issues/11128)）

+   `Index.take` 现在对 `allow_fill` 和 `fill_value` 的处理更加一致（[GH 12631](https://github.com/pandas-dev/pandas/issues/12631)）

    ```py
    In [24]: idx = pd.Index([1.0, 2.0, 3.0, 4.0], dtype="float")

    # default, allow_fill=True, fill_value=None
    In [25]: idx.take([2, -1])
    Out[25]: Index([3.0, 4.0], dtype='float64')

    In [26]: idx.take([2, -1], fill_value=True)
    Out[26]: Index([3.0, nan], dtype='float64') 
    ```

+   `Index` 现在支持 `.str.get_dummies()`，返回 `MultiIndex`，参见 创建指示变量（[GH 10008](https://github.com/pandas-dev/pandas/issues/10008), [GH 10103](https://github.com/pandas-dev/pandas/issues/10103)）

    ```py
    In [27]: idx = pd.Index(["a|b", "a|c", "b|c"])

    In [28]: idx.str.get_dummies("|")
    Out[28]: 
    MultiIndex([(1, 1, 0),
     (1, 0, 1),
     (0, 1, 1)],
     names=['a', 'b', 'c']) 
    ```

+   `pd.crosstab()` 增加了一个 `normalize` 参数用于归一化频率表（[GH 12569](https://github.com/pandas-dev/pandas/issues/12569)）。更新文档中的示例在 这里。

+   `.resample(..).interpolate()` 现在受支持（[GH 12925](https://github.com/pandas-dev/pandas/issues/12925)）

+   `.isin()` 现在接受传递的 `sets`（[GH 12988](https://github.com/pandas-dev/pandas/issues/12988)）  ## 稀疏变化

这些变化使稀疏处理返回正确的类型，并努力使索引体验更加顺畅。

`SparseArray.take` 现在对标量输入返回标量，对其他输入返回 `SparseArray`。此外，它处理负索引器的规则与 `Index` 相同（[GH 10560](https://github.com/pandas-dev/pandas/issues/10560), [GH 12796](https://github.com/pandas-dev/pandas/issues/12796)）

```py
s = pd.SparseArray([np.nan, np.nan, 1, 2, 3, np.nan, 4, 5, np.nan, 6])
s.take(0)
s.take([1, 2, 3]) 
```

+   `SparseSeries[]` 在使用 `Ellipsis` 索引时出现 `KeyError` 错误（[GH 9467](https://github.com/pandas-dev/pandas/issues/9467)）

+   `SparseArray[]` 在使用元组索引时未正确处理的错误已修复（[GH 12966](https://github.com/pandas-dev/pandas/issues/12966)）

+   `SparseSeries.loc[]` 在类似列表的输入时引发 `TypeError` 错误的问题已修复（[GH 10560](https://github.com/pandas-dev/pandas/issues/10560)）

+   `SparseSeries.iloc[]` 在标量输入时可能引发 `IndexError` 错误的问题已修复（[GH 10560](https://github.com/pandas-dev/pandas/issues/10560)）

+   `SparseSeries.loc[]`, `.iloc[]` 中使用 `slice` 时返回 `SparseArray` 而不是 `SparseSeries` 的错误已修复（[GH 10560](https://github.com/pandas-dev/pandas/issues/10560)）

+   `SparseDataFrame.loc[]`, `.iloc[]` 中的 Bug 可能导致密集的 `Series`，而不是 `SparseSeries`（[GH 12787](https://github.com/pandas-dev/pandas/issues/12787)）

+   `SparseArray` 中的加法 Bug 忽略了右侧的 `fill_value`（[GH 12910](https://github.com/pandas-dev/pandas/issues/12910)）

+   `SparseArray` mod 中的 Bug 引发 `AttributeError`（[GH 12910](https://github.com/pandas-dev/pandas/issues/12910)）

+   `SparseArray` 中的 pow Bug 计算 `1 ** np.nan` 为 `np.nan`，应为 1（[GH 12910](https://github.com/pandas-dev/pandas/issues/12910)）

+   `SparseArray` 比较输出中的 Bug 可能会产生不正确的结果或引发 `ValueError`（[GH 12971](https://github.com/pandas-dev/pandas/issues/12971)）

+   `SparseSeries.__repr__` 中的 Bug 在长度超过 `max_rows` 时引发 `TypeError`（[GH 10560](https://github.com/pandas-dev/pandas/issues/10560)）

+   `SparseSeries.shape` 中的 Bug 忽略了 `fill_value`（[GH 10452](https://github.com/pandas-dev/pandas/issues/10452)）

+   `SparseSeries` 和 `SparseArray` 中的 Bug 可能与其密集值的 `dtype` 不同（[GH 12908](https://github.com/pandas-dev/pandas/issues/12908)）

+   `SparseSeries.reindex` 中的 Bug 错误地处理了 `fill_value`（[GH 12797](https://github.com/pandas-dev/pandas/issues/12797)）

+   `SparseArray.to_frame()` 中的 Bug 导致了 `DataFrame`，而不是 `SparseDataFrame`（[GH 9850](https://github.com/pandas-dev/pandas/issues/9850)）

+   `SparseSeries.value_counts()` 中的 Bug 不计算 `fill_value`（[GH 6749](https://github.com/pandas-dev/pandas/issues/6749)）

+   `SparseArray.to_dense()` 中的 Bug 不保留 `dtype`（[GH 10648](https://github.com/pandas-dev/pandas/issues/10648)）

+   `SparseArray.to_dense()` 中的 Bug 错误地处理了 `fill_value`（[GH 12797](https://github.com/pandas-dev/pandas/issues/12797)）

+   `SparseSeries` 的 `pd.concat()` 中的 Bug 导致结果是密集的（[GH 10536](https://github.com/pandas-dev/pandas/issues/10536)）

+   `SparseDataFrame` 的 `pd.concat()` 中的 Bug 错误地处理了 `fill_value`（[GH 9765](https://github.com/pandas-dev/pandas/issues/9765)）

+   `SparseDataFrame` 的 `pd.concat()` 中的 Bug 可能引发 `AttributeError`（[GH 12174](https://github.com/pandas-dev/pandas/issues/12174)）

+   `SparseArray.shift()` 中的 Bug 可能会引发 `NameError` 或 `TypeError`（[GH 12908](https://github.com/pandas-dev/pandas/issues/12908)）  ## API 变更

### 方法 `.groupby(..).nth()` 变更

当传递 `as_index` 参数时，`.groupby(..).nth()` 输出中的索引现在更加一致（[GH 11039](https://github.com/pandas-dev/pandas/issues/11039)）：

```py
In [29]: df = pd.DataFrame({"A": ["a", "b", "a"], "B": [1, 2, 3]})

In [30]: df
Out[30]: 
 A  B
0  a  1
1  b  2
2  a  3

[3 rows x 2 columns] 
```

先前的行为：

```py
In [3]: df.groupby('A', as_index=True)['B'].nth(0)
Out[3]:
0    1
1    2
Name: B, dtype: int64

In [4]: df.groupby('A', as_index=False)['B'].nth(0)
Out[4]:
0    1
1    2
Name: B, dtype: int64 
```

新行为：

```py
In [31]: df.groupby("A", as_index=True)["B"].nth(0)
Out[31]: 
0    1
1    2
Name: B, Length: 2, dtype: int64

In [32]: df.groupby("A", as_index=False)["B"].nth(0)
Out[32]: 
0    1
1    2
Name: B, Length: 2, dtype: int64 
```

此外，以前，`.groupby` 总是会排序，无论是否使用 `.nth()` 传递了 `sort=False`。

```py
In [33]: np.random.seed(1234)

In [34]: df = pd.DataFrame(np.random.randn(100, 2), columns=["a", "b"])

In [35]: df["c"] = np.random.randint(0, 4, 100) 
```

先前的行为：

```py
In [4]: df.groupby('c', sort=True).nth(1)
Out[4]:
 a         b
c
0 -0.334077  0.002118
1  0.036142 -2.074978
2 -0.720589  0.887163
3  0.859588 -0.636524

In [5]: df.groupby('c', sort=False).nth(1)
Out[5]:
 a         b
c
0 -0.334077  0.002118
1  0.036142 -2.074978
2 -0.720589  0.887163
3  0.859588 -0.636524 
```

新行为：

```py
In [36]: df.groupby("c", sort=True).nth(1)
Out[36]: 
 a         b  c
2  -0.720589  0.887163  2
3   0.859588 -0.636524  3
7  -0.334077  0.002118  0
21  0.036142 -2.074978  1

[4 rows x 3 columns]

In [37]: df.groupby("c", sort=False).nth(1)
Out[37]: 
 a         b  c
2  -0.720589  0.887163  2
3   0.859588 -0.636524  3
7  -0.334077  0.002118  0
21  0.036142 -2.074978  1

[4 rows x 3 columns] 
```  ### NumPy 函数兼容性

通过增加`pandas`方法的签名，使其能够接受从`numpy`传入的参数，即使在`pandas`实现中并不一定使用这些参数，大大增加了`pandas`数组方法（例如`sum`和`take`）与它们的`numpy`对应方法之间的兼容性（[GH 12644](https://github.com/pandas-dev/pandas/issues/12644), [GH 12638](https://github.com/pandas-dev/pandas/issues/12638), [GH 12687](https://github.com/pandas-dev/pandas/issues/12687))

+   `Index`和`TimedeltaIndex`的`.searchsorted()`现在接受一个`sorter`参数，以保持与 numpy 的`searchsorted`函数的兼容性（[GH 12238](https://github.com/pandas-dev/pandas/issues/12238))

+   在`Series`上`np.round()`的 numpy 兼容性 bug（[GH 12600](https://github.com/pandas-dev/pandas/issues/12600))

下面是一个签名增强的示例：

```py
sp = pd.SparseDataFrame([1, 2, 3])
sp 
```

先前行为：

```py
In [2]: np.cumsum(sp, axis=0)
...
TypeError: cumsum() takes at most 2 arguments (4 given) 
```

新行为：

```py
np.cumsum(sp, axis=0) 
```  ### 在 GroupBy 重新采样上使用`.apply`

在对`pd.TimeGrouper`进行重新采样分组操作（使用`apply`）时，现在具有与其他 groupby 操作上类似`apply`调用相同的输出类型。([GH 11742](https://github.com/pandas-dev/pandas/issues/11742)).

```py
In [38]: df = pd.DataFrame(
 ....:    {"date": pd.to_datetime(["10/10/2000", "11/10/2000"]), "value": [10, 13]}
 ....: )
 ....: 

In [39]: df
Out[39]: 
 date  value
0 2000-10-10     10
1 2000-11-10     13

[2 rows x 2 columns] 
```

先前行为：

```py
In [1]: df.groupby(pd.TimeGrouper(key='date',
 ...:                          freq='M')).apply(lambda x: x.value.sum())
Out[1]:
...
TypeError: cannot concatenate a non-NDFrame object

# Output is a Series
In [2]: df.groupby(pd.TimeGrouper(key='date',
 ...:                          freq='M')).apply(lambda x: x[['value']].sum())
Out[2]:
date
2000-10-31  value    10
2000-11-30  value    13
dtype: int64 
```

新行为：

```py
# Output is a Series
In [55]: df.groupby(pd.TimeGrouper(key='date',
 ...:                           freq='M')).apply(lambda x: x.value.sum())
Out[55]:
date
2000-10-31    10
2000-11-30    13
Freq: M, dtype: int64

# Output is a DataFrame
In [56]: df.groupby(pd.TimeGrouper(key='date',
 ...:                           freq='M')).apply(lambda x: x[['value']].sum())
Out[56]:
 value
date
2000-10-31     10
2000-11-30     13 
```  ### `read_csv`异常更改

为了使`read_csv` API 在`c`和`python`引擎上标准化，现在两者在遇到空列或标题时都会引发`EmptyDataError`，这是`ValueError`的子类（[GH 12493](https://github.com/pandas-dev/pandas/issues/12493), [GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

先前行为：

```py
In [1]: import io

In [2]: df = pd.read_csv(io.StringIO(''), engine='c')
...
ValueError: No columns to parse from file

In [3]: df = pd.read_csv(io.StringIO(''), engine='python')
...
StopIteration 
```

新行为：

```py
In [1]: df = pd.read_csv(io.StringIO(''), engine='c')
...
pandas.io.common.EmptyDataError: No columns to parse from file

In [2]: df = pd.read_csv(io.StringIO(''), engine='python')
...
pandas.io.common.EmptyDataError: No columns to parse from file 
```

除了这个错误更改之外，还进行了其他几项更改：

+   `CParserError`现在是`ValueError`的子类，而不仅仅是`Exception`（[GH 12551](https://github.com/pandas-dev/pandas/issues/12551))

+   当`c`引擎无法解析列时，在`read_csv`中现在会引发`CParserError`而不是通用的`Exception`（[GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

+   当`c`引擎在整数列中遇到`NaN`值时，`read_csv`现在会引发`ValueError`而不是通用的`Exception`（[GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

+   当指定`true_values`时，在`c`引擎遇到包含无法编码字节的列中的元素时，`read_csv`现在会引发`ValueError`而不是通用的`Exception`（[GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

+   `pandas.parser.OverflowError`异常已被移除，并已被 Python 内置的`OverflowError`异常替换（[GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

+   `pd.read_csv()`不再允许在`usecols`参数中组合字符串和整数（[GH 12678](https://github.com/pandas-dev/pandas/issues/12678))  ### `to_datetime`方法错误更改

在传递可转换条目的 `unit` 和 `errors='coerce'` 或 `errors='ignore'` 时，`pd.to_datetime()` 中存在错误。此外，当遇到超出范围的值时，将引发 `OutOfBoundsDateime` 异常，`errors='raise'`。 ([GH 11758](https://github.com/pandas-dev/pandas/issues/11758), [GH 13052](https://github.com/pandas-dev/pandas/issues/13052), [GH 13059](https://github.com/pandas-dev/pandas/issues/13059))

先前的行为:

```py
In [27]: pd.to_datetime(1420043460, unit='s', errors='coerce')
Out[27]: NaT

In [28]: pd.to_datetime(11111111, unit='D', errors='ignore')
OverflowError: Python int too large to convert to C long

In [29]: pd.to_datetime(11111111, unit='D', errors='raise')
OverflowError: Python int too large to convert to C long 
```

新行为:

```py
In [2]: pd.to_datetime(1420043460, unit='s', errors='coerce')
Out[2]: Timestamp('2014-12-31 16:31:00')

In [3]: pd.to_datetime(11111111, unit='D', errors='ignore')
Out[3]: 11111111

In [4]: pd.to_datetime(11111111, unit='D', errors='raise')
OutOfBoundsDatetime: cannot convert input with unit 'D' 
```  ### 其他 API 更改

+   对于 `Series`、`DataFrame`、`Panel` 和 `MultiIndex` 的 `.swaplevel()` 现在具有其前两个参数 `i` 和 `j` 的默认值，这两个参数交换索引的最内层级别。 ([GH 12934](https://github.com/pandas-dev/pandas/issues/12934))

+   `.searchsorted()` 对于 `Index` 和 `TimedeltaIndex` 现在接受一个 `sorter` 参数，以保持与 numpy 的 `searchsorted` 函数的兼容性 ([GH 12238](https://github.com/pandas-dev/pandas/issues/12238))

+   `Period` 和 `PeriodIndex` 现在会引发 `IncompatibleFrequency` 错误，该错误继承自 `ValueError` 而不是原始的 `ValueError` ([GH 12615](https://github.com/pandas-dev/pandas/issues/12615))

+   `Series.apply` 对于类别 dtype 现在将传递的函数应用于每个 `.categories`（而不是 `.codes`），并在可能的情况下返回 `category` dtype ([GH 12473](https://github.com/pandas-dev/pandas/issues/12473))

+   如果 `parse_dates` 不是布尔值、列表或字典（与文档字符串匹配），`read_csv` 现在会引发 `TypeError` ([GH 5636](https://github.com/pandas-dev/pandas/issues/5636))

+   `.query()/.eval()` 的默认值现在是 `engine=None`，如果安装了 `numexpr`，则会使用 `numexpr`；否则，它将回退到 `python` 引擎。这模仿了在 0.18.1 之前如果安装了 `numexpr` 的行为（以及以前，如果未安装 `numexpr`，`.query()/.eval()` 将引发异常）。 ([GH 12749](https://github.com/pandas-dev/pandas/issues/12749))

+   `pd.show_versions()` 现在包括 `pandas_datareader` 版本 ([GH 12740](https://github.com/pandas-dev/pandas/issues/12740))

+   为通用函数提供适当的 `__name__` 和 `__qualname__` 属性 ([GH 12021](https://github.com/pandas-dev/pandas/issues/12021))

+   `pd.concat(ignore_index=True)` 现在默认使用 `RangeIndex` ([GH 12695](https://github.com/pandas-dev/pandas/issues/12695))

+   当将单级与多级数据框合并/连接时，`pd.merge()` 和 `DataFrame.join()` 将显示 `UserWarning` 警告 ([GH 9455](https://github.com/pandas-dev/pandas/issues/9455), [GH 12219](https://github.com/pandas-dev/pandas/issues/12219))

+   与 `scipy` > 0.17 兼容的已弃用的 `piecewise_polynomial` 插值方法；支持替换的 `from_derivatives` 方法 ([GH 12887](https://github.com/pandas-dev/pandas/issues/12887))  ### 弃用

+   方法名 `Index.sym_diff()` 已弃用，可以用 `Index.symmetric_difference()` 替换 ([GH 12591](https://github.com/pandas-dev/pandas/issues/12591))

+   方法名`Categorical.sort()`已被弃用，推荐使用`Categorical.sort_values()` ([GH 12882](https://github.com/pandas-dev/pandas/issues/12882))  ## 性能改进

+   提升了 SAS 读取器的速度 ([GH 12656](https://github.com/pandas-dev/pandas/issues/12656), [GH 12961](https://github.com/pandas-dev/pandas/issues/12961))

+   在`.groupby(..).cumcount()`中的性能改进 ([GH 11039](https://github.com/pandas-dev/pandas/issues/11039))

+   在使用`skiprows=an_integer`时，改进了`pd.read_csv()`的内存使用情况 ([GH 13005](https://github.com/pandas-dev/pandas/issues/13005))

+   在检查表的大小写敏感性时，改进了`DataFrame.to_sql`的性能。现在只有在表名不是小写时才检查表是否已正确创建。 ([GH 12876](https://github.com/pandas-dev/pandas/issues/12876))

+   改进了`Period`构造和时间序列绘图的性能 ([GH 12903](https://github.com/pandas-dev/pandas/issues/12903), [GH 11831](https://github.com/pandas-dev/pandas/issues/11831))

+   提升了`.str.encode()`和`.str.decode()`方法的性能 ([GH 13008](https://github.com/pandas-dev/pandas/issues/13008))

+   如果输入是数值类型，则提升了`to_numeric`的性能 ([GH 12777](https://github.com/pandas-dev/pandas/issues/12777))

+   通过`IntIndex`进行稀疏运算的性能改进 ([GH 13036](https://github.com/pandas-dev/pandas/issues/13036))  ## Bug 修复

+   现在即使 CSV 文件的行数不均匀，`pd.read_csv`中的`usecols`参数也会被尊重 ([GH 12203](https://github.com/pandas-dev/pandas/issues/12203))

+   当指定`axis=1`且具有非单调有序索引时，`groupby.transform(..)`中的 bug 已被修复 ([GH 12713](https://github.com/pandas-dev/pandas/issues/12713))

+   如果指定`freq="Minute"`，则创建`Period`和`PeriodIndex`时会引发`KeyError`的 bug 已被修复。请注意，“Minute”频率在 v0.17.0 中已被弃用，建议改用`freq="T"` ([GH 11854](https://github.com/pandas-dev/pandas/issues/11854))

+   在使用`PeriodIndex`时，`.resample(...).count()`总是引发`TypeError`的 bug 已被修复 ([GH 12774](https://github.com/pandas-dev/pandas/issues/12774))

+   修复了当为空时，`.resample(...)`在将`PeriodIndex`转换为`DatetimeIndex`时的 bug ([GH 12868](https://github.com/pandas-dev/pandas/issues/12868))

+   修复了在将`PeriodIndex`重新采样到现有频率时，`.resample(...)`中的 bug ([GH 12770](https://github.com/pandas-dev/pandas/issues/12770))

+   包含不同`freq`的`Period`数据打印时引发`ValueError`的 bug 已被修复 ([GH 12615](https://github.com/pandas-dev/pandas/issues/12615))

+   修复了当指定`dtype='category'`时，使用`Categorical`构造`Series`时的 bug ([GH 12574](https://github.com/pandas-dev/pandas/issues/12574))

+   在具有可强制转换 dtype 的连接中存在错误，过于激进，导致当对象长于`display.max_rows`时，在输出格式化中出现不同的 dtype([GH 12411](https://github.com/pandas-dev/pandas/issues/12411), [GH 12045](https://github.com/pandas-dev/pandas/issues/12045), [GH 11594](https://github.com/pandas-dev/pandas/issues/11594), [GH 10571](https://github.com/pandas-dev/pandas/issues/10571), [GH 12211](https://github.com/pandas-dev/pandas/issues/12211))

+   在`float_format`选项中，选项未被验证为可调用的错误。([GH 12706](https://github.com/pandas-dev/pandas/issues/12706))

+   在`GroupBy.filter`中，当`dropna=False`且没有组满足条件时存在错误([GH 12768](https://github.com/pandas-dev/pandas/issues/12768))

+   在`.cum*`函数的`__name__`中存在错误([GH 12021](https://github.com/pandas-dev/pandas/issues/12021))

+   在将`Float64Inde/Int64Index`转换为`Int64Index`的`.astype()`中存在错误([GH 12881](https://github.com/pandas-dev/pandas/issues/12881))

+   在`.to_json()/.read_json()`中整数索引的往返处理中存在错误，当`orient='index'`（默认）时([GH 12866](https://github.com/pandas-dev/pandas/issues/12866))

+   在绘制`Categorical` dtypes 时，当尝试堆叠条形图时导致错误([GH 13019](https://github.com/pandas-dev/pandas/issues/13019))

+   与`numpy` 1.11 兼容，用于`NaT`比较([GH 12969](https://github.com/pandas-dev/pandas/issues/12969))

+   在具有非唯一`MultiIndex`的`.drop()`中存在的错误。([GH 12701](https://github.com/pandas-dev/pandas/issues/12701))

+   在具有 datetime tz-aware 和 naive DataFrames 的`.concat`中存在错误([GH 12467](https://github.com/pandas-dev/pandas/issues/12467))

+   在传递非字符串时，在`.resample(..).fillna(..)`中正确引发`ValueError`的错误([GH 12952](https://github.com/pandas-dev/pandas/issues/12952))

+   在`pd.read_sas()`中存在各种编码和标题处理问题的错误修复([GH 12659](https://github.com/pandas-dev/pandas/issues/12659), [GH 12654](https://github.com/pandas-dev/pandas/issues/12654), [GH 12647](https://github.com/pandas-dev/pandas/issues/12647), [GH 12809](https://github.com/pandas-dev/pandas/issues/12809))

+   在`pd.crosstab()`中，如果`values=None`，则会悄悄忽略`aggfunc`([GH 12569](https://github.com/pandas-dev/pandas/issues/12569)).

+   在序列化`datetime.time`时，在`DataFrame.to_json`中存在潜在段错误([GH 11473](https://github.com/pandas-dev/pandas/issues/11473)).

+   在尝试序列化 0d 数组时，在`DataFrame.to_json`中存在潜在段错误([GH 11299](https://github.com/pandas-dev/pandas/issues/11299)).

+   在尝试序列化具有非 ndarray 值的`DataFrame`或`Series`时，在`to_json`中出现段错误；现在支持`category`、`sparse`和`datetime64[ns, tz]` dtypes 的序列化([GH 10778](https://github.com/pandas-dev/pandas/issues/10778))。

+   在不支持的 dtype 未传递给默认处理程序的`DataFrame.to_json`中存在错误([GH 12554](https://github.com/pandas-dev/pandas/issues/12554)).

+   `.align` 中的 Bug，未返回子类 ([GH 12983](https://github.com/pandas-dev/pandas/issues/12983))

+   将 `Series` 与 `DataFrame` 对齐时的 Bug ([GH 13037](https://github.com/pandas-dev/pandas/issues/13037))

+   `ABCPanel` 中的 Bug，`Panel4D` 未被视为该泛型类型的有效实例 ([GH 12810](https://github.com/pandas-dev/pandas/issues/12810))

+   `.groupby(..).apply(..)` 情况下 `.name` 的一致性 Bug ([GH 12363](https://github.com/pandas-dev/pandas/issues/12363))

+   `Timestamp.__repr__` 中的 Bug，导致嵌套结构中的 `pprint` 失败 ([GH 12622](https://github.com/pandas-dev/pandas/issues/12622))

+   `Timedelta.min` 和 `Timedelta.max` 中的 Bug，这些属性现在报告 pandas 认可的真正最小/最大 `timedeltas`。参见文档 ([GH 12727](https://github.com/pandas-dev/pandas/issues/12727))

+   `.quantile()` 中的 Bug，在插值时可能意外转换为 `float` ([GH 12772](https://github.com/pandas-dev/pandas/issues/12772))

+   `.quantile()` 中的 Bug，当 `Series` 为空时可能返回标量而不是空的 `Series` ([GH 12772](https://github.com/pandas-dev/pandas/issues/12772))

+   `.loc` 中的 Bug，在大型索引器中的越界会引发 `IndexError` 而不是 `KeyError` ([GH 12527](https://github.com/pandas-dev/pandas/issues/12527))

+   在使用 `TimedeltaIndex` 和 `.asfreq()` 进行重新采样时的 Bug，以前不包括最后一个标杆点 ([GH 12926](https://github.com/pandas-dev/pandas/issues/12926))

+   在 `DataFrame` 中使用 `Categorical` 进行相等性测试的 Bug ([GH 12564](https://github.com/pandas-dev/pandas/issues/12564))

+   `GroupBy.first()` 中的 Bug，当使用 `TimeGrouper` 时，`.last()` 返回错误行 ([GH 7453](https://github.com/pandas-dev/pandas/issues/7453))

+   在使用 `c` 引擎的 `pd.read_csv()` 中，当在引号项中指定 `skiprows` 时出现换行符 ([GH 10911](https://github.com/pandas-dev/pandas/issues/10911), [GH 12775](https://github.com/pandas-dev/pandas/issues/12775))

+   `DataFrame` 在赋值时丢失时区信息的 Bug，当赋值为带时区信息的 datetime `Series` 时出现对齐问题 ([GH 12981](https://github.com/pandas-dev/pandas/issues/12981))

+   `.value_counts()` 中的 Bug，在 `normalize=True` 和 `dropna=True` 时，null 仍然会对规范化计数产生影响 ([GH 12558](https://github.com/pandas-dev/pandas/issues/12558))

+   `Series.value_counts()` 中的 Bug，在其 dtype 为 `category` 时会丢失名称 ([GH 12835](https://github.com/pandas-dev/pandas/issues/12835))

+   `Series.value_counts()` 中的 Bug，丢失时区信息 ([GH 12835](https://github.com/pandas-dev/pandas/issues/12835))

+   `Series.value_counts(normalize=True)` 中的 Bug，当 `Categorical` 时会引发 `UnboundLocalError` ([GH 12835](https://github.com/pandas-dev/pandas/issues/12835))

+   `Panel.fillna()` 中的 Bug，忽略了 `inplace=True` ([GH 12633](https://github.com/pandas-dev/pandas/issues/12633))

+   在使用 `c` 引擎同时指定 `names`、`usecols` 和 `parse_dates` 时，`pd.read_csv()` 中的错误（[GH 9755](https://github.com/pandas-dev/pandas/issues/9755)）

+   在使用 `c` 引擎同时指定 `delim_whitespace=True` 和 `lineterminator` 时，`pd.read_csv()` 中的错误（[GH 12912](https://github.com/pandas-dev/pandas/issues/12912)）

+   `Series.rename`、`DataFrame.rename` 和 `DataFrame.rename_axis` 中的错误，不将 `Series` 视为映射以重新标记（[GH 12623](https://github.com/pandas-dev/pandas/issues/12623)）

+   在 `.rolling.min` 和 `.rolling.max` 中进行清理以增强 dtype 处理（[GH 12373](https://github.com/pandas-dev/pandas/issues/12373)）

+   在 `groupby` 中，复杂类型被强制转换为浮点数的错误（[GH 12902](https://github.com/pandas-dev/pandas/issues/12902)）

+   如果 `Series.map` 的 dtype 为 `category` 或 tz-aware `datetime`，则会引发 `TypeError` 的错误（[GH 12473](https://github.com/pandas-dev/pandas/issues/12473)）

+   一些测试比较在 32 位平台上的错误（[GH 12972](https://github.com/pandas-dev/pandas/issues/12972)）

+   从 `RangeIndex` 构造中回退时的索引强制转换错误（[GH 12893](https://github.com/pandas-dev/pandas/issues/12893)）

+   在窗口函数中传递无效参数（例如浮点窗口）时提供更好的错误消息（[GH 12669](https://github.com/pandas-dev/pandas/issues/12669)）

+   在定义为返回子类化 `Series` 的子类化 `DataFrame` 中切片时可能返回普通 `Series` 的错误（[GH 11559](https://github.com/pandas-dev/pandas/issues/11559)）

+   `.str` 访问器方法中的错误可能会在输入具有 `name` 且结果为 `DataFrame` 或 `MultiIndex` 时引发 `ValueError`（[GH 12617](https://github.com/pandas-dev/pandas/issues/12617)）

+   在空框架上的 `DataFrame.last_valid_index()` 和 `DataFrame.first_valid_index()` 中的错误（[GH 12800](https://github.com/pandas-dev/pandas/issues/12800)）

+   `CategoricalIndex.get_loc` 中的错误返回与常规 `Index` 不同（[GH 12531](https://github.com/pandas-dev/pandas/issues/12531)）

+   `PeriodIndex.resample` 中的错误，名称未传播（[GH 12769](https://github.com/pandas-dev/pandas/issues/12769)）

+   `date_range` 中 `closed` 关键字和时区的错误（[GH 12684](https://github.com/pandas-dev/pandas/issues/12684)）

+   当输入数据包含 tz-aware datetime 和 timedelta 时，`pd.concat` 中引发 `AttributeError` 的错误（[GH 12620](https://github.com/pandas-dev/pandas/issues/12620)）

+   `pd.concat` 未正确处理空 `Series` 的错误（[GH 11082](https://github.com/pandas-dev/pandas/issues/11082)）

+   当使用 `int` 指定 `width` 时，`.plot.bar` 对齐的错误（[GH 12979](https://github.com/pandas-dev/pandas/issues/12979)）

+   如果二元运算符的参数是常量，则忽略 `fill_value` 的错误（[GH 12723](https://github.com/pandas-dev/pandas/issues/12723)）

+   使用 bs4 风格和解析具有标题和仅一列的表时，`pd.read_html()` 中的错误（[GH 9178](https://github.com/pandas-dev/pandas/issues/9178)）

+   修复了当 `margins=True` 和 `dropna=True` 时 `.pivot_table` 中空值仍然会影响边际计数的错误（[GH 12577](https://github.com/pandas-dev/pandas/issues/12577))

+   修复了当 `dropna=False` 时 `.pivot_table` 中表索引/列名称消失的错误（[GH 12133](https://github.com/pandas-dev/pandas/issues/12133))

+   修复了当 `margins=True` 和 `dropna=False` 时 `pd.crosstab()` 中引发的错误（[GH 12642](https://github.com/pandas-dev/pandas/issues/12642))

+   修复了当 `name` 属性可以是可哈希类型时 `Series.name` 的错误（[GH 12610](https://github.com/pandas-dev/pandas/issues/12610))

+   修复了 `.describe()` 重置分类列信息的错误（[GH 11558](https://github.com/pandas-dev/pandas/issues/11558))

+   修复了在时间序列上调用 `resample().count()` 时未应用 `loffset` 参数的错误（[GH 12725](https://github.com/pandas-dev/pandas/issues/12725))

+   `pd.read_excel()` 现在接受与关键字参数 `names` 关联的列名（[GH 12870](https://github.com/pandas-dev/pandas/issues/12870))

+   修复了 `pd.to_numeric()` 在返回 `np.ndarray` 而不是 `Index` 时的错误（[GH 12777](https://github.com/pandas-dev/pandas/issues/12777))

+   修复了 `pd.to_numeric()` 在类似日期时间的情况下可能引发 `TypeError` 的错误（[GH 12777](https://github.com/pandas-dev/pandas/issues/12777))

+   修复了当标量使用 `pd.to_numeric()` 时引发 `ValueError` 的错误（[GH 12777](https://github.com/pandas-dev/pandas/issues/12777))  ## 贡献者

总共有 60 人为此版本贡献了补丁。名字后面带有“+”的人是第一次贡献补丁。

+   Andrew Fiore-Gartland +

+   Bastiaan +

+   Benoît Vinot +

+   Brandon Rhodes +

+   DaCoEx +

+   Drew Fustin +

+   Ernesto Freitas +

+   Filip Ter +

+   Gregory Livschitz +

+   Gábor Lipták

+   Hassan Kibirige +

+   Iblis Lin

+   Israel Saeta Pérez +

+   Jason Wolosonovich +

+   Jeff Reback

+   Joe Jevnik

+   Joris Van den Bossche

+   Joshua Storck +

+   Ka Wo Chen

+   Kerby Shedden

+   Kieran O’Mahony

+   Leif Walsh +

+   Mahmoud Lababidi +

+   Maoyuan Liu +

+   Mark Roth +

+   Matt Wittmann

+   MaxU +

+   Maximilian Roos

+   Michael Droettboom +

+   Nick Eubank

+   Nicolas Bonnotte

+   OXPHOS +

+   Pauli Virtanen +

+   Peter Waller +

+   Pietro Battiston

+   Prabhjot Singh +

+   Robin Wilson

+   Roger Thomas +

+   Sebastian Bank

+   Stephen Hoover

+   Tim Hopper +

+   Tom Augspurger

+   王爱勇

+   Wes Turner

+   Winand +

+   Xbar +

+   Yan Facai +

+   adneu +

+   ajenkins-cargometrics +

+   behzad nouri

+   chinskiy +

+   gfyoung

+   jeps-journal +

+   jonaslb +

+   kotrfa +

+   nileracecrew +

+   onesandzeroes

+   rs2 +

+   sinhrks

+   tsdlovell +  ## 新功能

### 自定义营业时间

`CustomBusinessHour` 是 `BusinessHour` 和 `CustomBusinessDay` 的混合体，允许您指定任意假期。详情请参阅自定义营业时间（[GH 11514](https://github.com/pandas-dev/pandas/issues/11514))

```py
In [1]: from pandas.tseries.offsets import CustomBusinessHour

In [2]: from pandas.tseries.holiday import USFederalHolidayCalendar

In [3]: bhour_us = CustomBusinessHour(calendar=USFederalHolidayCalendar()) 
```

马丁路德金日前的星期五

```py
In [4]: import datetime

In [5]: dt = datetime.datetime(2014, 1, 17, 15)

In [6]: dt + bhour_us
Out[6]: Timestamp('2014-01-17 16:00:00') 
```

马丁路德金日后的星期二（星期一被跳过，因为那是一个假期）

```py
In [7]: dt + bhour_us * 2
Out[7]: Timestamp('2014-01-20 09:00:00') 
```  ### 方法 `.groupby(..)` 语法与窗口和重采样操作

`.groupby(...)` 已经增强，以提供在每个分组上使用 `.rolling(..)`、`.expanding(..)` 和 `.resample(..)` 时方便的语法，请参见 ([GH 12486](https://github.com/pandas-dev/pandas/issues/12486), [GH 12738](https://github.com/pandas-dev/pandas/issues/12738))。

你现在可以在分组上使用 `.rolling(..)` 和 `.expanding(..)` 作为方法。这些返回另一个延迟对象（类似于在未分组的 pandas 对象上所做的 `.rolling()` 和 `.expanding()`）。然后，你可以以类似的方式操作这些 `RollingGroupby` 对象。

以前，你必须这样做才能得到每个分组的滚动窗口均值：

```py
In [8]: df = pd.DataFrame({"A": [1] * 20 + [2] * 12 + [3] * 8, "B": np.arange(40)})

In [9]: df
Out[9]: 
 A   B
0   1   0
1   1   1
2   1   2
3   1   3
4   1   4
.. ..  ..
35  3  35
36  3  36
37  3  37
38  3  38
39  3  39

[40 rows x 2 columns] 
```

```py
In [1]: df.groupby("A").apply(lambda x: x.rolling(4).B.mean())
Out[1]:
A
1  0      NaN
 1      NaN
 2      NaN
 3      1.5
 4      2.5
 5      3.5
 6      4.5
 7      5.5
 8      6.5
 9      7.5
 10     8.5
 11     9.5
 12    10.5
 13    11.5
 14    12.5
 15    13.5
 16    14.5
 17    15.5
 18    16.5
 19    17.5
2  20     NaN
 21     NaN
 22     NaN
 23    21.5
 24    22.5
 25    23.5
 26    24.5
 27    25.5
 28    26.5
 29    27.5
 30    28.5
 31    29.5
3  32     NaN
 33     NaN
 34     NaN
 35    33.5
 36    34.5
 37    35.5
 38    36.5
 39    37.5
Name: B, dtype: float64 
```

现在你可以这样做：

```py
In [10]: df.groupby("A").rolling(4).B.mean()
Out[10]: 
A 
1  0      NaN
 1      NaN
 2      NaN
 3      1.5
 4      2.5
 ... 
3  35    33.5
 36    34.5
 37    35.5
 38    36.5
 39    37.5
Name: B, Length: 40, dtype: float64 
```

对于 `.resample(..)` 类型的操作，以前你必须：

```py
In [11]: df = pd.DataFrame(
 ....:    {
 ....:        "date": pd.date_range(start="2016-01-01", periods=4, freq="W"),
 ....:        "group": [1, 1, 2, 2],
 ....:        "val": [5, 6, 7, 8],
 ....:    }
 ....: ).set_index("date")
 ....: 

In [12]: df
Out[12]: 
 group  val
date 
2016-01-03      1    5
2016-01-10      1    6
2016-01-17      2    7
2016-01-24      2    8

[4 rows x 2 columns] 
```

```py
In[1]: df.groupby("group").apply(lambda x: x.resample("1D").ffill())
Out[1]:
                  group  val
group date
1     2016-01-03      1    5
      2016-01-04      1    5
      2016-01-05      1    5
      2016-01-06      1    5
      2016-01-07      1    5
      2016-01-08      1    5
      2016-01-09      1    5
      2016-01-10      1    6
2     2016-01-17      2    7
      2016-01-18      2    7
      2016-01-19      2    7
      2016-01-20      2    7
      2016-01-21      2    7
      2016-01-22      2    7
      2016-01-23      2    7
      2016-01-24      2    8 
```

现在你可以这样做：

```py
In[1]: df.groupby("group").resample("1D").ffill()
Out[1]:
                  group  val
group date
1     2016-01-03      1    5
      2016-01-04      1    5
      2016-01-05      1    5
      2016-01-06      1    5
      2016-01-07      1    5
      2016-01-08      1    5
      2016-01-09      1    5
      2016-01-10      1    6
2     2016-01-17      2    7
      2016-01-18      2    7
      2016-01-19      2    7
      2016-01-20      2    7
      2016-01-21      2    7
      2016-01-22      2    7
      2016-01-23      2    7
      2016-01-24      2    8 
```  ### 方法链接改进

下列方法 / 索引器现在接受一个 `callable`。这意在使它们在方法链中更加有用，详见文档。 ([GH 11485](https://github.com/pandas-dev/pandas/issues/11485), [GH 12533](https://github.com/pandas-dev/pandas/issues/12533))

+   `.where()` 和 `.mask()`

+   `.loc[]`、`iloc[]` 和 `.ix[]`

+   `[]` 索引

#### 方法 `.where()` 和 `.mask()`

这些可以接受一个可调用函数作为条件和 `other` 参数。

```py
In [13]: df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})

In [14]: df.where(lambda x: x > 4, lambda x: x + 10)
Out[14]: 
 A   B  C
0  11  14  7
1  12   5  8
2  13   6  9

[3 rows x 3 columns] 
```

#### 方法 `.loc[]`、`.iloc[]`、`.ix[]`

这些可以接受一个可调用函数，以及一个可调用函数的元组作为切片器。可调用函数可以返回一个有效的布尔索引器或对于这些索引器的输入有效的任何内容。

```py
# callable returns bool indexer
In [15]: df.loc[lambda x: x.A >= 2, lambda x: x.sum() > 10]
Out[15]: 
 B  C
1  5  8
2  6  9

[2 rows x 2 columns]

# callable returns list of labels
In [16]: df.loc[lambda x: [1, 2], lambda x: ["A", "B"]]
Out[16]: 
 A  B
1  2  5
2  3  6

[2 rows x 2 columns] 
```

#### 使用 `[]` 进行索引

最后，你可以在 Series、DataFrame 和 Panel 的 `[]` 索引中使用可调用的函数。这个可调用函数必须根据其类和索引类型返回一个有效的 `[]` 索引的输入。

```py
In [17]: df[lambda x: "A"]
Out[17]: 
0    1
1    2
2    3
Name: A, Length: 3, dtype: int64 
```

使用这些方法 / 索引器，你可以在不使用临时变量的情况下链式进行数据选择操作。

```py
In [18]: bb = pd.read_csv("data/baseball.csv", index_col="id")

In [19]: (bb.groupby(["year", "team"]).sum(numeric_only=True).loc[lambda df: df.r > 100])
Out[19]: 
 stint    g    ab    r    h  X2b  ...     so   ibb   hbp    sh    sf  gidp
year team                                   ... 
2007 CIN       6  379   745  101  203   35  ...  127.0  14.0   1.0   1.0  15.0  18.0
 DET       5  301  1062  162  283   54  ...  176.0   3.0  10.0   4.0   8.0  28.0
 HOU       4  311   926  109  218   47  ...  212.0   3.0   9.0  16.0   6.0  17.0
 LAN      11  413  1021  153  293   61  ...  141.0   8.0   9.0   3.0   8.0  29.0
 NYN      13  622  1854  240  509  101  ...  310.0  24.0  23.0  18.0  15.0  48.0
 SFN       5  482  1305  198  337   67  ...  188.0  51.0   8.0  16.0   6.0  41.0
 TEX       2  198   729  115  200   40  ...  140.0   4.0   5.0   2.0   8.0  16.0
 TOR       4  459  1408  187  378   96  ...  265.0  16.0  12.0   4.0  16.0  38.0

[8 rows x 18 columns] 
```  ### 在 `MultiIndex` 的一部分是 `DatetimeIndex` 上的部分字符串索引

部分字符串索引现在匹配 `MultiIndex` 的一部分是 `DateTimeIndex` ([GH 10331](https://github.com/pandas-dev/pandas/issues/10331))

```py
In [20]: dft2 = pd.DataFrame(
 ....:    np.random.randn(20, 1),
 ....:    columns=["A"],
 ....:    index=pd.MultiIndex.from_product(
 ....:        [pd.date_range("20130101", periods=10, freq="12H"), ["a", "b"]]
 ....:    ),
 ....: )
 ....:

In [21]: dft2
Out[21]:
 A
2013-01-01 00:00:00 a  0.469112
 b -0.282863
2013-01-01 12:00:00 a -1.509059
 b -1.135632
2013-01-02 00:00:00 a  1.212112
...                         ...
2013-01-04 12:00:00 b  0.271860
2013-01-05 00:00:00 a -0.424972
 b  0.567020
2013-01-05 12:00:00 a  0.276232
 b -1.087401

[20 rows x 1 columns]

In [22]: dft2.loc["2013-01-05"]
Out[22]:
 A
2013-01-05 00:00:00 a -0.424972
 b  0.567020
2013-01-05 12:00:00 a  0.276232
 b -1.087401

[4 rows x 1 columns] 
```

在其他级别上

```py
In [26]: idx = pd.IndexSlice

In [27]: dft2 = dft2.swaplevel(0, 1).sort_index()

In [28]: dft2
Out[28]:
 A
a 2013-01-01 00:00:00  0.469112
 2013-01-01 12:00:00 -1.509059
 2013-01-02 00:00:00  1.212112
 2013-01-02 12:00:00  0.119209
 2013-01-03 00:00:00 -0.861849
...                         ...
b 2013-01-03 12:00:00  1.071804
 2013-01-04 00:00:00 -0.706771
 2013-01-04 12:00:00  0.271860
 2013-01-05 00:00:00  0.567020
 2013-01-05 12:00:00 -1.087401

[20 rows x 1 columns]

In [29]: dft2.loc[idx[:, "2013-01-05"], :]
Out[29]:
 A
a 2013-01-05 00:00:00 -0.424972
 2013-01-05 12:00:00  0.276232
b 2013-01-05 00:00:00  0.567020
 2013-01-05 12:00:00 -1.087401

[4 rows x 1 columns] 
```  ### 组装日期时间

`pd.to_datetime()` 现在具有从传递的 `DataFrame` 或字典中组装日期时间的能力 ([GH 8158](https://github.com/pandas-dev/pandas/issues/8158)).

```py
In [20]: df = pd.DataFrame(
 ....:    {"year": [2015, 2016], "month": [2, 3], "day": [4, 5], "hour": [2, 3]}
 ....: )
 ....: 

In [21]: df
Out[21]: 
 year  month  day  hour
0  2015      2    4     2
1  2016      3    5     3

[2 rows x 4 columns] 
```

使用传递的框架进行组装。

```py
In [22]: pd.to_datetime(df)
Out[22]: 
0   2015-02-04 02:00:00
1   2016-03-05 03:00:00
Length: 2, dtype: datetime64[ns] 
```

你只需要传递你需要组装的列。

```py
In [23]: pd.to_datetime(df[["year", "month", "day"]])
Out[23]: 
0   2015-02-04
1   2016-03-05
Length: 2, dtype: datetime64[ns] 
```  ### 其他增强

+   `pd.read_csv()` 现在支持 Python 引擎的 `delim_whitespace=True` ([GH 12958](https://github.com/pandas-dev/pandas/issues/12958))

+   `pd.read_csv()` 现在支持打开包含单个 CSV 的 ZIP 文件，通过扩展推断或明确指定 `compression='zip'` ([GH 12175](https://github.com/pandas-dev/pandas/issues/12175))

+   `pd.read_csv()` 现在支持使用 xz 压缩打开文件，通过扩展推断或明确指定 `compression='xz'`；`xz` 压缩也同样被 `DataFrame.to_csv` 支持，方式相同 ([GH 11852](https://github.com/pandas-dev/pandas/issues/11852))

+   `pd.read_msgpack()`现在即使使用压缩，也始终返回可写入的 ndarrays ([GH 12359](https://github.com/pandas-dev/pandas/issues/12359)).

+   `pd.read_msgpack()`现在支持使用 msgpack 序列化和反序列化分类变量 ([GH 12573](https://github.com/pandas-dev/pandas/issues/12573))

+   `.to_json()`现在支持包含分类和稀疏数据的`NDFrames` ([GH 10778](https://github.com/pandas-dev/pandas/issues/10778))

+   `interpolate()`现在支持`method='akima'` ([GH 7588](https://github.com/pandas-dev/pandas/issues/7588)).

+   `pd.read_excel()`现在接受路径对象（例如`pathlib.Path`、`py.path.local`）作为文件路径，与其他`read_*`函数保持一致 ([GH 12655](https://github.com/pandas-dev/pandas/issues/12655))

+   添加了`.weekday_name`属性作为`DatetimeIndex`和`.dt`访问器的组成部分。 ([GH 11128](https://github.com/pandas-dev/pandas/issues/11128))

+   `Index.take`现在一致处理`allow_fill`和`fill_value` ([GH 12631](https://github.com/pandas-dev/pandas/issues/12631))

    ```py
    In [24]: idx = pd.Index([1.0, 2.0, 3.0, 4.0], dtype="float")

    # default, allow_fill=True, fill_value=None
    In [25]: idx.take([2, -1])
    Out[25]: Index([3.0, 4.0], dtype='float64')

    In [26]: idx.take([2, -1], fill_value=True)
    Out[26]: Index([3.0, nan], dtype='float64') 
    ```

+   `Index`现在支持`.str.get_dummies()`，返回`MultiIndex`，参见 Creating Indicator Variables ([GH 10008](https://github.com/pandas-dev/pandas/issues/10008), [GH 10103](https://github.com/pandas-dev/pandas/issues/10103))

    ```py
    In [27]: idx = pd.Index(["a|b", "a|c", "b|c"])

    In [28]: idx.str.get_dummies("|")
    Out[28]: 
    MultiIndex([(1, 1, 0),
     (1, 0, 1),
     (0, 1, 1)],
     names=['a', 'b', 'c']) 
    ```

+   `pd.crosstab()`增加了一个`normalize`参数，用于规范化频率表 ([GH 12569](https://github.com/pandas-dev/pandas/issues/12569)). 更新文档中的示例在这里.

+   `.resample(..).interpolate()`现在受支持 ([GH 12925](https://github.com/pandas-dev/pandas/issues/12925))

+   `.isin()`现在接受传递的`sets` ([GH 12988](https://github.com/pandas-dev/pandas/issues/12988))  ### 自定义工作时间

`CustomBusinessHour`是`BusinessHour`和`CustomBusinessDay`的混合体，允许您指定任意假期。详情请参见 Custom Business Hour ([GH 11514](https://github.com/pandas-dev/pandas/issues/11514))

```py
In [1]: from pandas.tseries.offsets import CustomBusinessHour

In [2]: from pandas.tseries.holiday import USFederalHolidayCalendar

In [3]: bhour_us = CustomBusinessHour(calendar=USFederalHolidayCalendar()) 
```

MLK 日前的星期五

```py
In [4]: import datetime

In [5]: dt = datetime.datetime(2014, 1, 17, 15)

In [6]: dt + bhour_us
Out[6]: Timestamp('2014-01-17 16:00:00') 
```

MLK 日后的星期二（星期一被跳过，因为那是个假日）

```py
In [7]: dt + bhour_us * 2
Out[7]: Timestamp('2014-01-20 09:00:00') 
```

### 方法`.groupby(..)`语法与窗口和重新采样操作

`.groupby(...)`已经增强，提供了方便的语法，用于在每个组中使用`.rolling(..)`、`.expanding(..)`和`.resample(..)`，参见([GH 12486](https://github.com/pandas-dev/pandas/issues/12486), [GH 12738](https://github.com/pandas-dev/pandas/issues/12738)).

现在您可以在 groupbys 上使用`.rolling(..)`和`.expanding(..)`作为方法。这些返回另一个延迟对象（类似于在未分组的 pandas 对象上执行的`.rolling()`和`.expanding()`）。然后，您可以以类似的方式操作这些`RollingGroupby`对象。

以前你需要这样做才能获得��组的滚动窗口均值：

```py
In [8]: df = pd.DataFrame({"A": [1] * 20 + [2] * 12 + [3] * 8, "B": np.arange(40)})

In [9]: df
Out[9]: 
 A   B
0   1   0
1   1   1
2   1   2
3   1   3
4   1   4
.. ..  ..
35  3  35
36  3  36
37  3  37
38  3  38
39  3  39

[40 rows x 2 columns] 
```

```py
In [1]: df.groupby("A").apply(lambda x: x.rolling(4).B.mean())
Out[1]:
A
1  0      NaN
 1      NaN
 2      NaN
 3      1.5
 4      2.5
 5      3.5
 6      4.5
 7      5.5
 8      6.5
 9      7.5
 10     8.5
 11     9.5
 12    10.5
 13    11.5
 14    12.5
 15    13.5
 16    14.5
 17    15.5
 18    16.5
 19    17.5
2  20     NaN
 21     NaN
 22     NaN
 23    21.5
 24    22.5
 25    23.5
 26    24.5
 27    25.5
 28    26.5
 29    27.5
 30    28.5
 31    29.5
3  32     NaN
 33     NaN
 34     NaN
 35    33.5
 36    34.5
 37    35.5
 38    36.5
 39    37.5
Name: B, dtype: float64 
```

现在你可以这样做：

```py
In [10]: df.groupby("A").rolling(4).B.mean()
Out[10]: 
A 
1  0      NaN
 1      NaN
 2      NaN
 3      1.5
 4      2.5
 ... 
3  35    33.5
 36    34.5
 37    35.5
 38    36.5
 39    37.5
Name: B, Length: 40, dtype: float64 
```

对于`.resample(..)`类型的操作，以前你需要：

```py
In [11]: df = pd.DataFrame(
 ....:    {
 ....:        "date": pd.date_range(start="2016-01-01", periods=4, freq="W"),
 ....:        "group": [1, 1, 2, 2],
 ....:        "val": [5, 6, 7, 8],
 ....:    }
 ....: ).set_index("date")
 ....: 

In [12]: df
Out[12]: 
 group  val
date 
2016-01-03      1    5
2016-01-10      1    6
2016-01-17      2    7
2016-01-24      2    8

[4 rows x 2 columns] 
```

```py
In[1]: df.groupby("group").apply(lambda x: x.resample("1D").ffill())
Out[1]:
                  group  val
group date
1     2016-01-03      1    5
      2016-01-04      1    5
      2016-01-05      1    5
      2016-01-06      1    5
      2016-01-07      1    5
      2016-01-08      1    5
      2016-01-09      1    5
      2016-01-10      1    6
2     2016-01-17      2    7
      2016-01-18      2    7
      2016-01-19      2    7
      2016-01-20      2    7
      2016-01-21      2    7
      2016-01-22      2    7
      2016-01-23      2    7
      2016-01-24      2    8 
```

现在你可以这样做：

```py
In[1]: df.groupby("group").resample("1D").ffill()
Out[1]:
                  group  val
group date
1     2016-01-03      1    5
      2016-01-04      1    5
      2016-01-05      1    5
      2016-01-06      1    5
      2016-01-07      1    5
      2016-01-08      1    5
      2016-01-09      1    5
      2016-01-10      1    6
2     2016-01-17      2    7
      2016-01-18      2    7
      2016-01-19      2    7
      2016-01-20      2    7
      2016-01-21      2    7
      2016-01-22      2    7
      2016-01-23      2    7
      2016-01-24      2    8 
```

### 方法链改进

以下方法/索引器现在接受 `callable`。旨在使它们在方法链中更加实用，详见文档（[GH 11485](https://github.com/pandas-dev/pandas/issues/11485), [GH 12533](https://github.com/pandas-dev/pandas/issues/12533)）。

+   `.where()` 和 `.mask()`

+   `.loc[]`、`iloc[]` 和 `.ix[]`

+   `[]` 索引

#### 方法 `.where()` 和 `.mask()`

这些可以接受条件和 `other` 参数的可调用对象。

```py
In [13]: df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})

In [14]: df.where(lambda x: x > 4, lambda x: x + 10)
Out[14]: 
 A   B  C
0  11  14  7
1  12   5  8
2  13   6  9

[3 rows x 3 columns] 
```

#### 方法 `.loc[]`、`.iloc[]`、`.ix[]`

这些可以接受一个可调用对象，以及一个切片器的元组。可调用对象可以返回有效的布尔索引器或适用于这些索引器输入的任何内容。

```py
# callable returns bool indexer
In [15]: df.loc[lambda x: x.A >= 2, lambda x: x.sum() > 10]
Out[15]: 
 B  C
1  5  8
2  6  9

[2 rows x 2 columns]

# callable returns list of labels
In [16]: df.loc[lambda x: [1, 2], lambda x: ["A", "B"]]
Out[16]: 
 A  B
1  2  5
2  3  6

[2 rows x 2 columns] 
```

#### 使用 `[]` 进行索引

最后，你可以在 Series、DataFrame 和 Panel 的 `[]` 索引中使用可调用对象。可调用对象必须根据其类别和索引类型返回 `[]` 索引的有效输入。

```py
In [17]: df[lambda x: "A"]
Out[17]: 
0    1
1    2
2    3
Name: A, Length: 3, dtype: int64 
```

使用这些方法/索引器，你可以在不使用临时变量的情况下链接数据选择操作。

```py
In [18]: bb = pd.read_csv("data/baseball.csv", index_col="id")

In [19]: (bb.groupby(["year", "team"]).sum(numeric_only=True).loc[lambda df: df.r > 100])
Out[19]: 
 stint    g    ab    r    h  X2b  ...     so   ibb   hbp    sh    sf  gidp
year team                                   ... 
2007 CIN       6  379   745  101  203   35  ...  127.0  14.0   1.0   1.0  15.0  18.0
 DET       5  301  1062  162  283   54  ...  176.0   3.0  10.0   4.0   8.0  28.0
 HOU       4  311   926  109  218   47  ...  212.0   3.0   9.0  16.0   6.0  17.0
 LAN      11  413  1021  153  293   61  ...  141.0   8.0   9.0   3.0   8.0  29.0
 NYN      13  622  1854  240  509  101  ...  310.0  24.0  23.0  18.0  15.0  48.0
 SFN       5  482  1305  198  337   67  ...  188.0  51.0   8.0  16.0   6.0  41.0
 TEX       2  198   729  115  200   40  ...  140.0   4.0   5.0   2.0   8.0  16.0
 TOR       4  459  1408  187  378   96  ...  265.0  16.0  12.0   4.0  16.0  38.0

[8 rows x 18 columns] 
```

#### 方法 `.where()` 和 `.mask()`

这些可以接受条件和 `other` 参数的可调用对象。

```py
In [13]: df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})

In [14]: df.where(lambda x: x > 4, lambda x: x + 10)
Out[14]: 
 A   B  C
0  11  14  7
1  12   5  8
2  13   6  9

[3 rows x 3 columns] 
```

#### 方法 `.loc[]`、`.iloc[]`、`.ix[]`

这些可以接受一个可调用对象，以及一个切片器的元组。可调用对象可以返回有效的布尔索引器或适用于这些索引器输入的任何内容。

```py
# callable returns bool indexer
In [15]: df.loc[lambda x: x.A >= 2, lambda x: x.sum() > 10]
Out[15]: 
 B  C
1  5  8
2  6  9

[2 rows x 2 columns]

# callable returns list of labels
In [16]: df.loc[lambda x: [1, 2], lambda x: ["A", "B"]]
Out[16]: 
 A  B
1  2  5
2  3  6

[2 rows x 2 columns] 
```

#### 使用 `[]` 进行索引

最后，你可以在 Series、DataFrame 和 Panel 的 `[]` 索引中使用可调用对象。可调用对象必须根据其类别和索引类型返回 `[]` 索引的有效输入。

```py
In [17]: df[lambda x: "A"]
Out[17]: 
0    1
1    2
2    3
Name: A, Length: 3, dtype: int64 
```

使用这些方法/索引器，你可以在不使用临时变量的情况下链接数据选择操作。

```py
In [18]: bb = pd.read_csv("data/baseball.csv", index_col="id")

In [19]: (bb.groupby(["year", "team"]).sum(numeric_only=True).loc[lambda df: df.r > 100])
Out[19]: 
 stint    g    ab    r    h  X2b  ...     so   ibb   hbp    sh    sf  gidp
year team                                   ... 
2007 CIN       6  379   745  101  203   35  ...  127.0  14.0   1.0   1.0  15.0  18.0
 DET       5  301  1062  162  283   54  ...  176.0   3.0  10.0   4.0   8.0  28.0
 HOU       4  311   926  109  218   47  ...  212.0   3.0   9.0  16.0   6.0  17.0
 LAN      11  413  1021  153  293   61  ...  141.0   8.0   9.0   3.0   8.0  29.0
 NYN      13  622  1854  240  509  101  ...  310.0  24.0  23.0  18.0  15.0  48.0
 SFN       5  482  1305  198  337   67  ...  188.0  51.0   8.0  16.0   6.0  41.0
 TEX       2  198   729  115  200   40  ...  140.0   4.0   5.0   2.0   8.0  16.0
 TOR       4  459  1408  187  378   96  ...  265.0  16.0  12.0   4.0  16.0  38.0

[8 rows x 18 columns] 
```

### 部分字符串索引在 `DatetimeIndex` 的一部分时

当作为 `MultiIndex` 的一部分时，部分字符串索引现在匹配 `DateTimeIndex`（[GH 10331](https://github.com/pandas-dev/pandas/issues/10331)）。

```py
In [20]: dft2 = pd.DataFrame(
 ....:    np.random.randn(20, 1),
 ....:    columns=["A"],
 ....:    index=pd.MultiIndex.from_product(
 ....:        [pd.date_range("20130101", periods=10, freq="12H"), ["a", "b"]]
 ....:    ),
 ....: )
 ....:

In [21]: dft2
Out[21]:
 A
2013-01-01 00:00:00 a  0.469112
 b -0.282863
2013-01-01 12:00:00 a -1.509059
 b -1.135632
2013-01-02 00:00:00 a  1.212112
...                         ...
2013-01-04 12:00:00 b  0.271860
2013-01-05 00:00:00 a -0.424972
 b  0.567020
2013-01-05 12:00:00 a  0.276232
 b -1.087401

[20 rows x 1 columns]

In [22]: dft2.loc["2013-01-05"]
Out[22]:
 A
2013-01-05 00:00:00 a -0.424972
 b  0.567020
2013-01-05 12:00:00 a  0.276232
 b -1.087401

[4 rows x 1 columns] 
```

在其他级别上

```py
In [26]: idx = pd.IndexSlice

In [27]: dft2 = dft2.swaplevel(0, 1).sort_index()

In [28]: dft2
Out[28]:
 A
a 2013-01-01 00:00:00  0.469112
 2013-01-01 12:00:00 -1.509059
 2013-01-02 00:00:00  1.212112
 2013-01-02 12:00:00  0.119209
 2013-01-03 00:00:00 -0.861849
...                         ...
b 2013-01-03 12:00:00  1.071804
 2013-01-04 00:00:00 -0.706771
 2013-01-04 12:00:00  0.271860
 2013-01-05 00:00:00  0.567020
 2013-01-05 12:00:00 -1.087401

[20 rows x 1 columns]

In [29]: dft2.loc[idx[:, "2013-01-05"], :]
Out[29]:
 A
a 2013-01-05 00:00:00 -0.424972
 2013-01-05 12:00:00  0.276232
b 2013-01-05 00:00:00  0.567020
 2013-01-05 12:00:00 -1.087401

[4 rows x 1 columns] 
```

### 组装日期时间

`pd.to_datetime()` 现在具有从传递的 `DataFrame` 或字典组装日期时间的能力（[GH 8158](https://github.com/pandas-dev/pandas/issues/8158)）。

```py
In [20]: df = pd.DataFrame(
 ....:    {"year": [2015, 2016], "month": [2, 3], "day": [4, 5], "hour": [2, 3]}
 ....: )
 ....: 

In [21]: df
Out[21]: 
 year  month  day  hour
0  2015      2    4     2
1  2016      3    5     3

[2 rows x 4 columns] 
```

使用传递的框架进行组装。

```py
In [22]: pd.to_datetime(df)
Out[22]: 
0   2015-02-04 02:00:00
1   2016-03-05 03:00:00
Length: 2, dtype: datetime64[ns] 
```

你只需传递需要组装的列。

```py
In [23]: pd.to_datetime(df[["year", "month", "day"]])
Out[23]: 
0   2015-02-04
1   2016-03-05
Length: 2, dtype: datetime64[ns] 
```

### 其他增强

+   `pd.read_csv()` 现在支持 Python 引擎的 `delim_whitespace=True`（[GH 12958](https://github.com/pandas-dev/pandas/issues/12958)）。

+   `pd.read_csv()` 现在支持通过扩展推断或明确指定 `compression='zip'` 来打开包含单个 CSV 的 ZIP 文件（[GH 12175](https://github.com/pandas-dev/pandas/issues/12175)）。

+   `pd.read_csv()` 现在支持使用 xz 压缩打开文件，通过扩展推断或明确指定 `compression='xz'`；`xz` 压缩也同样被 `DataFrame.to_csv` 支持（[GH 11852](https://github.com/pandas-dev/pandas/issues/11852)）。

+   `pd.read_msgpack()` 现在即使使用了压缩，也总是返回可写入的 ndarrays（[GH 12359](https://github.com/pandas-dev/pandas/issues/12359)）。

+   `pd.read_msgpack()` 现在支持使用 msgpack 序列化和反序列化分类数据（[GH 12573](https://github.com/pandas-dev/pandas/issues/12573)）

+   `.to_json()` 现在支持包含分类和稀疏数据的 `NDFrames`（[GH 10778](https://github.com/pandas-dev/pandas/issues/10778)）

+   `interpolate()` 现在支持 `method='akima'`（[GH 7588](https://github.com/pandas-dev/pandas/issues/7588)）

+   `pd.read_excel()` 现在接受路径对象（例如 `pathlib.Path`，`py.path.local`）作为文件路径，与其他 `read_*` 函数保持一致（[GH 12655](https://github.com/pandas-dev/pandas/issues/12655)）

+   增加了 `.weekday_name` 属性作为 `DatetimeIndex` 和 `.dt` 访问器的组成部分（[GH 11128](https://github.com/pandas-dev/pandas/issues/11128)）

+   `Index.take` 现在一致地处理 `allow_fill` 和 `fill_value`（[GH 12631](https://github.com/pandas-dev/pandas/issues/12631)）

    ```py
    In [24]: idx = pd.Index([1.0, 2.0, 3.0, 4.0], dtype="float")

    # default, allow_fill=True, fill_value=None
    In [25]: idx.take([2, -1])
    Out[25]: Index([3.0, 4.0], dtype='float64')

    In [26]: idx.take([2, -1], fill_value=True)
    Out[26]: Index([3.0, nan], dtype='float64') 
    ```

+   `Index` 现在支持 `.str.get_dummies()`，返回 `MultiIndex`，详见 创建指示变量（[GH 10008](https://github.com/pandas-dev/pandas/issues/10008)，[GH 10103](https://github.com/pandas-dev/pandas/issues/10103)）

    ```py
    In [27]: idx = pd.Index(["a|b", "a|c", "b|c"])

    In [28]: idx.str.get_dummies("|")
    Out[28]: 
    MultiIndex([(1, 1, 0),
     (1, 0, 1),
     (0, 1, 1)],
     names=['a', 'b', 'c']) 
    ```

+   `pd.crosstab()` 增加了 `normalize` 参数以对频率表进行归一化处理（[GH 12569](https://github.com/pandas-dev/pandas/issues/12569)）。更新的文档示例在 这里。

+   `.resample(..).interpolate()` 现在受支持（[GH 12925](https://github.com/pandas-dev/pandas/issues/12925)）

+   `.isin()` 现在接受传递的 `sets`（[GH 12988](https://github.com/pandas-dev/pandas/issues/12988)）

## 稀疏变化

这些变化使稀疏处理返回正确的类型，并努力使索引体验更加流畅。

`SparseArray.take` 现在对标量输入返回标量，对其他输入返回 `SparseArray`。此外，它以与 `Index` 相同的规则处理负索引器（[GH 10560](https://github.com/pandas-dev/pandas/issues/10560)，[GH 12796](https://github.com/pandas-dev/pandas/issues/12796)）

```py
s = pd.SparseArray([np.nan, np.nan, 1, 2, 3, np.nan, 4, 5, np.nan, 6])
s.take(0)
s.take([1, 2, 3]) 
```

+   `SparseSeries[]` 使用 `Ellipsis` 进行索引时会引发 `KeyError` 的 Bug（[GH 9467](https://github.com/pandas-dev/pandas/issues/9467)）

+   `SparseArray[]` 对元组进行索引的 Bug 没有得到正确处理（[GH 12966](https://github.com/pandas-dev/pandas/issues/12966)）

+   `SparseSeries.loc[]` 中出现列表类似输入时引发 `TypeError` 的 Bug（[GH 10560](https://github.com/pandas-dev/pandas/issues/10560)）

+   `SparseSeries.iloc[]` 中出现标量输入可能引发 `IndexError` 的 Bug（[GH 10560](https://github.com/pandas-dev/pandas/issues/10560)）

+   `SparseSeries.loc[]`、`.iloc[]` 中使用 `slice` 返回 `SparseArray`，而不是 `SparseSeries` 的 Bug（[GH 10560](https://github.com/pandas-dev/pandas/issues/10560)）

+   `SparseDataFrame.loc[]`、`.iloc[]` 中出现的 Bug 可能导致密集 `Series`，而不是 `SparseSeries`（[GH 12787](https://github.com/pandas-dev/pandas/issues/12787)）

+   `SparseArray` 的加法中忽略右侧的 `fill_value` 的 Bug ([GH 12910](https://github.com/pandas-dev/pandas/issues/12910))

+   `SparseArray` 的 mod 函数中存在 Bug，会引发 `AttributeError` ([GH 12910](https://github.com/pandas-dev/pandas/issues/12910))

+   `SparseArray` 的 pow 函数中存在 Bug，将 `1 ** np.nan` 计算为 `np.nan`，应该是 `1` ([GH 12910](https://github.com/pandas-dev/pandas/issues/12910))

+   `SparseArray` 比较输出的 Bug 可能会产生不正确的结果或引发 `ValueError` ([GH 12971](https://github.com/pandas-dev/pandas/issues/12971))

+   `SparseSeries.__repr__` 中存在 Bug，当长度超过 `max_rows` 时会引发 `TypeError` ([GH 10560](https://github.com/pandas-dev/pandas/issues/10560))

+   `SparseSeries.shape` 中存在 Bug，忽略了 `fill_value` ([GH 10452](https://github.com/pandas-dev/pandas/issues/10452))

+   `SparseSeries` 和 `SparseArray` 中的 Bug 可能与其密集值的 `dtype` 不同 ([GH 12908](https://github.com/pandas-dev/pandas/issues/12908))

+   `SparseSeries.reindex` 中存在 Bug，不正确处理 `fill_value` ([GH 12797](https://github.com/pandas-dev/pandas/issues/12797))

+   `SparseArray.to_frame()` 中存在 Bug，结果是 `DataFrame`，而不是 `SparseDataFrame` ([GH 9850](https://github.com/pandas-dev/pandas/issues/9850))

+   `SparseSeries.value_counts()` 中存在 Bug，不计算 `fill_value` ([GH 6749](https://github.com/pandas-dev/pandas/issues/6749))

+   `SparseArray.to_dense()` 中存在 Bug，不保留 `dtype` ([GH 10648](https://github.com/pandas-dev/pandas/issues/10648))

+   `SparseArray.to_dense()` 中不正确处理 `fill_value` 的 Bug ([GH 12797](https://github.com/pandas-dev/pandas/issues/12797))

+   `pd.concat()` 中的 `SparseSeries` 导致密集化的 Bug ([GH 10536](https://github.com/pandas-dev/pandas/issues/10536))

+   `pd.concat()` 中的 `SparseDataFrame` 不正确处理 `fill_value` 的 Bug ([GH 9765](https://github.com/pandas-dev/pandas/issues/9765))

+   `pd.concat()` 中的 `SparseDataFrame` 可能会引发 `AttributeError` 的 Bug ([GH 12174](https://github.com/pandas-dev/pandas/issues/12174))

+   `SparseArray.shift()` 中存在 Bug，可能会引发 `NameError` 或 `TypeError` ([GH 12908](https://github.com/pandas-dev/pandas/issues/12908))

## API 变更

### 方法 `.groupby(..).nth()` 变更

当传递 `as_index` 参数时，`.groupby(..).nth()` 输出的索引现在更加一致了 ([GH 11039](https://github.com/pandas-dev/pandas/issues/11039)):

```py
In [29]: df = pd.DataFrame({"A": ["a", "b", "a"], "B": [1, 2, 3]})

In [30]: df
Out[30]: 
 A  B
0  a  1
1  b  2
2  a  3

[3 rows x 2 columns] 
```

之前的行为：

```py
In [3]: df.groupby('A', as_index=True)['B'].nth(0)
Out[3]:
0    1
1    2
Name: B, dtype: int64

In [4]: df.groupby('A', as_index=False)['B'].nth(0)
Out[4]:
0    1
1    2
Name: B, dtype: int64 
```

新行为：

```py
In [31]: df.groupby("A", as_index=True)["B"].nth(0)
Out[31]: 
0    1
1    2
Name: B, Length: 2, dtype: int64

In [32]: df.groupby("A", as_index=False)["B"].nth(0)
Out[32]: 
0    1
1    2
Name: B, Length: 2, dtype: int64 
```

此外，以前，`.groupby` 总是会排序，即使传递了 `sort=False` 也是如此，与 `.nth()` 一起。

```py
In [33]: np.random.seed(1234)

In [34]: df = pd.DataFrame(np.random.randn(100, 2), columns=["a", "b"])

In [35]: df["c"] = np.random.randint(0, 4, 100) 
```

之前的行为：

```py
In [4]: df.groupby('c', sort=True).nth(1)
Out[4]:
 a         b
c
0 -0.334077  0.002118
1  0.036142 -2.074978
2 -0.720589  0.887163
3  0.859588 -0.636524

In [5]: df.groupby('c', sort=False).nth(1)
Out[5]:
 a         b
c
0 -0.334077  0.002118
1  0.036142 -2.074978
2 -0.720589  0.887163
3  0.859588 -0.636524 
```

新行为：

```py
In [36]: df.groupby("c", sort=True).nth(1)
Out[36]: 
 a         b  c
2  -0.720589  0.887163  2
3   0.859588 -0.636524  3
7  -0.334077  0.002118  0
21  0.036142 -2.074978  1

[4 rows x 3 columns]

In [37]: df.groupby("c", sort=False).nth(1)
Out[37]: 
 a         b  c
2  -0.720589  0.887163  2
3   0.859588 -0.636524  3
7  -0.334077  0.002118  0
21  0.036142 -2.074978  1

[4 rows x 3 columns] 
```  ### NumPy 函数兼容性

通过增加`pandas`方法的签名，使其接受可以从`numpy`传递的参数，即使它们在`pandas`实现中并不一定被使用，大大增加了`pandas`数组方法（例如`sum`和`take`）与它们的`numpy`对应方法之间的兼容性。([GH 12644](https://github.com/pandas-dev/pandas/issues/12644), [GH 12638](https://github.com/pandas-dev/pandas/issues/12638), [GH 12687](https://github.com/pandas-dev/pandas/issues/12687))

+   `.searchsorted()`对于`Index`和`TimedeltaIndex`现在接受一个`sorter`参数，以保持与 numpy 的`searchsorted`函数的兼容性([GH 12238](https://github.com/pandas-dev/pandas/issues/12238))

+   在`Series`上的`np.round()`的 numpy 兼容性中存在错误([GH 12600](https://github.com/pandas-dev/pandas/issues/12600))

一个此类签名增强的示例如下所示：

```py
sp = pd.SparseDataFrame([1, 2, 3])
sp 
```

先前行为：

```py
In [2]: np.cumsum(sp, axis=0)
...
TypeError: cumsum() takes at most 2 arguments (4 given) 
```

新行为：

```py
np.cumsum(sp, axis=0) 
```  ### 在 GroupBy 重新采样上使用`.apply`

使用`apply`在重新采样分组操作（使用`pd.TimeGrouper`）上，现在具有与其他分组操作上类似的`apply`调用相同的输出类型。([GH 11742](https://github.com/pandas-dev/pandas/issues/11742))。

```py
In [38]: df = pd.DataFrame(
 ....:    {"date": pd.to_datetime(["10/10/2000", "11/10/2000"]), "value": [10, 13]}
 ....: )
 ....: 

In [39]: df
Out[39]: 
 date  value
0 2000-10-10     10
1 2000-11-10     13

[2 rows x 2 columns] 
```

先前行为：

```py
In [1]: df.groupby(pd.TimeGrouper(key='date',
 ...:                          freq='M')).apply(lambda x: x.value.sum())
Out[1]:
...
TypeError: cannot concatenate a non-NDFrame object

# Output is a Series
In [2]: df.groupby(pd.TimeGrouper(key='date',
 ...:                          freq='M')).apply(lambda x: x[['value']].sum())
Out[2]:
date
2000-10-31  value    10
2000-11-30  value    13
dtype: int64 
```

新行为：

```py
# Output is a Series
In [55]: df.groupby(pd.TimeGrouper(key='date',
 ...:                           freq='M')).apply(lambda x: x.value.sum())
Out[55]:
date
2000-10-31    10
2000-11-30    13
Freq: M, dtype: int64

# Output is a DataFrame
In [56]: df.groupby(pd.TimeGrouper(key='date',
 ...:                           freq='M')).apply(lambda x: x[['value']].sum())
Out[56]:
 value
date
2000-10-31     10
2000-11-30     13 
```  ### `read_csv`异常的更改

为了使`read_csv` API 在`c`和`python`引擎上标准化，现在两者都将对空列或标题引发`EmptyDataError`，这是`ValueError`的子类。([GH 12493](https://github.com/pandas-dev/pandas/issues/12493), [GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

先前行为：

```py
In [1]: import io

In [2]: df = pd.read_csv(io.StringIO(''), engine='c')
...
ValueError: No columns to parse from file

In [3]: df = pd.read_csv(io.StringIO(''), engine='python')
...
StopIteration 
```

新行为：

```py
In [1]: df = pd.read_csv(io.StringIO(''), engine='c')
...
pandas.io.common.EmptyDataError: No columns to parse from file

In [2]: df = pd.read_csv(io.StringIO(''), engine='python')
...
pandas.io.common.EmptyDataError: No columns to parse from file 
```

除了这个错误更改之外，还进行了其他几个更改：

+   `CParserError`现在是`ValueError`的子类，而不仅仅是`Exception`([GH 12551](https://github.com/pandas-dev/pandas/issues/12551))

+   当`c`引擎无法解析列时，在`read_csv`中现在会引发`CParserError`而不是通用的`Exception`([GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

+   当`c`引擎在整数列中遇到`NaN`值时，在`read_csv`中现在会引发`ValueError`而不是通用的`Exception`([GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

+   当指定`true_values`并且`c`引擎遇到包含不可编码字节的列中的元素时，在`read_csv`中现在会引发`ValueError`而不是通用的`Exception`([GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

+   `pandas.parser.OverflowError`异常已被移除，并已被 Python 内置的`OverflowError`异常替换([GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

+   `pd.read_csv()`不再允许在`usecols`参数中组合字符串和整数。([GH 12678](https://github.com/pandas-dev/pandas/issues/12678))  ### 方法`to_datetime`错误更改

在`pd.to_datetime()`中传递可转换条目和`errors='coerce'`或不可转换条目和`errors='ignore'`时存在错误。此外，当`errors='raise'`时遇到超出范围值时将引发`OutOfBoundsDateime`异常。([GH 11758](https://github.com/pandas-dev/pandas/issues/11758), [GH 13052](https://github.com/pandas-dev/pandas/issues/13052), [GH 13059](https://github.com/pandas-dev/pandas/issues/13059))

先前的行为:

```py
In [27]: pd.to_datetime(1420043460, unit='s', errors='coerce')
Out[27]: NaT

In [28]: pd.to_datetime(11111111, unit='D', errors='ignore')
OverflowError: Python int too large to convert to C long

In [29]: pd.to_datetime(11111111, unit='D', errors='raise')
OverflowError: Python int too large to convert to C long 
```

新行为:

```py
In [2]: pd.to_datetime(1420043460, unit='s', errors='coerce')
Out[2]: Timestamp('2014-12-31 16:31:00')

In [3]: pd.to_datetime(11111111, unit='D', errors='ignore')
Out[3]: 11111111

In [4]: pd.to_datetime(11111111, unit='D', errors='raise')
OutOfBoundsDatetime: cannot convert input with unit 'D' 
```  ### 其他 API 更改

+   对于`Series`、`DataFrame`、`Panel`和`MultiIndex`的`.swaplevel()`现在具有其前两个参数`i`和`j`的默认值，这两个参数交换索引的最内层级别。([GH 12934](https://github.com/pandas-dev/pandas/issues/12934))

+   `.searchsorted()`对于`Index`和`TimedeltaIndex`现在接受一个`sorter`参数以保持与 numpy 的`searchsorted`函数的兼容性 ([GH 12238](https://github.com/pandas-dev/pandas/issues/12238))

+   `Period`和`PeriodIndex`现在引发`IncompatibleFrequency`错误，该错误继承自`ValueError`而不是原始的`ValueError` ([GH 12615](https://github.com/pandas-dev/pandas/issues/12615))

+   `Series.apply`对于类别 dtype 现在将传递的函数应用于每个`.categories`（而不是`.codes`），如果可能的话返回`category` dtype ([GH 12473](https://github.com/pandas-dev/pandas/issues/12473))

+   `read_csv`现在会在`parse_dates`既不是布尔值、列表或字典时引发`TypeError`（与文档字符串匹配）([GH 5636](https://github.com/pandas-dev/pandas/issues/5636))

+   `.query()/.eval()`的默认值现在是`engine=None`，如果安装了`numexpr`，则会使用`numexpr`；否则将回退到`python`引擎。如果安装了`numexpr`，则模仿了 0.18.1 之前的行为（以前，如果未安装`numexpr`，`.query()/.eval()`会引发异常）。([GH 12749](https://github.com/pandas-dev/pandas/issues/12749))

+   `pd.show_versions()`现在包括`pandas_datareader`版本 ([GH 12740](https://github.com/pandas-dev/pandas/issues/12740))

+   为通用函数提供适当的`__name__`和`__qualname__`属性 ([GH 12021](https://github.com/pandas-dev/pandas/issues/12021))

+   `pd.concat(ignore_index=True)`现在默认使用`RangeIndex` ([GH 12695](https://github.com/pandas-dev/pandas/issues/12695))

+   当将单级和多级数据框合并/连接时，`pd.merge()`和`DataFrame.join()`将显示`UserWarning` ([GH 9455](https://github.com/pandas-dev/pandas/issues/9455), [GH 12219](https://github.com/pandas-dev/pandas/issues/12219))

+   与`scipy` > 0.17 兼容的已弃用的`piecewise_polynomial`插值方法；支持替代的`from_derivatives`方法 ([GH 12887](https://github.com/pandas-dev/pandas/issues/12887))  ### 弃用

+   方法名`Index.sym_diff()`已弃用，可以替换为`Index.symmetric_difference()` ([GH 12591](https://github.com/pandas-dev/pandas/issues/12591))

+   方法名 `Categorical.sort()` 已被弃用，推荐使用 `Categorical.sort_values()` ([GH 12882](https://github.com/pandas-dev/pandas/issues/12882))  ### 方法 `.groupby(..).nth()` 的变化

当传递 `as_index` 参数时，`.groupby(..).nth()` 输出中的索引现在更加一致 ([GH 11039](https://github.com/pandas-dev/pandas/issues/11039)):

```py
In [29]: df = pd.DataFrame({"A": ["a", "b", "a"], "B": [1, 2, 3]})

In [30]: df
Out[30]: 
 A  B
0  a  1
1  b  2
2  a  3

[3 rows x 2 columns] 
```

先前的行为：

```py
In [3]: df.groupby('A', as_index=True)['B'].nth(0)
Out[3]:
0    1
1    2
Name: B, dtype: int64

In [4]: df.groupby('A', as_index=False)['B'].nth(0)
Out[4]:
0    1
1    2
Name: B, dtype: int64 
```

新行为：

```py
In [31]: df.groupby("A", as_index=True)["B"].nth(0)
Out[31]: 
0    1
1    2
Name: B, Length: 2, dtype: int64

In [32]: df.groupby("A", as_index=False)["B"].nth(0)
Out[32]: 
0    1
1    2
Name: B, Length: 2, dtype: int64 
```

此外，以前，`.groupby` 总是会排序，无论是否使用 `.nth()` 传递了 `sort=False`。

```py
In [33]: np.random.seed(1234)

In [34]: df = pd.DataFrame(np.random.randn(100, 2), columns=["a", "b"])

In [35]: df["c"] = np.random.randint(0, 4, 100) 
```

先前的行为：

```py
In [4]: df.groupby('c', sort=True).nth(1)
Out[4]:
 a         b
c
0 -0.334077  0.002118
1  0.036142 -2.074978
2 -0.720589  0.887163
3  0.859588 -0.636524

In [5]: df.groupby('c', sort=False).nth(1)
Out[5]:
 a         b
c
0 -0.334077  0.002118
1  0.036142 -2.074978
2 -0.720589  0.887163
3  0.859588 -0.636524 
```

新行为：

```py
In [36]: df.groupby("c", sort=True).nth(1)
Out[36]: 
 a         b  c
2  -0.720589  0.887163  2
3   0.859588 -0.636524  3
7  -0.334077  0.002118  0
21  0.036142 -2.074978  1

[4 rows x 3 columns]

In [37]: df.groupby("c", sort=False).nth(1)
Out[37]: 
 a         b  c
2  -0.720589  0.887163  2
3   0.859588 -0.636524  3
7  -0.334077  0.002118  0
21  0.036142 -2.074978  1

[4 rows x 3 columns] 
```

### NumPy 函数兼容性

增加了 pandas 数组类方法（例如 `sum` 和 `take`）与它们的 `numpy` 对应方法之间的兼容性，通过增加 `pandas` 方法的签名，使其接受可以从 `numpy` 传递的参数，即使它们在 `pandas` 实现中并不一定会使用 ([GH 12644](https://github.com/pandas-dev/pandas/issues/12644), [GH 12638](https://github.com/pandas-dev/pandas/issues/12638), [GH 12687](https://github.com/pandas-dev/pandas/issues/12687))

+   `.searchsorted()` 用于 `Index` 和 `TimedeltaIndex` 现在接受一个 `sorter` 参数，以保持与 numpy 的 `searchsorted` 函数的兼容性 ([GH 12238](https://github.com/pandas-dev/pandas/issues/12238))

+   在 `Series` 上 `np.round()` 的 numpy 兼容性错误 ([GH 12600](https://github.com/pandas-dev/pandas/issues/12600))

此签名增强的示例如下：

```py
sp = pd.SparseDataFrame([1, 2, 3])
sp 
```

先前的行为：

```py
In [2]: np.cumsum(sp, axis=0)
...
TypeError: cumsum() takes at most 2 arguments (4 given) 
```

新行为：

```py
np.cumsum(sp, axis=0) 
```

### 在 GroupBy 重采样上使用 `.apply`

在重采样 GroupBy 操作（使用 `pd.TimeGrouper`）上使用 `apply` 现在与其他 GroupBy 操作上的类似 `apply` 调用具有相同的输出类型。 ([GH 11742](https://github.com/pandas-dev/pandas/issues/11742)).

```py
In [38]: df = pd.DataFrame(
 ....:    {"date": pd.to_datetime(["10/10/2000", "11/10/2000"]), "value": [10, 13]}
 ....: )
 ....: 

In [39]: df
Out[39]: 
 date  value
0 2000-10-10     10
1 2000-11-10     13

[2 rows x 2 columns] 
```

先前的行为：

```py
In [1]: df.groupby(pd.TimeGrouper(key='date',
 ...:                          freq='M')).apply(lambda x: x.value.sum())
Out[1]:
...
TypeError: cannot concatenate a non-NDFrame object

# Output is a Series
In [2]: df.groupby(pd.TimeGrouper(key='date',
 ...:                          freq='M')).apply(lambda x: x[['value']].sum())
Out[2]:
date
2000-10-31  value    10
2000-11-30  value    13
dtype: int64 
```

新行为：

```py
# Output is a Series
In [55]: df.groupby(pd.TimeGrouper(key='date',
 ...:                           freq='M')).apply(lambda x: x.value.sum())
Out[55]:
date
2000-10-31    10
2000-11-30    13
Freq: M, dtype: int64

# Output is a DataFrame
In [56]: df.groupby(pd.TimeGrouper(key='date',
 ...:                           freq='M')).apply(lambda x: x[['value']].sum())
Out[56]:
 value
date
2000-10-31     10
2000-11-30     13 
```

### `read_csv` 异常的变化

为了使 `c` 和 `python` 引擎的 `read_csv` API 标准化，现在两者都会在空列或标题的情况下引发 `EmptyDataError`，它是 `ValueError` 的子类 ([GH 12493](https://github.com/pandas-dev/pandas/issues/12493), [GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

先前的行为：

```py
In [1]: import io

In [2]: df = pd.read_csv(io.StringIO(''), engine='c')
...
ValueError: No columns to parse from file

In [3]: df = pd.read_csv(io.StringIO(''), engine='python')
...
StopIteration 
```

新行为：

```py
In [1]: df = pd.read_csv(io.StringIO(''), engine='c')
...
pandas.io.common.EmptyDataError: No columns to parse from file

In [2]: df = pd.read_csv(io.StringIO(''), engine='python')
...
pandas.io.common.EmptyDataError: No columns to parse from file 
```

除了这个错误的更改之外，还进行了其他几个更改：

+   `CParserError` 现在子类化 `ValueError` 而不仅仅是 `Exception` ([GH 12551](https://github.com/pandas-dev/pandas/issues/12551))

+   当 `c` 引擎无法解析列时，`read_csv` 现在会引发 `CParserError` 而不是一般的 `Exception` ([GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

+   当 `c` 引擎在整数列中遇到 `NaN` 值时，`read_csv` 现在会引发 `ValueError` 而不是一般的 `Exception` ([GH 12506](https://github.com/pandas-dev/pandas/issues/12506))

+   当指定 `true_values` 时，现在在 `read_csv` 中抛出 `ValueError` 而不是通用的 `Exception`，并且 `c` 引擎在包含无法编码的字节的列中遇到一个元素时将会抛出异常（[GH 12506](https://github.com/pandas-dev/pandas/issues/12506)）

+   `pandas.parser.OverflowError` 异常已被移除，并已被 Python 的内置 `OverflowError` 异常取代（[GH 12506](https://github.com/pandas-dev/pandas/issues/12506)）

+   `pd.read_csv()` 现在不再允许在 `usecols` 参数中组合字符串和整数（[GH 12678](https://github.com/pandas-dev/pandas/issues/12678)）

### `to_datetime` 方法错误变更

在传递可转换条目的 `unit` 和 `errors='coerce'` 或不可转换的 `errors='ignore'` 时，`pd.to_datetime()` 中存在错误。此外，当 `errors='raise'` 时遇到超出范围的值时，将引发 `OutOfBoundsDateime` 异常。([GH 11758](https://github.com/pandas-dev/pandas/issues/11758), [GH 13052](https://github.com/pandas-dev/pandas/issues/13052), [GH 13059](https://github.com/pandas-dev/pandas/issues/13059))

之前的行为：

```py
In [27]: pd.to_datetime(1420043460, unit='s', errors='coerce')
Out[27]: NaT

In [28]: pd.to_datetime(11111111, unit='D', errors='ignore')
OverflowError: Python int too large to convert to C long

In [29]: pd.to_datetime(11111111, unit='D', errors='raise')
OverflowError: Python int too large to convert to C long 
```

新行为：

```py
In [2]: pd.to_datetime(1420043460, unit='s', errors='coerce')
Out[2]: Timestamp('2014-12-31 16:31:00')

In [3]: pd.to_datetime(11111111, unit='D', errors='ignore')
Out[3]: 11111111

In [4]: pd.to_datetime(11111111, unit='D', errors='raise')
OutOfBoundsDatetime: cannot convert input with unit 'D' 
```

### 其他 API 变更

+   对于 `Series`、`DataFrame`、`Panel` 和 `MultiIndex`，`.swaplevel()` 现在具有其前两个参数 `i` 和 `j` 的默认值，用于交换索引的两个最内层级别。([GH 12934](https://github.com/pandas-dev/pandas/issues/12934))

+   对于 `Index` 和 `TimedeltaIndex`，`.searchsorted()` 现在接受一个 `sorter` 参数以保持与 numpy 的 `searchsorted` 函数的兼容性（[GH 12238](https://github.com/pandas-dev/pandas/issues/12238)）

+   `Period` 和 `PeriodIndex` 现在引发 `IncompatibleFrequency` 错误，该错误继承自 `ValueError` 而不是原始的 `ValueError`（[GH 12615](https://github.com/pandas-dev/pandas/issues/12615)）

+   `Series.apply` 对于类别 dtype 现在将传递的函数应用于每个 `.categories`（而不是 `.codes`），并在可能的情况下返回一个 `category` dtype（[GH 12473](https://github.com/pandas-dev/pandas/issues/12473)）

+   如果 `parse_dates` 不是布尔值、列表或字典（与文档字符串匹配），`read_csv` 现在会引发 `TypeError`（[GH 5636](https://github.com/pandas-dev/pandas/issues/5636)）

+   `.query()/.eval()` 的默认值现在是 `engine=None`，如果安装了 `numexpr`，则会使用它；否则将退回到 `python` 引擎。如果安装了 `numexpr`，则这模仿了 0.18.1 之前的行为（如果未安装 `numexpr`，`.query()/.eval()` 将引发异常）。([GH 12749](https://github.com/pandas-dev/pandas/issues/12749))

+   `pd.show_versions()` 现在包括 `pandas_datareader` 版本（[GH 12740](https://github.com/pandas-dev/pandas/issues/12740)）

+   为泛型函数提供适当的 `__name__` 和 `__qualname__` 属性（[GH 12021](https://github.com/pandas-dev/pandas/issues/12021)）

+   `pd.concat(ignore_index=True)` 现在使用 `RangeIndex` 作为默认值（[GH 12695](https://github.com/pandas-dev/pandas/issues/12695)）

+   在将单层与多层数据框合并/连接时，`pd.merge()`和`DataFrame.join()`将显示`UserWarning`警告（[GH 9455](https://github.com/pandas-dev/pandas/issues/9455)，[GH 12219](https://github.com/pandas-dev/pandas/issues/12219)）

+   对于已弃用的`piecewise_polynomial`插值方法与`scipy` > 0.17 兼容；支持替代方法`from_derivatives`（[GH 12887](https://github.com/pandas-dev/pandas/issues/12887)）

### 废弃

+   方法名`Index.sym_diff()`已弃用，可替换为`Index.symmetric_difference()`（[GH 12591](https://github.com/pandas-dev/pandas/issues/12591)）

+   方法名`Categorical.sort()`已弃用，改用`Categorical.sort_values()`（[GH 12882](https://github.com/pandas-dev/pandas/issues/12882)）

## 性能改进

+   提高了 SAS 阅读器的速度（[GH 12656](https://github.com/pandas-dev/pandas/issues/12656)，[GH 12961](https://github.com/pandas-dev/pandas/issues/12961)）

+   在`.groupby(..).cumcount()`中的性能改进（[GH 11039](https://github.com/pandas-dev/pandas/issues/11039)）

+   在使用`skiprows=an_integer`时，改进了`pd.read_csv()`的内存使用情况（[GH 13005](https://github.com/pandas-dev/pandas/issues/13005)）

+   在检查表的大小写敏感性时，改进了`DataFrame.to_sql`的性能。现在只在表名不是小写时才检查表是否已正确创建。([GH 12876](https://github.com/pandas-dev/pandas/issues/12876))

+   改进了`Period`构造和时间序列绘图的性能（[GH 12903](https://github.com/pandas-dev/pandas/issues/12903)，[GH 11831](https://github.com/pandas-dev/pandas/issues/11831)）。

+   改进了`.str.encode()`和`.str.decode()`方法的性能（[GH 13008](https://github.com/pandas-dev/pandas/issues/13008)）

+   如果输入是数字类型，则改进了`to_numeric`的性能（[GH 12777](https://github.com/pandas-dev/pandas/issues/12777)）

+   通过`IntIndex`进行稀疏算术的性能改进（[GH 13036](https://github.com/pandas-dev/pandas/issues/13036)）

## 错误修复

+   即使 CSV 文件的行数不均匀，`pd.read_csv`中的`usecols`参数现在也会受到尊重（[GH 12203](https://github.com/pandas-dev/pandas/issues/12203)）

+   当指定`axis=1`时，`groupby.transform(..)`中的错误（`axis=1`）与非单调有序索引一起使用时出现错误（[GH 12713](https://github.com/pandas-dev/pandas/issues/12713)）

+   如果指定`freq="Minute"`，则在`Period`和`PeriodIndex`创建中出现`KeyError`错误。请注意，“Minute”频率已在 v0.17.0 中弃用，建议改用`freq="T"`（[GH 11854](https://github.com/pandas-dev/pandas/issues/11854)）

+   始终引发`TypeError`的`.resample(...).count()`与`PeriodIndex`一起使用的错误（[GH 12774](https://github.com/pandas-dev/pandas/issues/12774)）

+   当为空时，`.resample(...)`与`PeriodIndex`转换为`DatetimeIndex`时的错误（[GH 12868](https://github.com/pandas-dev/pandas/issues/12868)）

+   当对 PeriodIndex 进行重采样到现有频率时，`.resample(...)` 存在 Bug（[GH 12770](https://github.com/pandas-dev/pandas/issues/12770)）

+   包含不同 `freq` 的 `Period` 数据打印时引发 `ValueError` 的 Bug（[GH 12615](https://github.com/pandas-dev/pandas/issues/12615)）

+   在指定 `dtype='category'` 的情况下，使用 `Categorical` 构建 `Series` 存在 Bug（[GH 12574](https://github.com/pandas-dev/pandas/issues/12574)）

+   当对象长于 `display.max_rows` 时，具有可强制转换 dtype 的连接在输出格式化时过于激进，导致不同的 dtype（[GH 12411](https://github.com/pandas-dev/pandas/issues/12411), [GH 12045](https://github.com/pandas-dev/pandas/issues/12045), [GH 11594](https://github.com/pandas-dev/pandas/issues/11594), [GH 10571](https://github.com/pandas-dev/pandas/issues/10571), [GH 12211](https://github.com/pandas-dev/pandas/issues/12211)）

+   选项 `float_format` 在未验证为可调用时出现的 Bug。([GH 12706](https://github.com/pandas-dev/pandas/issues/12706))

+   在 `GroupBy.filter` 中，当 `dropna=False` 且没有组符合条件时存在 Bug ([GH 12768](https://github.com/pandas-dev/pandas/issues/12768))

+   `.cum*` 函数的 `__name__` 中存在 Bug（[GH 12021](https://github.com/pandas-dev/pandas/issues/12021)）

+   将 `Float64Inde/Int64Index` 转换为 `Int64Index` 时存在 Bug 在 `.astype()` 中。 ([GH 12881](https://github.com/pandas-dev/pandas/issues/12881))

+   在 `.to_json()/.read_json()` 中，默认情况下`orient='index'`，对整数型索引进行回环处理存在 Bug ([GH 12866](https://github.com/pandas-dev/pandas/issues/12866))

+   在尝试堆叠条形图时，`Categorical` 数据类型绘图存在 Bug 导致错误（[GH 13019](https://github.com/pandas-dev/pandas/issues/13019)）

+   兼容 `numpy` 版本 `1.11` 以上的 `NaT` 比较（[GH 12969](https://github.com/pandas-dev/pandas/issues/12969)）

+   在非唯一的 `MultiIndex` 中使用 `.drop()` 存在 Bug。 ([GH 12701](https://github.com/pandas-dev/pandas/issues/12701))

+   `.concat` 方法在处理带时区和不带时区的 DataFrame 时存在 Bug（[GH 12467](https://github.com/pandas-dev/pandas/issues/12467)）

+   在传递非字符串时，在 `.resample(..).fillna(..)` 中正确引发 `ValueError` 的 Bug（[GH 12952](https://github.com/pandas-dev/pandas/issues/12952)）

+   在 `pd.read_sas()` 中存在各种编码和头部处理问题的 Bug 修复（[GH 12659](https://github.com/pandas-dev/pandas/issues/12659), [GH 12654](https://github.com/pandas-dev/pandas/issues/12654), [GH 12647](https://github.com/pandas-dev/pandas/issues/12647), [GH 12809](https://github.com/pandas-dev/pandas/issues/12809)）

+   在 `pd.crosstab()` 中存在的 Bug：如果 `values=None`，则会静默忽略 `aggfunc`（[GH 12569](https://github.com/pandas-dev/pandas/issues/12569)）

+   在序列化 `datetime.time` 时，在 `DataFrame.to_json` 中存在潜在的段错误（[GH 11473](https://github.com/pandas-dev/pandas/issues/11473)）

+   在尝试序列化 0d 数组时，`DataFrame.to_json` 中存在潜在的段错误 ([GH 11299](https://github.com/pandas-dev/pandas/issues/11299))。

+   在尝试序列化具有非 ndarray 值的 `DataFrame` 或 `Series` 时，`to_json` 中存在的段错误；现在支持 `category`、`sparse` 和 `datetime64[ns, tz]` dtypes 的序列化 ([GH 10778](https://github.com/pandas-dev/pandas/issues/10778))。

+   `DataFrame.to_json` 中存在的 Bug，不支持的 dtype 未传递给默认处理程序 ([GH 12554](https://github.com/pandas-dev/pandas/issues/12554))。

+   `.align` 中存在的 Bug，未返回子类 ([GH 12983](https://github.com/pandas-dev/pandas/issues/12983))。

+   将 `Series` 与 `DataFrame` 对齐时存在的 Bug ([GH 13037](https://github.com/pandas-dev/pandas/issues/13037))。

+   `ABCPanel` 中存在的 Bug，其中 `Panel4D` 不被视为此通用类型的有效实例 ([GH 12810](https://github.com/pandas-dev/pandas/issues/12810))。

+   `.groupby(..).apply(..)` 案例中 `.name` 一致性存在 Bug ([GH 12363](https://github.com/pandas-dev/pandas/issues/12363))。

+   导致 `pprint` 在嵌套结构中失败的 `Timestamp.__repr__` 中存在的 Bug ([GH 12622](https://github.com/pandas-dev/pandas/issues/12622))。

+   `Timedelta.min` 和 `Timedelta.max` 中存在的 Bug，现在的属性报告 pandas 认可的真实最小/最大 `timedeltas`。参见 documentation。 ([GH 12727](https://github.com/pandas-dev/pandas/issues/12727))。

+   使用插值的 `.quantile()` 中存在的 Bug，可能意外地强制转换为 `float` ([GH 12772](https://github.com/pandas-dev/pandas/issues/12772))。

+   使用空 `Series` 的 `.quantile()` 中存在的 Bug，可能返回标量而不是空 `Series` ([GH 12772](https://github.com/pandas-dev/pandas/issues/12772))。

+   在大量索引器中越界的 `.loc` 中存在的 Bug，会引发 `IndexError` 而不是 `KeyError` ([GH 12527](https://github.com/pandas-dev/pandas/issues/12527))。

+   使用 `TimedeltaIndex` 和 `.asfreq()` 重新采样时存在 Bug，之前不会包含最终的围栏。 ([GH 12926](https://github.com/pandas-dev/pandas/issues/12926))。

+   在 `DataFrame` 中的 `Categorical` 中的相等性测试中存在 Bug ([GH 12564](https://github.com/pandas-dev/pandas/issues/12564))。

+   使用 `TimeGrouper` 时，`GroupBy.first()` 和 `.last()` 返回的行不正确 ([GH 7453](https://github.com/pandas-dev/pandas/issues/7453))。

+   使用 `c` 引擎的 `pd.read_csv()` 中存在的 Bug，当在引号中的项中指定 `skiprows` 时存在新行 ([GH 10911](https://github.com/pandas-dev/pandas/issues/10911), [GH 12775](https://github.com/pandas-dev/pandas/issues/12775))。

+   在为具有对齐的时区感知日期时间 `Series` 分配时存在的 `DataFrame` 时区丢失的 Bug ([GH 12981](https://github.com/pandas-dev/pandas/issues/12981))。

+   当 `normalize=True` 和 `dropna=True` 时，`.value_counts()` 存在 Bug，其中空值仍然影响了归一化计数 ([GH 12558](https://github.com/pandas-dev/pandas/issues/12558))。

+   当`Series`的 dtype 为`category`时，在`Series.value_counts()`中存在错误，会丢失名称 ([GH 12835](https://github.com/pandas-dev/pandas/issues/12835))

+   在`Series.value_counts()`中存在错误，丢失时区信息 ([GH 12835](https://github.com/pandas-dev/pandas/issues/12835))

+   在`Series.value_counts(normalize=True)`与`Categorical`一起使用时，会引发`UnboundLocalError` ([GH 12835](https://github.com/pandas-dev/pandas/issues/12835))

+   在`Panel.fillna()`中存在错误，忽略了`inplace=True` ([GH 12633](https://github.com/pandas-dev/pandas/issues/12633))

+   当同时使用`c`引擎和`names`、`usecols`以及`parse_dates`来指定`pd.read_csv()`时出现错误 ([GH 9755](https://github.com/pandas-dev/pandas/issues/9755))

+   当同时使用`c`引擎和`delim_whitespace=True`以及`lineterminator`来指定`pd.read_csv()`时出现错误 ([GH 12912](https://github.com/pandas-dev/pandas/issues/12912))

+   在`Series.rename`、`DataFrame.rename`和`DataFrame.rename_axis`中存在错误，未将`Series`视为映射来重新标记 ([GH 12623](https://github.com/pandas-dev/pandas/issues/12623))

+   在`.rolling.min`和`.rolling.max`中进行清理以增强 dtype 处理 ([GH 12373](https://github.com/pandas-dev/pandas/issues/12373))

+   在`groupby`中存在错误，复杂类型被强制转换为浮点数 ([GH 12902](https://github.com/pandas-dev/pandas/issues/12902))

+   当其 dtype 为`category`或 tz-aware `datetime`时，`Series.map`存在错误，会引发`TypeError` ([GH 12473](https://github.com/pandas-dev/pandas/issues/12473))

+   在某些测试比较中，32 位平台上存在错误 ([GH 12972](https://github.com/pandas-dev/pandas/issues/12972))

+   当从`RangeIndex`构造中回退时，索引强制转换存在错误 ([GH 12893](https://github.com/pandas-dev/pandas/issues/12893))

+   在窗口函数中改进了错误消息，当传递无效参数（例如浮点窗口）时 ([GH 12669](https://github.com/pandas-dev/pandas/issues/12669))

+   在对子类化的`DataFrame`进行切片时存在错误，定义为返回子类化的`Series`可能返回普通的`Series` ([GH 11559](https://github.com/pandas-dev/pandas/issues/11559))

+   在输入具有`name`并且结果为`DataFrame`或`MultiIndex`的情况下，使用`.str`访问器方法可能会引发`ValueError` ([GH 12617](https://github.com/pandas-dev/pandas/issues/12617))

+   在空框架上使用`DataFrame.last_valid_index()`和`DataFrame.first_valid_index()`时存在错误 ([GH 12800](https://github.com/pandas-dev/pandas/issues/12800))

+   在`CategoricalIndex.get_loc`中存在错误，与常规`Index`返回不同的结果 ([GH 12531](https://github.com/pandas-dev/pandas/issues/12531))

+   在`PeriodIndex.resample`中存在错误，名称未传播 ([GH 12769](https://github.com/pandas-dev/pandas/issues/12769))

+   在`date_range`中`closed`关键字和时区存在错误 ([GH 12684](https://github.com/pandas-dev/pandas/issues/12684))

+   当输入数据包含 tz-aware datetime 和 timedelta 时，`pd.concat`存在错误，会引发`AttributeError` ([GH 12620](https://github.com/pandas-dev/pandas/issues/12620))

+   `pd.concat` 中存在 bug，未正确处理空 `Series` ([GH 11082](https://github.com/pandas-dev/pandas/issues/11082))

+   当指定 `width` 时，`.plot.bar` 对齐存在 bug，其中 `width` 是 `int` ([GH 12979](https://github.com/pandas-dev/pandas/issues/12979))

+   当二进制运算符的参数为常数时，`fill_value` 中的 bug 被忽略 ([GH 12723](https://github.com/pandas-dev/pandas/issues/12723))

+   当使用 bs4 flavor 并解析只有一个标题列的表格时，`pd.read_html()` 存在 bug ([GH 9178](https://github.com/pandas-dev/pandas/issues/9178))

+   当 `margins=True` 和 `dropna=True` 时，`.pivot_table` 存在 bug，其中空值仍然会对边距计数有贡献 ([GH 12577](https://github.com/pandas-dev/pandas/issues/12577))

+   当 `dropna=False` 时，`.pivot_table` 中存在 bug，表格索引/列名消失 ([GH 12133](https://github.com/pandas-dev/pandas/issues/12133))

+   当 `margins=True` 和 `dropna=False` 时，`pd.crosstab()` 中存在 bug，会引发异常 ([GH 12642](https://github.com/pandas-dev/pandas/issues/12642))

+   当 `name` 属性可以是可哈希类型时，`Series.name` 存在 bug ([GH 12610](https://github.com/pandas-dev/pandas/issues/12610))

+   `.describe()` 中存在 bug，重置了分类列信息 ([GH 11558](https://github.com/pandas-dev/pandas/issues/11558))

+   当在时间序列上调用 `resample().count()` 时，`loffset` 参数未被应用的 bug ([GH 12725](https://github.com/pandas-dev/pandas/issues/12725))

+   `pd.read_excel()` 现在接受与关键字参数 `names` 关联的列名 ([GH 12870](https://github.com/pandas-dev/pandas/issues/12870))

+   当 `Index` 作为参数时，`pd.to_numeric()` 存在 bug，返回 `np.ndarray` 而不是 `Index` ([GH 12777](https://github.com/pandas-dev/pandas/issues/12777))

+   当类似日期时间的对象作为参数时，`pd.to_numeric()` 中存在 bug，可能引发 `TypeError` ([GH 12777](https://github.com/pandas-dev/pandas/issues/12777))

+   `pd.to_numeric()` 存在 bug，使用标量会引发 `ValueError` ([GH 12777](https://github.com/pandas-dev/pandas/issues/12777))

## 贡献者

这个版本共有 60 人贡献了补丁。带有“+”符号的人是首次贡献补丁的。

+   Andrew Fiore-Gartland +

+   Bastiaan +

+   Benoît Vinot +

+   Brandon Rhodes +

+   DaCoEx +

+   Drew Fustin +

+   Ernesto Freitas +

+   Filip Ter +

+   Gregory Livschitz +

+   Gábor Lipták

+   Hassan Kibirige +

+   Iblis Lin

+   Israel Saeta Pérez +

+   Jason Wolosonovich +

+   Jeff Reback

+   Joe Jevnik

+   Joris Van den Bossche

+   Joshua Storck +

+   Ka Wo Chen

+   Kerby Shedden

+   Kieran O’Mahony

+   Leif Walsh +

+   Mahmoud Lababidi +

+   Maoyuan Liu +

+   Mark Roth +

+   Matt Wittmann

+   MaxU +

+   Maximilian Roos

+   Michael Droettboom +

+   Nick Eubank

+   Nicolas Bonnotte

+   OXPHOS +

+   Pauli Virtanen +

+   Peter Waller +

+   Pietro Battiston

+   Prabhjot Singh +

+   Robin Wilson

+   Roger Thomas +

+   Sebastian Bank

+   Stephen Hoover

+   Tim Hopper +

+   Tom Augspurger

+   WANG Aiyong

+   Wes Turner

+   Winand +

+   Xbar +

+   Yan Facai +

+   adneu +

+   ajenkins-cargometrics +

+   behzad nouri

+   chinskiy +

+   gfyoung

+   jeps-journal +

+   jonaslb +

+   kotrfa +

+   nileracecrew +

+   onesandzeroes

+   rs2 +

+   sinhrks

+   tsdlovell +
