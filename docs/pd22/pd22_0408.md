# pandas.DataFrame.to_pickle

> [`pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html)

```py
DataFrame.to_pickle(path, *, compression='infer', protocol=5, storage_options=None)
```

将对象序列化（pickle）到文件。

参数：

**path**str、路径对象或类似文件的对象

字符串、路径对象（实现`os.PathLike[str]`）或实现二进制`write()`函数的类似文件的对象。pickle 对象将存储的文件路径。

**compression**字符串或字典，默认为‘infer’

用于即时压缩输出数据。如果‘infer’和‘path’是类似路径的对象，则从以下扩展名检测压缩：‘.gz’、‘.bz2’、‘.zip’、‘.xz’、‘.zst’、‘.tar’、‘.tar.gz’、‘.tar.xz’或‘.tar.bz2’（否则不压缩）。设置为`None`表示不压缩。也可以是一个字典，其中键`'method'`设置为其中之一{`'zip'`、`'gzip'`、`'bz2'`、`'zstd'`、`'xz'`、`'tar'`}，其他键值对转发给`zipfile.ZipFile`、`gzip.GzipFile`、`bz2.BZ2File`、`zstandard.ZstdCompressor`、`lzma.LZMAFile`或`tarfile.TarFile`。例如，可以传递以下内容以进行更快的压缩并创建可重现的 gzip 存档：`compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}`。

版本 1.5.0 中的新功能：增加对.tar 文件的支持。

**protocol**整数

指示 pickler 应使用的协议的整数，默认为 HIGHEST_PROTOCOL（参见[[1]](#rc4e85fbd536b-1)第 12.1.2 段）。可能的值为 0、1、2、3、4、5。协议参数的负值等效于将其值设置为 HIGHEST_PROTOCOL。

[1]

[`docs.python.org/3/library/pickle.html`](https://docs.python.org/3/library/pickle.html).

**storage_options**字典，可选

适用于特定存储连接的额外选项，例如主机、端口、用户名、密码等。对于 HTTP(S) URL，键值对将作为标头选项转发给`urllib.request.Request`。对于其他 URL（例如以“s3://”和“gcs://”开头的 URL），键值对将转发给`fsspec.open`。请参阅`fsspec`和`urllib`以获取更多详细信息，并参考[此处](https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files)获取有关存储选项的更多示例。

另请参阅

`read_pickle`

从文件加载 pickle 的 pandas 对象（或任何对象）。

`DataFrame.to_hdf`

将 DataFrame 写入 HDF5 文件。

`DataFrame.to_sql`

将 DataFrame 写入 SQL 数据库。

`DataFrame.to_parquet`

将 DataFrame 写入二进制 parquet 格式。

示例

```py
>>> original_df = pd.DataFrame({"foo": range(5), "bar": range(5, 10)})  
>>> original_df  
 foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
>>> original_df.to_pickle("./dummy.pkl") 
```

```py
>>> unpickled_df = pd.read_pickle("./dummy.pkl")  
>>> unpickled_df  
 foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9 
```
