- en: YOLOv5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/models/yolov5/`](https://docs.ultralytics.com/models/yolov5/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: YOLOv5u represents an advancement in object detection methodologies. Originating
    from the foundational architecture of the [YOLOv5](https://github.com/ultralytics/yolov5)
    model developed by Ultralytics, YOLOv5u integrates the anchor-free, objectness-free
    split head, a feature previously introduced in the YOLOv8 models. This adaptation
    refines the model's architecture, leading to an improved accuracy-speed tradeoff
    in object detection tasks. Given the empirical results and its derived features,
    YOLOv5u provides an efficient alternative for those seeking robust solutions in
    both research and practical applications.
  prefs: []
  type: TYPE_NORMAL
- en: '![Ultralytics YOLOv5](img/043a7987b73c701bfe07aa6ab67c7f4c.png)'
  prefs: []
  type: TYPE_IMG
- en: Key Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Anchor-free Split Ultralytics Head:** Traditional object detection models
    rely on predefined anchor boxes to predict object locations. However, YOLOv5u
    modernizes this approach. By adopting an anchor-free split Ultralytics head, it
    ensures a more flexible and adaptive detection mechanism, consequently enhancing
    the performance in diverse scenarios.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimized Accuracy-Speed Tradeoff:** Speed and accuracy often pull in opposite
    directions. But YOLOv5u challenges this tradeoff. It offers a calibrated balance,
    ensuring real-time detections without compromising on accuracy. This feature is
    particularly invaluable for applications that demand swift responses, such as
    autonomous vehicles, robotics, and real-time video analytics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variety of Pre-trained Models:** Understanding that different tasks require
    different toolsets, YOLOv5u provides a plethora of pre-trained models. Whether
    you''re focusing on Inference, Validation, or Training, there''s a tailor-made
    model awaiting you. This variety ensures you''re not just using a one-size-fits-all
    solution, but a model specifically fine-tuned for your unique challenge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supported Tasks and Modes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The YOLOv5u models, with various pre-trained weights, excel in Object Detection
    tasks. They support a comprehensive range of modes, making them suitable for diverse
    applications, from development to deployment.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model Type | Pre-trained Weights | Task | Inference | Validation | Training
    | Export |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOv5u | `yolov5nu`, `yolov5su`, `yolov5mu`, `yolov5lu`, `yolov5xu`, `yolov5n6u`,
    `yolov5s6u`, `yolov5m6u`, `yolov5l6u`, `yolov5x6u` | Object Detection | ✅ | ✅
    | ✅ | ✅ |'
  prefs: []
  type: TYPE_TB
- en: This table provides a detailed overview of the YOLOv5u model variants, highlighting
    their applicability in object detection tasks and support for various operational
    modes such as Inference, Validation, Training, and Export. This comprehensive
    support ensures that users can fully leverage the capabilities of YOLOv5u models
    in a wide range of object detection scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Performance Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Performance
  prefs: []
  type: TYPE_NORMAL
- en: See Detection Docs for usage examples with these models trained on COCO, which
    include 80 pre-trained classes.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | YAML | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [yolov5nu.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5nu.pt)
    | [yolov5n.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/v5/yolov5.yaml)
    | 640 | 34.3 | 73.6 | 1.06 | 2.6 | 7.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [yolov5su.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5su.pt)
    | [yolov5s.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/v5/yolov5.yaml)
    | 640 | 43.0 | 120.7 | 1.27 | 9.1 | 24.0 |'
  prefs: []
  type: TYPE_TB
- en: '| [yolov5mu.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5mu.pt)
    | [yolov5m.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/v5/yolov5.yaml)
    | 640 | 49.0 | 233.9 | 1.86 | 25.1 | 64.2 |'
  prefs: []
  type: TYPE_TB
- en: '| [yolov5lu.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5lu.pt)
    | [yolov5l.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/v5/yolov5.yaml)
    | 640 | 52.2 | 408.4 | 2.50 | 53.2 | 135.0 |'
  prefs: []
  type: TYPE_TB
- en: '| [yolov5xu.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5xu.pt)
    | [yolov5x.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/v5/yolov5.yaml)
    | 640 | 53.2 | 763.2 | 3.81 | 97.2 | 246.4 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| [yolov5n6u.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5n6u.pt)
    | [yolov5n6.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/v5/yolov5-p6.yaml)
    | 1280 | 42.1 | 211.0 | 1.83 | 4.3 | 7.8 |'
  prefs: []
  type: TYPE_TB
- en: '| [yolov5s6u.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5s6u.pt)
    | [yolov5s6.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/v5/yolov5-p6.yaml)
    | 1280 | 48.6 | 422.6 | 2.34 | 15.3 | 24.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [yolov5m6u.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5m6u.pt)
    | [yolov5m6.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/v5/yolov5-p6.yaml)
    | 1280 | 53.6 | 810.9 | 4.36 | 41.2 | 65.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [yolov5l6u.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5l6u.pt)
    | [yolov5l6.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/v5/yolov5-p6.yaml)
    | 1280 | 55.7 | 1470.9 | 5.47 | 86.1 | 137.4 |'
  prefs: []
  type: TYPE_TB
- en: '| [yolov5x6u.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5x6u.pt)
    | [yolov5x6.yaml](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/v5/yolov5-p6.yaml)
    | 1280 | 56.8 | 2436.5 | 8.98 | 155.4 | 250.7 |'
  prefs: []
  type: TYPE_TB
- en: Usage Examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This example provides simple YOLOv5 training and inference examples. For full
    documentation on these and other modes see the Predict, Train, Val and Export
    docs pages.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: 'PyTorch pretrained `*.pt` models as well as configuration `*.yaml` files can
    be passed to the `YOLO()` class to create a model instance in python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'CLI commands are available to directly run the models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Citations and Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you use YOLOv5 or YOLOv5u in your research, please cite the Ultralytics
    YOLOv5 repository as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Please note that YOLOv5 models are provided under [AGPL-3.0](https://github.com/ultralytics/ultralytics/blob/main/LICENSE)
    and [Enterprise](https://ultralytics.com/license) licenses.
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is Ultralytics YOLOv5u and how does it differ from YOLOv5?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ultralytics YOLOv5u is an advanced version of YOLOv5, integrating the anchor-free,
    objectness-free split head that enhances the accuracy-speed tradeoff for real-time
    object detection tasks. Unlike the traditional YOLOv5, YOLOv5u adopts an anchor-free
    detection mechanism, making it more flexible and adaptive in diverse scenarios.
    For more detailed information on its features, you can refer to the YOLOv5 Overview.
  prefs: []
  type: TYPE_NORMAL
- en: How does the anchor-free Ultralytics head improve object detection performance
    in YOLOv5u?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The anchor-free Ultralytics head in YOLOv5u improves object detection performance
    by eliminating the dependency on predefined anchor boxes. This results in a more
    flexible and adaptive detection mechanism that can handle various object sizes
    and shapes with greater efficiency. This enhancement directly contributes to a
    balanced tradeoff between accuracy and speed, making YOLOv5u suitable for real-time
    applications. Learn more about its architecture in the Key Features section.
  prefs: []
  type: TYPE_NORMAL
- en: Can I use pre-trained YOLOv5u models for different tasks and modes?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Yes, you can use pre-trained YOLOv5u models for various tasks such as Object
    Detection. These models support multiple modes, including Inference, Validation,
    Training, and Export. This flexibility allows users to leverage the capabilities
    of YOLOv5u models across different operational requirements. For a detailed overview,
    check the Supported Tasks and Modes section.
  prefs: []
  type: TYPE_NORMAL
- en: How do the performance metrics of YOLOv5u models compare on different platforms?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The performance metrics of YOLOv5u models vary depending on the platform and
    hardware used. For example, the YOLOv5nu model achieves a 34.3 mAP on COCO dataset
    with a speed of 73.6 ms on CPU (ONNX) and 1.06 ms on A100 TensorRT. Detailed performance
    metrics for different YOLOv5u models can be found in the Performance Metrics section,
    which provides a comprehensive comparison across various devices.
  prefs: []
  type: TYPE_NORMAL
- en: How can I train a YOLOv5u model using the Ultralytics Python API?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can train a YOLOv5u model by loading a pre-trained model and running the
    training command with your dataset. Here''s a quick example:'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: For more detailed instructions, visit the Usage Examples section.
  prefs: []
  type: TYPE_NORMAL
