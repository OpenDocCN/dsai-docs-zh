- en: Model Export with Ultralytics YOLO
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Ultralytics YOLO导出模型
- en: 原文：[`docs.ultralytics.com/modes/export/`](https://docs.ultralytics.com/modes/export/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/modes/export/`](https://docs.ultralytics.com/modes/export/)
- en: '![Ultralytics YOLO ecosystem and integrations](img/1933b0eeaf180eaa6d0c37f29931fb7d.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Ultralytics YOLO生态系统和集成](img/1933b0eeaf180eaa6d0c37f29931fb7d.png)'
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简介
- en: The ultimate goal of training a model is to deploy it for real-world applications.
    Export mode in Ultralytics YOLOv8 offers a versatile range of options for exporting
    your trained model to different formats, making it deployable across various platforms
    and devices. This comprehensive guide aims to walk you through the nuances of
    model exporting, showcasing how to achieve maximum compatibility and performance.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型的最终目标是在实际应用中部署它。Ultralytics YOLOv8的导出模式提供了多种选项，可将训练好的模型导出至不同格式，从而使其能够在各种平台和设备上部署。本详尽指南旨在引导您了解模型导出的细节，展示如何实现最大的兼容性和性能。
- en: '[`www.youtube.com/embed/WbomGeoOT_k?si=aGmuyooWftA0ue9X`](https://www.youtube.com/embed/WbomGeoOT_k?si=aGmuyooWftA0ue9X)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[`www.youtube.com/embed/WbomGeoOT_k?si=aGmuyooWftA0ue9X`](https://www.youtube.com/embed/WbomGeoOT_k?si=aGmuyooWftA0ue9X)'
- en: '**Watch:** How To Export Custom Trained Ultralytics YOLOv8 Model and Run Live
    Inference on Webcam.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**观看：** 如何导出自定义训练的Ultralytics YOLOv8模型，并在网络摄像头上进行实时推理。'
- en: Why Choose YOLOv8's Export Mode?
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么选择YOLOv8的导出模式？
- en: '**Versatility:** Export to multiple formats including ONNX, TensorRT, CoreML,
    and more.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多功能性：** 导出至包括ONNX、TensorRT、CoreML等多种格式。'
- en: '**Performance:** Gain up to 5x GPU speedup with TensorRT and 3x CPU speedup
    with ONNX or OpenVINO.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能：** 使用TensorRT可获得最多5倍的GPU加速，使用ONNX或OpenVINO可获得最多3倍的CPU加速。'
- en: '**Compatibility:** Make your model universally deployable across numerous hardware
    and software environments.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性：** 使您的模型能够普遍适用于多种硬件和软件环境。'
- en: '**Ease of Use:** Simple CLI and Python API for quick and straightforward model
    exporting.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易用性：** 简单的命令行界面和Python API，便于快速和直接的模型导出。'
- en: Key Features of Export Mode
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导出模式的关键特性
- en: 'Here are some of the standout functionalities:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一些突出的功能：
- en: '**One-Click Export:** Simple commands for exporting to different formats.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一键导出：** 简单命令，可导出至不同格式。'
- en: '**Batch Export:** Export batched-inference capable models.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量导出：** 导出支持批处理推理的模型。'
- en: '**Optimized Inference:** Exported models are optimized for quicker inference
    times.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优化推理速度：** 导出模型经过优化，推理速度更快。'
- en: '**Tutorial Videos:** In-depth guides and tutorials for a smooth exporting experience.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**教程视频：** 深入指南和教程，帮助您顺利进行导出操作。'
- en: Tip
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Export to ONNX or OpenVINO for up to 3x CPU speedup.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导出至ONNX或OpenVINO，CPU速度提升最多3倍。
- en: Export to TensorRT for up to 5x GPU speedup.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导出至TensorRT，GPU速度提升最多5倍。
- en: Usage Examples
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用示例
- en: Export a YOLOv8n model to a different format like ONNX or TensorRT. See Arguments
    section below for a full list of export arguments.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 将YOLOv8n模型导出至ONNX或TensorRT等不同格式。查看下面的参数部分，了解所有导出参数的完整列表。
- en: Example
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Arguments
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参数
- en: This table details the configurations and options available for exporting YOLO
    models to different formats. These settings are critical for optimizing the exported
    model's performance, size, and compatibility across various platforms and environments.
    Proper configuration ensures that the model is ready for deployment in the intended
    application with optimal efficiency.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此表详细描述了将YOLO模型导出至不同格式的配置和选项。这些设置对优化导出模型的性能、大小和在各种平台和环境中的兼容性至关重要。适当的配置确保模型能够在预期应用中以最佳效率部署。
- en: '| Argument | Type | Default | Description |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 类型 | 默认值 | 描述 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| `format` | `str` | `''torchscript''` | Target format for the exported model,
    such as `''onnx''`, `''torchscript''`, `''tensorflow''`, or others, defining compatibility
    with various deployment environments. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| `format` | `str` | `''torchscript''` | 导出模型的目标格式，如 `''onnx''`、`''torchscript''`、`''tensorflow''`
    等，定义与各种部署环境的兼容性。 |'
- en: '| `imgsz` | `int` or `tuple` | `640` | Desired image size for the model input.
    Can be an integer for square images or a tuple `(height, width)` for specific
    dimensions. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| `imgsz` | `int` 或 `tuple` | `640` | 模型输入的期望图像尺寸。可以是整数表示正方形图像，也可以是元组 `(height,
    width)` 表示具体尺寸。 |'
- en: '| `keras` | `bool` | `False` | Enables export to Keras format for TensorFlow
    SavedModel, providing compatibility with TensorFlow serving and APIs. |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| `keras` | `bool` | `False` | 启用导出至TensorFlow SavedModel的Keras格式，提供与TensorFlow
    Serving和API的兼容性。 |'
- en: '| `optimize` | `bool` | `False` | Applies optimization for mobile devices when
    exporting to TorchScript, potentially reducing model size and improving performance.
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| `optimize` | `bool` | `False` | 在导出 TorchScript 到移动设备时应用优化，可能减小模型大小并提高性能。
    |'
- en: '| `half` | `bool` | `False` | Enables FP16 (half-precision) quantization, reducing
    model size and potentially speeding up inference on supported hardware. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| `half` | `bool` | `False` | 启用 FP16（半精度）量化，减小模型大小并在支持的硬件上加快推断速度。 |'
- en: '| `int8` | `bool` | `False` | Activates INT8 quantization, further compressing
    the model and speeding up inference with minimal accuracy loss, primarily for
    edge devices. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| `int8` | `bool` | `False` | 激活 INT8 量化，进一步压缩模型并在几乎不损失精度的情况下加快推断速度，主要用于边缘设备。
    |'
- en: '| `dynamic` | `bool` | `False` | Allows dynamic input sizes for ONNX, TensorRT
    and OpenVINO exports, enhancing flexibility in handling varying image dimensions.
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| `dynamic` | `bool` | `False` | 允许 ONNX、TensorRT 和 OpenVINO 导出使用动态输入尺寸，增强处理不同图像尺寸的灵活性。
    |'
- en: '| `simplify` | `bool` | `False` | Simplifies the model graph for ONNX exports
    with `onnxslim`, potentially improving performance and compatibility. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| `simplify` | `bool` | `False` | 使用 `onnxslim` 简化 ONNX 导出的模型图，可能提高性能和兼容性。
    |'
- en: '| `opset` | `int` | `None` | Specifies the ONNX opset version for compatibility
    with different ONNX parsers and runtimes. If not set, uses the latest supported
    version. |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| `opset` | `int` | `None` | 指定 ONNX opset 版本，以便与不同的 ONNX 解析器和运行时兼容。如果未设置，将使用支持的最新版本。
    |'
- en: '| `workspace` | `float` | `4.0` | Sets the maximum workspace size in GiB for
    TensorRT optimizations, balancing memory usage and performance. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| `workspace` | `float` | `4.0` | 设置 TensorRT 优化的最大工作空间大小（单位：GiB），平衡内存使用和性能。
    |'
- en: '| `nms` | `bool` | `False` | Adds Non-Maximum Suppression (NMS) to the CoreML
    export, essential for accurate and efficient detection post-processing. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| `nms` | `bool` | `False` | 在 CoreML 导出中添加非最大抑制（NMS），用于精确和高效的检测后处理。 |'
- en: '| `batch` | `int` | `1` | Specifies export model batch inference size or the
    max number of images the exported model will process concurrently in `predict`
    mode. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| `batch` | `int` | `1` | 指定导出模型的批量推断大小，或者导出模型在 `predict` 模式下并发处理的最大图像数量。 |'
- en: Adjusting these parameters allows for customization of the export process to
    fit specific requirements, such as deployment environment, hardware constraints,
    and performance targets. Selecting the appropriate format and settings is essential
    for achieving the best balance between model size, speed, and accuracy.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 调整这些参数允许定制导出过程，以适应特定的需求，如部署环境、硬件约束和性能目标。选择合适的格式和设置对于实现模型大小、速度和精度的最佳平衡至关重要。
- en: Export Formats
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导出格式
- en: Available YOLOv8 export formats are in the table below. You can export to any
    format using the `format` argument, i.e. `format='onnx'` or `format='engine'`.
    You can predict or validate directly on exported models, i.e. `yolo predict model=yolov8n.onnx`.
    Usage examples are shown for your model after export completes.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的表格列出了可用的 YOLOv8 导出格式。您可以使用 `format` 参数导出到任何格式，例如 `format='onnx'` 或 `format='engine'`。导出完成后，您可以直接预测或验证导出的模型，例如
    `yolo predict model=yolov8n.onnx`。下面展示了导出后您模型的使用示例。
- en: '| Format | `format` Argument | Model | Metadata | Arguments |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 格式 | `format` 参数 | 模型 | 元数据 | 参数 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| [PyTorch](https://pytorch.org/) | - | `yolov8n.pt` | ✅ | - |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| [PyTorch](https://pytorch.org/) | - | `yolov8n.pt` | ✅ | - |'
- en: '| TorchScript | `torchscript` | `yolov8n.torchscript` | ✅ | `imgsz`, `optimize`,
    `batch` |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| TorchScript | `torchscript` | `yolov8n.torchscript` | ✅ | `imgsz`, `optimize`,
    `batch` |'
- en: '| ONNX | `onnx` | `yolov8n.onnx` | ✅ | `imgsz`, `half`, `dynamic`, `simplify`,
    `opset`, `batch` |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| ONNX | `onnx` | `yolov8n.onnx` | ✅ | `imgsz`, `half`, `dynamic`, `simplify`,
    `opset`, `batch` |'
- en: '| OpenVINO | `openvino` | `yolov8n_openvino_model/` | ✅ | `imgsz`, `half`,
    `int8`, `batch`, `dynamic` |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| OpenVINO | `openvino` | `yolov8n_openvino_model/` | ✅ | `imgsz`, `half`,
    `int8`, `batch`, `dynamic` |'
- en: '| TensorRT | `engine` | `yolov8n.engine` | ✅ | `imgsz`, `half`, `dynamic`,
    `simplify`, `workspace`, `int8`, `batch` |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| TensorRT | `engine` | `yolov8n.engine` | ✅ | `imgsz`, `half`, `dynamic`,
    `simplify`, `workspace`, `int8`, `batch` |'
- en: '| CoreML | `coreml` | `yolov8n.mlpackage` | ✅ | `imgsz`, `half`, `int8`, `nms`,
    `batch` |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| CoreML | `coreml` | `yolov8n.mlpackage` | ✅ | `imgsz`, `half`, `int8`, `nms`,
    `batch` |'
- en: '| TF SavedModel | `saved_model` | `yolov8n_saved_model/` | ✅ | `imgsz`, `keras`,
    `int8`, `batch` |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| TF SavedModel | `saved_model` | `yolov8n_saved_model/` | ✅ | `imgsz`, `keras`,
    `int8`, `batch` |'
- en: '| TF GraphDef | `pb` | `yolov8n.pb` | ❌ | `imgsz`, `batch` |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| TF GraphDef | `pb` | `yolov8n.pb` | ❌ | `imgsz`, `batch` |'
- en: '| TF Lite | `tflite` | `yolov8n.tflite` | ✅ | `imgsz`, `half`, `int8`, `batch`
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| TF Lite | `tflite` | `yolov8n.tflite` | ✅ | `imgsz`, `half`, `int8`, `batch`
    |'
- en: '| TF Edge TPU | `edgetpu` | `yolov8n_edgetpu.tflite` | ✅ | `imgsz` |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| TF Edge TPU | `edgetpu` | `yolov8n_edgetpu.tflite` | ✅ | `imgsz` |'
- en: '| TF.js | `tfjs` | `yolov8n_web_model/` | ✅ | `imgsz`, `half`, `int8`, `batch`
    |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| TF.js | `tfjs` | `yolov8n_web_model/` | ✅ | `imgsz`, `half`, `int8`, `batch`
    |'
- en: '| PaddlePaddle | `paddle` | `yolov8n_paddle_model/` | ✅ | `imgsz`, `batch`
    |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| PaddlePaddle | `paddle` | `yolov8n_paddle_model/` | ✅ | `imgsz`, `batch`
    |'
- en: '| NCNN | `ncnn` | `yolov8n_ncnn_model/` | ✅ | `imgsz`, `half`, `batch` |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| NCNN | `ncnn` | `yolov8n_ncnn_model/` | ✅ | `imgsz`, `half`, `batch` |'
- en: FAQ
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题解答
- en: How do I export a YOLOv8 model to ONNX format?
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何将YOLOv8模型导出为ONNX格式？
- en: Exporting a YOLOv8 model to ONNX format is straightforward with Ultralytics.
    It provides both Python and CLI methods for exporting models.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Ultralytics导出YOLOv8模型到ONNX格式非常简单，提供了Python和CLI方法来导出模型。
- en: Example
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: For more details on the process, including advanced options like handling different
    input sizes, refer to the ONNX section.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 关于包括处理不同输入尺寸在内的高级选项，更多详细流程请参考ONNX部分。
- en: What are the benefits of using TensorRT for model export?
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用TensorRT进行模型导出的好处是什么？
- en: Using TensorRT for model export offers significant performance improvements.
    YOLOv8 models exported to TensorRT can achieve up to a 5x GPU speedup, making
    it ideal for real-time inference applications.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorRT进行模型导出能显著提升性能。导出到TensorRT的YOLOv8模型可以实现多达5倍的GPU加速，非常适合实时推理应用。
- en: '**Versatility:** Optimize models for a specific hardware setup.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通用性：** 为特定硬件设置优化模型。'
- en: '**Speed:** Achieve faster inference through advanced optimizations.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度：** 通过先进优化实现更快推理速度。'
- en: '**Compatibility:** Integrate smoothly with NVIDIA hardware.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容性：** 与NVIDIA硬件无缝集成。'
- en: To learn more about integrating TensorRT, see the TensorRT integration guide.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多有关集成TensorRT的信息，请参阅TensorRT集成指南。
- en: How do I enable INT8 quantization when exporting my YOLOv8 model?
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何在导出YOLOv8模型时启用INT8量化？
- en: 'INT8 quantization is an excellent way to compress the model and speed up inference,
    especially on edge devices. Here''s how you can enable INT8 quantization:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: INT8量化是压缩模型并加速推理的优秀方式，尤其适用于边缘设备。以下是如何启用INT8量化的方法：
- en: Example
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: INT8 quantization can be applied to various formats, such as TensorRT and CoreML.
    More details can be found in the Export section.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: INT8量化可以应用于多种格式，如TensorRT和CoreML。更多详细信息请参考导出部分。
- en: Why is dynamic input size important when exporting models?
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在导出模型时，为什么动态输入尺寸很重要？
- en: Dynamic input size allows the exported model to handle varying image dimensions,
    providing flexibility and optimizing processing efficiency for different use cases.
    When exporting to formats like ONNX or TensorRT, enabling dynamic input size ensures
    that the model can adapt to different input shapes seamlessly.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 动态输入尺寸允许导出的模型处理不同的图像尺寸，为不同用例提供灵活性并优化处理效率。当导出到ONNX或TensorRT等格式时，启用动态输入尺寸可以确保模型能够无缝适应不同的输入形状。
- en: 'To enable this feature, use the `dynamic=True` flag during export:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用此功能，在导出时使用`dynamic=True`标志：
- en: Example
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For additional context, refer to the dynamic input size configuration.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 关于动态输入尺寸配置的更多上下文，请参考。
- en: What are the key export arguments to consider for optimizing model performance?
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何优化模型性能的关键导出参数是什么？
- en: 'Understanding and configuring export arguments is crucial for optimizing model
    performance:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 理解和配置导出参数对优化模型性能至关重要：
- en: '**`format:`** The target format for the exported model (e.g., `onnx`, `torchscript`,
    `tensorflow`).'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`format:`** 导出模型的目标格式（例如`onnx`、`torchscript`、`tensorflow`）。'
- en: '**`imgsz:`** Desired image size for the model input (e.g., `640` or `(height,
    width)`).'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`imgsz:`** 模型输入的期望图像尺寸（例如`640`或`(height, width)`）。'
- en: '**`half:`** Enables FP16 quantization, reducing model size and potentially
    speeding up inference.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`half:`** 启用FP16量化，减小模型大小并可能加快推理速度。'
- en: '**`optimize:`** Applies specific optimizations for mobile or constrained environments.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`optimize:`** 为移动或受限环境应用特定优化。'
- en: '**`int8:`** Enables INT8 quantization, highly beneficial for edge deployments.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`int8:`** 启用INT8量化，对边缘部署极为有益。'
- en: For a detailed list and explanations of all the export arguments, visit the
    Export Arguments section.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解所有导出参数的详细列表和解释，请访问导出参数部分。
