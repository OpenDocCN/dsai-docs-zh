- en: ROS (Robot Operating System) quickstart guide
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ROS（机器人操作系统）快速入门指南
- en: 原文：[`docs.ultralytics.com/guides/ros-quickstart/`](https://docs.ultralytics.com/guides/ros-quickstart/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/guides/ros-quickstart/`](https://docs.ultralytics.com/guides/ros-quickstart/)
- en: '[`player.vimeo.com/video/639236696?h=740f412ce5`](https://player.vimeo.com/video/639236696?h=740f412ce5)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[`player.vimeo.com/video/639236696?h=740f412ce5`](https://player.vimeo.com/video/639236696?h=740f412ce5)'
- en: '[ROS Introduction (captioned)](https://vimeo.com/639236696) from [Open Robotics](https://vimeo.com/osrfoundation)
    on [Vimeo](https://vimeo.com).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[ROS 简介（字幕）](https://vimeo.com/639236696) 来自 [Open Robotics](https://vimeo.com/osrfoundation)
    在 [Vimeo](https://vimeo.com) 上。'
- en: What is ROS?
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 ROS？
- en: The [Robot Operating System (ROS)](https://www.ros.org/) is an open-source framework
    widely used in robotics research and industry. ROS provides a collection of [libraries
    and tools](https://www.ros.org/blog/ecosystem/) to help developers create robot
    applications. ROS is designed to work with various [robotic platforms](https://robots.ros.org/),
    making it a flexible and powerful tool for roboticists.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[机器人操作系统（ROS）](https://www.ros.org/)是一个广泛用于机器人研究和工业的开源框架。ROS 提供了一系列[库和工具](https://www.ros.org/blog/ecosystem/)，帮助开发者创建机器人应用程序。ROS
    设计用于与各种[机器人平台](https://robots.ros.org/)兼容，使其成为机器人学家的一种灵活而强大的工具。'
- en: Key Features of ROS
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ROS 的关键特性
- en: '**Modular Architecture**: ROS has a modular architecture, allowing developers
    to build complex systems by combining smaller, reusable components called [nodes](https://wiki.ros.org/ROS/Tutorials/UnderstandingNodes).
    Each node typically performs a specific function, and nodes communicate with each
    other using messages over [topics](https://wiki.ros.org/ROS/Tutorials/UnderstandingTopics)
    or [services](https://wiki.ros.org/ROS/Tutorials/UnderstandingServicesParams).'
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模块化架构**：ROS 采用模块化架构，允许开发者通过组合称为[节点](https://wiki.ros.org/ROS/Tutorials/UnderstandingNodes)的较小、可重复使用的组件构建复杂系统。每个节点通常执行特定的功能，并且节点之间通过[主题](https://wiki.ros.org/ROS/Tutorials/UnderstandingTopics)或[服务](https://wiki.ros.org/ROS/Tutorials/UnderstandingServicesParams)上的消息进行通信。'
- en: '**Communication Middleware**: ROS offers a robust communication infrastructure
    that supports inter-process communication and distributed computing. This is achieved
    through a publish-subscribe model for data streams (topics) and a request-reply
    model for service calls.'
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**通信中间件**：ROS 提供了强大的通信基础设施，支持进程间通信和分布式计算。通过数据流（主题）的发布-订阅模型和服务调用的请求-响应模型实现。'
- en: '**Hardware Abstraction**: ROS provides a layer of abstraction over the hardware,
    enabling developers to write device-agnostic code. This allows the same code to
    be used with different hardware setups, facilitating easier integration and experimentation.'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**硬件抽象**：ROS 在硬件上提供了一层抽象，使开发者能够编写与设备无关的代码。这使得相同的代码可以在不同的硬件设置上使用，从而更容易进行集成和实验。'
- en: '**Tools and Utilities**: ROS comes with a rich set of tools and utilities for
    visualization, debugging, and simulation. For instance, RViz is used for visualizing
    sensor data and robot state information, while Gazebo provides a powerful simulation
    environment for testing algorithms and robot designs.'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**工具和实用程序**：ROS 自带丰富的可视化、调试和仿真工具集。例如，RViz 用于可视化传感器数据和机器人状态信息，而 Gazebo 则提供了一个强大的仿真环境，用于测试算法和机器人设计。'
- en: '**Extensive Ecosystem**: The ROS ecosystem is vast and continually growing,
    with numerous packages available for different robotic applications, including
    navigation, manipulation, perception, and more. The community actively contributes
    to the development and maintenance of these packages.'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**广泛的生态系统**：ROS 生态系统庞大且不断增长，为不同的机器人应用提供了大量的包，包括导航、操作、感知等。社区积极参与这些包的开发和维护。'
- en: <details class="note" open="open"><summary>Evolution of ROS Versions</summary>
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="note" open="open"><summary>ROS 版本的演变</summary>
- en: 'Since its development in 2007, ROS has evolved through [multiple versions](https://wiki.ros.org/Distributions),
    each introducing new features and improvements to meet the growing needs of the
    robotics community. The development of ROS can be categorized into two main series:
    ROS 1 and ROS 2\. This guide focuses on the Long Term Support (LTS) version of
    ROS 1, known as ROS Noetic Ninjemys, the code should also work with earlier versions.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 自 2007 年开发以来，ROS 已经通过[多个版本](https://wiki.ros.org/Distributions)进行了演进，每个版本都引入了新功能和改进，以满足机器人社区不断增长的需求。ROS
    的开发可以分为两个主要系列：ROS 1 和 ROS 2。本指南侧重于 ROS 1 的长期支持（LTS）版本，称为 ROS Noetic Ninjemys，该代码也应该适用于早期版本。
- en: ROS 1 vs. ROS 2
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ROS 1 与 ROS 2
- en: 'While ROS 1 provided a solid foundation for robotic development, ROS 2 addresses
    its shortcomings by offering:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 ROS 1 为机器人开发提供了坚实的基础，但 ROS 2 通过提供以下功能解决了其缺点：
- en: '**Real-time Performance**: Improved support for real-time systems and deterministic
    behavior.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时性能**：改进了对实时系统和确定性行为的支持。'
- en: '**Security**: Enhanced security features for safe and reliable operation in
    various environments.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性**：增强的安全功能，确保在各种环境下的安全可靠运行。'
- en: '**Scalability**: Better support for multi-robot systems and large-scale deployments.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：更好地支持多机器人系统和大规模部署。'
- en: '**Cross-platform Support**: Expanded compatibility with various operating systems
    beyond Linux, including Windows and macOS.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跨平台支持**：扩展了对 Linux 以外的各种操作系统的兼容性，包括 Windows 和 macOS。'
- en: '**Flexible Communication**: Use of DDS for more flexible and efficient inter-process
    communication.</details>'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活通信**：使用 DDS 实现更灵活和高效的进程间通信。</details>'
- en: ROS Messages and Topics
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ROS 消息和话题
- en: In ROS, communication between nodes is facilitated through [messages](https://wiki.ros.org/Messages)
    and [topics](https://wiki.ros.org/Topics). A message is a data structure that
    defines the information exchanged between nodes, while a topic is a named channel
    over which messages are sent and received. Nodes can publish messages to a topic
    or subscribe to messages from a topic, enabling them to communicate with each
    other. This publish-subscribe model allows for asynchronous communication and
    decoupling between nodes. Each sensor or actuator in a robotic system typically
    publishes data to a topic, which can then be consumed by other nodes for processing
    or control. For the purpose of this guide, we will focus on Image, Depth and PointCloud
    messages and camera topics.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在ROS中，节点之间的通信通过[消息](https://wiki.ros.org/Messages)和[话题](https://wiki.ros.org/Topics)来进行。消息是定义节点之间交换信息的数据结构，而话题是命名通道，用于发送和接收消息。节点可以向话题发布消息或者从话题订阅消息，从而使它们能够相互通信。这种发布-订阅模型支持异步通信，并解耦了节点之间的关系。在机器人系统中，每个传感器或执行器通常会向话题发布数据，然后其他节点可以消费这些数据进行处理或控制。在本指南中，我们将重点关注图像（Image）、深度（Depth）和点云（PointCloud）消息以及摄像头话题。
- en: Setting Up Ultralytics YOLO with ROS
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Ultralytics YOLO 配置 ROS
- en: This guide has been tested using [this ROS environment](https://github.com/ambitious-octopus/rosbot_ros/tree/noetic),
    which is a fork of the [ROSbot ROS repository](https://github.com/husarion/rosbot_ros).
    This environment includes the Ultralytics YOLO package, a Docker container for
    easy setup, comprehensive ROS packages, and Gazebo worlds for rapid testing. It
    is designed to work with the [Husarion ROSbot 2 PRO](https://husarion.com/manuals/rosbot/).
    The code examples provided will work in any ROS Noetic/Melodic environment, including
    both simulation and real-world.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南已在 [此 ROS 环境](https://github.com/ambitious-octopus/rosbot_ros/tree/noetic)
    中进行了测试，该环境是 [ROSbot ROS 仓库](https://github.com/husarion/rosbot_ros) 的分支。该环境包括
    Ultralytics YOLO 包、用于简便设置的 Docker 容器、全面的 ROS 包以及用于快速测试的 Gazebo 世界。它专为与 [Husarion
    ROSbot 2 PRO](https://husarion.com/manuals/rosbot/) 兼容设计。提供的代码示例将在任何 ROS Noetic/Melodic
    环境中运行，包括仿真和真实世界中。
- en: '![Husarion ROSbot 2 PRO](img/6c8e2c01a43d9da9a2eeff4f5afc66f9.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![Husarion ROSbot 2 PRO](img/6c8e2c01a43d9da9a2eeff4f5afc66f9.png)'
- en: Dependencies Installation
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 依赖安装
- en: 'Apart from the ROS environment, you will need to install the following dependencies:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 ROS 环境外，您还需要安装以下依赖项：
- en: '**[ROS Numpy package](https://github.com/eric-wieser/ros_numpy)**: This is
    required for fast conversion between ROS Image messages and numpy arrays.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[ROS Numpy 包](https://github.com/eric-wieser/ros_numpy)**：用于快速转换 ROS Image
    消息和 numpy 数组。'
- en: '[PRE0]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Ultralytics package**:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ultralytics 包**：'
- en: '[PRE1]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Use Ultralytics with ROS `sensor_msgs/Image`
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Ultralytics 与 ROS `sensor_msgs/Image`
- en: The `sensor_msgs/Image` [message type](https://docs.ros.org/en/api/sensor_msgs/html/msg/Image.html)
    is commonly used in ROS for representing image data. It contains fields for encoding,
    height, width, and pixel data, making it suitable for transmitting images captured
    by cameras or other sensors. Image messages are widely used in robotic applications
    for tasks such as visual perception, object detection, and navigation.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`sensor_msgs/Image` [消息类型](https://docs.ros.org/en/api/sensor_msgs/html/msg/Image.html)
    在 ROS 中常用于表示图像数据。它包含编码、高度、宽度和像素数据字段，适合用于传输摄像机或其他传感器捕获的图像。图像消息在机器人应用中广泛用于视觉感知、物体检测和导航等任务。'
- en: '![Detection and Segmentation in ROS Gazebo](img/62c6684e47f97d6c0debdbced67d9c27.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![ROS Gazebo 中的检测与分割](img/62c6684e47f97d6c0debdbced67d9c27.png)'
- en: Image Step-by-Step Usage
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图像逐步使用
- en: The following code snippet demonstrates how to use the Ultralytics YOLO package
    with ROS. In this example, we subscribe to a camera topic, process the incoming
    image using YOLO, and publish the detected objects to new topics for detection
    and segmentation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段演示了如何在ROS中使用Ultralytics YOLO包。在此示例中，我们订阅一个相机主题，使用YOLO处理传入的图像，并将检测到的对象发布到新的检测和分割主题。
- en: 'First, import the necessary libraries and instantiate two models: one for segmentation
    and one for detection. Initialize a ROS node (with the name `ultralytics`) to
    enable communication with the ROS master. To ensure a stable connection, we include
    a brief pause, giving the node sufficient time to establish the connection before
    proceeding.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入必要的库并实例化两个模型：一个用于分割，一个用于检测。初始化一个ROS节点（名称为`ultralytics`），以便与ROS主节点进行通信。为确保稳定连接，在此我们包含一个简短的暂停，以确保节点有足够的时间建立连接后再继续。
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Initialize two ROS topics: one for detection and one for segmentation. These
    topics will be used to publish the annotated images, making them accessible for
    further processing. The communication between nodes is facilitated using `sensor_msgs/Image`
    messages.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化两个ROS主题：一个用于检测，一个用于分割。这些主题将用于发布带注释的图像，使它们可以进一步处理。节点之间的通信使用`sensor_msgs/Image`消息进行。
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Finally, create a subscriber that listens to messages on the `/camera/color/image_raw`
    topic and calls a callback function for each new message. This callback function
    receives messages of type `sensor_msgs/Image`, converts them into a numpy array
    using `ros_numpy`, processes the images with the previously instantiated YOLO
    models, annotates the images, and then publishes them back to the respective topics:
    `/ultralytics/detection/image` for detection and `/ultralytics/segmentation/image`
    for segmentation.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，创建一个订阅器，监听`/camera/color/image_raw`主题上的消息，并为每个新消息调用回调函数。此回调函数接收类型为`sensor_msgs/Image`的消息，使用`ros_numpy`将其转换为numpy数组，使用之前实例化的YOLO模型处理图像，标注图像，然后将其分别发布回`/ultralytics/detection/image`（用于检测）和`/ultralytics/segmentation/image`（用于分割）的主题。
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: <details class="example"><summary>Complete code</summary>
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="example"><summary>完整代码</summary>
- en: '[PRE5]</details> <details class="tip" open="open"><summary>Debugging</summary>'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE5]</details> <details class="tip" open="open"><summary>调试</summary>'
- en: 'Debugging ROS (Robot Operating System) nodes can be challenging due to the
    system''s distributed nature. Several tools can assist with this process:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ROS（机器人操作系统）的调试由于系统的分布性质可能具有挑战性。有几个工具可以协助此过程：
- en: '`rostopic echo <TOPIC-NAME>` : This command allows you to view messages published
    on a specific topic, helping you inspect the data flow.'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rostopic echo <TOPIC-NAME>`：此命令允许您查看发布在特定主题上的消息，帮助您检查数据流动态。'
- en: '`rostopic list`: Use this command to list all available topics in the ROS system,
    giving you an overview of the active data streams.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rostopic list`：使用此命令列出ROS系统中所有可用的主题，为您提供活动数据流的概述。'
- en: '`rqt_graph`: This visualization tool displays the communication graph between
    nodes, providing insights into how nodes are interconnected and how they interact.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rqt_graph`：这个可视化工具显示节点之间的通信图，提供节点如何互连及相互作用的洞察。'
- en: For more complex visualizations, such as 3D representations, you can use [RViz](https://wiki.ros.org/rviz).
    RViz (ROS Visualization) is a powerful 3D visualization tool for ROS. It allows
    you to visualize the state of your robot and its environment in real-time. With
    RViz, you can view sensor data (e.g. `sensors_msgs/Image`), robot model states,
    and various other types of information, making it easier to debug and understand
    the behavior of your robotic system.</details>
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于更复杂的可视化，如三维表示，可以使用[RViz](https://wiki.ros.org/rviz)。RViz（ROS可视化）是一个强大的ROS三维可视化工具，允许您实时查看机器人及其环境的状态。通过RViz，您可以查看传感器数据（例如`sensors_msgs/Image`），机器人模型状态以及各种其他类型的信息，这有助于调试和理解您的机器人系统行为。</details>
- en: Publish Detected Classes with `std_msgs/String`
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用`std_msgs/String`发布检测到的类别
- en: Standard ROS messages also include `std_msgs/String` messages. In many applications,
    it is not necessary to republish the entire annotated image; instead, only the
    classes present in the robot's view are needed. The following example demonstrates
    how to use `std_msgs/String` [messages](https://docs.ros.org/en/noetic/api/std_msgs/html/msg/String.html)
    to republish the detected classes on the `/ultralytics/detection/classes` topic.
    These messages are more lightweight and provide essential information, making
    them valuable for various applications.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的 ROS 消息也包括 `std_msgs/String` 消息。在许多应用中，不必重新发布整个带有注释的图像；相反，只需要机器人视野中存在的类。以下示例演示了如何使用
    `std_msgs/String` [消息](https://docs.ros.org/en/noetic/api/std_msgs/html/msg/String.html)
    将检测到的类别重新发布到 `/ultralytics/detection/classes` 话题。这些消息更轻量级且提供了关键信息，对各种应用非常有价值。
- en: Example Use Case
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 示例用例
- en: Consider a warehouse robot equipped with a camera and object detection model.
    Instead of sending large annotated images over the network, the robot can publish
    a list of detected classes as `std_msgs/String` messages. For instance, when the
    robot detects objects like "box", "pallet" and "forklift" it publishes these classes
    to the `/ultralytics/detection/classes` topic. This information can then be used
    by a central monitoring system to track the inventory in real-time, optimize the
    robot's path planning to avoid obstacles, or trigger specific actions such as
    picking up a detected box. This approach reduces the bandwidth required for communication
    and focuses on transmitting critical data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个配备有相机和物体检测模型的仓库机器人。机器人可以通过发布 `std_msgs/String` 消息列表而不是通过网络发送大型带有注释的图像。例如，当机器人检测到像
    "box"、"pallet" 和 "forklift" 这样的对象时，它将这些类别发布到 `/ultralytics/detection/classes`
    话题。然后，中央监控系统可以使用这些信息实时跟踪库存，优化机器人的路径规划以避开障碍物，或触发特定动作，如拾取检测到的箱子。这种方法减少了通信所需的带宽，并侧重于传输关键数据。
- en: String Step-by-Step Usage
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 逐步使用字符串
- en: This example demonstrates how to use the Ultralytics YOLO package with ROS.
    In this example, we subscribe to a camera topic, process the incoming image using
    YOLO, and publish the detected objects to new topic `/ultralytics/detection/classes`
    using `std_msgs/String` messages. The `ros_numpy` package is used to convert the
    ROS Image message to a numpy array for processing with YOLO.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 本示例演示了如何在 ROS 中使用 Ultralytics YOLO 软件包。在这个例子中，我们订阅相机话题，使用 YOLO 处理传入的图像，并通过 `std_msgs/String`
    消息将检测到的对象发布到新的话题 `/ultralytics/detection/classes`。使用 `ros_numpy` 软件包将 ROS Image
    消息转换为 numpy 数组，以便与 YOLO 进行处理。
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Use Ultralytics with ROS Depth Images
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Ultralytics 和 ROS 深度图像
- en: In addition to RGB images, ROS supports [depth images](https://en.wikipedia.org/wiki/Depth_map),
    which provide information about the distance of objects from the camera. Depth
    images are crucial for robotic applications such as obstacle avoidance, 3D mapping,
    and localization.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 RGB 图像外，ROS 还支持 [深度图像](https://en.wikipedia.org/wiki/Depth_map)，这些图像提供了有关物体与相机之间距离的信息。深度图像对于机器人应用（如避障、3D
    映射和定位）至关重要。
- en: A depth image is an image where each pixel represents the distance from the
    camera to an object. Unlike RGB images that capture color, depth images capture
    spatial information, enabling robots to perceive the 3D structure of their environment.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 深度图像是一种图像，其中每个像素表示从相机到对象的距离。与捕捉颜色的 RGB 图像不同，深度图像捕捉空间信息，使机器人能够感知其环境的三维结构。
- en: Obtaining Depth Images
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 获取深度图像
- en: 'Depth images can be obtained using various sensors:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用各种传感器获取深度图像：
- en: '[Stereo Cameras](https://en.wikipedia.org/wiki/Stereo_camera): Use two cameras
    to calculate depth based on image disparity.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[立体相机](https://en.wikipedia.org/wiki/Stereo_camera)：使用两个相机根据图像视差计算深度。'
- en: '[Time-of-Flight (ToF) Cameras](https://en.wikipedia.org/wiki/Time-of-flight_camera):
    Measure the time light takes to return from an object.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[飞行时间（ToF）相机](https://en.wikipedia.org/wiki/Time-of-flight_camera)：测量光返回对象所需的时间。'
- en: '[Structured Light Sensors](https://en.wikipedia.org/wiki/Structured-light_3D_scanner):
    Project a pattern and measure its deformation on surfaces.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[结构光传感器](https://en.wikipedia.org/wiki/Structured-light_3D_scanner)：投射模式并测量其在表面上的变形。'
- en: Using YOLO with Depth Images
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用深度图像的 YOLO
- en: In ROS, depth images are represented by the `sensor_msgs/Image` message type,
    which includes fields for encoding, height, width, and pixel data. The encoding
    field for depth images often uses a format like "16UC1", indicating a 16-bit unsigned
    integer per pixel, where each value represents the distance to the object. Depth
    images are commonly used in conjunction with RGB images to provide a more comprehensive
    view of the environment.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在ROS中，深度图像由`sensor_msgs/Image`消息类型表示，其中包括编码、高度、宽度和像素数据字段。深度图像的编码字段通常使用像"16UC1"这样的格式，表示每个像素的16位无符号整数，其中每个值表示到物体的距离。深度图像通常与RGB图像一起使用，以提供环境的更全面视图。
- en: Using YOLO, it is possible to extract and combine information from both RGB
    and depth images. For instance, YOLO can detect objects within an RGB image, and
    this detection can be used to pinpoint corresponding regions in the depth image.
    This allows for the extraction of precise depth information for detected objects,
    enhancing the robot's ability to understand its environment in three dimensions.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用YOLO可以从RGB和深度图像中提取并结合信息。例如，YOLO可以检测RGB图像中的对象，这一检测可以用于在深度图像中确定相应的区域。这样可以提取检测到对象的精确深度信息，增强机器人在三维环境中理解其环境的能力。
- en: RGB-D Cameras
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: RGB-D相机
- en: When working with depth images, it is essential to ensure that the RGB and depth
    images are correctly aligned. RGB-D cameras, such as the [Intel RealSense](https://www.intelrealsense.com/)
    series, provide synchronized RGB and depth images, making it easier to combine
    information from both sources. If using separate RGB and depth cameras, it is
    crucial to calibrate them to ensure accurate alignment.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理深度图像时，确保RGB和深度图像正确对齐非常重要。RGB-D相机（如[Intel RealSense](https://www.intelrealsense.com/)系列）提供了同步的RGB和深度图像，使得从两个来源结合信息更加容易。如果使用单独的RGB和深度相机，重要的是对它们进行校准，以确保准确的对齐。
- en: Depth Step-by-Step Usage
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 深度逐步使用
- en: In this example, we use YOLO to segment an image and apply the extracted mask
    to segment the object in the depth image. This allows us to determine the distance
    of each pixel of the object of interest from the camera's focal center. By obtaining
    this distance information, we can calculate the distance between the camera and
    the specific object in the scene. Begin by importing the necessary libraries,
    creating a ROS node, and instantiating a segmentation model and a ROS topic.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们使用YOLO对图像进行分割，并将提取的掩码应用于深度图像中的对象分割。这样可以确定感兴趣对象的每个像素距离相机的焦点中心的距离。通过获取这些距离信息，我们可以计算场景中相机与特定对象之间的距离。首先导入必要的库，创建一个ROS节点，并实例化分割模型和ROS主题。
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Next, define a callback function that processes the incoming depth image message.
    The function waits for the depth image and RGB image messages, converts them into
    numpy arrays, and applies the segmentation model to the RGB image. It then extracts
    the segmentation mask for each detected object and calculates the average distance
    of the object from the camera using the depth image. Most sensors have a maximum
    distance, known as the clip distance, beyond which values are represented as inf
    (`np.inf`). Before processing, it is important to filter out these null values
    and assign them a value of `0`. Finally, it publishes the detected objects along
    with their average distances to the `/ultralytics/detection/distance` topic.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，定义一个回调函数来处理传入的深度图像消息。该函数等待深度图像和RGB图像消息，将它们转换为numpy数组，并将分割模型应用于RGB图像。然后提取每个检测到对象的分割掩码，并使用深度图像计算对象距相机的平均距离。大多数传感器具有最大距离，称为剪裁距离，超出此距离的值被表示为inf（`np.inf`）。在处理之前，过滤这些空值并将它们赋值为`0`是非常重要的。最后，将检测到的对象及其平均距离发布到`/ultralytics/detection/distance`主题上。
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: <details class="example"><summary>Complete code</summary>
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="example"><summary>完整代码</summary>
- en: '[PRE9]</details>'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE9]</details>'
- en: Use Ultralytics with ROS `sensor_msgs/PointCloud2`
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用ROS的Ultralytics `sensor_msgs/PointCloud2`
- en: '![Detection and Segmentation in ROS Gazebo](img/034919731770fe377697d6eddc2c6aa4.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![ROS Gazebo 中的检测和分割](img/034919731770fe377697d6eddc2c6aa4.png)'
- en: The `sensor_msgs/PointCloud2` [message type](https://docs.ros.org/en/api/sensor_msgs/html/msg/PointCloud2.html)
    is a data structure used in ROS to represent 3D point cloud data. This message
    type is integral to robotic applications, enabling tasks such as 3D mapping, object
    recognition, and localization.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`sensor_msgs/PointCloud2` [消息类型](https://docs.ros.org/en/api/sensor_msgs/html/msg/PointCloud2.html)
    是ROS中用于表示3D点云数据的数据结构。该消息类型对机器人应用至关重要，可以执行3D映射、对象识别和定位等任务。'
- en: A point cloud is a collection of data points defined within a three-dimensional
    coordinate system. These data points represent the external surface of an object
    or a scene, captured via 3D scanning technologies. Each point in the cloud has
    `X`, `Y`, and `Z` coordinates, which correspond to its position in space, and
    may also include additional information such as color and intensity.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 点云是在三维坐标系内定义的数据点集合。这些数据点代表通过3D扫描技术捕获的对象或场景的外部表面。云中的每个点都有`X`、`Y`和`Z`坐标，对应其空间位置，可能还包括颜色和强度等附加信息。
- en: Reference frame
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 参考框架
- en: When working with `sensor_msgs/PointCloud2`, it's essential to consider the
    reference frame of the sensor from which the point cloud data was acquired. The
    point cloud is initially captured in the sensor's reference frame. You can determine
    this reference frame by listening to the `/tf_static` topic. However, depending
    on your specific application requirements, you might need to convert the point
    cloud into another reference frame. This transformation can be achieved using
    the `tf2_ros` package, which provides tools for managing coordinate frames and
    transforming data between them.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理`sensor_msgs/PointCloud2`时，必须考虑从中获取点云数据的传感器参考框架。点云最初是在传感器的参考框架中捕获的。您可以通过监听`/tf_static`话题来确定这个参考框架。然而，根据您的具体应用需求，您可能需要将点云转换为另一个参考框架。这可以通过使用`tf2_ros`包来实现，该包提供了管理坐标框架和在它们之间转换数据的工具。
- en: Obtaining Point clouds
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 获取点云
- en: 'Point Clouds can be obtained using various sensors:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用各种传感器获取点云：
- en: '**LIDAR (Light Detection and Ranging)**: Uses laser pulses to measure distances
    to objects and create high-precision 3D maps.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**激光雷达（Light Detection and Ranging，LIDAR）**：使用激光脉冲测量物体的距离并创建高精度的3D地图。'
- en: '**Depth Cameras**: Capture depth information for each pixel, allowing for 3D
    reconstruction of the scene.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**深度摄像头**：捕获每个像素的深度信息，允许对场景进行3D重建。'
- en: '**Stereo Cameras**: Utilize two or more cameras to obtain depth information
    through triangulation.'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**立体相机**：利用两个或更多摄像头通过三角测量获取深度信息。'
- en: '**Structured Light Scanners**: Project a known pattern onto a surface and measure
    the deformation to calculate depth.'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**结构光扫描仪**：在表面投射已知模式，并测量变形以计算深度。'
- en: Using YOLO with Point Clouds
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用YOLO处理点云
- en: To integrate YOLO with `sensor_msgs/PointCloud2` type messages, we can employ
    a method similar to the one used for depth maps. By leveraging the color information
    embedded in the point cloud, we can extract a 2D image, perform segmentation on
    this image using YOLO, and then apply the resulting mask to the three-dimensional
    points to isolate the 3D object of interest.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 要将YOLO与`sensor_msgs/PointCloud2`类型的消息集成，可以采用类似于深度图的方法。通过利用点云中嵌入的颜色信息，我们可以提取一个2D图像，使用YOLO对该图像进行分割，然后将结果掩码应用于三维点，以隔离感兴趣的3D对象。
- en: For handling point clouds, we recommend using Open3D (`pip install open3d`),
    a user-friendly Python library. Open3D provides robust tools for managing point
    cloud data structures, visualizing them, and executing complex operations seamlessly.
    This library can significantly simplify the process and enhance our ability to
    manipulate and analyze point clouds in conjunction with YOLO-based segmentation.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 处理点云推荐使用Open3D（`pip install open3d`），这是一个用户友好的Python库。Open3D提供了强大的工具来管理点云数据结构、可视化它们，并无缝执行复杂操作。这个库可以显著简化处理过程，增强我们在与基于YOLO的分割结合时操作和分析点云的能力。
- en: Point Clouds Step-by-Step Usage
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 点云逐步使用
- en: Import the necessary libraries and instantiate the YOLO model for segmentation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 导入必要的库并实例化YOLO模型用于分割。
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Create a function `pointcloud2_to_array`, which transforms a `sensor_msgs/PointCloud2`
    message into two numpy arrays. The `sensor_msgs/PointCloud2` messages contain
    `n` points based on the `width` and `height` of the acquired image. For instance,
    a `480 x 640` image will have `307,200` points. Each point includes three spatial
    coordinates (`xyz`) and the corresponding color in `RGB` format. These can be
    considered as two separate channels of information.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为`pointcloud2_to_array`的函数，将`sensor_msgs/PointCloud2`消息转换为两个numpy数组。`sensor_msgs/PointCloud2`消息基于获取图像的`width`和`height`包含`n`个点。例如，一个`480
    x 640`的图像将有`307,200`个点。每个点包括三个空间坐标(`xyz`)和对应的`RGB`格式颜色。这些可以被视为两个独立的信息通道。
- en: The function returns the `xyz` coordinates and `RGB` values in the format of
    the original camera resolution (`width x height`). Most sensors have a maximum
    distance, known as the clip distance, beyond which values are represented as inf
    (`np.inf`). Before processing, it is important to filter out these null values
    and assign them a value of `0`.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 函数以原始相机分辨率(`width x height`)返回`xyz`坐标和`RGB`值。大多数传感器具有最大距离，称为剪裁距离，超出该距离的值表示为inf(`np.inf`)。在处理之前，过滤这些空值并将它们分配一个`0`值是很重要的。
- en: '[PRE11]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Next, subscribe to the `/camera/depth/points` topic to receive the point cloud
    message and convert the `sensor_msgs/PointCloud2` message into numpy arrays containing
    the XYZ coordinates and RGB values (using the `pointcloud2_to_array` function).
    Process the RGB image using the YOLO model to extract segmented objects. For each
    detected object, extract the segmentation mask and apply it to both the RGB image
    and the XYZ coordinates to isolate the object in 3D space.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，订阅`/camera/depth/points`话题以接收点云消息，并使用`pointcloud2_to_array`函数将`sensor_msgs/PointCloud2`消息转换为包含XYZ坐标和RGB值的numpy数组。使用YOLO模型处理RGB图像以提取分割的物体。对于每个检测到的物体，提取分割掩码并将其应用于RGB图像和XYZ坐标，以在3D空间中隔离物体。
- en: Processing the mask is straightforward since it consists of binary values, with
    `1` indicating the presence of the object and `0` indicating the absence. To apply
    the mask, simply multiply the original channels by the mask. This operation effectively
    isolates the object of interest within the image. Finally, create an Open3D point
    cloud object and visualize the segmented object in 3D space with associated colors.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 处理掩码很简单，因为它由二进制值组成，其中`1`表示物体的存在，`0`表示物体的不存在。要应用掩码，只需将原始通道乘以掩码。这个操作有效地将兴趣对象从图像中隔离出来。最后，创建一个Open3D点云对象，并使用相关颜色在3D空间中可视化分割的对象。
- en: '[PRE12]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: <details class="example"><summary>Complete code</summary>
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="example"><summary>完整代码</summary>
- en: '[PRE13]</details>'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE13]</details>'
- en: '![Point Cloud Segmentation with Ultralytics ](img/53ab87c81395c1cae864d340d0d0fd07.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![使用Ultralytics进行点云分割](img/53ab87c81395c1cae864d340d0d0fd07.png)'
- en: FAQ
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题解答（FAQ）
- en: What is the Robot Operating System (ROS)?
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是机器人操作系统（ROS）？
- en: The [Robot Operating System (ROS)](https://www.ros.org/) is an open-source framework
    commonly used in robotics to help developers create robust robot applications.
    It provides a collection of [libraries and tools](https://www.ros.org/blog/ecosystem/)
    for building and interfacing with robotic systems, enabling easier development
    of complex applications. ROS supports communication between nodes using messages
    over [topics](https://wiki.ros.org/ROS/Tutorials/UnderstandingTopics) or [services](https://wiki.ros.org/ROS/Tutorials/UnderstandingServicesParams).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[机器人操作系统（ROS）](https://www.ros.org/)是一个开源框架，广泛用于机器人领域，帮助开发者创建健壮的机器人应用程序。它提供了一系列[库和工具](https://www.ros.org/blog/ecosystem/)用于构建和与机器人系统交互，使复杂应用程序的开发更加轻松。ROS支持节点间通过[话题](https://wiki.ros.org/ROS/Tutorials/UnderstandingTopics)或[服务](https://wiki.ros.org/ROS/Tutorials/UnderstandingServicesParams)传递消息进行通信。'
- en: How do I integrate Ultralytics YOLO with ROS for real-time object detection?
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何将Ultralytics YOLO与ROS集成以进行实时目标检测？
- en: 'Integrating Ultralytics YOLO with ROS involves setting up a ROS environment
    and using YOLO for processing sensor data. Begin by installing the required dependencies
    like `ros_numpy` and Ultralytics YOLO:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 将Ultralytics YOLO与ROS集成涉及设置ROS环境并使用YOLO处理传感器数据。首先安装必要的依赖项，如`ros_numpy`和Ultralytics
    YOLO：
- en: '[PRE14]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, create a ROS node and subscribe to an image topic to process the incoming
    data. Here is a minimal example:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个ROS节点并订阅图像话题以处理传入数据。以下是一个简单的示例：
- en: '[PRE15]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: What are ROS topics and how are they used in Ultralytics YOLO?
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ROS话题是什么以及它们在Ultralytics YOLO中如何使用？
- en: ROS topics facilitate communication between nodes in a ROS network by using
    a publish-subscribe model. A topic is a named channel that nodes use to send and
    receive messages asynchronously. In the context of Ultralytics YOLO, you can make
    a node subscribe to an image topic, process the images using YOLO for tasks like
    detection or segmentation, and publish outcomes to new topics.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ROS主题通过发布-订阅模型在ROS网络中的节点之间进行通信。主题是节点用来异步发送和接收消息的命名通道。在Ultralytics YOLO的背景下，您可以使一个节点订阅图像主题，使用YOLO处理图像进行检测或分割等任务，并将结果发布到新的主题上。
- en: 'For example, subscribe to a camera topic and process the incoming image for
    detection:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，订阅相机主题并处理传入图像进行检测：
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Why use depth images with Ultralytics YOLO in ROS?
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在ROS中为什么要使用Ultralytics YOLO的深度图像？
- en: Depth images in ROS, represented by `sensor_msgs/Image`, provide the distance
    of objects from the camera, crucial for tasks like obstacle avoidance, 3D mapping,
    and localization. By [using depth information](https://en.wikipedia.org/wiki/Depth_map)
    along with RGB images, robots can better understand their 3D environment.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ROS中的深度图像，由`sensor_msgs/Image`表示，提供了物体距相机的距离，对于障碍物避免、3D地图和定位等任务至关重要。通过[使用深度信息](https://en.wikipedia.org/wiki/Depth_map)和RGB图像，机器人可以更好地理解其3D环境。
- en: With YOLO, you can extract segmentation masks from RGB images and apply these
    masks to depth images to obtain precise 3D object information, improving the robot's
    ability to navigate and interact with its surroundings.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用YOLO，可以从RGB图像中提取分割掩模，并将这些掩模应用到深度图像上，以获取精确的3D物体信息，从而提升机器人在环境中导航和交互的能力。
- en: How can I visualize 3D point clouds with YOLO in ROS?
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何使用YOLO在ROS中可视化3D点云？
- en: 'To visualize 3D point clouds in ROS with YOLO:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用YOLO在ROS中可视化3D点云：
- en: Convert `sensor_msgs/PointCloud2` messages to numpy arrays.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`sensor_msgs/PointCloud2`消息转换为numpy数组。
- en: Use YOLO to segment RGB images.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用YOLO来分割RGB图像。
- en: Apply the segmentation mask to the point cloud.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将分割掩模应用于点云。
- en: 'Here''s an example using Open3D for visualization:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个使用Open3D进行可视化的例子：
- en: '[PRE17]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This approach provides a 3D visualization of segmented objects, useful for tasks
    like navigation and manipulation.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法提供了分割对象的3D可视化，对于导航和操作等任务非常有用。
