- en: COCO-Seg Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/datasets/segment/coco/`](https://docs.ultralytics.com/datasets/segment/coco/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The [COCO-Seg](https://cocodataset.org/#home) dataset, an extension of the COCO
    (Common Objects in Context) dataset, is specially designed to aid research in
    object instance segmentation. It uses the same images as COCO but introduces more
    detailed segmentation annotations. This dataset is a crucial resource for researchers
    and developers working on instance segmentation tasks, especially for training
    YOLO models.
  prefs: []
  type: TYPE_NORMAL
- en: COCO-Seg Pretrained Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(box 50-95) | mAP^(mask 50-95) | Speed ^(CPU
    ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-seg.pt)
    | 640 | 36.7 | 30.5 | 96.1 | 1.21 | 3.4 | 12.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-seg.pt)
    | 640 | 44.6 | 36.8 | 155.7 | 1.47 | 11.8 | 42.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-seg.pt)
    | 640 | 49.9 | 40.8 | 317.0 | 2.18 | 27.3 | 110.2 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-seg.pt)
    | 640 | 52.3 | 42.6 | 572.4 | 2.79 | 46.0 | 220.5 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-seg.pt)
    | 640 | 53.4 | 43.4 | 712.1 | 4.02 | 71.8 | 344.1 |'
  prefs: []
  type: TYPE_TB
- en: Key Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: COCO-Seg retains the original 330K images from COCO.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dataset consists of the same 80 object categories found in the original
    COCO dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Annotations now include more detailed instance segmentation masks for each object
    in the images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: COCO-Seg provides standardized evaluation metrics like mean Average Precision
    (mAP) for object detection, and mean Average Recall (mAR) for instance segmentation
    tasks, enabling effective comparison of model performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset Structure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The COCO-Seg dataset is partitioned into three subsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Train2017**: This subset contains 118K images for training instance segmentation
    models.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Val2017**: This subset includes 5K images used for validation purposes during
    model training.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Test2017**: This subset encompasses 20K images used for testing and benchmarking
    the trained models. Ground truth annotations for this subset are not publicly
    available, and the results are submitted to the [COCO evaluation server](https://codalab.lisn.upsaclay.fr/competitions/7383)
    for performance evaluation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: COCO-Seg is widely used for training and evaluating deep learning models in
    instance segmentation, such as the YOLO models. The large number of annotated
    images, the diversity of object categories, and the standardized evaluation metrics
    make it an indispensable resource for computer vision researchers and practitioners.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset YAML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A YAML (Yet Another Markup Language) file is used to define the dataset configuration.
    It contains information about the dataset's paths, classes, and other relevant
    information. In the case of the COCO-Seg dataset, the `coco.yaml` file is maintained
    at [`github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml).
  prefs: []
  type: TYPE_NORMAL
- en: ultralytics/cfg/datasets/coco.yaml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To train a YOLOv8n-seg model on the COCO-Seg dataset for 100 epochs with an
    image size of 640, you can use the following code snippets. For a comprehensive
    list of available arguments, refer to the model Training page.
  prefs: []
  type: TYPE_NORMAL
- en: Train Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Sample Images and Annotations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'COCO-Seg, like its predecessor COCO, contains a diverse set of images with
    various object categories and complex scenes. However, COCO-Seg introduces more
    detailed instance segmentation masks for each object in the images. Here are some
    examples of images from the dataset, along with their corresponding instance segmentation
    masks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dataset sample image](img/bde4040cf8681815abc7d465309f9ba4.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Mosaiced Image**: This image demonstrates a training batch composed of mosaiced
    dataset images. Mosaicing is a technique used during training that combines multiple
    images into a single image to increase the variety of objects and scenes within
    each training batch. This aids the model''s ability to generalize to different
    object sizes, aspect ratios, and contexts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The example showcases the variety and complexity of the images in the COCO-Seg
    dataset and the benefits of using mosaicing during the training process.
  prefs: []
  type: TYPE_NORMAL
- en: Citations and Acknowledgments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you use the COCO-Seg dataset in your research or development work, please
    cite the original COCO paper and acknowledge the extension to COCO-Seg:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We extend our thanks to the COCO Consortium for creating and maintaining this
    invaluable resource for the computer vision community. For more information about
    the COCO dataset and its creators, visit the [COCO dataset website](https://cocodataset.org/#home).
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is the COCO-Seg dataset and how does it differ from the original COCO dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The [COCO-Seg](https://cocodataset.org/#home) dataset is an extension of the
    original COCO (Common Objects in Context) dataset, specifically designed for instance
    segmentation tasks. While it uses the same images as the COCO dataset, COCO-Seg
    includes more detailed segmentation annotations, making it a powerful resource
    for researchers and developers focusing on object instance segmentation.
  prefs: []
  type: TYPE_NORMAL
- en: How can I train a YOLOv8 model using the COCO-Seg dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To train a YOLOv8n-seg model on the COCO-Seg dataset for 100 epochs with an
    image size of 640, you can use the following code snippets. For a detailed list
    of available arguments, refer to the model Training page.
  prefs: []
  type: TYPE_NORMAL
- en: Train Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: What are the key features of the COCO-Seg dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The COCO-Seg dataset includes several key features:'
  prefs: []
  type: TYPE_NORMAL
- en: Retains the original 330K images from the COCO dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Annotates the same 80 object categories found in the original COCO.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provides more detailed instance segmentation masks for each object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uses standardized evaluation metrics such as mean Average Precision (mAP) for
    object detection and mean Average Recall (mAR) for instance segmentation tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What pretrained models are available for COCO-Seg, and what are their performance
    metrics?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The COCO-Seg dataset supports multiple pretrained YOLOv8 segmentation models
    with varying performance metrics. Here''s a summary of the available models and
    their key metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | size ^((pixels)) | mAP^(box 50-95) | mAP^(mask 50-95) | Speed ^(CPU
    ONNX'
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | Speed ^(A100 TensorRT
  prefs: []
  type: TYPE_NORMAL
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8n-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-seg.pt)
    | 640 | 36.7 | 30.5 | 96.1 | 1.21 | 3.4 | 12.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8s-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-seg.pt)
    | 640 | 44.6 | 36.8 | 155.7 | 1.47 | 11.8 | 42.6 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8m-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-seg.pt)
    | 640 | 49.9 | 40.8 | 317.0 | 2.18 | 27.3 | 110.2 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8l-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-seg.pt)
    | 640 | 52.3 | 42.6 | 572.4 | 2.79 | 46.0 | 220.5 |'
  prefs: []
  type: TYPE_TB
- en: '| [YOLOv8x-seg](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-seg.pt)
    | 640 | 53.4 | 43.4 | 712.1 | 4.02 | 71.8 | 344.1 |'
  prefs: []
  type: TYPE_TB
- en: How is the COCO-Seg dataset structured and what subsets does it contain?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The COCO-Seg dataset is partitioned into three subsets for specific training
    and evaluation needs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Train2017**: Contains 118K images used primarily for training instance segmentation
    models.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Val2017**: Comprises 5K images utilized for validation during the training
    process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Test2017**: Encompasses 20K images reserved for testing and benchmarking
    trained models. Note that ground truth annotations for this subset are not publicly
    available, and performance results are submitted to the [COCO evaluation server](https://codalab.lisn.upsaclay.fr/competitions/7383)
    for assessment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
