- en: Object Detection
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标检测
- en: 原文：[`docs.ultralytics.com/tasks/detect/`](https://docs.ultralytics.com/tasks/detect/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/tasks/detect/`](https://docs.ultralytics.com/tasks/detect/)
- en: '![Object detection examples](img/50b6b378e346803a6cbcccf9fc297381.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![目标检测示例](img/50b6b378e346803a6cbcccf9fc297381.png)'
- en: Object detection is a task that involves identifying the location and class
    of objects in an image or video stream.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 目标检测是一项任务，涉及在图像或视频流中识别对象的位置和类别。
- en: The output of an object detector is a set of bounding boxes that enclose the
    objects in the image, along with class labels and confidence scores for each box.
    Object detection is a good choice when you need to identify objects of interest
    in a scene, but don't need to know exactly where the object is or its exact shape.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 目标检测器的输出是一组边界框，这些边界框围绕图像中的对象，以及每个框的类别标签和置信度分数。当您需要识别场景中感兴趣的对象，但不需要知道对象的确切位置或确切形状时，目标检测是一个不错的选择。
- en: '[`www.youtube.com/embed/5ku7npMrW40?si=6HQO1dDXunV8gekh`](https://www.youtube.com/embed/5ku7npMrW40?si=6HQO1dDXunV8gekh)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[`www.youtube.com/embed/5ku7npMrW40?si=6HQO1dDXunV8gekh`](https://www.youtube.com/embed/5ku7npMrW40?si=6HQO1dDXunV8gekh)'
- en: '**Watch:** Object Detection with Pre-trained Ultralytics YOLOv8 Model.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**观看：** 使用预训练的 Ultralytics YOLOv8 模型进行目标检测。'
- en: Tip
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: YOLOv8 Detect models are the default YOLOv8 models, i.e. `yolov8n.pt` and are
    pretrained on [COCO](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv8 Detect 模型是默认的 YOLOv8 模型，即 `yolov8n.pt`，并在 [COCO](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml)
    上进行了预训练。
- en: '[Models](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v8)'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[模型](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v8)'
- en: YOLOv8 pretrained Detect models are shown here. Detect, Segment and Pose models
    are pretrained on the [COCO](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml)
    dataset, while Classify models are pretrained on the [ImageNet](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/ImageNet.yaml)
    dataset.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv8 预训练 Detect 模型显示在此处。Detect、Segment 和 Pose 模型在 [COCO](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml)
    数据集上进行了预训练，而 Classify 模型在 [ImageNet](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/ImageNet.yaml)
    数据集上进行了预训练。
- en: '[Models](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models)
    download automatically from the latest Ultralytics [release](https://github.com/ultralytics/assets/releases)
    on first use.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[模型](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models)
    在首次使用时会自动从最新的 Ultralytics [发布](https://github.com/ultralytics/assets/releases)
    中下载。'
- en: '| Model | size ^((pixels)) | mAP^(val 50-95) | Speed ^(CPU ONNX'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '| 模型 | 尺寸 ^((像素)) | mAP^(val 50-95) | 速度 ^(CPU ONNX'
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: (ms)) | 速度 ^(A100 TensorRT
- en: (ms)) | params ^((M)) | FLOPs ^((B)) |
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: (ms)) | 参数 ^((M)) | FLOPs ^((B)) |
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)
    | 640 | 37.3 | 80.4 | 0.99 | 3.2 | 8.7 |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)
    | 640 | 37.3 | 80.4 | 0.99 | 3.2 | 8.7 |'
- en: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)
    | 640 | 44.9 | 128.4 | 1.20 | 11.2 | 28.6 |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)
    | 640 | 44.9 | 128.4 | 1.20 | 11.2 | 28.6 |'
- en: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)
    | 640 | 50.2 | 234.7 | 1.83 | 25.9 | 78.9 |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)
    | 640 | 50.2 | 234.7 | 1.83 | 25.9 | 78.9 |'
- en: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt)
    | 640 | 52.9 | 375.2 | 2.39 | 43.7 | 165.2 |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt)
    | 640 | 52.9 | 375.2 | 2.39 | 43.7 | 165.2 |'
- en: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt)
    | 640 | 53.9 | 479.1 | 3.53 | 68.2 | 257.8 |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt)
    | 640 | 53.9 | 479.1 | 3.53 | 68.2 | 257.8 |'
- en: '**mAP^(val)** values are for single-model single-scale on [COCO val2017](https://cocodataset.org)
    dataset.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mAP^(val)** 值是在 [COCO val2017](https://cocodataset.org) 数据集上进行单模型单尺度测试的结果。'
- en: Reproduce by `yolo val detect data=coco.yaml device=0`
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过 `yolo val detect data=coco.yaml device=0` 复现
- en: '**Speed** averaged over COCO val images using an [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/)
    instance.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度** 是在使用 [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/)
    实例对 COCO val 图像进行平均处理的。'
- en: Reproduce by `yolo val detect data=coco8.yaml batch=1 device=0|cpu`
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过 `yolo val detect data=coco8.yaml batch=1 device=0|cpu` 复现
- en: Train
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练
- en: Train YOLOv8n on the COCO8 dataset for 100 epochs at image size 640\. For a
    full list of available arguments see the Configuration page.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在尺寸为 640 的图像上使用 COCO8 数据集对 YOLOv8n 进行 100 个 epochs 的训练。有关可用参数的完整列表，请参阅配置页面。
- en: Example
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Dataset format
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集格式
- en: YOLO detection dataset format can be found in detail in the Dataset Guide. To
    convert your existing dataset from other formats (like COCO etc.) to YOLO format,
    please use [JSON2YOLO](https://github.com/ultralytics/JSON2YOLO) tool by Ultralytics.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO检测数据集格式的详细信息可以在数据集指南中找到。要将现有数据集从其他格式（如COCO等）转换为YOLO格式，请使用Ultralytics的[JSON2YOLO](https://github.com/ultralytics/JSON2YOLO)工具。
- en: Val
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Val
- en: Validate trained YOLOv8n model accuracy on the COCO8 dataset. No argument need
    to passed as the `model` retains its training `data` and arguments as model attributes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在COCO8数据集上验证训练好的YOLOv8n模型的准确性。不需要传递任何参数，因为`model`保留了其训练`data`和参数作为模型属性。
- en: Example
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Predict
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测
- en: Use a trained YOLOv8n model to run predictions on images.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用训练好的YOLOv8n模型对图像进行预测。
- en: Example
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: See full `predict` mode details in the Predict page.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 查看预测模式详细信息，请参阅预测页面。
- en: Export
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导出
- en: Export a YOLOv8n model to a different format like ONNX, CoreML, etc.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将YOLOv8n模型导出到ONNX、CoreML等不同格式。
- en: Example
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Available YOLOv8 export formats are in the table below. You can export to any
    format using the `format` argument, i.e. `format='onnx'` or `format='engine'`.
    You can predict or validate directly on exported models, i.e. `yolo predict model=yolov8n.onnx`.
    Usage examples are shown for your model after export completes.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的YOLOv8导出格式在下表中列出。您可以使用`format`参数导出到任何格式，例如`format='onnx'`或`format='engine'`。您可以直接在导出的模型上进行预测或验证，例如`yolo
    predict model=yolov8n.onnx`。导出完成后，显示了您的模型的使用示例。
- en: '| Format | `format` Argument | Model | Metadata | Arguments |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| Format | `format` Argument | Model | Metadata | Arguments |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| [PyTorch](https://pytorch.org/) | - | `yolov8n.pt` | ✅ | - |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| [PyTorch](https://pytorch.org/) | - | `yolov8n.pt` | ✅ | - |'
- en: '| TorchScript | `torchscript` | `yolov8n.torchscript` | ✅ | `imgsz`, `optimize`,
    `batch` |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| TorchScript | `torchscript` | `yolov8n.torchscript` | ✅ | `imgsz`, `optimize`,
    `batch` |'
- en: '| ONNX | `onnx` | `yolov8n.onnx` | ✅ | `imgsz`, `half`, `dynamic`, `simplify`,
    `opset`, `batch` |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| ONNX | `onnx` | `yolov8n.onnx` | ✅ | `imgsz`, `half`, `dynamic`, `simplify`,
    `opset`, `batch` |'
- en: '| OpenVINO | `openvino` | `yolov8n_openvino_model/` | ✅ | `imgsz`, `half`,
    `int8`, `batch`, `dynamic` |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| OpenVINO | `openvino` | `yolov8n_openvino_model/` | ✅ | `imgsz`, `half`,
    `int8`, `batch`, `dynamic` |'
- en: '| TensorRT | `engine` | `yolov8n.engine` | ✅ | `imgsz`, `half`, `dynamic`,
    `simplify`, `workspace`, `int8`, `batch` |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| TensorRT | `engine` | `yolov8n.engine` | ✅ | `imgsz`, `half`, `dynamic`,
    `simplify`, `workspace`, `int8`, `batch` |'
- en: '| CoreML | `coreml` | `yolov8n.mlpackage` | ✅ | `imgsz`, `half`, `int8`, `nms`,
    `batch` |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| CoreML | `coreml` | `yolov8n.mlpackage` | ✅ | `imgsz`, `half`, `int8`, `nms`,
    `batch` |'
- en: '| TF SavedModel | `saved_model` | `yolov8n_saved_model/` | ✅ | `imgsz`, `keras`,
    `int8`, `batch` |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| TF SavedModel | `saved_model` | `yolov8n_saved_model/` | ✅ | `imgsz`, `keras`,
    `int8`, `batch` |'
- en: '| TF GraphDef | `pb` | `yolov8n.pb` | ❌ | `imgsz`, `batch` |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| TF GraphDef | `pb` | `yolov8n.pb` | ❌ | `imgsz`, `batch` |'
- en: '| TF Lite | `tflite` | `yolov8n.tflite` | ✅ | `imgsz`, `half`, `int8`, `batch`
    |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| TF Lite | `tflite` | `yolov8n.tflite` | ✅ | `imgsz`, `half`, `int8`, `batch`
    |'
- en: '| TF Edge TPU | `edgetpu` | `yolov8n_edgetpu.tflite` | ✅ | `imgsz` |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| TF Edge TPU | `edgetpu` | `yolov8n_edgetpu.tflite` | ✅ | `imgsz` |'
- en: '| TF.js | `tfjs` | `yolov8n_web_model/` | ✅ | `imgsz`, `half`, `int8`, `batch`
    |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| TF.js | `tfjs` | `yolov8n_web_model/` | ✅ | `imgsz`, `half`, `int8`, `batch`
    |'
- en: '| PaddlePaddle | `paddle` | `yolov8n_paddle_model/` | ✅ | `imgsz`, `batch`
    |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| PaddlePaddle | `paddle` | `yolov8n_paddle_model/` | ✅ | `imgsz`, `batch`
    |'
- en: '| NCNN | `ncnn` | `yolov8n_ncnn_model/` | ✅ | `imgsz`, `half`, `batch` |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| NCNN | `ncnn` | `yolov8n_ncnn_model/` | ✅ | `imgsz`, `half`, `batch` |'
- en: See full `export` details in the Export page.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 查看完整的导出详细信息，请参阅导出页面。
- en: FAQ
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题解答
- en: How do I train a YOLOv8 model on my custom dataset?
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何在自定义数据集上训练YOLOv8模型？
- en: 'Training a YOLOv8 model on a custom dataset involves a few steps:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 训练YOLOv8模型的自定义数据集涉及几个步骤：
- en: '**Prepare the Dataset**: Ensure your dataset is in the YOLO format. For guidance,
    refer to our Dataset Guide.'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准备数据集**：确保您的数据集采用YOLO格式。有关指导，请参阅我们的数据集指南。'
- en: '**Load the Model**: Use the Ultralytics YOLO library to load a pre-trained
    model or create a new model from a YAML file.'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**加载模型**：使用Ultralytics YOLO库加载预训练模型或从YAML文件创建新模型。'
- en: '**Train the Model**: Execute the `train` method in Python or the `yolo detect
    train` command in CLI.'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练模型**：在Python中执行`train`方法或在CLI中执行`yolo detect train`命令。'
- en: Example
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For detailed configuration options, visit the Configuration page.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解详细的配置选项，请访问配置页面。
- en: What pretrained models are available in YOLOv8?
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: YOLOv8中有哪些预训练模型可用？
- en: 'Ultralytics YOLOv8 offers various pretrained models for object detection, segmentation,
    and pose estimation. These models are pretrained on the COCO dataset or ImageNet
    for classification tasks. Here are some of the available models:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics YOLOv8提供多个预训练模型，用于目标检测、分割和姿态估计。这些模型在COCO数据集或ImageNet上进行了预训练，用于分类任务。以下是一些可用的模型：
- en: '[YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)'
- en: '[YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt)'
- en: '[YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt)'
- en: '[YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt)'
- en: '[YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt)'
- en: For a detailed list and performance metrics, refer to the [Models](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v8)
    section.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如需详细列表和性能指标，请参阅[模型](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v8)部分。
- en: How can I validate the accuracy of my trained YOLOv8 model?
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何验证我训练的YOLOv8模型的准确性？
- en: To validate the accuracy of your trained YOLOv8 model, you can use the `.val()`
    method in Python or the `yolo detect val` command in CLI. This will provide metrics
    like mAP50-95, mAP50, and more.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证您训练的YOLOv8模型的准确性，可以在Python中使用`.val()`方法或在CLI中使用`yolo detect val`命令。这将提供诸如mAP50-95、mAP50等指标。
- en: Example
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: For more validation details, visit the Val page.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 更多验证细节，请访问Val页面。
- en: What formats can I export a YOLOv8 model to?
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: YOLOv8模型可以导出到哪些格式？
- en: Ultralytics YOLOv8 allows exporting models to various formats such as ONNX,
    TensorRT, CoreML, and more to ensure compatibility across different platforms
    and devices.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics YOLOv8支持将模型导出到各种格式，如ONNX、TensorRT、CoreML等，以确保在不同平台和设备上的兼容性。
- en: Example
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE12]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Check the full list of supported formats and instructions on the Export page.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 查看支持的格式列表和导出页面的说明。
- en: Why should I use Ultralytics YOLOv8 for object detection?
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么应该使用Ultralytics YOLOv8进行目标检测？
- en: 'Ultralytics YOLOv8 is designed to offer state-of-the-art performance for object
    detection, segmentation, and pose estimation. Here are some key advantages:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Ultralytics YOLOv8旨在提供优越的目标检测、分割和姿态估计性能。以下是一些关键优势：
- en: '**Pretrained Models**: Utilize models pretrained on popular datasets like COCO
    and ImageNet for faster development.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预训练模型**：利用在流行数据集如COCO和ImageNet上预训练的模型，加快开发速度。'
- en: '**High Accuracy**: Achieves impressive mAP scores, ensuring reliable object
    detection.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**高准确性**：实现了令人印象深刻的mAP分数，确保可靠的目标检测。'
- en: '**Speed**: Optimized for real-time inference, making it ideal for applications
    requiring swift processing.'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**速度**：优化用于实时推理，非常适合需要快速处理的应用。'
- en: '**Flexibility**: Export models to various formats like ONNX and TensorRT for
    deployment across multiple platforms.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**灵活性**：将模型导出到ONNX和TensorRT等多种格式，用于在多平台部署。'
- en: Explore our [Blog](https://www.ultralytics.com/blog) for use cases and success
    stories showcasing YOLOv8 in action.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 浏览我们的[博客](https://www.ultralytics.com/blog)，查看使用案例和展示YOLOv8效果的成功故事。
