# `scipy.optimize.lsq_linear`

> 原始文本：[`docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.lsq_linear.html#scipy.optimize.lsq_linear`](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.optimize.lsq_linear.html#scipy.optimize.lsq_linear)

```py
scipy.optimize.lsq_linear(A, b, bounds=(-inf, inf), method='trf', tol=1e-10, lsq_solver=None, lsmr_tol=None, max_iter=None, verbose=0, *, lsmr_maxiter=None)
```

解决具有变量界限的线性最小二乘问题。

给定一个 m × n 的设计矩阵 A 和一个具有 m 个元素的目标向量 b，`lsq_linear` 解决以下优化问题：

```py
minimize 0.5 * ||A x - b||**2
subject to lb <= x <= ub 
```

该优化问题是凸的，因此找到的最小值（如果迭代收敛）保证是全局的。

参数：

**A**array_like，稀疏矩阵或 LinearOperator，形状为 (m, n)

设计矩阵。可以是 `scipy.sparse.linalg.LinearOperator`。

**b**array_like，形状为 (m,)

目标向量。

**bounds**2-tuple of array_like 或 `Bounds` 的实例，可选

参数的上下界。默认情况下没有界限。有两种指定界限的方式：

> +   `Bounds` 类的实例。
> +   
> +   2-tuple of array_like：元组的每个元素必须是长度等于参数数目的数组，或者是一个标量（在这种情况下，界限被认为对所有参数都是相同的）。使用 `np.inf` 和适当的符号来禁用所有或某些参数的界限。

**method**‘trf’ 或 ‘bvls’，可选

执行最小化的方法。

> +   ‘trf’：适用于线性最小二乘问题的信任区域反射算法。这是一种类似内点的方法，所需的迭代次数与变量数目弱相关。
> +   
> +   ‘bvls’：有界变量最小二乘算法。这是一种活动集方法，需要的迭代次数与变量数目相当。当 *A* 是稀疏的或 LinearOperator 时无法使用。

默认为 ‘trf’。

**tol**float，可选

容差参数。如果成本函数的相对变化在最后一次迭代中小于 *tol*，则算法终止。此外，还考虑第一阶优化度量：

> +   `method='trf'` 如果梯度的均匀范数（考虑到界限的存在）小于 *tol*，则终止。
> +   
> +   `method='bvls'` 如果在 *tol* 的容差内满足 Karush-Kuhn-Tucker 条件，则终止。

**lsq_solver**{None, ‘exact’, ‘lsmr’}，可选

在迭代过程中解决无界最小二乘问题的方法：

> +   ‘exact’：使用密集的 QR 或 SVD 分解方法。当 *A* 是稀疏的或 LinearOperator 时无法使用。
> +   
> +   ‘lsmr’：使用 `scipy.sparse.linalg.lsmr` 迭代过程，仅需要矩阵-向量乘积评估。不能与 `method='bvls'` 同时使用。

如果为 None（默认值），则根据 *A* 的类型选择求解器。

**lsmr_tol**None、float 或 ‘auto’，可选

耐受参数 ‘atol’ 和 ‘btol’ 用于 [`scipy.sparse.linalg.lsmr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lsmr.html#scipy.sparse.linalg.lsmr "scipy.sparse.linalg.lsmr")。如果为 None（默认值），则设置为 `1e-2 * tol`。如果是 ‘auto’，则基于当前迭代的最优性调整容差，这可以加速优化过程，但不总是可靠。

**max_iter**None 或 int，可选

终止前的最大迭代次数。如果为 None（默认值），则对于 `method='trf'` 设置为 100，对于 `method='bvls'` 设置为变量数（不计算 ‘bvls’ 初始化的迭代）。

**verbose**{0, 1, 2}，可选

算法详细程度：

> +   0：静默工作（默认值）。
> +   
> +   1：显示终止报告。
> +   
> +   2：显示迭代过程。

**lsmr_maxiter**None 或 int，可选

lsmr 最小二乘求解器的最大迭代次数（通过设置 `lsq_solver='lsmr'`）。如果为 None（默认值），则使用 lsmr 的默认值 `min(m, n)`，其中 `m` 和 `n` 分别为 *A* 的行数和列数。如果 `lsq_solver='exact'`，则不起作用。

返回：

OptimizeResult，其以下字段已定义：

**x**ndarray，形状为 (n,)

找到解。

**cost**float

解处的成本函数值。

**fun**数组，形状为 (m,)

解处的残差向量。

**optimality**float

一阶优化度量。确切含义取决于 *method*，请参阅 *tol* 参数的描述。

**active_mask**int 数组，形状为 (n,)

每个组件显示相应约束是否活跃（即变量是否位于边界）：

> +   0：无约束被激活。
> +   
> +   -1：下限被激活。
> +   
> +   1：上限被激活。

对于 *trf* 方法可能有些随意，因为它生成严格可行迭代序列，并且在容差阈值内确定 *active_mask*。

**unbounded_sol**元组

最小二乘求解器返回的无界解元组（使用 *lsq_solver* 选项设置）。如果 *lsq_solver* 未设置或设置为 `'exact'`，则元组包含形状为 (n,) 的 ndarray，其无界解、残差平方和的 ndarray、*A* 的秩和 *A* 的奇异值的 int（请参阅 NumPy 的 `linalg.lstsq` 获取更多信息）。如果 *lsq_solver* 设置为 `'lsmr'`，则元组包含形状为 (n,) 的 ndarray，其无界解、退出代码的 int、迭代次数的 int 和五个不同规范及 *A* 的条件数的 float（请参阅 SciPy 的 `sparse.linalg.lsmr` 获取更多信息）。此输出对于确定最小二乘求解器的收敛性尤为有用，特别是迭代 `'lsmr'` 求解器。无界最小二乘问题是最小化 `0.5 * ||A x - b||**2`。

**nit**int

迭代次数。如果无约束解是最优解，则为零。

**status**int

算法终止的原因：

> +   -1：算法在最后一次迭代时无法取得进展。
> +   
> +   0：超过最大迭代次数。
> +   
> +   1：一阶优化性能度量小于*tol*。
> +   
> +   2：成本函数的相对变化小于*tol*。
> +   
> +   3：无约束解决方案是最优的。

**message**字符串

终止原因的口头描述。

**success**布尔值

如果满足一个收敛标准（*status* > 0），则为真。

另请参阅

`nnls`

具有非负约束的线性最小二乘法。

`least_squares`

具有变量界限的非线性最小二乘法。

注释

该算法首先通过[`numpy.linalg.lstsq`](https://numpy.org/devdocs/reference/generated/numpy.linalg.lstsq.html#numpy.linalg.lstsq "(在 NumPy v2.0.dev0 中)")或`scipy.sparse.linalg.lsmr`计算无约束最小二乘解决方案，具体取决于*lsq_solver*。如果解决方案在界限内，则返回此解决方案作为最优解。

方法 'trf' 运行了适应于线性最小二乘问题的算法描述的改编版[[STIR]](#r74f8b7a68993-stir)。迭代基本与非线性最小二乘算法相同，但由于二次函数模型始终准确，因此我们不需要跟踪或修改信任区域的半径。当所选步骤未减少成本函数时，使用线搜索（回溯）作为安全网。详细了解该算法的更多信息，请参阅`scipy.optimize.least_squares`。

方法 'bvls' 运行了一个 Python 实现的算法，描述在[[BVLS]](#r74f8b7a68993-bvls)。该算法维护变量的活动和自由集，在每次迭代中选择一个新变量从活动集移动到自由集，然后在自由变量上解决无约束最小二乘问题。此算法保证最终提供准确的解决方案，但对于具有 n 个变量的问题可能需要多达 n 次迭代。此外，还实施了一种特定初始化过程，确定最初要设置为自由或活动的变量。在实际 BVLS 开始之前需要进行一些迭代，但可以显著减少进一步迭代次数。

参考文献

[STIR]

M. A. Branch, T. F. Coleman 和 Y. Li，《大规模约束最小化问题的子空间、内点和共轭梯度法》，《SIAM 科学计算杂志》，第 21 卷，第 1 号，1-23 页，1999 年。

[BVLS]

P. B. Start 和 R. L. Parker，《有界变量最小二乘法：算法与应用》，《计算统计学》，10，129-141，1995 年。

示例

在这个例子中，解决了一个涉及大稀疏矩阵和变量边界的问题。

```py
>>> import numpy as np
>>> from scipy.sparse import rand
>>> from scipy.optimize import lsq_linear
>>> rng = np.random.default_rng()
...
>>> m = 20000
>>> n = 10000
...
>>> A = rand(m, n, density=1e-4, random_state=rng)
>>> b = rng.standard_normal(m)
...
>>> lb = rng.standard_normal(n)
>>> ub = lb + 1
...
>>> res = lsq_linear(A, b, bounds=(lb, ub), lsmr_tol='auto', verbose=1)
# may vary
The relative change of the cost function is less than `tol`.
Number of iterations 16, initial cost 1.5039e+04, final cost 1.1112e+04,
first-order optimality 4.66e-08. 
```
