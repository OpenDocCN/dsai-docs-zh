- en: pandas.DataFrame.to_pickle
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: pandas.DataFrame.to_pickle
- en: 原文：[https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html)
- en: '[PRE0]'
  id: totrans-2
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Pickle (serialize) object to file.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 将对象序列化为文件。
- en: 'Parameters:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '**path**str, path object, or file-like object'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**path**str, path object, or file-like object'
- en: String, path object (implementing `os.PathLike[str]`), or file-like object implementing
    a binary `write()` function. File path where the pickled object will be stored.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串、路径对象（实现了`os.PathLike[str]`）或实现了二进制`write()`函数的文件对象。要存储 pickled 对象的文件路径。
- en: '**compression**str or dict, default ‘infer’'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**compression**str or dict, default ‘infer’'
- en: 'For on-the-fly compression of the output data. If ‘infer’ and ‘path’ is path-like,
    then detect compression from the following extensions: ‘.gz’, ‘.bz2’, ‘.zip’,
    ‘.xz’, ‘.zst’, ‘.tar’, ‘.tar.gz’, ‘.tar.xz’ or ‘.tar.bz2’ (otherwise no compression).
    Set to `None` for no compression. Can also be a dict with key `''method''` set
    to one of {`''zip''`, `''gzip''`, `''bz2''`, `''zstd''`, `''xz''`, `''tar''`}
    and other key-value pairs are forwarded to `zipfile.ZipFile`, `gzip.GzipFile`,
    `bz2.BZ2File`, `zstandard.ZstdCompressor`, `lzma.LZMAFile` or `tarfile.TarFile`,
    respectively. As an example, the following could be passed for faster compression
    and to create a reproducible gzip archive: `compression={''method'': ''gzip'',
    ''compresslevel'': 1, ''mtime'': 1}`.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '用于输出数据的即时压缩。如果是''infer''并且''path''是路径形式的，则从以下扩展名检测压缩：''.gz''、''.bz2''、''.zip''、''.xz''、''.zst''、''.tar''、''.tar.gz''、''.tar.xz''或''.tar.bz2''（否则不压缩）。设置为`None`以不压缩。也可以是一个字典，其中键“method”设置为其中一个{`''zip''`、`''gzip''`、`''bz2''`、`''zstd''`、`''xz''`、`''tar''`}，其他键值对将转发到`zipfile.ZipFile`、`gzip.GzipFile`、`bz2.BZ2File`、`zstandard.ZstdCompressor`、`lzma.LZMAFile`或`tarfile.TarFile`。例如，可以传递以下内容以进行更快的压缩并创建可重现的
    gzip 存档：`compression={''method'': ''gzip'', ''compresslevel'': 1, ''mtime'': 1}`。'
- en: 'New in version 1.5.0: Added support for .tar files.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 1.5.0 版本新增支持.tar 文件。
- en: '**protocol**int'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**protocol**int'
- en: Int which indicates which protocol should be used by the pickler, default HIGHEST_PROTOCOL
    (see [[1]](#rc4e85fbd536b-1) paragraph 12.1.2). The possible values are 0, 1,
    2, 3, 4, 5\. A negative value for the protocol parameter is equivalent to setting
    its value to HIGHEST_PROTOCOL.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 指示 pickler 应使用的协议，默认为 HIGHEST_PROTOCOL（参见[[1]](#rc4e85fbd536b-1)第12.1.2段）。可能的值为
    0、1、2、3、4、5。将协议参数设置为负值等效于将其值设置为 HIGHEST_PROTOCOL。
- en: '[[1](#id1)]'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1](#id1)]'
- en: '[https://docs.python.org/3/library/pickle.html](https://docs.python.org/3/library/pickle.html).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.python.org/3/library/pickle.html](https://docs.python.org/3/library/pickle.html).'
- en: '**storage_options**dict, optional'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**storage_options**dict, optional'
- en: Extra options that make sense for a particular storage connection, e.g. host,
    port, username, password, etc. For HTTP(S) URLs the key-value pairs are forwarded
    to `urllib.request.Request` as header options. For other URLs (e.g. starting with
    “s3://”, and “gcs://”) the key-value pairs are forwarded to `fsspec.open`. Please
    see `fsspec` and `urllib` for more details, and for more examples on storage options
    refer [here](https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 特定存储连接的额外选项，例如主机、端口、用户名、密码等。对于 HTTP(S) URL，键值对将作为标头选项转发到`urllib.request.Request`。对于其他
    URL（例如以“s3://”和“gcs://”开头的 URL），键值对将转发到`fsspec.open`。请参阅`fsspec`和`urllib`获取更多详情，并参考[这里](https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files)中有关存储选项的更多示例。
- en: See also
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '[`read_pickle`](pandas.read_pickle.html#pandas.read_pickle "pandas.read_pickle")'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[`read_pickle`](pandas.read_pickle.html#pandas.read_pickle "pandas.read_pickle")'
- en: Load pickled pandas object (or any object) from file.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从文件中加载 pickle 的 pandas 对象（或任何对象）。
- en: '[`DataFrame.to_hdf`](pandas.DataFrame.to_hdf.html#pandas.DataFrame.to_hdf "pandas.DataFrame.to_hdf")'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[`DataFrame.to_hdf`](pandas.DataFrame.to_hdf.html#pandas.DataFrame.to_hdf "pandas.DataFrame.to_hdf")'
- en: Write DataFrame to an HDF5 file.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 将 DataFrame 写入 HDF5 文件。
- en: '[`DataFrame.to_sql`](pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql "pandas.DataFrame.to_sql")'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[`DataFrame.to_sql`](pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql "pandas.DataFrame.to_sql")'
- en: Write DataFrame to a SQL database.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 将 DataFrame 写入 SQL 数据库。
- en: '[`DataFrame.to_parquet`](pandas.DataFrame.to_parquet.html#pandas.DataFrame.to_parquet
    "pandas.DataFrame.to_parquet")'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[`DataFrame.to_parquet`](pandas.DataFrame.to_parquet.html#pandas.DataFrame.to_parquet
    "pandas.DataFrame.to_parquet")'
- en: Write a DataFrame to the binary parquet format.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 将 DataFrame 写入二进制 Parquet 格式。
- en: Examples
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
