- en: Object Detection Datasets Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`docs.ultralytics.com/datasets/detect/`](https://docs.ultralytics.com/datasets/detect/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Training a robust and accurate object detection model requires a comprehensive
    dataset. This guide introduces various formats of datasets that are compatible
    with the Ultralytics YOLO model and provides insights into their structure, usage,
    and how to convert between different formats.
  prefs: []
  type: TYPE_NORMAL
- en: Supported Dataset Formats
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ultralytics YOLO format
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Ultralytics YOLO format is a dataset configuration format that allows you
    to define the dataset root directory, the relative paths to training/validation/testing
    image directories or `*.txt` files containing image paths, and a dictionary of
    class names. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Labels for this format should be exported to YOLO format with one `*.txt` file
    per image. If there are no objects in an image, no `*.txt` file is required. The
    `*.txt` file should be formatted with one row per object in `class x_center y_center
    width height` format. Box coordinates must be in **normalized xywh** format (from
    0 to 1). If your boxes are in pixels, you should divide `x_center` and `width`
    by image width, and `y_center` and `height` by image height. Class numbers should
    be zero-indexed (start with 0).
  prefs: []
  type: TYPE_NORMAL
- en: '![Example labelled image](img/7862b814c7eb88586c58cc415aac0ee0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The label file corresponding to the above image contains 2 persons (class `0`)
    and a tie (class `27`):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Example label file](img/95161ff593802e8e1a7aee55e61c2d5a.png)'
  prefs: []
  type: TYPE_IMG
- en: When using the Ultralytics YOLO format, organize your training and validation
    images and labels as shown in the COCO8 dataset example below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Example dataset directory structure](img/52500aea9533986fdf1dd40e1efc0367.png)'
  prefs: []
  type: TYPE_IMG
- en: Usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here''s how you can use these formats to train your model:'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Supported Datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is a list of the supported datasets and a brief description for each:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Argoverse: A dataset containing 3D tracking and motion forecasting data from
    urban environments with rich annotations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'COCO: Common Objects in Context (COCO) is a large-scale object detection, segmentation,
    and captioning dataset with 80 object categories.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LVIS: A large-scale object detection, segmentation, and captioning dataset
    with 1203 object categories.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'COCO8: A smaller subset of the first 4 images from COCO train and COCO val,
    suitable for quick tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Global Wheat 2020: A dataset containing images of wheat heads for the Global
    Wheat Challenge 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Objects365: A high-quality, large-scale dataset for object detection with 365
    object categories and over 600K annotated images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OpenImagesV7: A comprehensive dataset by Google with 1.7M train images and
    42k validation images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SKU-110K: A dataset featuring dense object detection in retail environments
    with over 11K images and 1.7 million bounding boxes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'VisDrone: A dataset containing object detection and multi-object tracking data
    from drone-captured imagery with over 10K images and video sequences.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'VOC: The Pascal Visual Object Classes (VOC) dataset for object detection and
    segmentation with 20 object classes and over 11K images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'xView: A dataset for object detection in overhead imagery with 60 object categories
    and over 1 million annotated objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Roboflow 100: A diverse object detection benchmark with 100 datasets spanning
    seven imagery domains for comprehensive model evaluation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Brain-tumor: A dataset for detecting brain tumors includes MRI or CT scan images
    with details on tumor presence, location, and characteristics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'African-wildlife: A dataset featuring images of African wildlife, including
    buffalo, elephant, rhino, and zebras.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Signature: A dataset featuring images of various documents with annotated signatures,
    supporting document verification and fraud detection research.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding your own dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you have your own dataset and would like to use it for training detection
    models with Ultralytics YOLO format, ensure that it follows the format specified
    above under "Ultralytics YOLO format". Convert your annotations to the required
    format and specify the paths, number of classes, and class names in the YAML configuration
    file.
  prefs: []
  type: TYPE_NORMAL
- en: Port or Convert Label Formats
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: COCO Dataset Format to YOLO Format
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can easily convert labels from the popular COCO dataset format to the YOLO
    format using the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This conversion tool can be used to convert the COCO dataset or any dataset
    in the COCO format to the Ultralytics YOLO format.
  prefs: []
  type: TYPE_NORMAL
- en: Remember to double-check if the dataset you want to use is compatible with your
    model and follows the necessary format conventions. Properly formatted datasets
    are crucial for training successful object detection models.
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is the Ultralytics YOLO dataset format and how to structure it?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Ultralytics YOLO format is a structured configuration for defining datasets
    in your training projects. It involves setting paths to your training, validation,
    and testing images and corresponding labels. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Labels are saved in `*.txt` files with one file per image, formatted as `class
    x_center y_center width height` with normalized coordinates. For a detailed guide,
    see the COCO8 dataset example.
  prefs: []
  type: TYPE_NORMAL
- en: How do I convert a COCO dataset to the YOLO format?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can convert a COCO dataset to the YOLO format using the Ultralytics conversion
    tools. Here''s a quick method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This code will convert your COCO annotations to YOLO format, enabling seamless
    integration with Ultralytics YOLO models. For additional details, visit the Port
    or Convert Label Formats section.
  prefs: []
  type: TYPE_NORMAL
- en: Which datasets are supported by Ultralytics YOLO for object detection?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Ultralytics YOLO supports a wide range of datasets, including:'
  prefs: []
  type: TYPE_NORMAL
- en: Argoverse
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: COCO
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LVIS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: COCO8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Global Wheat 2020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Objects365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenImagesV7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each dataset page provides detailed information on the structure and usage tailored
    for efficient YOLOv8 training. Explore the full list in the Supported Datasets
    section.
  prefs: []
  type: TYPE_NORMAL
- en: How do I start training a YOLOv8 model using my dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To start training a YOLOv8 model, ensure your dataset is formatted correctly
    and the paths are defined in a YAML file. Use the following script to begin training:'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Refer to the Usage section for more details on utilizing different modes, including
    CLI commands.
  prefs: []
  type: TYPE_NORMAL
- en: Where can I find practical examples of using Ultralytics YOLO for object detection?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ultralytics provides numerous examples and practical guides for using YOLOv8
    in diverse applications. For a comprehensive overview, visit the [Ultralytics
    Blog](https://www.ultralytics.com/blog) where you can find case studies, detailed
    tutorials, and community stories showcasing object detection, segmentation, and
    more with YOLOv8\. For specific examples, check the Usage section in the documentation.
  prefs: []
  type: TYPE_NORMAL
