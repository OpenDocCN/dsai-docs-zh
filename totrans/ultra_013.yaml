- en: Image Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像分类
- en: 原文：[`docs.ultralytics.com/tasks/classify/`](https://docs.ultralytics.com/tasks/classify/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`docs.ultralytics.com/tasks/classify/`](https://docs.ultralytics.com/tasks/classify/)
- en: '![Image classification examples](img/d9a956cdec314a5204b6ea5e05fc9381.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![图像分类示例](img/d9a956cdec314a5204b6ea5e05fc9381.png)'
- en: Image classification is the simplest of the three tasks and involves classifying
    an entire image into one of a set of predefined classes.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类是三项任务中最简单的，它涉及将整个图像分类为预定义类别集中的一类。
- en: The output of an image classifier is a single class label and a confidence score.
    Image classification is useful when you need to know only what class an image
    belongs to and don't need to know where objects of that class are located or what
    their exact shape is.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类器的输出是一个类标签和置信度分数。当你只需知道图像属于哪个类别，而不需要知道该类别的对象在何处或其确切形状时，图像分类非常有用。
- en: '[`www.youtube.com/embed/5BO0Il_YYAg`](https://www.youtube.com/embed/5BO0Il_YYAg)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[`www.youtube.com/embed/5BO0Il_YYAg`](https://www.youtube.com/embed/5BO0Il_YYAg)'
- en: '**Watch:** Explore Ultralytics YOLO Tasks: Image Classification using Ultralytics
    HUB'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**观看：** 探索Ultralytics YOLO任务：使用Ultralytics HUB进行图像分类'
- en: Tip
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: YOLOv8 Classify models use the `-cls` suffix, i.e. `yolov8n-cls.pt` and are
    pretrained on [ImageNet](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/ImageNet.yaml).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv8分类模型使用`-cls`后缀，例如`yolov8n-cls.pt`，并且在[ImageNet](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/ImageNet.yaml)上进行了预训练。
- en: '[Models](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v8)'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[模型](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v8)'
- en: YOLOv8 pretrained Classify models are shown here. Detect, Segment and Pose models
    are pretrained on the [COCO](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml)
    dataset, while Classify models are pretrained on the [ImageNet](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/ImageNet.yaml)
    dataset.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv8预训练分类模型显示在此处。检测、分割和姿态模型是在[COCO](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml)数据集上预训练的，而分类模型是在[ImageNet](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/ImageNet.yaml)数据集上预训练的。
- en: '[Models](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models)
    download automatically from the latest Ultralytics [release](https://github.com/ultralytics/assets/releases)
    on first use.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[模型](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models)在第一次使用时会从最新的Ultralytics
    [发布](https://github.com/ultralytics/assets/releases)自动下载。'
- en: '| Model | size ^((pixels)) | acc ^(top1) | acc ^(top5) | Speed ^(CPU ONNX'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '| 模型 | 尺寸 ^(像素) | 准确率 ^(top1) | 准确率 ^(top5) | 速度 ^(CPU ONNX'
- en: (ms)) | Speed ^(A100 TensorRT
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: (毫秒)) | 速度 ^(A100 TensorRT
- en: (ms)) | params ^((M)) | FLOPs ^((B) at 640) |
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: (毫秒)) | 参数 ^((百万)) | FLOPs ^((十亿，以640为单位)) |
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| [YOLOv8n-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-cls.pt)
    | 224 | 69.0 | 88.3 | 12.9 | 0.31 | 2.7 | 4.3 |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8n-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-cls.pt)
    | 224 | 69.0 | 88.3 | 12.9 | 0.31 | 2.7 | 4.3 |'
- en: '| [YOLOv8s-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-cls.pt)
    | 224 | 73.8 | 91.7 | 23.4 | 0.35 | 6.4 | 13.5 |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8s-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s-cls.pt)
    | 224 | 73.8 | 91.7 | 23.4 | 0.35 | 6.4 | 13.5 |'
- en: '| [YOLOv8m-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-cls.pt)
    | 224 | 76.8 | 93.5 | 85.4 | 0.62 | 17.0 | 42.7 |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8m-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-cls.pt)
    | 224 | 76.8 | 93.5 | 85.4 | 0.62 | 17.0 | 42.7 |'
- en: '| [YOLOv8l-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-cls.pt)
    | 224 | 76.8 | 93.5 | 163.0 | 0.87 | 37.5 | 99.7 |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8l-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-cls.pt)
    | 224 | 76.8 | 93.5 | 163.0 | 0.87 | 37.5 | 99.7 |'
- en: '| [YOLOv8x-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-cls.pt)
    | 224 | 79.0 | 94.6 | 232.0 | 1.01 | 57.4 | 154.8 |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| [YOLOv8x-cls](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-cls.pt)
    | 224 | 79.0 | 94.6 | 232.0 | 1.01 | 57.4 | 154.8 |'
- en: '**acc** values are model accuracies on the [ImageNet](https://www.image-net.org/)
    dataset validation set.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确度**值是模型在[ImageNet](https://www.image-net.org/)数据集验证集上的准确性。'
- en: Reproduce by `yolo val classify data=path/to/ImageNet device=0`
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重现命令 `yolo val classify data=path/to/ImageNet device=0`
- en: '**Speed** averaged over ImageNet val images using an [Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/)
    instance.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度**是通过ImageNet验证图像在[Amazon EC2 P4d](https://aws.amazon.com/ec2/instance-types/p4/)实例上平均得出的。'
- en: Reproduce by `yolo val classify data=path/to/ImageNet batch=1 device=0|cpu`
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重现命令 `yolo val classify data=path/to/ImageNet batch=1 device=0|cpu`
- en: Train
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练
- en: Train YOLOv8n-cls on the MNIST160 dataset for 100 epochs at image size 64\.
    For a full list of available arguments see the Configuration page.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像大小为64的MNIST160数据集上训练YOLOv8n-cls 100个周期。有关所有可用参数的完整列表，请参阅配置页面。
- en: Example
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Dataset format
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集格式
- en: YOLO classification dataset format can be found in detail in the Dataset Guide.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO分类数据集格式的详细信息可在数据集指南中找到。
- en: Val
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证
- en: Validate trained YOLOv8n-cls model accuracy on the MNIST160 dataset. No argument
    need to passed as the `model` retains its training `data` and arguments as model
    attributes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在MNIST160数据集上验证训练好的YOLOv8n-cls模型准确性。作为模型保留其训练数据和参数属性，无需传递任何参数。
- en: Example
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Predict
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测
- en: Use a trained YOLOv8n-cls model to run predictions on images.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用训练好的YOLOv8n-cls模型对图像进行预测。
- en: Example
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: See full `predict` mode details in the Predict page.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 查看完整的预测模式细节，请参阅预测页面。
- en: Export
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导出
- en: Export a YOLOv8n-cls model to a different format like ONNX, CoreML, etc.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将YOLOv8n-cls模型导出为ONNX、CoreML等其他格式。
- en: Example
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Available YOLOv8-cls export formats are in the table below. You can export to
    any format using the `format` argument, i.e. `format='onnx'` or `format='engine'`.
    You can predict or validate directly on exported models, i.e. `yolo predict model=yolov8n-cls.onnx`.
    Usage examples are shown for your model after export completes.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的YOLOv8-cls导出格式如下表所示。您可以使用`format`参数导出到任何格式，例如`format='onnx'`或`format='engine'`。您可以直接在导出的模型上进行预测或验证，例如`yolo
    predict model=yolov8n-cls.onnx`。导出完成后，示例中将显示您模型的用法。
- en: '| Format | `format` Argument | Model | Metadata | Arguments |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 格式 | `format` 参数 | 模型 | 元数据 | 参数 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| [PyTorch](https://pytorch.org/) | - | `yolov8n-cls.pt` | ✅ | - |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| [PyTorch](https://pytorch.org/) | - | `yolov8n-cls.pt` | ✅ | - |'
- en: '| TorchScript | `torchscript` | `yolov8n-cls.torchscript` | ✅ | `imgsz`, `optimize`,
    `batch` |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| TorchScript | `torchscript` | `yolov8n-cls.torchscript` | ✅ | `imgsz`, `optimize`,
    `batch` |'
- en: '| ONNX | `onnx` | `yolov8n-cls.onnx` | ✅ | `imgsz`, `half`, `dynamic`, `simplify`,
    `opset`, `batch` |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| ONNX | `onnx` | `yolov8n-cls.onnx` | ✅ | `imgsz`, `half`, `dynamic`, `simplify`,
    `opset`, `batch` |'
- en: '| OpenVINO | `openvino` | `yolov8n-cls_openvino_model/` | ✅ | `imgsz`, `half`,
    `int8`, `batch`, `dynamic` |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| OpenVINO | `openvino` | `yolov8n-cls_openvino_model/` | ✅ | `imgsz`, `half`,
    `int8`, `batch`, `dynamic` |'
- en: '| TensorRT | `engine` | `yolov8n-cls.engine` | ✅ | `imgsz`, `half`, `dynamic`,
    `simplify`, `workspace`, `int8`, `batch` |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| TensorRT | `engine` | `yolov8n-cls.engine` | ✅ | `imgsz`, `half`, `dynamic`,
    `simplify`, `workspace`, `int8`, `batch` |'
- en: '| CoreML | `coreml` | `yolov8n-cls.mlpackage` | ✅ | `imgsz`, `half`, `int8`,
    `nms`, `batch` |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| CoreML | `coreml` | `yolov8n-cls.mlpackage` | ✅ | `imgsz`, `half`, `int8`,
    `nms`, `batch` |'
- en: '| TF SavedModel | `saved_model` | `yolov8n-cls_saved_model/` | ✅ | `imgsz`,
    `keras`, `int8`, `batch` |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| TF SavedModel | `saved_model` | `yolov8n-cls_saved_model/` | ✅ | `imgsz`,
    `keras`, `int8`, `batch` |'
- en: '| TF GraphDef | `pb` | `yolov8n-cls.pb` | ❌ | `imgsz`, `batch` |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| TF GraphDef | `pb` | `yolov8n-cls.pb` | ❌ | `imgsz`, `batch` |'
- en: '| TF Lite | `tflite` | `yolov8n-cls.tflite` | ✅ | `imgsz`, `half`, `int8`,
    `batch` |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| TF Lite | `tflite` | `yolov8n-cls.tflite` | ✅ | `imgsz`, `half`, `int8`,
    `batch` |'
- en: '| TF Edge TPU | `edgetpu` | `yolov8n-cls_edgetpu.tflite` | ✅ | `imgsz` |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| TF Edge TPU | `edgetpu` | `yolov8n-cls_edgetpu.tflite` | ✅ | `imgsz` |'
- en: '| TF.js | `tfjs` | `yolov8n-cls_web_model/` | ✅ | `imgsz`, `half`, `int8`,
    `batch` |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| TF.js | `tfjs` | `yolov8n-cls_web_model/` | ✅ | `imgsz`, `half`, `int8`,
    `batch` |'
- en: '| PaddlePaddle | `paddle` | `yolov8n-cls_paddle_model/` | ✅ | `imgsz`, `batch`
    |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| PaddlePaddle | `paddle` | `yolov8n-cls_paddle_model/` | ✅ | `imgsz`, `batch`
    |'
- en: '| NCNN | `ncnn` | `yolov8n-cls_ncnn_model/` | ✅ | `imgsz`, `half`, `batch`
    |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| NCNN | `ncnn` | `yolov8n-cls_ncnn_model/` | ✅ | `imgsz`, `half`, `batch`
    |'
- en: See full `export` details in the Export page.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 查看完整的导出细节，请参阅导出页面。
- en: FAQ
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题解答
- en: What is the purpose of YOLOv8 in image classification?
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: YOLOv8在图像分类中的目的是什么？
- en: YOLOv8 models, such as `yolov8n-cls.pt`, are designed for efficient image classification.
    They assign a single class label to an entire image along with a confidence score.
    This is particularly useful for applications where knowing the specific class
    of an image is sufficient, rather than identifying the location or shape of objects
    within the image.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv8模型（例如`yolov8n-cls.pt`）专为高效的图像分类而设计。它们为整个图像分配单一类别标签，并提供置信度分数。对于仅需知道图像具体类别而无需识别其位置或形状的应用程序，这非常有用。
- en: How do I train a YOLOv8 model for image classification?
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何训练YOLOv8模型进行图像分类？
- en: 'To train a YOLOv8 model, you can use either Python or CLI commands. For example,
    to train a `yolov8n-cls` model on the MNIST160 dataset for 100 epochs at an image
    size of 64:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用Python或CLI命令训练YOLOv8模型。例如，对于图像大小为64的MNIST160数据集，可以在100个周期内训练`yolov8n-cls`模型：
- en: Example
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For more configuration options, visit the Configuration page.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多配置选项，请访问配置页面。
- en: Where can I find pretrained YOLOv8 classification models?
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我可以在哪里找到预训练的YOLOv8分类模型？
- en: Pretrained YOLOv8 classification models can be found in the [Models](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v8)
    section. Models like `yolov8n-cls.pt`, `yolov8s-cls.pt`, `yolov8m-cls.pt`, etc.,
    are pretrained on the [ImageNet](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/ImageNet.yaml)
    dataset and can be easily downloaded and used for various image classification
    tasks.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练的YOLOv8分类模型可以在[模型](https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v8)部分找到。像`yolov8n-cls.pt`、`yolov8s-cls.pt`、`yolov8m-cls.pt`等模型，都是在[ImageNet](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/ImageNet.yaml)数据集上进行了预训练，可以轻松下载并用于各种图像分类任务。
- en: How can I export a trained YOLOv8 model to different formats?
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何将训练好的YOLOv8模型导出到不同的格式？
- en: 'You can export a trained YOLOv8 model to various formats using Python or CLI
    commands. For instance, to export a model to ONNX format:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用Python或CLI命令将训练好的YOLOv8模型导出到各种格式。例如，要将模型导出为ONNX格式：
- en: Example
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: For detailed export options, refer to the Export page.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解详细的导出选项，请参考导出页面。
- en: How do I validate a trained YOLOv8 classification model?
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我如何验证训练好的YOLOv8分类模型？
- en: 'To validate a trained model''s accuracy on a dataset like MNIST160, you can
    use the following Python or CLI commands:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证训练好的模型在类似MNIST160的数据集上的准确性，可以使用以下Python或CLI命令：
- en: Example
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: For more information, visit the Validate section.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多信息，请访问验证部分。
